{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a637f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from glove.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06280f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MS014_processed_mono.csv',\n",
       " 'MS001_processed_mono.csv',\n",
       " 'MS008_processed_mono.csv',\n",
       " 'DSM_processed_mono.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import file names\n",
    "files = os.listdir(\"data/\")\n",
    "files = [f for f in files if \"processed_mono.csv\" in f]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66f683",
   "metadata": {},
   "source": [
    "# fit gLV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af71ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 70, Updated regularization: 1.00e-03\n",
      "Loss: 10.997, Residuals: -0.322\n",
      "Loss: 4.880, Residuals: -0.060\n",
      "Loss: 2.807, Residuals: 0.006\n",
      "Loss: 2.578, Residuals: -0.011\n",
      "Loss: 2.173, Residuals: -0.006\n",
      "Loss: 2.004, Residuals: 0.019\n",
      "Loss: 1.733, Residuals: 0.012\n",
      "Loss: 1.637, Residuals: 0.012\n",
      "Loss: 1.508, Residuals: 0.001\n",
      "Loss: 1.498, Residuals: 0.014\n",
      "Loss: 1.481, Residuals: 0.012\n",
      "Loss: 1.450, Residuals: 0.006\n",
      "Loss: 1.414, Residuals: -0.001\n",
      "Loss: 1.410, Residuals: 0.002\n",
      "Loss: 1.403, Residuals: -0.000\n",
      "Loss: 1.399, Residuals: 0.000\n",
      "Loss: 1.393, Residuals: -0.002\n",
      "Loss: 1.383, Residuals: -0.007\n",
      "Loss: 1.383, Residuals: -0.006\n",
      "Loss: 1.376, Residuals: -0.010\n",
      "Loss: 1.376, Residuals: -0.009\n",
      "Loss: 1.373, Residuals: -0.011\n",
      "Loss: 1.368, Residuals: -0.015\n",
      "Loss: 1.368, Residuals: -0.015\n",
      "Loss: 1.367, Residuals: -0.015\n",
      "Loss: 1.364, Residuals: -0.017\n",
      "Loss: 1.364, Residuals: -0.016\n",
      "Loss: 1.361, Residuals: -0.017\n",
      "Loss: 1.358, Residuals: -0.019\n",
      "Loss: 1.358, Residuals: -0.019\n",
      "Loss: 1.358, Residuals: -0.019\n",
      "Loss: 1.357, Residuals: -0.019\n",
      "Loss: 1.357, Residuals: -0.019\n",
      "Loss: 1.357, Residuals: -0.019\n",
      "Loss: 1.357, Residuals: -0.019\n",
      "Loss: 1.357, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Loss: 1.356, Residuals: -0.019\n",
      "Evidence -236.320\n",
      "Updating hyper-parameters...\n",
      "Total samples: 70, Updated regularization: 2.90e-02\n",
      "Loss: 13.258, Residuals: -0.010\n",
      "Loss: 13.169, Residuals: -0.012\n",
      "Loss: 13.146, Residuals: -0.009\n",
      "Loss: 13.111, Residuals: -0.007\n",
      "Loss: 13.093, Residuals: -0.002\n",
      "Loss: 13.088, Residuals: -0.004\n",
      "Loss: 13.087, Residuals: -0.004\n",
      "Loss: 13.086, Residuals: -0.003\n",
      "Loss: 13.083, Residuals: -0.003\n",
      "Loss: 13.079, Residuals: -0.003\n",
      "Loss: 13.079, Residuals: -0.003\n",
      "Evidence 459.389\n",
      "Updating hyper-parameters...\n",
      "Total samples: 70, Updated regularization: 2.02e-01\n",
      "Loss: 72.792, Residuals: -0.002\n",
      "Loss: 72.665, Residuals: -0.001\n",
      "Loss: 72.640, Residuals: -0.004\n",
      "Loss: 72.617, Residuals: -0.003\n",
      "Loss: 72.579, Residuals: -0.003\n",
      "Loss: 72.514, Residuals: -0.003\n",
      "Loss: 72.511, Residuals: -0.002\n",
      "Evidence 930.433\n",
      "Updating hyper-parameters...\n",
      "Total samples: 70, Updated regularization: 7.13e-01\n",
      "Loss: 192.987, Residuals: -0.005\n",
      "Loss: 192.262, Residuals: -0.005\n",
      "Loss: 191.972, Residuals: -0.007\n",
      "Loss: 191.873, Residuals: -0.007\n",
      "Loss: 191.695, Residuals: -0.007\n",
      "Loss: 191.428, Residuals: -0.008\n",
      "Loss: 190.972, Residuals: -0.008\n",
      "Loss: 190.946, Residuals: -0.007\n",
      "Evidence 1124.165\n",
      "Updating hyper-parameters...\n",
      "Total samples: 70, Updated regularization: 1.12e+00\n",
      "Loss: 257.481, Residuals: -0.007\n",
      "Loss: 257.045, Residuals: -0.011\n",
      "Loss: 256.557, Residuals: -0.012\n",
      "Loss: 256.195, Residuals: -0.011\n",
      "Loss: 256.122, Residuals: -0.011\n",
      "Loss: 256.102, Residuals: -0.012\n",
      "Loss: 255.910, Residuals: -0.012\n",
      "Loss: 255.592, Residuals: -0.012\n",
      "Loss: 255.583, Residuals: -0.012\n",
      "Evidence 1153.257\n",
      "Updating hyper-parameters...\n",
      "Total samples: 70, Updated regularization: 1.33e+00\n",
      "Loss: 271.706, Residuals: -0.011\n",
      "Loss: 271.448, Residuals: -0.012\n",
      "Loss: 271.206, Residuals: -0.013\n",
      "Loss: 270.912, Residuals: -0.013\n",
      "Loss: 270.901, Residuals: -0.013\n",
      "Evidence 1157.829\n",
      "Updating hyper-parameters...\n",
      "Total samples: 70, Updated regularization: 1.44e+00\n",
      "Loss: 274.839, Residuals: -0.012\n",
      "Evidence 1159.297\n",
      "Updating hyper-parameters...\n",
      "Total samples: 70, Updated regularization: 1.46e+00\n",
      "Loss: 276.038, Residuals: -0.013\n",
      "Loss: 276.019, Residuals: -0.013\n",
      "Loss: 275.853, Residuals: -0.013\n",
      "Loss: 275.852, Residuals: -0.013\n",
      "Evidence 1159.940\n",
      "Pass count  1\n",
      "Total samples: 74, Updated regularization: 1.00e-03\n",
      "Loss: 11.846, Residuals: -0.331\n",
      "Loss: 5.657, Residuals: -0.029\n",
      "Loss: 5.300, Residuals: -0.053\n",
      "Loss: 4.640, Residuals: -0.044\n",
      "Loss: 3.469, Residuals: -0.018\n",
      "Loss: 2.680, Residuals: 0.009\n",
      "Loss: 2.342, Residuals: 0.012\n",
      "Loss: 2.177, Residuals: 0.031\n",
      "Loss: 2.095, Residuals: 0.047\n",
      "Loss: 1.962, Residuals: 0.037\n",
      "Loss: 1.944, Residuals: 0.041\n",
      "Loss: 1.911, Residuals: 0.036\n",
      "Loss: 1.853, Residuals: 0.027\n",
      "Loss: 1.826, Residuals: 0.025\n",
      "Loss: 1.781, Residuals: 0.018\n",
      "Loss: 1.724, Residuals: 0.006\n",
      "Loss: 1.722, Residuals: 0.008\n",
      "Loss: 1.719, Residuals: 0.008\n",
      "Loss: 1.715, Residuals: 0.006\n",
      "Loss: 1.708, Residuals: 0.003\n",
      "Loss: 1.705, Residuals: 0.001\n",
      "Loss: 1.700, Residuals: -0.001\n",
      "Loss: 1.699, Residuals: -0.000\n",
      "Loss: 1.693, Residuals: -0.005\n",
      "Loss: 1.693, Residuals: -0.004\n",
      "Loss: 1.692, Residuals: -0.005\n",
      "Loss: 1.689, Residuals: -0.008\n",
      "Loss: 1.688, Residuals: -0.009\n",
      "Loss: 1.687, Residuals: -0.010\n",
      "Loss: 1.686, Residuals: -0.011\n",
      "Loss: 1.685, Residuals: -0.012\n",
      "Loss: 1.684, Residuals: -0.012\n",
      "Loss: 1.683, Residuals: -0.013\n",
      "Loss: 1.683, Residuals: -0.013\n",
      "Loss: 1.682, Residuals: -0.014\n",
      "Loss: 1.680, Residuals: -0.015\n",
      "Loss: 1.680, Residuals: -0.016\n",
      "Loss: 1.680, Residuals: -0.016\n",
      "Loss: 1.680, Residuals: -0.016\n",
      "Loss: 1.680, Residuals: -0.017\n",
      "Loss: 1.680, Residuals: -0.017\n",
      "Loss: 1.679, Residuals: -0.017\n",
      "Loss: 1.679, Residuals: -0.018\n",
      "Loss: 1.679, Residuals: -0.018\n",
      "Loss: 1.679, Residuals: -0.018\n",
      "Loss: 1.679, Residuals: -0.018\n",
      "Loss: 1.679, Residuals: -0.018\n",
      "Loss: 1.679, Residuals: -0.018\n",
      "Loss: 1.679, Residuals: -0.019\n",
      "Loss: 1.679, Residuals: -0.019\n",
      "Loss: 1.679, Residuals: -0.019\n",
      "Loss: 1.679, Residuals: -0.019\n",
      "Loss: 1.679, Residuals: -0.019\n",
      "Loss: 1.679, Residuals: -0.019\n",
      "Loss: 1.679, Residuals: -0.019\n",
      "Loss: 1.679, Residuals: -0.019\n",
      "Loss: 1.679, Residuals: -0.020\n",
      "Loss: 1.679, Residuals: -0.020\n",
      "Loss: 1.679, Residuals: -0.020\n",
      "Loss: 1.679, Residuals: -0.020\n",
      "Loss: 1.678, Residuals: -0.020\n",
      "Loss: 1.678, Residuals: -0.020\n",
      "Loss: 1.677, Residuals: -0.021\n",
      "Loss: 1.675, Residuals: -0.019\n",
      "Loss: 1.675, Residuals: -0.018\n",
      "Loss: 1.673, Residuals: -0.018\n",
      "Loss: 1.670, Residuals: -0.019\n",
      "Loss: 1.669, Residuals: -0.021\n",
      "Loss: 1.665, Residuals: -0.021\n",
      "Loss: 1.665, Residuals: -0.021\n",
      "Loss: 1.662, Residuals: -0.021\n",
      "Loss: 1.661, Residuals: -0.021\n",
      "Loss: 1.660, Residuals: -0.022\n",
      "Loss: 1.657, Residuals: -0.022\n",
      "Loss: 1.657, Residuals: -0.022\n",
      "Loss: 1.655, Residuals: -0.022\n",
      "Loss: 1.653, Residuals: -0.022\n",
      "Loss: 1.653, Residuals: -0.022\n",
      "Loss: 1.653, Residuals: -0.022\n",
      "Loss: 1.652, Residuals: -0.022\n",
      "Loss: 1.652, Residuals: -0.022\n",
      "Loss: 1.652, Residuals: -0.022\n",
      "Loss: 1.651, Residuals: -0.022\n",
      "Loss: 1.651, Residuals: -0.022\n",
      "Loss: 1.651, Residuals: -0.022\n",
      "Loss: 1.651, Residuals: -0.022\n",
      "Loss: 1.651, Residuals: -0.022\n",
      "Loss: 1.651, Residuals: -0.022\n",
      "Loss: 1.651, Residuals: -0.022\n",
      "Loss: 1.651, Residuals: -0.022\n",
      "Evidence -241.145\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 1.96e-02\n",
      "Loss: 16.561, Residuals: -0.019\n",
      "Loss: 16.500, Residuals: -0.014\n",
      "Loss: 16.433, Residuals: -0.010\n",
      "Loss: 16.422, Residuals: -0.006\n",
      "Loss: 16.405, Residuals: -0.006\n",
      "Loss: 16.379, Residuals: -0.005\n",
      "Loss: 16.377, Residuals: -0.004\n",
      "Loss: 16.360, Residuals: -0.003\n",
      "Loss: 16.346, Residuals: -0.000\n",
      "Loss: 16.345, Residuals: -0.001\n",
      "Loss: 16.334, Residuals: -0.001\n",
      "Loss: 16.316, Residuals: -0.001\n",
      "Loss: 16.315, Residuals: -0.001\n",
      "Evidence 522.115\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 4.63e-02\n",
      "Loss: 92.576, Residuals: 0.006\n",
      "Evidence 1013.908\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 1.20e-01\n",
      "Loss: 223.034, Residuals: -0.002\n",
      "Loss: 222.273, Residuals: -0.002\n",
      "Loss: 221.663, Residuals: -0.006\n",
      "Loss: 221.302, Residuals: -0.006\n",
      "Loss: 221.251, Residuals: -0.005\n",
      "Loss: 221.205, Residuals: -0.007\n",
      "Loss: 221.127, Residuals: -0.007\n",
      "Loss: 221.048, Residuals: -0.007\n",
      "Loss: 221.041, Residuals: -0.007\n",
      "Evidence 1182.148\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 2.08e-01\n",
      "Loss: 278.173, Residuals: -0.002\n",
      "Loss: 277.587, Residuals: -0.011\n",
      "Loss: 277.337, Residuals: -0.013\n",
      "Loss: 277.248, Residuals: -0.013\n",
      "Loss: 277.220, Residuals: -0.013\n",
      "Loss: 277.172, Residuals: -0.013\n",
      "Loss: 277.091, Residuals: -0.013\n",
      "Loss: 277.087, Residuals: -0.013\n",
      "Evidence 1206.124\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 2.72e-01\n",
      "Loss: 289.837, Residuals: -0.013\n",
      "Loss: 289.681, Residuals: -0.014\n",
      "Loss: 289.543, Residuals: -0.017\n",
      "Loss: 289.442, Residuals: -0.017\n",
      "Loss: 289.429, Residuals: -0.017\n",
      "Loss: 289.403, Residuals: -0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 289.358, Residuals: -0.017\n",
      "Loss: 289.356, Residuals: -0.017\n",
      "Evidence 1210.471\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 3.10e-01\n",
      "Loss: 292.606, Residuals: -0.016\n",
      "Evidence 1211.842\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 3.32e-01\n",
      "Loss: 293.912, Residuals: -0.017\n",
      "Loss: 293.795, Residuals: -0.018\n",
      "Loss: 293.751, Residuals: -0.019\n",
      "Loss: 293.696, Residuals: -0.019\n",
      "Loss: 293.693, Residuals: -0.019\n",
      "Evidence 1212.560\n",
      "Pass count  1\n",
      "Total samples: 74, Updated regularization: 1.00e-03\n",
      "Loss: 11.577, Residuals: -0.318\n",
      "Loss: 5.552, Residuals: -0.068\n",
      "Loss: 3.295, Residuals: 0.011\n",
      "Loss: 2.925, Residuals: -0.027\n",
      "Loss: 2.636, Residuals: 0.013\n",
      "Loss: 2.241, Residuals: -0.011\n",
      "Loss: 2.056, Residuals: 0.000\n",
      "Loss: 2.016, Residuals: 0.005\n",
      "Loss: 1.981, Residuals: -0.006\n",
      "Loss: 1.923, Residuals: -0.009\n",
      "Loss: 1.848, Residuals: -0.015\n",
      "Loss: 1.843, Residuals: -0.005\n",
      "Loss: 1.834, Residuals: -0.008\n",
      "Loss: 1.818, Residuals: -0.014\n",
      "Loss: 1.816, Residuals: -0.019\n",
      "Loss: 1.811, Residuals: -0.021\n",
      "Loss: 1.803, Residuals: -0.024\n",
      "Loss: 1.802, Residuals: -0.023\n",
      "Loss: 1.798, Residuals: -0.025\n",
      "Loss: 1.793, Residuals: -0.028\n",
      "Loss: 1.792, Residuals: -0.027\n",
      "Loss: 1.789, Residuals: -0.029\n",
      "Loss: 1.784, Residuals: -0.032\n",
      "Loss: 1.783, Residuals: -0.033\n",
      "Loss: 1.782, Residuals: -0.033\n",
      "Loss: 1.779, Residuals: -0.035\n",
      "Loss: 1.778, Residuals: -0.035\n",
      "Loss: 1.771, Residuals: -0.039\n",
      "Loss: 1.771, Residuals: -0.038\n",
      "Loss: 1.770, Residuals: -0.038\n",
      "Loss: 1.768, Residuals: -0.039\n",
      "Loss: 1.758, Residuals: -0.042\n",
      "Loss: 1.752, Residuals: -0.044\n",
      "Loss: 1.751, Residuals: -0.046\n",
      "Loss: 1.749, Residuals: -0.045\n",
      "Loss: 1.746, Residuals: -0.046\n",
      "Loss: 1.746, Residuals: -0.044\n",
      "Loss: 1.745, Residuals: -0.045\n",
      "Loss: 1.743, Residuals: -0.045\n",
      "Loss: 1.743, Residuals: -0.047\n",
      "Loss: 1.740, Residuals: -0.047\n",
      "Loss: 1.736, Residuals: -0.047\n",
      "Loss: 1.736, Residuals: -0.047\n",
      "Loss: 1.736, Residuals: -0.048\n",
      "Loss: 1.734, Residuals: -0.048\n",
      "Loss: 1.734, Residuals: -0.048\n",
      "Loss: 1.732, Residuals: -0.049\n",
      "Loss: 1.731, Residuals: -0.049\n",
      "Loss: 1.730, Residuals: -0.049\n",
      "Loss: 1.730, Residuals: -0.050\n",
      "Loss: 1.729, Residuals: -0.050\n",
      "Loss: 1.729, Residuals: -0.051\n",
      "Loss: 1.729, Residuals: -0.050\n",
      "Loss: 1.728, Residuals: -0.050\n",
      "Loss: 1.728, Residuals: -0.051\n",
      "Loss: 1.728, Residuals: -0.051\n",
      "Loss: 1.728, Residuals: -0.051\n",
      "Loss: 1.727, Residuals: -0.051\n",
      "Loss: 1.727, Residuals: -0.051\n",
      "Loss: 1.727, Residuals: -0.051\n",
      "Loss: 1.727, Residuals: -0.051\n",
      "Loss: 1.727, Residuals: -0.051\n",
      "Loss: 1.727, Residuals: -0.051\n",
      "Loss: 1.727, Residuals: -0.051\n",
      "Loss: 1.727, Residuals: -0.051\n",
      "Loss: 1.727, Residuals: -0.052\n",
      "Loss: 1.727, Residuals: -0.052\n",
      "Loss: 1.727, Residuals: -0.052\n",
      "Evidence -239.301\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 2.01e-02\n",
      "Loss: 17.178, Residuals: -0.045\n",
      "Loss: 17.081, Residuals: -0.035\n",
      "Loss: 16.959, Residuals: -0.035\n",
      "Loss: 16.931, Residuals: -0.030\n",
      "Loss: 16.886, Residuals: -0.028\n",
      "Loss: 16.882, Residuals: -0.028\n",
      "Loss: 16.875, Residuals: -0.028\n",
      "Loss: 16.863, Residuals: -0.027\n",
      "Loss: 16.850, Residuals: -0.024\n",
      "Loss: 16.849, Residuals: -0.024\n",
      "Evidence 512.327\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 6.33e-02\n",
      "Loss: 95.869, Residuals: -0.021\n",
      "Loss: 95.583, Residuals: -0.021\n",
      "Loss: 95.442, Residuals: -0.023\n",
      "Loss: 95.413, Residuals: -0.022\n",
      "Loss: 95.366, Residuals: -0.022\n",
      "Loss: 95.315, Residuals: -0.022\n",
      "Loss: 95.310, Residuals: -0.022\n",
      "Evidence 990.312\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 1.79e-01\n",
      "Loss: 226.369, Residuals: -0.019\n",
      "Evidence 1142.660\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 3.25e-01\n",
      "Loss: 277.410, Residuals: -0.023\n",
      "Loss: 276.726, Residuals: -0.024\n",
      "Loss: 276.591, Residuals: -0.026\n",
      "Loss: 276.382, Residuals: -0.026\n",
      "Loss: 276.213, Residuals: -0.026\n",
      "Loss: 276.200, Residuals: -0.026\n",
      "Evidence 1161.068\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 3.87e-01\n",
      "Loss: 287.768, Residuals: -0.026\n",
      "Evidence 1164.484\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 4.19e-01\n",
      "Loss: 290.583, Residuals: -0.028\n",
      "Loss: 290.418, Residuals: -0.029\n",
      "Loss: 290.290, Residuals: -0.028\n",
      "Loss: 290.261, Residuals: -0.029\n",
      "Loss: 290.252, Residuals: -0.029\n",
      "Loss: 290.237, Residuals: -0.029\n",
      "Loss: 290.235, Residuals: -0.029\n",
      "Evidence 1165.792\n",
      "Updating hyper-parameters...\n",
      "Total samples: 74, Updated regularization: 4.31e-01\n",
      "Loss: 290.968, Residuals: -0.029\n",
      "Evidence 1166.512\n",
      "Pass count  1\n",
      "Total samples: 72, Updated regularization: 1.00e-03\n",
      "Loss: 12.522, Residuals: -0.322\n",
      "Loss: 5.964, Residuals: -0.058\n",
      "Loss: 4.180, Residuals: -0.020\n",
      "Loss: 3.450, Residuals: 0.059\n",
      "Loss: 2.885, Residuals: 0.033\n",
      "Loss: 2.459, Residuals: 0.017\n",
      "Loss: 2.349, Residuals: 0.021\n",
      "Loss: 2.163, Residuals: 0.016\n",
      "Loss: 2.064, Residuals: 0.016\n",
      "Loss: 2.026, Residuals: 0.033\n",
      "Loss: 1.964, Residuals: 0.018\n",
      "Loss: 1.884, Residuals: -0.006\n",
      "Loss: 1.881, Residuals: -0.004\n",
      "Loss: 1.877, Residuals: -0.005\n",
      "Loss: 1.869, Residuals: -0.007\n",
      "Loss: 1.855, Residuals: -0.010\n",
      "Loss: 1.829, Residuals: -0.015\n",
      "Loss: 1.822, Residuals: -0.013\n",
      "Loss: 1.821, Residuals: -0.013\n",
      "Loss: 1.811, Residuals: -0.015\n",
      "Loss: 1.793, Residuals: -0.021\n",
      "Loss: 1.793, Residuals: -0.019\n",
      "Loss: 1.783, Residuals: -0.022\n",
      "Loss: 1.781, Residuals: -0.023\n",
      "Loss: 1.780, Residuals: -0.021\n",
      "Loss: 1.771, Residuals: -0.024\n",
      "Loss: 1.771, Residuals: -0.024\n",
      "Loss: 1.769, Residuals: -0.025\n",
      "Loss: 1.764, Residuals: -0.027\n",
      "Loss: 1.763, Residuals: -0.028\n",
      "Loss: 1.762, Residuals: -0.028\n",
      "Loss: 1.760, Residuals: -0.029\n",
      "Loss: 1.755, Residuals: -0.031\n",
      "Loss: 1.755, Residuals: -0.031\n",
      "Loss: 1.754, Residuals: -0.031\n",
      "Loss: 1.748, Residuals: -0.034\n",
      "Loss: 1.745, Residuals: -0.035\n",
      "Loss: 1.743, Residuals: -0.035\n",
      "Loss: 1.738, Residuals: -0.037\n",
      "Loss: 1.738, Residuals: -0.037\n",
      "Loss: 1.725, Residuals: -0.037\n",
      "Loss: 1.725, Residuals: -0.037\n",
      "Loss: 1.720, Residuals: -0.037\n",
      "Loss: 1.717, Residuals: -0.037\n",
      "Loss: 1.711, Residuals: -0.037\n",
      "Loss: 1.706, Residuals: -0.037\n",
      "Loss: 1.697, Residuals: -0.037\n",
      "Loss: 1.695, Residuals: -0.036\n",
      "Loss: 1.692, Residuals: -0.037\n",
      "Loss: 1.686, Residuals: -0.038\n",
      "Loss: 1.686, Residuals: -0.037\n",
      "Loss: 1.682, Residuals: -0.038\n",
      "Loss: 1.675, Residuals: -0.038\n",
      "Loss: 1.675, Residuals: -0.037\n",
      "Loss: 1.675, Residuals: -0.037\n",
      "Loss: 1.671, Residuals: -0.038\n",
      "Loss: 1.670, Residuals: -0.038\n",
      "Loss: 1.670, Residuals: -0.038\n",
      "Loss: 1.667, Residuals: -0.038\n",
      "Loss: 1.667, Residuals: -0.038\n",
      "Loss: 1.667, Residuals: -0.038\n",
      "Loss: 1.665, Residuals: -0.038\n",
      "Loss: 1.664, Residuals: -0.038\n",
      "Loss: 1.663, Residuals: -0.038\n",
      "Loss: 1.662, Residuals: -0.038\n",
      "Loss: 1.662, Residuals: -0.038\n",
      "Loss: 1.661, Residuals: -0.038\n",
      "Loss: 1.661, Residuals: -0.038\n",
      "Loss: 1.661, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Loss: 1.660, Residuals: -0.038\n",
      "Evidence -241.747\n",
      "Updating hyper-parameters...\n",
      "Total samples: 72, Updated regularization: 1.70e-02\n",
      "Loss: 16.617, Residuals: -0.018\n",
      "Loss: 16.465, Residuals: -0.029\n",
      "Loss: 16.391, Residuals: -0.027\n",
      "Loss: 16.370, Residuals: -0.020\n",
      "Loss: 16.339, Residuals: -0.020\n",
      "Loss: 16.299, Residuals: -0.017\n",
      "Loss: 16.258, Residuals: -0.015\n",
      "Loss: 16.257, Residuals: -0.016\n",
      "Evidence 500.489\n",
      "Updating hyper-parameters...\n",
      "Total samples: 72, Updated regularization: 4.39e-02\n",
      "Loss: 92.823, Residuals: -0.014\n",
      "Loss: 92.457, Residuals: -0.013\n",
      "Loss: 92.196, Residuals: -0.013\n",
      "Loss: 92.120, Residuals: -0.014\n",
      "Loss: 92.013, Residuals: -0.015\n",
      "Loss: 91.999, Residuals: -0.015\n",
      "Loss: 91.971, Residuals: -0.015\n",
      "Loss: 91.924, Residuals: -0.015\n",
      "Loss: 91.859, Residuals: -0.015\n",
      "Loss: 91.857, Residuals: -0.015\n",
      "Evidence 969.883\n",
      "Updating hyper-parameters...\n",
      "Total samples: 72, Updated regularization: 1.15e-01\n",
      "Loss: 222.476, Residuals: -0.014\n",
      "Loss: 222.166, Residuals: -0.015\n",
      "Loss: 221.977, Residuals: -0.017\n",
      "Loss: 221.929, Residuals: -0.017\n",
      "Loss: 221.911, Residuals: -0.017\n",
      "Loss: 221.880, Residuals: -0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 221.838, Residuals: -0.018\n",
      "Loss: 221.472, Residuals: -0.018\n",
      "Loss: 221.465, Residuals: -0.018\n",
      "Evidence 1121.542\n",
      "Updating hyper-parameters...\n",
      "Total samples: 72, Updated regularization: 1.68e-01\n",
      "Loss: 274.795, Residuals: -0.018\n",
      "Loss: 274.680, Residuals: -0.020\n",
      "Loss: 274.550, Residuals: -0.021\n",
      "Loss: 274.533, Residuals: -0.020\n",
      "Loss: 274.507, Residuals: -0.020\n",
      "Loss: 274.503, Residuals: -0.021\n",
      "Evidence 1136.162\n",
      "Updating hyper-parameters...\n",
      "Total samples: 72, Updated regularization: 2.06e-01\n",
      "Loss: 284.374, Residuals: -0.021\n",
      "Loss: 284.233, Residuals: -0.022\n",
      "Loss: 284.205, Residuals: -0.022\n",
      "Loss: 284.165, Residuals: -0.022\n",
      "Loss: 284.163, Residuals: -0.022\n",
      "Evidence 1138.072\n",
      "Updating hyper-parameters...\n",
      "Total samples: 72, Updated regularization: 2.26e-01\n",
      "Loss: 286.051, Residuals: -0.023\n",
      "Evidence 1138.843\n",
      "Pass count  1\n"
     ]
    }
   ],
   "source": [
    "exp_names = []\n",
    "for file in files:\n",
    "    # import data\n",
    "    df = pd.read_csv(f\"data/{file}\")\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "\n",
    "    # instantiate gLV fit \n",
    "    model = gLV(species, df)\n",
    "\n",
    "    # fit to data \n",
    "    model.fit()\n",
    "    \n",
    "    # list of parameter names \n",
    "    param_names = []\n",
    "    for s1 in species:\n",
    "        for s2 in species:\n",
    "            param_names += [s1+\"*\"+s2]\n",
    "    param_names = list(species) + param_names\n",
    "    \n",
    "    # plot parameter distribution\n",
    "    n_species = len(species)\n",
    "    Avec = model.params[n_species:]\n",
    "    Aij_std = np.sqrt(np.diag(model.Ainv))[n_species:]\n",
    "\n",
    "    plt.figure(figsize=(18,18))\n",
    "    # set counter for parameter std. \n",
    "    k = 0\n",
    "\n",
    "    for i in range(n_species):\n",
    "        for j in range(n_species):\n",
    "            plt.subplot(n_species, n_species, k+1)\n",
    "            a = np.linspace(Avec[k]-np.std(Avec), Avec[k]+np.std(Avec))\n",
    "            plt.plot(a, norm.pdf(a,Avec[k],Aij_std[k]))\n",
    "            plt.axvline(x=0, c='k', alpha=.5)\n",
    "            k += 1\n",
    "            if j == 0:\n",
    "                plt.ylabel(species[i], fontsize=18)\n",
    "            if i == n_species-1:\n",
    "                plt.xlabel(species[j], fontsize=18)\n",
    "            #plt.xlim([-2,2])\n",
    "\n",
    "    plt.suptitle(file.split(\"_\")[0], fontsize=24)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(\"figures/\"+file.split(\"_\")[0]+\".pdf\")\n",
    "    plt.close()\n",
    "    \n",
    "    # compute Wald test for each parameter\n",
    "    std_errors = np.sqrt(np.diag(model.Ainv))\n",
    "    walds = model.params/std_errors\n",
    "    wald_p_vals = 2*norm.cdf(-np.abs(walds))\n",
    "\n",
    "    # save to df \n",
    "    df = pd.DataFrame()\n",
    "    df[\"Param name\"] = param_names\n",
    "    df[\"Param value\"] = model.params\n",
    "    df[\"Param stdv\"]  = np.sqrt(np.diag(model.Ainv))\n",
    "    df[\"Param p-value\"] = wald_p_vals\n",
    "    for j, param_name in enumerate(param_names):\n",
    "        df[param_name]  = model.Ainv[:, j]\n",
    "    df.to_csv(\"params/\"+file.split(\"_\")[0]+\".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
