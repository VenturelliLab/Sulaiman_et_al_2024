{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a637f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-gt7dqk3f because the default path (/home/jaron/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm, linregress\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from glove.mse_model import *\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06280f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXP0019_MS001_processed.csv',\n",
       " 'EXP0019_DSM27147_processed.csv',\n",
       " 'EXP0019_MS008_processed.csv',\n",
       " 'EXP0019_MS014_processed.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import file names\n",
    "files = os.listdir(\"data/\")\n",
    "files = [f for f in files if \"processed\" in f]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66f683",
   "metadata": {},
   "source": [
    "# Function to make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104c6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(model, df, species):\n",
    "    \n",
    "    # save measured and predicted values\n",
    "    pred_species = []\n",
    "    pred = []\n",
    "    stdv = []\n",
    "    true = []\n",
    "\n",
    "    # pull just the community data\n",
    "    test_data = process_df(df, species) \n",
    "\n",
    "    # plot the results\n",
    "    for exp, t_span, Y_m in test_data:\n",
    "\n",
    "        # increase evaluation time\n",
    "        t_eval = np.linspace(t_span[0], t_span[-1])\n",
    "\n",
    "        # predict \n",
    "        Y_p, Y_std = model.predict(Y_m, t_eval)\n",
    "        \n",
    "        # set NaN to zero\n",
    "        Y_p = np.nan_to_num(Y_p)\n",
    "        Y_std = np.nan_to_num(Y_std)\n",
    "\n",
    "        ### append only end-point prediction results for non-zero outcomes ###\n",
    "        inds_pos = Y_m[-1,:] > 0 \n",
    "        pred_species.append(np.array(species)[inds_pos])\n",
    "        true.append(Y_m[-1,:][inds_pos])\n",
    "        pred.append(Y_p[-1,:][inds_pos])\n",
    "        stdv.append(Y_std[-1,:][inds_pos])\n",
    "        \n",
    "    # concatenate list\n",
    "    pred_species = np.concatenate(pred_species)\n",
    "    true = np.concatenate(true)\n",
    "    pred = np.concatenate(pred)\n",
    "    stdv = np.concatenate(stdv)\n",
    "        \n",
    "    return pred_species, true, pred, stdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1147f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.990, Residuals: -0.038\n",
      "Loss: 7.596, Residuals: -0.014\n",
      "Loss: 6.262, Residuals: -0.011\n",
      "Loss: 4.589, Residuals: -0.027\n",
      "Loss: 4.539, Residuals: -0.005\n",
      "Loss: 4.114, Residuals: -0.019\n",
      "Loss: 3.994, Residuals: 0.054\n",
      "Loss: 3.780, Residuals: 0.028\n",
      "Loss: 3.640, Residuals: -0.006\n",
      "Loss: 3.614, Residuals: 0.035\n",
      "Loss: 3.421, Residuals: -0.005\n",
      "Loss: 3.418, Residuals: -0.008\n",
      "Loss: 3.297, Residuals: -0.026\n",
      "Loss: 3.252, Residuals: -0.021\n",
      "Loss: 3.173, Residuals: -0.030\n",
      "Loss: 3.122, Residuals: -0.040\n",
      "Loss: 3.120, Residuals: -0.041\n",
      "Loss: 3.054, Residuals: -0.051\n",
      "Loss: 2.960, Residuals: -0.059\n",
      "Loss: 2.957, Residuals: -0.057\n",
      "Loss: 2.941, Residuals: -0.056\n",
      "Loss: 2.937, Residuals: -0.046\n",
      "Loss: 2.905, Residuals: -0.053\n",
      "Loss: 2.903, Residuals: -0.051\n",
      "Loss: 2.892, Residuals: -0.054\n",
      "Loss: 2.872, Residuals: -0.059\n",
      "Loss: 2.868, Residuals: -0.059\n",
      "Loss: 2.863, Residuals: -0.060\n",
      "Loss: 2.854, Residuals: -0.063\n",
      "Loss: 2.837, Residuals: -0.068\n",
      "Loss: 2.836, Residuals: -0.067\n",
      "Loss: 2.834, Residuals: -0.068\n",
      "Loss: 2.815, Residuals: -0.072\n",
      "Loss: 2.812, Residuals: -0.070\n",
      "Loss: 2.811, Residuals: -0.072\n",
      "Loss: 2.801, Residuals: -0.075\n",
      "Loss: 2.801, Residuals: -0.075\n",
      "Loss: 2.781, Residuals: -0.080\n",
      "Loss: 2.781, Residuals: -0.079\n",
      "Loss: 2.781, Residuals: -0.079\n",
      "Loss: 2.774, Residuals: -0.079\n",
      "Loss: 2.761, Residuals: -0.078\n",
      "Loss: 2.761, Residuals: -0.078\n",
      "Loss: 2.753, Residuals: -0.080\n",
      "Loss: 2.739, Residuals: -0.083\n",
      "Loss: 2.738, Residuals: -0.079\n",
      "Loss: 2.738, Residuals: -0.081\n",
      "Loss: 2.708, Residuals: -0.085\n",
      "Loss: 2.705, Residuals: -0.087\n",
      "Loss: 2.705, Residuals: -0.086\n",
      "Evidence -394.805\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.94e-03\n",
      "Loss: 12.739, Residuals: -0.047\n",
      "Loss: 12.734, Residuals: -0.048\n",
      "Loss: 12.726, Residuals: -0.048\n",
      "Loss: 12.712, Residuals: -0.049\n",
      "Loss: 12.688, Residuals: -0.053\n",
      "Loss: 12.645, Residuals: -0.054\n",
      "Loss: 12.575, Residuals: -0.054\n",
      "Loss: 12.453, Residuals: -0.049\n",
      "Loss: 12.453, Residuals: -0.049\n",
      "Evidence 93.174\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.90e-02\n",
      "Loss: 41.565, Residuals: -0.049\n",
      "Evidence 282.442\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.71e-01\n",
      "Loss: 87.059, Residuals: -0.050\n",
      "Loss: 86.123, Residuals: -0.051\n",
      "Loss: 84.712, Residuals: -0.051\n",
      "Loss: 84.708, Residuals: -0.051\n",
      "Evidence 385.188\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.36e-01\n",
      "Loss: 124.388, Residuals: -0.052\n",
      "Loss: 124.134, Residuals: -0.053\n",
      "Loss: 123.691, Residuals: -0.056\n",
      "Loss: 122.901, Residuals: -0.057\n",
      "Loss: 121.781, Residuals: -0.054\n",
      "Loss: 121.666, Residuals: -0.060\n",
      "Loss: 120.564, Residuals: -0.057\n",
      "Loss: 120.545, Residuals: -0.052\n",
      "Loss: 119.000, Residuals: -0.049\n",
      "Loss: 118.940, Residuals: -0.050\n",
      "Loss: 118.891, Residuals: -0.050\n",
      "Loss: 118.475, Residuals: -0.048\n",
      "Loss: 118.422, Residuals: -0.045\n",
      "Loss: 117.941, Residuals: -0.043\n",
      "Loss: 117.940, Residuals: -0.043\n",
      "Evidence 421.396\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.99e-01\n",
      "Loss: 139.932, Residuals: -0.044\n",
      "Loss: 139.855, Residuals: -0.045\n",
      "Loss: 139.208, Residuals: -0.046\n",
      "Loss: 138.150, Residuals: -0.041\n",
      "Loss: 138.123, Residuals: -0.041\n",
      "Loss: 138.082, Residuals: -0.042\n",
      "Loss: 137.688, Residuals: -0.041\n",
      "Loss: 136.982, Residuals: -0.038\n",
      "Loss: 136.683, Residuals: -0.037\n",
      "Loss: 136.622, Residuals: -0.033\n",
      "Loss: 136.071, Residuals: -0.031\n",
      "Loss: 136.047, Residuals: -0.032\n",
      "Loss: 135.202, Residuals: -0.027\n",
      "Loss: 135.152, Residuals: -0.032\n",
      "Loss: 135.137, Residuals: -0.029\n",
      "Loss: 135.131, Residuals: -0.028\n",
      "Loss: 135.129, Residuals: -0.029\n",
      "Loss: 134.695, Residuals: -0.028\n",
      "Loss: 134.654, Residuals: -0.028\n",
      "Loss: 134.581, Residuals: -0.026\n",
      "Loss: 134.478, Residuals: -0.024\n",
      "Loss: 134.459, Residuals: -0.022\n",
      "Loss: 133.723, Residuals: -0.023\n",
      "Loss: 133.555, Residuals: -0.029\n",
      "Loss: 133.532, Residuals: -0.028\n",
      "Loss: 133.313, Residuals: -0.027\n",
      "Loss: 133.301, Residuals: -0.028\n",
      "Loss: 132.881, Residuals: -0.027\n",
      "Loss: 132.836, Residuals: -0.028\n",
      "Loss: 132.486, Residuals: -0.027\n",
      "Loss: 132.462, Residuals: -0.029\n",
      "Loss: 132.275, Residuals: -0.028\n",
      "Loss: 132.255, Residuals: -0.027\n",
      "Loss: 132.225, Residuals: -0.027\n",
      "Loss: 132.176, Residuals: -0.027\n",
      "Loss: 132.171, Residuals: -0.027\n",
      "Loss: 132.161, Residuals: -0.027\n",
      "Loss: 132.144, Residuals: -0.027\n",
      "Loss: 132.141, Residuals: -0.026\n",
      "Loss: 132.123, Residuals: -0.026\n",
      "Loss: 132.122, Residuals: -0.026\n",
      "Loss: 132.119, Residuals: -0.026\n",
      "Loss: 132.116, Residuals: -0.026\n",
      "Loss: 132.116, Residuals: -0.026\n",
      "Loss: 132.115, Residuals: -0.026\n",
      "Loss: 132.112, Residuals: -0.026\n",
      "Loss: 132.112, Residuals: -0.026\n",
      "Loss: 132.110, Residuals: -0.026\n",
      "Loss: 132.110, Residuals: -0.026\n",
      "Loss: 132.110, Residuals: -0.026\n",
      "Loss: 132.109, Residuals: -0.026\n",
      "Evidence 435.831\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.08e+00\n",
      "Loss: 142.640, Residuals: -0.017\n",
      "Loss: 142.380, Residuals: -0.018\n",
      "Loss: 142.037, Residuals: -0.013\n",
      "Loss: 142.011, Residuals: -0.013\n",
      "Loss: 141.962, Residuals: -0.014\n",
      "Loss: 141.890, Residuals: -0.014\n",
      "Loss: 141.846, Residuals: -0.014\n",
      "Loss: 141.843, Residuals: -0.014\n",
      "Loss: 141.841, Residuals: -0.015\n",
      "Loss: 141.837, Residuals: -0.015\n",
      "Loss: 141.831, Residuals: -0.015\n",
      "Loss: 141.822, Residuals: -0.015\n",
      "Loss: 141.821, Residuals: -0.015\n",
      "Loss: 141.817, Residuals: -0.015\n",
      "Loss: 141.813, Residuals: -0.014\n",
      "Loss: 141.813, Residuals: -0.014\n",
      "Loss: 141.812, Residuals: -0.014\n",
      "Evidence 448.641\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.37e+00\n",
      "Loss: 147.235, Residuals: -0.009\n",
      "Loss: 147.149, Residuals: -0.012\n",
      "Loss: 147.122, Residuals: -0.009\n",
      "Loss: 147.076, Residuals: -0.010\n",
      "Loss: 147.029, Residuals: -0.010\n",
      "Loss: 147.025, Residuals: -0.010\n",
      "Loss: 147.018, Residuals: -0.010\n",
      "Loss: 147.018, Residuals: -0.011\n",
      "Loss: 147.014, Residuals: -0.011\n",
      "Loss: 147.008, Residuals: -0.011\n",
      "Loss: 147.008, Residuals: -0.011\n",
      "Loss: 147.007, Residuals: -0.011\n",
      "Loss: 147.006, Residuals: -0.010\n",
      "Loss: 147.006, Residuals: -0.010\n",
      "Loss: 147.005, Residuals: -0.010\n",
      "Loss: 147.005, Residuals: -0.010\n",
      "Loss: 147.005, Residuals: -0.010\n",
      "Evidence 452.171\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.50e+00\n",
      "Loss: 149.318, Residuals: -0.007\n",
      "Loss: 149.250, Residuals: -0.009\n",
      "Loss: 149.217, Residuals: -0.009\n",
      "Loss: 149.211, Residuals: -0.009\n",
      "Loss: 149.204, Residuals: -0.009\n",
      "Loss: 149.204, Residuals: -0.009\n",
      "Loss: 149.202, Residuals: -0.009\n",
      "Loss: 149.201, Residuals: -0.009\n",
      "Loss: 149.200, Residuals: -0.009\n",
      "Loss: 149.199, Residuals: -0.009\n",
      "Loss: 149.198, Residuals: -0.009\n",
      "Loss: 149.198, Residuals: -0.009\n",
      "Evidence 453.739\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.54e+00\n",
      "Loss: 150.211, Residuals: -0.006\n",
      "Loss: 150.165, Residuals: -0.008\n",
      "Loss: 150.159, Residuals: -0.007\n",
      "Loss: 150.148, Residuals: -0.007\n",
      "Loss: 150.141, Residuals: -0.008\n",
      "Loss: 150.140, Residuals: -0.008\n",
      "Loss: 150.139, Residuals: -0.008\n",
      "Loss: 150.137, Residuals: -0.008\n",
      "Loss: 150.137, Residuals: -0.008\n",
      "Loss: 150.137, Residuals: -0.008\n",
      "Loss: 150.137, Residuals: -0.008\n",
      "Loss: 150.137, Residuals: -0.008\n",
      "Evidence 454.698\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.54e+00\n",
      "Loss: 150.643, Residuals: -0.006\n",
      "Loss: 150.612, Residuals: -0.007\n",
      "Loss: 150.608, Residuals: -0.007\n",
      "Loss: 150.601, Residuals: -0.007\n",
      "Loss: 150.595, Residuals: -0.008\n",
      "Loss: 150.594, Residuals: -0.008\n",
      "Loss: 150.594, Residuals: -0.008\n",
      "Loss: 150.593, Residuals: -0.008\n",
      "Loss: 150.592, Residuals: -0.008\n",
      "Loss: 150.592, Residuals: -0.008\n",
      "Loss: 150.592, Residuals: -0.008\n",
      "Loss: 150.592, Residuals: -0.008\n",
      "Evidence 455.368\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.53e+00\n",
      "Loss: 150.884, Residuals: -0.006\n",
      "Loss: 150.864, Residuals: -0.008\n",
      "Loss: 150.860, Residuals: -0.007\n",
      "Loss: 150.855, Residuals: -0.007\n",
      "Loss: 150.850, Residuals: -0.008\n",
      "Loss: 150.850, Residuals: -0.008\n",
      "Loss: 150.849, Residuals: -0.008\n",
      "Loss: 150.848, Residuals: -0.008\n",
      "Loss: 150.848, Residuals: -0.008\n",
      "Loss: 150.848, Residuals: -0.008\n",
      "Loss: 150.848, Residuals: -0.008\n",
      "Loss: 150.848, Residuals: -0.008\n",
      "Evidence 455.879\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.51e+00\n",
      "Loss: 151.041, Residuals: -0.007\n",
      "Loss: 151.025, Residuals: -0.008\n",
      "Loss: 151.020, Residuals: -0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 151.018, Residuals: -0.008\n",
      "Loss: 151.017, Residuals: -0.007\n",
      "Loss: 151.016, Residuals: -0.007\n",
      "Loss: 151.014, Residuals: -0.008\n",
      "Loss: 151.014, Residuals: -0.008\n",
      "Loss: 151.014, Residuals: -0.008\n",
      "Loss: 151.013, Residuals: -0.008\n",
      "Loss: 151.013, Residuals: -0.008\n",
      "Loss: 151.013, Residuals: -0.008\n",
      "Loss: 151.013, Residuals: -0.008\n",
      "Loss: 151.013, Residuals: -0.008\n",
      "Loss: 151.013, Residuals: -0.008\n",
      "Evidence 456.307\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.737, Residuals: -0.055\n",
      "Loss: 7.220, Residuals: -0.047\n",
      "Loss: 5.856, Residuals: -0.042\n",
      "Loss: 4.613, Residuals: -0.014\n",
      "Loss: 4.505, Residuals: 0.080\n",
      "Loss: 4.303, Residuals: 0.057\n",
      "Loss: 3.944, Residuals: 0.026\n",
      "Loss: 3.759, Residuals: 0.039\n",
      "Loss: 3.661, Residuals: 0.017\n",
      "Loss: 3.483, Residuals: 0.004\n",
      "Loss: 3.244, Residuals: -0.017\n",
      "Loss: 3.235, Residuals: -0.022\n",
      "Loss: 3.219, Residuals: -0.023\n",
      "Loss: 3.190, Residuals: -0.020\n",
      "Loss: 3.138, Residuals: -0.028\n",
      "Loss: 3.048, Residuals: -0.040\n",
      "Loss: 3.038, Residuals: -0.013\n",
      "Loss: 2.960, Residuals: -0.026\n",
      "Loss: 2.923, Residuals: -0.030\n",
      "Loss: 2.922, Residuals: -0.025\n",
      "Loss: 2.861, Residuals: -0.037\n",
      "Loss: 2.841, Residuals: -0.039\n",
      "Loss: 2.840, Residuals: -0.039\n",
      "Loss: 2.803, Residuals: -0.047\n",
      "Loss: 2.803, Residuals: -0.048\n",
      "Loss: 2.777, Residuals: -0.052\n",
      "Loss: 2.768, Residuals: -0.038\n",
      "Loss: 2.767, Residuals: -0.042\n",
      "Loss: 2.719, Residuals: -0.052\n",
      "Loss: 2.718, Residuals: -0.049\n",
      "Loss: 2.715, Residuals: -0.049\n",
      "Loss: 2.711, Residuals: -0.048\n",
      "Loss: 2.711, Residuals: -0.048\n",
      "Evidence -412.364\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.97e-02\n",
      "Loss: 13.177, Residuals: -0.031\n",
      "Loss: 13.162, Residuals: -0.035\n",
      "Loss: 13.029, Residuals: -0.028\n",
      "Loss: 12.898, Residuals: -0.005\n",
      "Loss: 12.892, Residuals: -0.007\n",
      "Loss: 12.881, Residuals: -0.006\n",
      "Loss: 12.866, Residuals: -0.003\n",
      "Loss: 12.840, Residuals: -0.001\n",
      "Loss: 12.803, Residuals: 0.003\n",
      "Loss: 12.802, Residuals: 0.002\n",
      "Loss: 12.792, Residuals: 0.003\n",
      "Loss: 12.787, Residuals: 0.005\n",
      "Loss: 12.779, Residuals: 0.005\n",
      "Loss: 12.778, Residuals: 0.005\n",
      "Loss: 12.774, Residuals: 0.005\n",
      "Loss: 12.772, Residuals: 0.005\n",
      "Loss: 12.769, Residuals: 0.005\n",
      "Loss: 12.764, Residuals: 0.005\n",
      "Loss: 12.763, Residuals: 0.005\n",
      "Loss: 12.763, Residuals: 0.005\n",
      "Loss: 12.763, Residuals: 0.005\n",
      "Loss: 12.763, Residuals: 0.006\n",
      "Loss: 12.762, Residuals: 0.006\n",
      "Loss: 12.762, Residuals: 0.006\n",
      "Loss: 12.761, Residuals: 0.005\n",
      "Loss: 12.761, Residuals: 0.005\n",
      "Evidence 96.397\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.60e-01\n",
      "Loss: 41.460, Residuals: 0.004\n",
      "Loss: 41.363, Residuals: 0.003\n",
      "Loss: 41.208, Residuals: 0.004\n",
      "Loss: 41.068, Residuals: 0.010\n",
      "Loss: 41.054, Residuals: 0.015\n",
      "Loss: 41.029, Residuals: 0.015\n",
      "Loss: 40.984, Residuals: 0.015\n",
      "Loss: 40.910, Residuals: 0.015\n",
      "Loss: 40.900, Residuals: 0.013\n",
      "Loss: 40.819, Residuals: 0.014\n",
      "Loss: 40.811, Residuals: 0.014\n",
      "Loss: 40.795, Residuals: 0.014\n",
      "Loss: 40.768, Residuals: 0.014\n",
      "Loss: 40.760, Residuals: 0.015\n",
      "Loss: 40.748, Residuals: 0.015\n",
      "Loss: 40.728, Residuals: 0.015\n",
      "Loss: 40.724, Residuals: 0.014\n",
      "Loss: 40.722, Residuals: 0.014\n",
      "Loss: 40.719, Residuals: 0.014\n",
      "Loss: 40.719, Residuals: 0.014\n",
      "Loss: 40.716, Residuals: 0.014\n",
      "Loss: 40.713, Residuals: 0.014\n",
      "Loss: 40.712, Residuals: 0.014\n",
      "Loss: 40.711, Residuals: 0.014\n",
      "Loss: 40.711, Residuals: 0.014\n",
      "Loss: 40.711, Residuals: 0.014\n",
      "Loss: 40.710, Residuals: 0.014\n",
      "Loss: 40.710, Residuals: 0.014\n",
      "Loss: 40.710, Residuals: 0.014\n",
      "Loss: 40.709, Residuals: 0.014\n",
      "Loss: 40.709, Residuals: 0.014\n",
      "Loss: 40.709, Residuals: 0.014\n",
      "Loss: 40.709, Residuals: 0.014\n",
      "Loss: 40.709, Residuals: 0.014\n",
      "Loss: 40.708, Residuals: 0.014\n",
      "Loss: 40.708, Residuals: 0.014\n",
      "Loss: 40.708, Residuals: 0.014\n",
      "Loss: 40.708, Residuals: 0.014\n",
      "Loss: 40.708, Residuals: 0.014\n",
      "Loss: 40.708, Residuals: 0.014\n",
      "Evidence 284.986\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 5.67e-01\n",
      "Loss: 82.657, Residuals: 0.017\n",
      "Loss: 82.351, Residuals: 0.007\n",
      "Loss: 82.168, Residuals: 0.002\n",
      "Loss: 82.138, Residuals: 0.007\n",
      "Loss: 82.083, Residuals: 0.006\n",
      "Loss: 81.995, Residuals: 0.005\n",
      "Loss: 81.940, Residuals: 0.004\n",
      "Loss: 81.937, Residuals: 0.005\n",
      "Loss: 81.933, Residuals: 0.004\n",
      "Loss: 81.928, Residuals: 0.003\n",
      "Loss: 81.918, Residuals: 0.003\n",
      "Loss: 81.918, Residuals: 0.003\n",
      "Loss: 81.883, Residuals: 0.004\n",
      "Loss: 81.881, Residuals: 0.003\n",
      "Loss: 81.880, Residuals: 0.004\n",
      "Loss: 81.841, Residuals: 0.004\n",
      "Loss: 81.839, Residuals: 0.004\n",
      "Loss: 81.837, Residuals: 0.003\n",
      "Loss: 81.834, Residuals: 0.003\n",
      "Loss: 81.809, Residuals: 0.003\n",
      "Loss: 81.807, Residuals: 0.003\n",
      "Loss: 81.805, Residuals: 0.004\n",
      "Loss: 81.729, Residuals: 0.003\n",
      "Loss: 81.710, Residuals: 0.004\n",
      "Loss: 81.690, Residuals: 0.004\n",
      "Loss: 81.686, Residuals: 0.005\n",
      "Loss: 81.525, Residuals: 0.004\n",
      "Loss: 81.516, Residuals: 0.006\n",
      "Loss: 81.503, Residuals: 0.004\n",
      "Loss: 81.477, Residuals: 0.004\n",
      "Loss: 81.433, Residuals: 0.004\n",
      "Loss: 81.426, Residuals: 0.004\n",
      "Loss: 81.414, Residuals: 0.004\n",
      "Loss: 81.393, Residuals: 0.003\n",
      "Loss: 81.374, Residuals: 0.004\n",
      "Loss: 81.372, Residuals: 0.003\n",
      "Loss: 81.372, Residuals: 0.003\n",
      "Loss: 81.371, Residuals: 0.003\n",
      "Loss: 81.371, Residuals: 0.003\n",
      "Loss: 81.371, Residuals: 0.003\n",
      "Loss: 81.370, Residuals: 0.004\n",
      "Evidence 396.601\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.33e+00\n",
      "Loss: 119.033, Residuals: 0.008\n",
      "Loss: 118.723, Residuals: -0.003\n",
      "Loss: 118.518, Residuals: -0.005\n",
      "Loss: 118.432, Residuals: -0.004\n",
      "Loss: 118.391, Residuals: -0.004\n",
      "Loss: 118.380, Residuals: -0.005\n",
      "Loss: 118.366, Residuals: -0.005\n",
      "Loss: 118.360, Residuals: -0.003\n",
      "Loss: 118.348, Residuals: -0.004\n",
      "Loss: 118.331, Residuals: -0.004\n",
      "Loss: 118.330, Residuals: -0.004\n",
      "Loss: 118.328, Residuals: -0.004\n",
      "Loss: 118.325, Residuals: -0.004\n",
      "Loss: 118.324, Residuals: -0.004\n",
      "Loss: 118.323, Residuals: -0.004\n",
      "Loss: 118.322, Residuals: -0.004\n",
      "Loss: 118.320, Residuals: -0.004\n",
      "Loss: 118.320, Residuals: -0.004\n",
      "Loss: 118.320, Residuals: -0.004\n",
      "Loss: 118.320, Residuals: -0.004\n",
      "Loss: 118.320, Residuals: -0.004\n",
      "Loss: 118.320, Residuals: -0.004\n",
      "Loss: 118.320, Residuals: -0.004\n",
      "Loss: 118.320, Residuals: -0.004\n",
      "Loss: 118.320, Residuals: -0.004\n",
      "Evidence 439.892\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.75e+00\n",
      "Loss: 139.130, Residuals: 0.004\n",
      "Loss: 138.957, Residuals: -0.005\n",
      "Loss: 138.830, Residuals: -0.007\n",
      "Loss: 138.798, Residuals: -0.006\n",
      "Loss: 138.784, Residuals: -0.005\n",
      "Loss: 138.761, Residuals: -0.006\n",
      "Loss: 138.738, Residuals: -0.007\n",
      "Loss: 138.738, Residuals: -0.007\n",
      "Loss: 138.737, Residuals: -0.007\n",
      "Loss: 138.736, Residuals: -0.007\n",
      "Loss: 138.735, Residuals: -0.007\n",
      "Loss: 138.735, Residuals: -0.007\n",
      "Loss: 138.735, Residuals: -0.007\n",
      "Loss: 138.735, Residuals: -0.007\n",
      "Loss: 138.735, Residuals: -0.007\n",
      "Loss: 138.734, Residuals: -0.007\n",
      "Loss: 138.734, Residuals: -0.007\n",
      "Loss: 138.734, Residuals: -0.007\n",
      "Loss: 138.734, Residuals: -0.007\n",
      "Evidence 451.646\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.85e+00\n",
      "Loss: 146.578, Residuals: -0.002\n",
      "Loss: 146.486, Residuals: -0.008\n",
      "Loss: 146.382, Residuals: -0.008\n",
      "Loss: 146.375, Residuals: -0.008\n",
      "Loss: 146.364, Residuals: -0.008\n",
      "Loss: 146.360, Residuals: -0.009\n",
      "Loss: 146.354, Residuals: -0.009\n",
      "Loss: 146.354, Residuals: -0.009\n",
      "Loss: 146.353, Residuals: -0.009\n",
      "Loss: 146.352, Residuals: -0.009\n",
      "Loss: 146.350, Residuals: -0.010\n",
      "Loss: 146.350, Residuals: -0.010\n",
      "Loss: 146.350, Residuals: -0.010\n",
      "Loss: 146.349, Residuals: -0.010\n",
      "Loss: 146.349, Residuals: -0.010\n",
      "Evidence 455.411\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.85e+00\n",
      "Loss: 149.056, Residuals: -0.006\n",
      "Loss: 148.959, Residuals: -0.011\n",
      "Loss: 148.938, Residuals: -0.009\n",
      "Loss: 148.906, Residuals: -0.009\n",
      "Loss: 148.893, Residuals: -0.010\n",
      "Loss: 148.892, Residuals: -0.010\n",
      "Loss: 148.888, Residuals: -0.011\n",
      "Loss: 148.883, Residuals: -0.012\n",
      "Loss: 148.882, Residuals: -0.011\n",
      "Loss: 148.882, Residuals: -0.011\n",
      "Loss: 148.882, Residuals: -0.012\n",
      "Loss: 148.882, Residuals: -0.012\n",
      "Loss: 148.882, Residuals: -0.012\n",
      "Loss: 148.882, Residuals: -0.012\n",
      "Evidence 457.442\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.81e+00\n",
      "Loss: 149.934, Residuals: -0.008\n",
      "Loss: 149.847, Residuals: -0.012\n",
      "Loss: 149.829, Residuals: -0.010\n",
      "Loss: 149.802, Residuals: -0.011\n",
      "Loss: 149.790, Residuals: -0.012\n",
      "Loss: 149.788, Residuals: -0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 149.787, Residuals: -0.011\n",
      "Loss: 149.780, Residuals: -0.012\n",
      "Loss: 149.776, Residuals: -0.013\n",
      "Loss: 149.776, Residuals: -0.013\n",
      "Loss: 149.775, Residuals: -0.013\n",
      "Loss: 149.775, Residuals: -0.013\n",
      "Loss: 149.775, Residuals: -0.013\n",
      "Evidence 458.940\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.75e+00\n",
      "Loss: 150.270, Residuals: -0.010\n",
      "Loss: 150.212, Residuals: -0.014\n",
      "Loss: 150.188, Residuals: -0.011\n",
      "Loss: 150.181, Residuals: -0.013\n",
      "Loss: 150.171, Residuals: -0.013\n",
      "Loss: 150.162, Residuals: -0.013\n",
      "Loss: 150.160, Residuals: -0.014\n",
      "Loss: 150.159, Residuals: -0.014\n",
      "Loss: 150.159, Residuals: -0.013\n",
      "Loss: 150.158, Residuals: -0.013\n",
      "Loss: 150.158, Residuals: -0.014\n",
      "Loss: 150.158, Residuals: -0.014\n",
      "Loss: 150.158, Residuals: -0.014\n",
      "Loss: 150.158, Residuals: -0.014\n",
      "Loss: 150.158, Residuals: -0.014\n",
      "Evidence 460.120\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.69e+00\n",
      "Loss: 150.491, Residuals: -0.011\n",
      "Loss: 150.462, Residuals: -0.014\n",
      "Loss: 150.447, Residuals: -0.013\n",
      "Loss: 150.445, Residuals: -0.013\n",
      "Loss: 150.444, Residuals: -0.012\n",
      "Loss: 150.442, Residuals: -0.012\n",
      "Loss: 150.439, Residuals: -0.013\n",
      "Loss: 150.436, Residuals: -0.014\n",
      "Loss: 150.436, Residuals: -0.014\n",
      "Loss: 150.436, Residuals: -0.014\n",
      "Loss: 150.435, Residuals: -0.014\n",
      "Loss: 150.435, Residuals: -0.014\n",
      "Loss: 150.435, Residuals: -0.014\n",
      "Loss: 150.435, Residuals: -0.014\n",
      "Loss: 150.435, Residuals: -0.014\n",
      "Evidence 460.973\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.64e+00\n",
      "Loss: 150.710, Residuals: -0.012\n",
      "Loss: 150.703, Residuals: -0.014\n",
      "Loss: 150.696, Residuals: -0.013\n",
      "Loss: 150.694, Residuals: -0.013\n",
      "Loss: 150.692, Residuals: -0.013\n",
      "Loss: 150.689, Residuals: -0.013\n",
      "Evidence 461.528\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.61e+00\n",
      "Loss: 150.914, Residuals: -0.011\n",
      "Loss: 150.904, Residuals: -0.013\n",
      "Loss: 150.900, Residuals: -0.012\n",
      "Loss: 150.899, Residuals: -0.013\n",
      "Loss: 150.897, Residuals: -0.012\n",
      "Loss: 150.895, Residuals: -0.013\n",
      "Loss: 150.895, Residuals: -0.013\n",
      "Loss: 150.895, Residuals: -0.013\n",
      "Loss: 150.895, Residuals: -0.013\n",
      "Loss: 150.895, Residuals: -0.013\n",
      "Loss: 150.895, Residuals: -0.013\n",
      "Loss: 150.895, Residuals: -0.013\n",
      "Evidence 461.941\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.377, Residuals: -0.044\n",
      "Loss: 7.684, Residuals: -0.051\n",
      "Loss: 4.991, Residuals: -0.034\n",
      "Loss: 4.713, Residuals: 0.085\n",
      "Loss: 4.250, Residuals: 0.036\n",
      "Loss: 4.059, Residuals: 0.035\n",
      "Loss: 3.738, Residuals: 0.012\n",
      "Loss: 3.723, Residuals: 0.023\n",
      "Loss: 3.586, Residuals: 0.007\n",
      "Loss: 3.391, Residuals: -0.031\n",
      "Loss: 3.384, Residuals: -0.024\n",
      "Loss: 3.326, Residuals: -0.037\n",
      "Loss: 3.224, Residuals: -0.048\n",
      "Loss: 3.185, Residuals: -0.034\n",
      "Loss: 3.118, Residuals: -0.042\n",
      "Loss: 3.031, Residuals: -0.056\n",
      "Loss: 3.028, Residuals: -0.053\n",
      "Loss: 3.025, Residuals: -0.052\n",
      "Loss: 3.018, Residuals: -0.051\n",
      "Loss: 3.006, Residuals: -0.053\n",
      "Loss: 2.997, Residuals: -0.052\n",
      "Loss: 2.980, Residuals: -0.055\n",
      "Loss: 2.962, Residuals: -0.057\n",
      "Loss: 2.961, Residuals: -0.059\n",
      "Loss: 2.961, Residuals: -0.058\n",
      "Loss: 2.933, Residuals: -0.064\n",
      "Loss: 2.932, Residuals: -0.056\n",
      "Loss: 2.918, Residuals: -0.060\n",
      "Loss: 2.893, Residuals: -0.067\n",
      "Loss: 2.887, Residuals: -0.069\n",
      "Loss: 2.886, Residuals: -0.071\n",
      "Loss: 2.886, Residuals: -0.070\n",
      "Loss: 2.885, Residuals: -0.068\n",
      "Loss: 2.868, Residuals: -0.071\n",
      "Loss: 2.867, Residuals: -0.068\n",
      "Loss: 2.846, Residuals: -0.072\n",
      "Loss: 2.816, Residuals: -0.079\n",
      "Loss: 2.813, Residuals: -0.078\n",
      "Loss: 2.809, Residuals: -0.077\n",
      "Loss: 2.808, Residuals: -0.077\n",
      "Loss: 2.771, Residuals: -0.082\n",
      "Loss: 2.769, Residuals: -0.081\n",
      "Loss: 2.766, Residuals: -0.082\n",
      "Loss: 2.766, Residuals: -0.078\n",
      "Loss: 2.693, Residuals: -0.084\n",
      "Loss: 2.683, Residuals: -0.089\n",
      "Loss: 2.681, Residuals: -0.088\n",
      "Loss: 2.676, Residuals: -0.087\n",
      "Loss: 2.668, Residuals: -0.087\n",
      "Loss: 2.666, Residuals: -0.085\n",
      "Loss: 2.663, Residuals: -0.086\n",
      "Loss: 2.658, Residuals: -0.085\n",
      "Loss: 2.609, Residuals: -0.087\n",
      "Loss: 2.608, Residuals: -0.086\n",
      "Loss: 2.606, Residuals: -0.086\n",
      "Loss: 2.604, Residuals: -0.082\n",
      "Loss: 2.604, Residuals: -0.084\n",
      "Loss: 2.603, Residuals: -0.084\n",
      "Loss: 2.598, Residuals: -0.085\n",
      "Loss: 2.561, Residuals: -0.088\n",
      "Loss: 2.556, Residuals: -0.088\n",
      "Loss: 2.555, Residuals: -0.090\n",
      "Loss: 2.554, Residuals: -0.089\n",
      "Loss: 2.552, Residuals: -0.087\n",
      "Loss: 2.550, Residuals: -0.089\n",
      "Loss: 2.545, Residuals: -0.088\n",
      "Loss: 2.545, Residuals: -0.088\n",
      "Loss: 2.545, Residuals: -0.088\n",
      "Loss: 2.511, Residuals: -0.093\n",
      "Loss: 2.509, Residuals: -0.093\n",
      "Loss: 2.509, Residuals: -0.093\n",
      "Loss: 2.504, Residuals: -0.092\n",
      "Loss: 2.503, Residuals: -0.090\n",
      "Loss: 2.503, Residuals: -0.091\n",
      "Loss: 2.503, Residuals: -0.091\n",
      "Loss: 2.476, Residuals: -0.095\n",
      "Loss: 2.474, Residuals: -0.096\n",
      "Loss: 2.474, Residuals: -0.096\n",
      "Loss: 2.474, Residuals: -0.096\n",
      "Loss: 2.474, Residuals: -0.096\n",
      "Loss: 2.474, Residuals: -0.096\n",
      "Loss: 2.464, Residuals: -0.097\n",
      "Loss: 2.464, Residuals: -0.097\n",
      "Loss: 2.446, Residuals: -0.100\n",
      "Loss: 2.445, Residuals: -0.100\n",
      "Loss: 2.445, Residuals: -0.099\n",
      "Loss: 2.445, Residuals: -0.100\n",
      "Loss: 2.442, Residuals: -0.099\n",
      "Loss: 2.442, Residuals: -0.099\n",
      "Loss: 2.441, Residuals: -0.099\n",
      "Loss: 2.441, Residuals: -0.097\n",
      "Loss: 2.441, Residuals: -0.097\n",
      "Loss: 2.441, Residuals: -0.097\n",
      "Loss: 2.430, Residuals: -0.099\n",
      "Loss: 2.430, Residuals: -0.098\n",
      "Evidence -418.764\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.75e-03\n",
      "Loss: 13.843, Residuals: -0.057\n",
      "Loss: 13.763, Residuals: -0.044\n",
      "Loss: 13.674, Residuals: -0.052\n",
      "Loss: 13.565, Residuals: -0.063\n",
      "Loss: 13.563, Residuals: -0.062\n",
      "Loss: 13.507, Residuals: -0.062\n",
      "Loss: 13.400, Residuals: -0.061\n",
      "Loss: 13.219, Residuals: -0.057\n",
      "Loss: 13.214, Residuals: -0.059\n",
      "Loss: 13.211, Residuals: -0.058\n",
      "Loss: 13.084, Residuals: -0.052\n",
      "Loss: 13.081, Residuals: -0.054\n",
      "Loss: 13.054, Residuals: -0.052\n",
      "Loss: 13.023, Residuals: -0.046\n",
      "Loss: 13.021, Residuals: -0.048\n",
      "Loss: 13.018, Residuals: -0.048\n",
      "Loss: 12.992, Residuals: -0.046\n",
      "Loss: 12.949, Residuals: -0.041\n",
      "Loss: 12.949, Residuals: -0.042\n",
      "Loss: 12.948, Residuals: -0.042\n",
      "Loss: 12.948, Residuals: -0.042\n",
      "Loss: 12.948, Residuals: -0.042\n",
      "Loss: 12.936, Residuals: -0.041\n",
      "Loss: 12.921, Residuals: -0.039\n",
      "Loss: 12.920, Residuals: -0.040\n",
      "Loss: 12.893, Residuals: -0.037\n",
      "Loss: 12.893, Residuals: -0.037\n",
      "Evidence 111.632\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.32e-02\n",
      "Loss: 46.026, Residuals: -0.037\n",
      "Loss: 45.977, Residuals: -0.037\n",
      "Loss: 45.889, Residuals: -0.035\n",
      "Loss: 45.763, Residuals: -0.031\n",
      "Loss: 45.565, Residuals: -0.029\n",
      "Loss: 45.351, Residuals: -0.022\n",
      "Loss: 45.339, Residuals: -0.026\n",
      "Loss: 44.929, Residuals: -0.021\n",
      "Loss: 44.924, Residuals: -0.021\n",
      "Loss: 44.916, Residuals: -0.021\n",
      "Loss: 44.904, Residuals: -0.022\n",
      "Loss: 44.889, Residuals: -0.022\n",
      "Loss: 44.750, Residuals: -0.021\n",
      "Loss: 44.745, Residuals: -0.021\n",
      "Loss: 44.743, Residuals: -0.021\n",
      "Loss: 44.741, Residuals: -0.021\n",
      "Loss: 44.542, Residuals: -0.020\n",
      "Loss: 44.530, Residuals: -0.021\n",
      "Loss: 44.516, Residuals: -0.022\n",
      "Loss: 44.509, Residuals: -0.021\n",
      "Loss: 44.499, Residuals: -0.021\n",
      "Loss: 44.488, Residuals: -0.022\n",
      "Loss: 44.481, Residuals: -0.021\n",
      "Loss: 44.229, Residuals: -0.020\n",
      "Loss: 44.224, Residuals: -0.020\n",
      "Loss: 44.214, Residuals: -0.021\n",
      "Loss: 44.202, Residuals: -0.022\n",
      "Loss: 44.183, Residuals: -0.022\n",
      "Loss: 44.170, Residuals: -0.019\n",
      "Loss: 44.164, Residuals: -0.021\n",
      "Loss: 43.929, Residuals: -0.020\n",
      "Loss: 43.925, Residuals: -0.020\n",
      "Loss: 43.920, Residuals: -0.021\n",
      "Loss: 43.912, Residuals: -0.020\n",
      "Loss: 43.616, Residuals: -0.018\n",
      "Loss: 43.606, Residuals: -0.018\n",
      "Loss: 43.594, Residuals: -0.021\n",
      "Loss: 43.576, Residuals: -0.020\n",
      "Loss: 42.995, Residuals: -0.010\n",
      "Loss: 42.882, Residuals: -0.006\n",
      "Loss: 42.811, Residuals: -0.021\n",
      "Loss: 42.700, Residuals: -0.019\n",
      "Loss: 42.570, Residuals: -0.011\n",
      "Loss: 42.366, Residuals: -0.012\n",
      "Loss: 42.349, Residuals: -0.014\n",
      "Loss: 41.799, Residuals: -0.004\n",
      "Loss: 41.767, Residuals: -0.010\n",
      "Loss: 41.713, Residuals: -0.006\n",
      "Loss: 41.655, Residuals: -0.002\n",
      "Loss: 41.545, Residuals: -0.001\n",
      "Loss: 41.353, Residuals: 0.000\n",
      "Loss: 41.344, Residuals: -0.001\n",
      "Loss: 41.255, Residuals: -0.000\n",
      "Loss: 41.103, Residuals: 0.001\n",
      "Loss: 41.096, Residuals: -0.001\n",
      "Loss: 41.032, Residuals: -0.000\n",
      "Loss: 41.026, Residuals: 0.000\n",
      "Loss: 40.977, Residuals: 0.001\n",
      "Loss: 40.975, Residuals: -0.000\n",
      "Loss: 40.973, Residuals: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.956, Residuals: -0.000\n",
      "Loss: 40.929, Residuals: -0.000\n",
      "Loss: 40.928, Residuals: -0.001\n",
      "Loss: 40.926, Residuals: -0.001\n",
      "Loss: 40.913, Residuals: -0.001\n",
      "Loss: 40.913, Residuals: -0.001\n",
      "Loss: 40.912, Residuals: -0.001\n",
      "Loss: 40.904, Residuals: -0.001\n",
      "Loss: 40.902, Residuals: -0.001\n",
      "Loss: 40.902, Residuals: -0.001\n",
      "Loss: 40.901, Residuals: -0.001\n",
      "Loss: 40.896, Residuals: -0.001\n",
      "Loss: 40.895, Residuals: -0.001\n",
      "Loss: 40.895, Residuals: -0.001\n",
      "Loss: 40.894, Residuals: -0.001\n",
      "Loss: 40.892, Residuals: -0.001\n",
      "Loss: 40.892, Residuals: -0.002\n",
      "Loss: 40.890, Residuals: -0.001\n",
      "Loss: 40.889, Residuals: -0.001\n",
      "Loss: 40.889, Residuals: -0.001\n",
      "Loss: 40.887, Residuals: -0.001\n",
      "Loss: 40.887, Residuals: -0.001\n",
      "Loss: 40.887, Residuals: -0.001\n",
      "Loss: 40.887, Residuals: -0.001\n",
      "Loss: 40.885, Residuals: -0.001\n",
      "Loss: 40.885, Residuals: -0.001\n",
      "Loss: 40.885, Residuals: -0.001\n",
      "Loss: 40.884, Residuals: -0.001\n",
      "Loss: 40.884, Residuals: -0.001\n",
      "Loss: 40.883, Residuals: -0.001\n",
      "Loss: 40.883, Residuals: -0.001\n",
      "Loss: 40.883, Residuals: -0.001\n",
      "Loss: 40.883, Residuals: -0.001\n",
      "Loss: 40.882, Residuals: -0.001\n",
      "Loss: 40.882, Residuals: -0.001\n",
      "Loss: 40.881, Residuals: -0.001\n",
      "Loss: 40.881, Residuals: -0.001\n",
      "Loss: 40.881, Residuals: -0.001\n",
      "Loss: 40.881, Residuals: -0.001\n",
      "Loss: 40.881, Residuals: -0.001\n",
      "Loss: 40.879, Residuals: -0.001\n",
      "Loss: 40.879, Residuals: -0.001\n",
      "Loss: 40.879, Residuals: -0.001\n",
      "Loss: 40.879, Residuals: -0.001\n",
      "Loss: 40.876, Residuals: -0.001\n",
      "Loss: 40.876, Residuals: -0.001\n",
      "Loss: 40.876, Residuals: -0.001\n",
      "Loss: 40.875, Residuals: -0.001\n",
      "Loss: 40.875, Residuals: -0.001\n",
      "Loss: 40.875, Residuals: -0.001\n",
      "Loss: 40.871, Residuals: -0.000\n",
      "Loss: 40.870, Residuals: -0.000\n",
      "Loss: 40.870, Residuals: -0.000\n",
      "Loss: 40.870, Residuals: -0.000\n",
      "Loss: 40.870, Residuals: -0.000\n",
      "Loss: 40.867, Residuals: -0.000\n",
      "Loss: 40.867, Residuals: -0.000\n",
      "Loss: 40.857, Residuals: 0.000\n",
      "Loss: 40.857, Residuals: 0.000\n",
      "Loss: 40.856, Residuals: 0.001\n",
      "Loss: 40.854, Residuals: 0.001\n",
      "Loss: 40.854, Residuals: 0.000\n",
      "Loss: 40.853, Residuals: 0.001\n",
      "Loss: 40.853, Residuals: 0.001\n",
      "Loss: 40.851, Residuals: 0.001\n",
      "Loss: 40.851, Residuals: 0.001\n",
      "Loss: 40.850, Residuals: 0.001\n",
      "Loss: 40.846, Residuals: 0.001\n",
      "Loss: 40.846, Residuals: 0.001\n",
      "Loss: 40.845, Residuals: 0.001\n",
      "Loss: 40.845, Residuals: 0.001\n",
      "Loss: 40.845, Residuals: 0.001\n",
      "Loss: 40.845, Residuals: 0.001\n",
      "Loss: 40.843, Residuals: 0.001\n",
      "Loss: 40.840, Residuals: 0.001\n",
      "Loss: 40.840, Residuals: 0.001\n",
      "Loss: 40.840, Residuals: 0.001\n",
      "Loss: 40.839, Residuals: 0.001\n",
      "Loss: 40.839, Residuals: 0.001\n",
      "Loss: 40.839, Residuals: 0.002\n",
      "Loss: 40.838, Residuals: 0.002\n",
      "Loss: 40.837, Residuals: 0.002\n",
      "Loss: 40.837, Residuals: 0.002\n",
      "Loss: 40.836, Residuals: 0.001\n",
      "Loss: 40.836, Residuals: 0.002\n",
      "Loss: 40.834, Residuals: 0.002\n",
      "Loss: 40.834, Residuals: 0.002\n",
      "Loss: 40.833, Residuals: 0.002\n",
      "Loss: 40.833, Residuals: 0.002\n",
      "Loss: 40.833, Residuals: 0.002\n",
      "Loss: 40.832, Residuals: 0.002\n",
      "Loss: 40.832, Residuals: 0.002\n",
      "Loss: 40.832, Residuals: 0.002\n",
      "Loss: 40.832, Residuals: 0.002\n",
      "Loss: 40.831, Residuals: 0.002\n",
      "Loss: 40.831, Residuals: 0.002\n",
      "Loss: 40.830, Residuals: 0.002\n",
      "Loss: 40.830, Residuals: 0.002\n",
      "Loss: 40.830, Residuals: 0.002\n",
      "Loss: 40.829, Residuals: 0.002\n",
      "Loss: 40.829, Residuals: 0.002\n",
      "Loss: 40.829, Residuals: 0.002\n",
      "Loss: 40.829, Residuals: 0.002\n",
      "Loss: 40.829, Residuals: 0.002\n",
      "Evidence 318.513\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.48e-02\n",
      "Loss: 86.179, Residuals: 0.005\n",
      "Loss: 85.854, Residuals: -0.005\n",
      "Loss: 85.690, Residuals: -0.004\n",
      "Loss: 85.544, Residuals: -0.004\n",
      "Loss: 85.524, Residuals: -0.006\n",
      "Loss: 85.489, Residuals: -0.006\n",
      "Loss: 85.429, Residuals: -0.005\n",
      "Loss: 85.358, Residuals: -0.004\n",
      "Loss: 85.355, Residuals: -0.005\n",
      "Loss: 85.328, Residuals: -0.005\n",
      "Loss: 85.284, Residuals: -0.005\n",
      "Loss: 85.282, Residuals: -0.005\n",
      "Loss: 85.266, Residuals: -0.005\n",
      "Loss: 85.241, Residuals: -0.005\n",
      "Loss: 85.241, Residuals: -0.005\n",
      "Loss: 85.238, Residuals: -0.005\n",
      "Loss: 85.237, Residuals: -0.006\n",
      "Loss: 85.236, Residuals: -0.006\n",
      "Loss: 85.233, Residuals: -0.006\n",
      "Loss: 85.233, Residuals: -0.006\n",
      "Loss: 85.231, Residuals: -0.006\n",
      "Loss: 85.229, Residuals: -0.006\n",
      "Loss: 85.229, Residuals: -0.006\n",
      "Loss: 85.227, Residuals: -0.006\n",
      "Loss: 85.227, Residuals: -0.006\n",
      "Loss: 85.225, Residuals: -0.006\n",
      "Loss: 85.225, Residuals: -0.006\n",
      "Loss: 85.221, Residuals: -0.006\n",
      "Loss: 85.221, Residuals: -0.006\n",
      "Loss: 85.221, Residuals: -0.006\n",
      "Loss: 85.221, Residuals: -0.006\n",
      "Loss: 85.221, Residuals: -0.006\n",
      "Loss: 85.218, Residuals: -0.006\n",
      "Loss: 85.218, Residuals: -0.006\n",
      "Loss: 85.215, Residuals: -0.006\n",
      "Loss: 85.215, Residuals: -0.006\n",
      "Loss: 85.213, Residuals: -0.006\n",
      "Loss: 85.213, Residuals: -0.006\n",
      "Loss: 85.208, Residuals: -0.006\n",
      "Loss: 85.208, Residuals: -0.006\n",
      "Loss: 85.208, Residuals: -0.006\n",
      "Loss: 85.208, Residuals: -0.006\n",
      "Loss: 85.204, Residuals: -0.006\n",
      "Loss: 85.204, Residuals: -0.006\n",
      "Loss: 85.202, Residuals: -0.006\n",
      "Loss: 85.202, Residuals: -0.006\n",
      "Loss: 85.200, Residuals: -0.006\n",
      "Loss: 85.200, Residuals: -0.006\n",
      "Evidence 440.087\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.09e-02\n",
      "Loss: 125.040, Residuals: -0.017\n",
      "Loss: 124.610, Residuals: -0.021\n",
      "Loss: 124.302, Residuals: -0.019\n",
      "Loss: 124.213, Residuals: -0.018\n",
      "Loss: 124.181, Residuals: -0.018\n",
      "Loss: 124.126, Residuals: -0.019\n",
      "Loss: 124.052, Residuals: -0.021\n",
      "Loss: 124.020, Residuals: -0.021\n",
      "Loss: 124.016, Residuals: -0.023\n",
      "Loss: 124.014, Residuals: -0.022\n",
      "Loss: 123.997, Residuals: -0.022\n",
      "Loss: 123.996, Residuals: -0.023\n",
      "Loss: 123.962, Residuals: -0.023\n",
      "Loss: 123.962, Residuals: -0.023\n",
      "Loss: 123.950, Residuals: -0.023\n",
      "Loss: 123.949, Residuals: -0.023\n",
      "Loss: 123.921, Residuals: -0.023\n",
      "Loss: 123.920, Residuals: -0.023\n",
      "Loss: 123.770, Residuals: -0.023\n",
      "Loss: 123.756, Residuals: -0.023\n",
      "Loss: 123.740, Residuals: -0.022\n",
      "Loss: 123.614, Residuals: -0.023\n",
      "Loss: 123.609, Residuals: -0.022\n",
      "Loss: 123.604, Residuals: -0.023\n",
      "Loss: 123.559, Residuals: -0.023\n",
      "Loss: 123.476, Residuals: -0.024\n",
      "Loss: 123.472, Residuals: -0.024\n",
      "Loss: 123.137, Residuals: -0.024\n",
      "Loss: 123.120, Residuals: -0.026\n",
      "Loss: 123.102, Residuals: -0.025\n",
      "Loss: 122.943, Residuals: -0.022\n",
      "Loss: 122.941, Residuals: -0.022\n",
      "Loss: 122.888, Residuals: -0.020\n",
      "Loss: 122.858, Residuals: -0.018\n",
      "Loss: 122.857, Residuals: -0.018\n",
      "Loss: 122.855, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Loss: 122.853, Residuals: -0.017\n",
      "Evidence 479.989\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.99e-01\n",
      "Loss: 144.428, Residuals: -0.015\n",
      "Loss: 144.168, Residuals: -0.022\n",
      "Loss: 143.884, Residuals: -0.020\n",
      "Loss: 143.864, Residuals: -0.020\n",
      "Loss: 143.829, Residuals: -0.020\n",
      "Loss: 143.786, Residuals: -0.019\n",
      "Loss: 143.784, Residuals: -0.019\n",
      "Loss: 143.781, Residuals: -0.019\n",
      "Loss: 143.777, Residuals: -0.019\n",
      "Loss: 143.772, Residuals: -0.019\n",
      "Loss: 143.772, Residuals: -0.019\n",
      "Loss: 143.772, Residuals: -0.019\n",
      "Loss: 143.771, Residuals: -0.019\n",
      "Loss: 143.771, Residuals: -0.018\n",
      "Loss: 143.771, Residuals: -0.018\n",
      "Evidence 494.507\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.54e-01\n",
      "Loss: 152.081, Residuals: -0.017\n",
      "Loss: 151.922, Residuals: -0.020\n",
      "Loss: 151.894, Residuals: -0.018\n",
      "Loss: 151.867, Residuals: -0.019\n",
      "Loss: 151.843, Residuals: -0.020\n",
      "Loss: 151.842, Residuals: -0.019\n",
      "Loss: 151.841, Residuals: -0.020\n",
      "Loss: 151.840, Residuals: -0.020\n",
      "Loss: 151.839, Residuals: -0.019\n",
      "Loss: 151.839, Residuals: -0.019\n",
      "Loss: 151.838, Residuals: -0.019\n",
      "Loss: 151.838, Residuals: -0.019\n",
      "Loss: 151.838, Residuals: -0.019\n",
      "Evidence 497.953\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.63e-01\n",
      "Loss: 154.709, Residuals: -0.018\n",
      "Loss: 154.656, Residuals: -0.019\n",
      "Loss: 154.623, Residuals: -0.018\n",
      "Loss: 154.617, Residuals: -0.020\n",
      "Loss: 154.613, Residuals: -0.019\n",
      "Loss: 154.608, Residuals: -0.019\n",
      "Loss: 154.603, Residuals: -0.019\n",
      "Loss: 154.603, Residuals: -0.020\n",
      "Loss: 154.603, Residuals: -0.019\n",
      "Loss: 154.603, Residuals: -0.019\n",
      "Loss: 154.603, Residuals: -0.019\n",
      "Loss: 154.603, Residuals: -0.019\n",
      "Evidence 499.404\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.60e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 155.695, Residuals: -0.019\n",
      "Loss: 155.668, Residuals: -0.019\n",
      "Loss: 155.652, Residuals: -0.018\n",
      "Loss: 155.647, Residuals: -0.019\n",
      "Loss: 155.645, Residuals: -0.019\n",
      "Loss: 155.644, Residuals: -0.019\n",
      "Loss: 155.641, Residuals: -0.019\n",
      "Loss: 155.639, Residuals: -0.019\n",
      "Loss: 155.638, Residuals: -0.019\n",
      "Loss: 155.638, Residuals: -0.019\n",
      "Loss: 155.638, Residuals: -0.019\n",
      "Loss: 155.638, Residuals: -0.019\n",
      "Loss: 155.638, Residuals: -0.019\n",
      "Loss: 155.638, Residuals: -0.019\n",
      "Evidence 500.198\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.54e-01\n",
      "Loss: 156.136, Residuals: -0.017\n",
      "Loss: 156.130, Residuals: -0.018\n",
      "Loss: 156.119, Residuals: -0.018\n",
      "Loss: 156.106, Residuals: -0.018\n",
      "Loss: 156.106, Residuals: -0.018\n",
      "Loss: 156.105, Residuals: -0.018\n",
      "Loss: 156.104, Residuals: -0.018\n",
      "Evidence 500.706\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.46e-01\n",
      "Loss: 156.369, Residuals: -0.016\n",
      "Loss: 156.352, Residuals: -0.016\n",
      "Loss: 156.347, Residuals: -0.017\n",
      "Loss: 156.345, Residuals: -0.017\n",
      "Loss: 156.344, Residuals: -0.017\n",
      "Loss: 156.343, Residuals: -0.017\n",
      "Loss: 156.342, Residuals: -0.017\n",
      "Loss: 156.342, Residuals: -0.017\n",
      "Evidence 501.095\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.794, Residuals: -0.081\n",
      "Loss: 7.205, Residuals: -0.055\n",
      "Loss: 5.899, Residuals: -0.044\n",
      "Loss: 4.771, Residuals: -0.038\n",
      "Loss: 4.180, Residuals: -0.015\n",
      "Loss: 3.991, Residuals: -0.030\n",
      "Loss: 3.668, Residuals: -0.042\n",
      "Loss: 3.347, Residuals: -0.047\n",
      "Loss: 3.319, Residuals: -0.061\n",
      "Loss: 3.273, Residuals: -0.053\n",
      "Loss: 3.224, Residuals: -0.037\n",
      "Loss: 3.138, Residuals: -0.042\n",
      "Loss: 3.000, Residuals: -0.054\n",
      "Loss: 2.987, Residuals: -0.033\n",
      "Loss: 2.963, Residuals: -0.031\n",
      "Loss: 2.918, Residuals: -0.036\n",
      "Loss: 2.881, Residuals: -0.025\n",
      "Loss: 2.880, Residuals: -0.027\n",
      "Loss: 2.879, Residuals: -0.027\n",
      "Loss: 2.876, Residuals: -0.027\n",
      "Loss: 2.854, Residuals: -0.030\n",
      "Loss: 2.813, Residuals: -0.036\n",
      "Loss: 2.810, Residuals: -0.027\n",
      "Loss: 2.785, Residuals: -0.032\n",
      "Loss: 2.782, Residuals: -0.039\n",
      "Loss: 2.750, Residuals: -0.046\n",
      "Loss: 2.750, Residuals: -0.046\n",
      "Loss: 2.721, Residuals: -0.051\n",
      "Loss: 2.721, Residuals: -0.051\n",
      "Loss: 2.716, Residuals: -0.049\n",
      "Loss: 2.716, Residuals: -0.044\n",
      "Loss: 2.685, Residuals: -0.049\n",
      "Loss: 2.685, Residuals: -0.048\n",
      "Loss: 2.685, Residuals: -0.048\n",
      "Loss: 2.679, Residuals: -0.048\n",
      "Loss: 2.679, Residuals: -0.047\n",
      "Loss: 2.646, Residuals: -0.051\n",
      "Loss: 2.645, Residuals: -0.050\n",
      "Loss: 2.644, Residuals: -0.050\n",
      "Loss: 2.623, Residuals: -0.053\n",
      "Loss: 2.621, Residuals: -0.054\n",
      "Loss: 2.621, Residuals: -0.054\n",
      "Evidence -412.377\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.68e-02\n",
      "Loss: 13.306, Residuals: -0.055\n",
      "Loss: 13.281, Residuals: -0.053\n",
      "Loss: 13.278, Residuals: -0.054\n",
      "Loss: 13.273, Residuals: -0.052\n",
      "Loss: 13.264, Residuals: -0.051\n",
      "Loss: 13.247, Residuals: -0.049\n",
      "Loss: 13.090, Residuals: -0.044\n",
      "Loss: 12.848, Residuals: -0.031\n",
      "Loss: 12.848, Residuals: -0.031\n",
      "Evidence 106.907\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.01e-01\n",
      "Loss: 41.447, Residuals: -0.032\n",
      "Loss: 41.436, Residuals: -0.029\n",
      "Loss: 41.034, Residuals: -0.021\n",
      "Loss: 40.513, Residuals: -0.006\n",
      "Loss: 40.507, Residuals: -0.007\n",
      "Evidence 307.649\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.25e-01\n",
      "Loss: 86.834, Residuals: -0.007\n",
      "Evidence 420.204\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.31e-01\n",
      "Loss: 127.760, Residuals: 0.003\n",
      "Loss: 126.835, Residuals: -0.001\n",
      "Loss: 126.796, Residuals: -0.001\n",
      "Loss: 126.791, Residuals: -0.001\n",
      "Evidence 456.713\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.14e-01\n",
      "Loss: 146.609, Residuals: -0.001\n",
      "Loss: 146.279, Residuals: -0.004\n",
      "Loss: 145.739, Residuals: -0.011\n",
      "Loss: 144.843, Residuals: -0.011\n",
      "Loss: 144.833, Residuals: -0.012\n",
      "Loss: 144.442, Residuals: -0.011\n",
      "Loss: 143.894, Residuals: -0.011\n",
      "Loss: 143.894, Residuals: -0.011\n",
      "Evidence 468.375\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.53e-01\n",
      "Loss: 152.904, Residuals: -0.010\n",
      "Loss: 152.558, Residuals: -0.012\n",
      "Loss: 152.558, Residuals: -0.012\n",
      "Evidence 471.273\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.65e-01\n",
      "Loss: 155.289, Residuals: -0.017\n",
      "Loss: 155.205, Residuals: -0.015\n",
      "Loss: 155.177, Residuals: -0.013\n",
      "Loss: 154.942, Residuals: -0.014\n",
      "Loss: 154.691, Residuals: -0.017\n",
      "Loss: 154.690, Residuals: -0.017\n",
      "Evidence 473.791\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.63e-01\n",
      "Loss: 156.048, Residuals: -0.017\n",
      "Evidence 474.416\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.68e-01\n",
      "Loss: 156.638, Residuals: -0.014\n",
      "Loss: 156.622, Residuals: -0.016\n",
      "Loss: 156.482, Residuals: -0.016\n",
      "Loss: 156.433, Residuals: -0.017\n",
      "Loss: 156.352, Residuals: -0.017\n",
      "Loss: 156.351, Residuals: -0.017\n",
      "Loss: 156.303, Residuals: -0.018\n",
      "Loss: 156.303, Residuals: -0.018\n",
      "Evidence 475.766\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.64e-01\n",
      "Loss: 156.546, Residuals: -0.018\n",
      "Loss: 156.529, Residuals: -0.017\n",
      "Loss: 156.394, Residuals: -0.017\n",
      "Loss: 156.393, Residuals: -0.017\n",
      "Evidence 476.541\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.64e-01\n",
      "Loss: 156.684, Residuals: -0.016\n",
      "Loss: 156.631, Residuals: -0.017\n",
      "Loss: 156.543, Residuals: -0.018\n",
      "Loss: 156.543, Residuals: -0.018\n",
      "Evidence 477.262\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.62e-01\n",
      "Loss: 156.677, Residuals: -0.016\n",
      "Loss: 156.673, Residuals: -0.017\n",
      "Loss: 156.547, Residuals: -0.018\n",
      "Loss: 156.546, Residuals: -0.018\n",
      "Evidence 477.833\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.61e-01\n",
      "Loss: 156.693, Residuals: -0.019\n",
      "Loss: 156.598, Residuals: -0.020\n",
      "Loss: 156.598, Residuals: -0.020\n",
      "Evidence 478.429\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.59e-01\n",
      "Loss: 156.669, Residuals: -0.020\n",
      "Loss: 156.562, Residuals: -0.021\n",
      "Loss: 156.562, Residuals: -0.021\n",
      "Loss: 156.561, Residuals: -0.021\n",
      "Loss: 156.515, Residuals: -0.021\n",
      "Loss: 156.514, Residuals: -0.021\n",
      "Evidence 479.141\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.55e-01\n",
      "Loss: 156.665, Residuals: -0.020\n",
      "Loss: 156.635, Residuals: -0.021\n",
      "Loss: 156.579, Residuals: -0.021\n",
      "Loss: 156.578, Residuals: -0.021\n",
      "Loss: 156.448, Residuals: -0.022\n",
      "Loss: 156.446, Residuals: -0.022\n",
      "Loss: 156.446, Residuals: -0.022\n",
      "Loss: 156.322, Residuals: -0.023\n",
      "Loss: 156.318, Residuals: -0.024\n",
      "Loss: 156.317, Residuals: -0.023\n",
      "Evidence 480.120\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.61e-01\n",
      "Loss: 156.596, Residuals: -0.023\n",
      "Loss: 156.560, Residuals: -0.023\n",
      "Loss: 156.491, Residuals: -0.024\n",
      "Loss: 156.384, Residuals: -0.025\n",
      "Loss: 156.363, Residuals: -0.027\n",
      "Loss: 156.191, Residuals: -0.028\n",
      "Loss: 156.185, Residuals: -0.028\n",
      "Loss: 156.179, Residuals: -0.028\n",
      "Loss: 155.986, Residuals: -0.030\n",
      "Loss: 155.964, Residuals: -0.031\n",
      "Loss: 155.955, Residuals: -0.030\n",
      "Loss: 155.947, Residuals: -0.030\n",
      "Loss: 155.933, Residuals: -0.031\n",
      "Loss: 155.808, Residuals: -0.032\n",
      "Loss: 155.796, Residuals: -0.032\n",
      "Loss: 155.790, Residuals: -0.031\n",
      "Loss: 155.785, Residuals: -0.032\n",
      "Loss: 155.744, Residuals: -0.032\n",
      "Loss: 155.741, Residuals: -0.032\n",
      "Loss: 155.663, Residuals: -0.033\n",
      "Loss: 155.657, Residuals: -0.032\n",
      "Loss: 155.653, Residuals: -0.033\n",
      "Loss: 155.646, Residuals: -0.033\n",
      "Loss: 155.633, Residuals: -0.033\n",
      "Loss: 155.632, Residuals: -0.033\n",
      "Loss: 155.623, Residuals: -0.033\n",
      "Loss: 155.607, Residuals: -0.034\n",
      "Loss: 155.606, Residuals: -0.034\n",
      "Loss: 155.598, Residuals: -0.035\n",
      "Loss: 155.596, Residuals: -0.035\n",
      "Loss: 155.594, Residuals: -0.035\n",
      "Loss: 155.590, Residuals: -0.035\n",
      "Loss: 155.590, Residuals: -0.035\n",
      "Loss: 155.587, Residuals: -0.036\n",
      "Loss: 155.587, Residuals: -0.036\n",
      "Loss: 155.587, Residuals: -0.036\n",
      "Loss: 155.586, Residuals: -0.036\n",
      "Loss: 155.585, Residuals: -0.036\n",
      "Loss: 155.584, Residuals: -0.036\n",
      "Loss: 155.584, Residuals: -0.036\n",
      "Loss: 155.584, Residuals: -0.036\n",
      "Evidence 482.421\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.65e-01\n",
      "Loss: 155.104, Residuals: -0.038\n",
      "Loss: 154.652, Residuals: -0.042\n",
      "Loss: 154.521, Residuals: -0.044\n",
      "Loss: 154.479, Residuals: -0.044\n",
      "Loss: 154.463, Residuals: -0.044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 154.434, Residuals: -0.044\n",
      "Loss: 154.384, Residuals: -0.045\n",
      "Loss: 154.382, Residuals: -0.045\n",
      "Loss: 154.357, Residuals: -0.045\n",
      "Loss: 154.351, Residuals: -0.045\n",
      "Loss: 154.340, Residuals: -0.045\n",
      "Loss: 154.321, Residuals: -0.046\n",
      "Loss: 154.321, Residuals: -0.046\n",
      "Loss: 154.312, Residuals: -0.046\n",
      "Loss: 154.301, Residuals: -0.046\n",
      "Loss: 154.301, Residuals: -0.046\n",
      "Evidence 484.415\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.24e-01\n",
      "Loss: 154.701, Residuals: -0.046\n",
      "Loss: 154.126, Residuals: -0.048\n",
      "Loss: 153.690, Residuals: -0.049\n",
      "Loss: 153.654, Residuals: -0.047\n",
      "Loss: 153.617, Residuals: -0.044\n",
      "Loss: 153.589, Residuals: -0.043\n",
      "Loss: 153.588, Residuals: -0.043\n",
      "Loss: 153.587, Residuals: -0.044\n",
      "Loss: 153.576, Residuals: -0.044\n",
      "Loss: 153.557, Residuals: -0.044\n",
      "Loss: 153.557, Residuals: -0.044\n",
      "Loss: 153.547, Residuals: -0.044\n",
      "Loss: 153.546, Residuals: -0.045\n",
      "Loss: 153.540, Residuals: -0.045\n",
      "Loss: 153.540, Residuals: -0.045\n",
      "Evidence 487.934\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.02e-01\n",
      "Loss: 154.917, Residuals: -0.044\n",
      "Loss: 154.876, Residuals: -0.042\n",
      "Loss: 154.800, Residuals: -0.043\n",
      "Loss: 154.674, Residuals: -0.042\n",
      "Loss: 154.614, Residuals: -0.043\n",
      "Loss: 154.572, Residuals: -0.039\n",
      "Loss: 154.570, Residuals: -0.039\n",
      "Loss: 154.558, Residuals: -0.040\n",
      "Loss: 154.541, Residuals: -0.040\n",
      "Loss: 154.541, Residuals: -0.040\n",
      "Loss: 154.529, Residuals: -0.040\n",
      "Loss: 154.512, Residuals: -0.040\n",
      "Loss: 154.512, Residuals: -0.040\n",
      "Evidence 489.875\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.83e-01\n",
      "Loss: 155.601, Residuals: -0.040\n",
      "Loss: 155.583, Residuals: -0.038\n",
      "Loss: 155.550, Residuals: -0.038\n",
      "Loss: 155.496, Residuals: -0.037\n",
      "Loss: 155.478, Residuals: -0.036\n",
      "Loss: 155.456, Residuals: -0.035\n",
      "Loss: 155.441, Residuals: -0.035\n",
      "Loss: 155.440, Residuals: -0.036\n",
      "Loss: 155.439, Residuals: -0.035\n",
      "Loss: 155.429, Residuals: -0.035\n",
      "Loss: 155.414, Residuals: -0.035\n",
      "Loss: 155.414, Residuals: -0.035\n",
      "Loss: 155.409, Residuals: -0.035\n",
      "Loss: 155.408, Residuals: -0.036\n",
      "Loss: 155.406, Residuals: -0.036\n",
      "Loss: 155.406, Residuals: -0.036\n",
      "Evidence 490.874\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.60e-01\n",
      "Loss: 156.013, Residuals: -0.035\n",
      "Loss: 156.005, Residuals: -0.034\n",
      "Loss: 155.990, Residuals: -0.034\n",
      "Loss: 155.968, Residuals: -0.033\n",
      "Loss: 155.948, Residuals: -0.031\n",
      "Loss: 155.940, Residuals: -0.032\n",
      "Loss: 155.937, Residuals: -0.031\n",
      "Loss: 155.931, Residuals: -0.031\n",
      "Loss: 155.920, Residuals: -0.032\n",
      "Loss: 155.920, Residuals: -0.032\n",
      "Loss: 155.914, Residuals: -0.032\n",
      "Loss: 155.913, Residuals: -0.032\n",
      "Loss: 155.913, Residuals: -0.032\n",
      "Loss: 155.911, Residuals: -0.032\n",
      "Loss: 155.911, Residuals: -0.032\n",
      "Loss: 155.911, Residuals: -0.032\n",
      "Loss: 155.910, Residuals: -0.032\n",
      "Loss: 155.910, Residuals: -0.032\n",
      "Evidence 491.525\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.34e-01\n",
      "Loss: 156.251, Residuals: -0.032\n",
      "Loss: 156.247, Residuals: -0.031\n",
      "Loss: 156.240, Residuals: -0.031\n",
      "Loss: 156.229, Residuals: -0.030\n",
      "Loss: 156.214, Residuals: -0.029\n",
      "Loss: 156.213, Residuals: -0.028\n",
      "Loss: 156.210, Residuals: -0.028\n",
      "Loss: 156.205, Residuals: -0.029\n",
      "Loss: 156.204, Residuals: -0.029\n",
      "Loss: 156.201, Residuals: -0.029\n",
      "Loss: 156.197, Residuals: -0.029\n",
      "Loss: 156.197, Residuals: -0.029\n",
      "Loss: 156.195, Residuals: -0.029\n",
      "Loss: 156.193, Residuals: -0.029\n",
      "Loss: 156.191, Residuals: -0.029\n",
      "Loss: 156.191, Residuals: -0.029\n",
      "Loss: 156.191, Residuals: -0.029\n",
      "Loss: 156.191, Residuals: -0.029\n",
      "Evidence 491.990\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.249, Residuals: -0.065\n",
      "Loss: 7.565, Residuals: -0.029\n",
      "Loss: 5.283, Residuals: -0.025\n",
      "Loss: 4.581, Residuals: -0.031\n",
      "Loss: 4.039, Residuals: 0.009\n",
      "Loss: 3.956, Residuals: 0.006\n",
      "Loss: 3.800, Residuals: -0.004\n",
      "Loss: 3.537, Residuals: -0.025\n",
      "Loss: 3.507, Residuals: -0.011\n",
      "Loss: 3.277, Residuals: -0.030\n",
      "Loss: 3.240, Residuals: -0.017\n",
      "Loss: 3.175, Residuals: -0.029\n",
      "Loss: 3.076, Residuals: -0.040\n",
      "Loss: 3.073, Residuals: -0.037\n",
      "Loss: 3.068, Residuals: -0.037\n",
      "Loss: 3.023, Residuals: -0.043\n",
      "Loss: 3.016, Residuals: -0.038\n",
      "Loss: 3.002, Residuals: -0.041\n",
      "Loss: 2.978, Residuals: -0.046\n",
      "Loss: 2.975, Residuals: -0.035\n",
      "Loss: 2.947, Residuals: -0.044\n",
      "Loss: 2.947, Residuals: -0.044\n",
      "Loss: 2.945, Residuals: -0.044\n",
      "Loss: 2.941, Residuals: -0.045\n",
      "Loss: 2.934, Residuals: -0.047\n",
      "Loss: 2.922, Residuals: -0.050\n",
      "Loss: 2.922, Residuals: -0.047\n",
      "Loss: 2.916, Residuals: -0.049\n",
      "Loss: 2.907, Residuals: -0.052\n",
      "Loss: 2.907, Residuals: -0.052\n",
      "Loss: 2.905, Residuals: -0.052\n",
      "Loss: 2.889, Residuals: -0.058\n",
      "Loss: 2.888, Residuals: -0.057\n",
      "Loss: 2.888, Residuals: -0.057\n",
      "Loss: 2.886, Residuals: -0.058\n",
      "Loss: 2.884, Residuals: -0.059\n",
      "Loss: 2.868, Residuals: -0.066\n",
      "Loss: 2.867, Residuals: -0.065\n",
      "Loss: 2.867, Residuals: -0.066\n",
      "Loss: 2.866, Residuals: -0.064\n",
      "Loss: 2.865, Residuals: -0.065\n",
      "Loss: 2.863, Residuals: -0.066\n",
      "Loss: 2.860, Residuals: -0.067\n",
      "Loss: 2.859, Residuals: -0.067\n",
      "Loss: 2.859, Residuals: -0.067\n",
      "Evidence -395.913\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.97e-03\n",
      "Loss: 13.078, Residuals: -0.042\n",
      "Loss: 13.029, Residuals: -0.047\n",
      "Loss: 13.022, Residuals: -0.046\n",
      "Loss: 13.015, Residuals: -0.046\n",
      "Loss: 12.959, Residuals: -0.045\n",
      "Loss: 12.862, Residuals: -0.039\n",
      "Loss: 12.738, Residuals: -0.021\n",
      "Loss: 12.738, Residuals: -0.022\n",
      "Loss: 12.736, Residuals: -0.022\n",
      "Loss: 12.733, Residuals: -0.022\n",
      "Loss: 12.728, Residuals: -0.022\n",
      "Loss: 12.718, Residuals: -0.022\n",
      "Loss: 12.699, Residuals: -0.021\n",
      "Loss: 12.668, Residuals: -0.020\n",
      "Loss: 12.664, Residuals: -0.019\n",
      "Loss: 12.637, Residuals: -0.017\n",
      "Loss: 12.637, Residuals: -0.017\n",
      "Loss: 12.572, Residuals: -0.014\n",
      "Loss: 12.568, Residuals: -0.013\n",
      "Loss: 12.567, Residuals: -0.014\n",
      "Loss: 12.567, Residuals: -0.013\n",
      "Loss: 12.565, Residuals: -0.012\n",
      "Loss: 12.563, Residuals: -0.011\n",
      "Loss: 12.559, Residuals: -0.010\n",
      "Loss: 12.528, Residuals: -0.011\n",
      "Loss: 12.527, Residuals: -0.010\n",
      "Loss: 12.527, Residuals: -0.011\n",
      "Evidence 100.924\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.48e-02\n",
      "Loss: 41.076, Residuals: -0.011\n",
      "Loss: 40.902, Residuals: -0.010\n",
      "Loss: 40.760, Residuals: -0.006\n",
      "Loss: 40.759, Residuals: -0.006\n",
      "Evidence 303.128\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.38e-01\n",
      "Loss: 83.672, Residuals: 0.008\n",
      "Loss: 83.328, Residuals: 0.004\n",
      "Loss: 82.902, Residuals: -0.009\n",
      "Loss: 82.201, Residuals: -0.008\n",
      "Loss: 82.198, Residuals: -0.008\n",
      "Loss: 81.797, Residuals: -0.006\n",
      "Loss: 81.744, Residuals: -0.006\n",
      "Loss: 81.643, Residuals: -0.006\n",
      "Loss: 81.471, Residuals: -0.007\n",
      "Loss: 81.465, Residuals: -0.008\n",
      "Loss: 81.273, Residuals: -0.008\n",
      "Loss: 81.267, Residuals: -0.008\n",
      "Loss: 81.262, Residuals: -0.008\n",
      "Loss: 81.256, Residuals: -0.008\n",
      "Loss: 81.195, Residuals: -0.008\n",
      "Loss: 81.191, Residuals: -0.008\n",
      "Loss: 81.189, Residuals: -0.007\n",
      "Loss: 80.938, Residuals: -0.009\n",
      "Loss: 80.848, Residuals: -0.008\n",
      "Loss: 80.779, Residuals: -0.004\n",
      "Loss: 80.697, Residuals: -0.007\n",
      "Loss: 80.685, Residuals: -0.008\n",
      "Loss: 80.574, Residuals: -0.008\n",
      "Loss: 80.572, Residuals: -0.007\n",
      "Loss: 80.476, Residuals: -0.008\n",
      "Loss: 80.343, Residuals: -0.009\n",
      "Loss: 80.337, Residuals: -0.008\n",
      "Loss: 80.326, Residuals: -0.008\n",
      "Loss: 80.309, Residuals: -0.009\n",
      "Loss: 80.307, Residuals: -0.009\n",
      "Loss: 80.305, Residuals: -0.009\n",
      "Loss: 80.301, Residuals: -0.010\n",
      "Loss: 80.301, Residuals: -0.010\n",
      "Loss: 80.299, Residuals: -0.010\n",
      "Loss: 80.299, Residuals: -0.010\n",
      "Loss: 80.299, Residuals: -0.010\n",
      "Loss: 80.299, Residuals: -0.010\n",
      "Loss: 80.298, Residuals: -0.010\n",
      "Loss: 80.298, Residuals: -0.010\n",
      "Loss: 80.298, Residuals: -0.010\n",
      "Evidence 424.609\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.03e-01\n",
      "Loss: 119.119, Residuals: -0.003\n",
      "Loss: 118.615, Residuals: -0.016\n",
      "Loss: 118.409, Residuals: -0.019\n",
      "Loss: 118.351, Residuals: -0.021\n",
      "Loss: 118.316, Residuals: -0.018\n",
      "Loss: 118.301, Residuals: -0.020\n",
      "Loss: 118.275, Residuals: -0.021\n",
      "Loss: 118.228, Residuals: -0.021\n",
      "Loss: 118.171, Residuals: -0.022\n",
      "Loss: 118.169, Residuals: -0.023\n",
      "Loss: 118.165, Residuals: -0.023\n",
      "Loss: 118.160, Residuals: -0.023\n",
      "Loss: 118.159, Residuals: -0.023\n",
      "Loss: 118.158, Residuals: -0.023\n",
      "Loss: 118.156, Residuals: -0.023\n",
      "Loss: 118.155, Residuals: -0.023\n",
      "Loss: 118.154, Residuals: -0.023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 118.153, Residuals: -0.023\n",
      "Loss: 118.153, Residuals: -0.023\n",
      "Loss: 118.151, Residuals: -0.023\n",
      "Loss: 118.149, Residuals: -0.023\n",
      "Loss: 118.149, Residuals: -0.023\n",
      "Evidence 478.129\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.05e-01\n",
      "Loss: 142.054, Residuals: -0.021\n",
      "Loss: 141.757, Residuals: -0.030\n",
      "Loss: 141.726, Residuals: -0.031\n",
      "Loss: 141.677, Residuals: -0.031\n",
      "Loss: 141.605, Residuals: -0.032\n",
      "Loss: 141.602, Residuals: -0.033\n",
      "Loss: 141.581, Residuals: -0.033\n",
      "Loss: 141.576, Residuals: -0.034\n",
      "Loss: 141.570, Residuals: -0.034\n",
      "Loss: 141.569, Residuals: -0.034\n",
      "Loss: 141.567, Residuals: -0.034\n",
      "Loss: 141.567, Residuals: -0.034\n",
      "Loss: 141.565, Residuals: -0.034\n",
      "Loss: 141.564, Residuals: -0.035\n",
      "Loss: 141.564, Residuals: -0.034\n",
      "Loss: 141.564, Residuals: -0.034\n",
      "Loss: 141.564, Residuals: -0.035\n",
      "Loss: 141.563, Residuals: -0.035\n",
      "Loss: 141.563, Residuals: -0.035\n",
      "Loss: 141.563, Residuals: -0.035\n",
      "Loss: 141.563, Residuals: -0.035\n",
      "Evidence 492.426\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.41e-01\n",
      "Loss: 151.193, Residuals: -0.032\n",
      "Loss: 151.062, Residuals: -0.037\n",
      "Loss: 151.052, Residuals: -0.039\n",
      "Loss: 151.033, Residuals: -0.039\n",
      "Loss: 151.000, Residuals: -0.039\n",
      "Loss: 150.980, Residuals: -0.040\n",
      "Loss: 150.974, Residuals: -0.040\n",
      "Loss: 150.967, Residuals: -0.041\n",
      "Loss: 150.956, Residuals: -0.041\n",
      "Loss: 150.956, Residuals: -0.041\n",
      "Loss: 150.953, Residuals: -0.042\n",
      "Loss: 150.952, Residuals: -0.042\n",
      "Loss: 150.951, Residuals: -0.042\n",
      "Loss: 150.950, Residuals: -0.042\n",
      "Evidence 496.039\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.51e-01\n",
      "Loss: 154.340, Residuals: -0.040\n",
      "Loss: 154.284, Residuals: -0.042\n",
      "Loss: 154.255, Residuals: -0.044\n",
      "Loss: 154.251, Residuals: -0.045\n",
      "Loss: 154.243, Residuals: -0.045\n",
      "Loss: 154.230, Residuals: -0.045\n",
      "Loss: 154.225, Residuals: -0.044\n",
      "Loss: 154.221, Residuals: -0.045\n",
      "Loss: 154.221, Residuals: -0.045\n",
      "Loss: 154.219, Residuals: -0.045\n",
      "Loss: 154.216, Residuals: -0.045\n",
      "Loss: 154.216, Residuals: -0.045\n",
      "Loss: 154.215, Residuals: -0.045\n",
      "Loss: 154.215, Residuals: -0.045\n",
      "Loss: 154.214, Residuals: -0.046\n",
      "Loss: 154.213, Residuals: -0.046\n",
      "Loss: 154.213, Residuals: -0.046\n",
      "Evidence 497.445\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.52e-01\n",
      "Loss: 155.482, Residuals: -0.044\n",
      "Loss: 155.457, Residuals: -0.045\n",
      "Loss: 155.440, Residuals: -0.047\n",
      "Loss: 155.435, Residuals: -0.047\n",
      "Loss: 155.433, Residuals: -0.047\n",
      "Loss: 155.429, Residuals: -0.047\n",
      "Loss: 155.424, Residuals: -0.047\n",
      "Loss: 155.423, Residuals: -0.047\n",
      "Loss: 155.422, Residuals: -0.047\n",
      "Loss: 155.421, Residuals: -0.048\n",
      "Loss: 155.421, Residuals: -0.047\n",
      "Evidence 498.171\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.53e-01\n",
      "Loss: 155.996, Residuals: -0.046\n",
      "Loss: 155.985, Residuals: -0.047\n",
      "Loss: 155.976, Residuals: -0.048\n",
      "Loss: 155.976, Residuals: -0.048\n",
      "Loss: 155.971, Residuals: -0.048\n",
      "Loss: 155.968, Residuals: -0.048\n",
      "Loss: 155.968, Residuals: -0.048\n",
      "Loss: 155.968, Residuals: -0.048\n",
      "Loss: 155.968, Residuals: -0.048\n",
      "Loss: 155.968, Residuals: -0.048\n",
      "Evidence 498.587\n",
      "Pass count  1\n",
      "Total samples: 37, Updated regularization: 1.00e-05\n",
      "Loss: 13.119, Residuals: -0.031\n",
      "Loss: 7.148, Residuals: -0.017\n",
      "Loss: 4.819, Residuals: -0.019\n",
      "Loss: 4.121, Residuals: -0.018\n",
      "Loss: 4.060, Residuals: -0.001\n",
      "Loss: 3.943, Residuals: -0.011\n",
      "Loss: 3.731, Residuals: -0.029\n",
      "Loss: 3.467, Residuals: -0.055\n",
      "Loss: 3.399, Residuals: -0.023\n",
      "Loss: 3.283, Residuals: -0.034\n",
      "Loss: 3.108, Residuals: -0.056\n",
      "Loss: 3.097, Residuals: -0.028\n",
      "Loss: 2.997, Residuals: -0.046\n",
      "Loss: 2.995, Residuals: -0.048\n",
      "Loss: 2.939, Residuals: -0.058\n",
      "Loss: 2.919, Residuals: -0.065\n",
      "Loss: 2.913, Residuals: -0.058\n",
      "Loss: 2.902, Residuals: -0.062\n",
      "Loss: 2.881, Residuals: -0.065\n",
      "Loss: 2.845, Residuals: -0.073\n",
      "Loss: 2.839, Residuals: -0.075\n",
      "Loss: 2.837, Residuals: -0.079\n",
      "Loss: 2.836, Residuals: -0.078\n",
      "Loss: 2.799, Residuals: -0.084\n",
      "Loss: 2.798, Residuals: -0.073\n",
      "Loss: 2.797, Residuals: -0.079\n",
      "Loss: 2.790, Residuals: -0.082\n",
      "Loss: 2.778, Residuals: -0.085\n",
      "Loss: 2.769, Residuals: -0.092\n",
      "Loss: 2.768, Residuals: -0.094\n",
      "Loss: 2.767, Residuals: -0.093\n",
      "Loss: 2.758, Residuals: -0.095\n",
      "Loss: 2.757, Residuals: -0.093\n",
      "Loss: 2.729, Residuals: -0.099\n",
      "Loss: 2.728, Residuals: -0.098\n",
      "Loss: 2.728, Residuals: -0.099\n",
      "Loss: 2.728, Residuals: -0.099\n",
      "Loss: 2.725, Residuals: -0.101\n",
      "Loss: 2.725, Residuals: -0.101\n",
      "Loss: 2.705, Residuals: -0.106\n",
      "Loss: 2.705, Residuals: -0.105\n",
      "Loss: 2.705, Residuals: -0.106\n",
      "Evidence -398.149\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.32e-03\n",
      "Loss: 12.058, Residuals: -0.100\n",
      "Loss: 12.048, Residuals: -0.101\n",
      "Loss: 12.047, Residuals: -0.100\n",
      "Loss: 12.046, Residuals: -0.100\n",
      "Loss: 12.036, Residuals: -0.097\n",
      "Loss: 12.021, Residuals: -0.090\n",
      "Loss: 11.990, Residuals: -0.088\n",
      "Loss: 11.938, Residuals: -0.083\n",
      "Loss: 11.938, Residuals: -0.082\n",
      "Loss: 11.914, Residuals: -0.080\n",
      "Loss: 11.873, Residuals: -0.075\n",
      "Loss: 11.851, Residuals: -0.065\n",
      "Loss: 11.851, Residuals: -0.065\n",
      "Evidence 79.639\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.31e-02\n",
      "Loss: 37.911, Residuals: -0.065\n",
      "Loss: 37.910, Residuals: -0.065\n",
      "Loss: 37.781, Residuals: -0.066\n",
      "Loss: 37.560, Residuals: -0.060\n",
      "Loss: 37.559, Residuals: -0.060\n",
      "Evidence 263.871\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 6.20e-02\n",
      "Loss: 78.355, Residuals: -0.060\n",
      "Loss: 78.180, Residuals: -0.061\n",
      "Loss: 77.902, Residuals: -0.061\n",
      "Loss: 77.455, Residuals: -0.056\n",
      "Loss: 76.795, Residuals: -0.053\n",
      "Loss: 76.759, Residuals: -0.054\n",
      "Loss: 75.505, Residuals: -0.044\n",
      "Loss: 75.495, Residuals: -0.044\n",
      "Loss: 75.486, Residuals: -0.045\n",
      "Loss: 75.472, Residuals: -0.046\n",
      "Loss: 75.341, Residuals: -0.044\n",
      "Loss: 75.105, Residuals: -0.041\n",
      "Loss: 75.079, Residuals: -0.038\n",
      "Loss: 74.844, Residuals: -0.037\n",
      "Loss: 74.457, Residuals: -0.033\n",
      "Loss: 74.447, Residuals: -0.034\n",
      "Loss: 74.430, Residuals: -0.034\n",
      "Loss: 74.290, Residuals: -0.032\n",
      "Loss: 74.246, Residuals: -0.028\n",
      "Loss: 74.172, Residuals: -0.028\n",
      "Loss: 74.167, Residuals: -0.027\n",
      "Loss: 74.120, Residuals: -0.027\n",
      "Loss: 74.120, Residuals: -0.027\n",
      "Loss: 74.053, Residuals: -0.027\n",
      "Loss: 74.052, Residuals: -0.027\n",
      "Loss: 73.999, Residuals: -0.027\n",
      "Loss: 73.994, Residuals: -0.027\n",
      "Loss: 73.989, Residuals: -0.025\n",
      "Loss: 73.981, Residuals: -0.027\n",
      "Loss: 73.980, Residuals: -0.026\n",
      "Loss: 73.732, Residuals: -0.027\n",
      "Loss: 73.696, Residuals: -0.022\n",
      "Loss: 73.640, Residuals: -0.024\n",
      "Loss: 73.629, Residuals: -0.024\n",
      "Loss: 73.256, Residuals: -0.025\n",
      "Loss: 73.240, Residuals: -0.024\n",
      "Loss: 73.211, Residuals: -0.025\n",
      "Loss: 73.160, Residuals: -0.025\n",
      "Loss: 73.149, Residuals: -0.026\n",
      "Loss: 73.130, Residuals: -0.026\n",
      "Loss: 73.100, Residuals: -0.026\n",
      "Loss: 73.099, Residuals: -0.027\n",
      "Loss: 73.088, Residuals: -0.026\n",
      "Loss: 72.968, Residuals: -0.030\n",
      "Loss: 72.951, Residuals: -0.027\n",
      "Loss: 72.943, Residuals: -0.027\n",
      "Loss: 72.832, Residuals: -0.029\n",
      "Loss: 72.817, Residuals: -0.026\n",
      "Loss: 72.789, Residuals: -0.025\n",
      "Loss: 72.740, Residuals: -0.024\n",
      "Loss: 72.736, Residuals: -0.024\n",
      "Loss: 72.697, Residuals: -0.022\n",
      "Loss: 72.696, Residuals: -0.023\n",
      "Loss: 72.668, Residuals: -0.022\n",
      "Loss: 72.641, Residuals: -0.021\n",
      "Loss: 72.637, Residuals: -0.021\n",
      "Loss: 72.630, Residuals: -0.021\n",
      "Loss: 72.628, Residuals: -0.021\n",
      "Loss: 72.625, Residuals: -0.021\n",
      "Loss: 72.620, Residuals: -0.020\n",
      "Loss: 72.620, Residuals: -0.020\n",
      "Loss: 72.620, Residuals: -0.020\n",
      "Loss: 72.620, Residuals: -0.020\n",
      "Loss: 72.617, Residuals: -0.020\n",
      "Loss: 72.613, Residuals: -0.020\n",
      "Loss: 72.613, Residuals: -0.020\n",
      "Loss: 72.612, Residuals: -0.020\n",
      "Loss: 72.611, Residuals: -0.019\n",
      "Loss: 72.611, Residuals: -0.019\n",
      "Loss: 72.611, Residuals: -0.019\n",
      "Loss: 72.611, Residuals: -0.019\n",
      "Loss: 72.611, Residuals: -0.019\n",
      "Loss: 72.611, Residuals: -0.019\n",
      "Loss: 72.611, Residuals: -0.019\n",
      "Loss: 72.610, Residuals: -0.019\n",
      "Loss: 72.610, Residuals: -0.019\n",
      "Evidence 372.315\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 5.60e-01\n",
      "Loss: 111.907, Residuals: -0.015\n",
      "Loss: 111.386, Residuals: -0.016\n",
      "Loss: 110.913, Residuals: -0.018\n",
      "Loss: 110.779, Residuals: -0.020\n",
      "Loss: 110.573, Residuals: -0.018\n",
      "Loss: 110.400, Residuals: -0.017\n",
      "Loss: 110.363, Residuals: -0.019\n",
      "Loss: 110.333, Residuals: -0.021\n",
      "Loss: 110.329, Residuals: -0.018\n",
      "Loss: 110.289, Residuals: -0.018\n",
      "Loss: 110.245, Residuals: -0.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 110.242, Residuals: -0.019\n",
      "Loss: 110.240, Residuals: -0.019\n",
      "Loss: 110.240, Residuals: -0.018\n",
      "Loss: 110.239, Residuals: -0.018\n",
      "Loss: 110.238, Residuals: -0.018\n",
      "Loss: 110.236, Residuals: -0.018\n",
      "Loss: 110.236, Residuals: -0.018\n",
      "Loss: 110.236, Residuals: -0.018\n",
      "Loss: 110.236, Residuals: -0.018\n",
      "Loss: 110.236, Residuals: -0.018\n",
      "Loss: 110.236, Residuals: -0.018\n",
      "Loss: 110.236, Residuals: -0.018\n",
      "Loss: 110.236, Residuals: -0.018\n",
      "Evidence 428.949\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 7.88e-01\n",
      "Loss: 133.215, Residuals: -0.016\n",
      "Loss: 132.882, Residuals: -0.022\n",
      "Loss: 132.660, Residuals: -0.020\n",
      "Loss: 132.616, Residuals: -0.022\n",
      "Loss: 132.560, Residuals: -0.021\n",
      "Loss: 132.556, Residuals: -0.021\n",
      "Loss: 132.521, Residuals: -0.021\n",
      "Loss: 132.490, Residuals: -0.021\n",
      "Loss: 132.488, Residuals: -0.021\n",
      "Loss: 132.486, Residuals: -0.022\n",
      "Loss: 132.483, Residuals: -0.022\n",
      "Loss: 132.482, Residuals: -0.021\n",
      "Loss: 132.482, Residuals: -0.021\n",
      "Loss: 132.482, Residuals: -0.021\n",
      "Loss: 132.481, Residuals: -0.021\n",
      "Loss: 132.481, Residuals: -0.021\n",
      "Loss: 132.481, Residuals: -0.021\n",
      "Loss: 132.481, Residuals: -0.021\n",
      "Loss: 132.480, Residuals: -0.021\n",
      "Loss: 132.480, Residuals: -0.021\n",
      "Evidence 443.845\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 8.81e-01\n",
      "Loss: 141.250, Residuals: -0.023\n",
      "Loss: 141.046, Residuals: -0.017\n",
      "Loss: 141.022, Residuals: -0.019\n",
      "Loss: 140.980, Residuals: -0.019\n",
      "Loss: 140.920, Residuals: -0.021\n",
      "Loss: 140.918, Residuals: -0.021\n",
      "Loss: 140.913, Residuals: -0.022\n",
      "Loss: 140.905, Residuals: -0.022\n",
      "Loss: 140.901, Residuals: -0.022\n",
      "Loss: 140.895, Residuals: -0.022\n",
      "Loss: 140.894, Residuals: -0.022\n",
      "Loss: 140.890, Residuals: -0.022\n",
      "Loss: 140.883, Residuals: -0.022\n",
      "Loss: 140.883, Residuals: -0.022\n",
      "Loss: 140.882, Residuals: -0.022\n",
      "Loss: 140.881, Residuals: -0.022\n",
      "Loss: 140.881, Residuals: -0.022\n",
      "Loss: 140.881, Residuals: -0.022\n",
      "Loss: 140.881, Residuals: -0.022\n",
      "Loss: 140.880, Residuals: -0.022\n",
      "Loss: 140.880, Residuals: -0.022\n",
      "Loss: 140.880, Residuals: -0.022\n",
      "Loss: 140.880, Residuals: -0.022\n",
      "Loss: 140.880, Residuals: -0.022\n",
      "Loss: 140.879, Residuals: -0.022\n",
      "Evidence 449.242\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 9.20e-01\n",
      "Loss: 143.971, Residuals: -0.019\n",
      "Loss: 143.863, Residuals: -0.018\n",
      "Loss: 143.842, Residuals: -0.019\n",
      "Loss: 143.818, Residuals: -0.020\n",
      "Loss: 143.811, Residuals: -0.019\n",
      "Loss: 143.801, Residuals: -0.019\n",
      "Loss: 143.800, Residuals: -0.020\n",
      "Loss: 143.795, Residuals: -0.020\n",
      "Loss: 143.792, Residuals: -0.020\n",
      "Loss: 143.791, Residuals: -0.020\n",
      "Loss: 143.791, Residuals: -0.020\n",
      "Loss: 143.791, Residuals: -0.020\n",
      "Loss: 143.790, Residuals: -0.020\n",
      "Loss: 143.790, Residuals: -0.020\n",
      "Evidence 451.929\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 9.34e-01\n",
      "Loss: 145.201, Residuals: -0.019\n",
      "Loss: 145.155, Residuals: -0.019\n",
      "Loss: 145.139, Residuals: -0.018\n",
      "Loss: 145.128, Residuals: -0.018\n",
      "Loss: 145.124, Residuals: -0.018\n",
      "Loss: 145.120, Residuals: -0.018\n",
      "Loss: 145.117, Residuals: -0.019\n",
      "Loss: 145.116, Residuals: -0.019\n",
      "Loss: 145.116, Residuals: -0.019\n",
      "Loss: 145.115, Residuals: -0.019\n",
      "Loss: 145.113, Residuals: -0.019\n",
      "Loss: 145.111, Residuals: -0.019\n",
      "Loss: 145.111, Residuals: -0.019\n",
      "Loss: 145.111, Residuals: -0.019\n",
      "Loss: 145.111, Residuals: -0.019\n",
      "Loss: 145.111, Residuals: -0.019\n",
      "Evidence 453.249\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.00e+00\n",
      "Loss: 145.788, Residuals: -0.016\n",
      "Loss: 145.763, Residuals: -0.017\n",
      "Loss: 145.753, Residuals: -0.017\n",
      "Loss: 145.748, Residuals: -0.017\n",
      "Loss: 145.746, Residuals: -0.016\n",
      "Loss: 145.745, Residuals: -0.017\n",
      "Loss: 145.744, Residuals: -0.017\n",
      "Loss: 145.741, Residuals: -0.017\n",
      "Loss: 145.741, Residuals: -0.017\n",
      "Loss: 145.736, Residuals: -0.017\n",
      "Loss: 145.735, Residuals: -0.017\n",
      "Loss: 145.735, Residuals: -0.017\n",
      "Loss: 145.735, Residuals: -0.017\n",
      "Loss: 145.735, Residuals: -0.017\n",
      "Loss: 145.733, Residuals: -0.017\n",
      "Loss: 145.733, Residuals: -0.017\n",
      "Loss: 145.733, Residuals: -0.017\n",
      "Loss: 145.733, Residuals: -0.017\n",
      "Loss: 145.732, Residuals: -0.017\n",
      "Loss: 145.732, Residuals: -0.017\n",
      "Loss: 145.732, Residuals: -0.017\n",
      "Loss: 145.732, Residuals: -0.017\n",
      "Evidence 454.035\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.07e+00\n",
      "Loss: 146.077, Residuals: -0.015\n",
      "Loss: 146.055, Residuals: -0.015\n",
      "Loss: 146.052, Residuals: -0.015\n",
      "Loss: 146.048, Residuals: -0.015\n",
      "Loss: 146.042, Residuals: -0.015\n",
      "Loss: 146.042, Residuals: -0.015\n",
      "Loss: 146.040, Residuals: -0.015\n",
      "Loss: 146.038, Residuals: -0.016\n",
      "Loss: 146.038, Residuals: -0.016\n",
      "Loss: 146.036, Residuals: -0.016\n",
      "Loss: 146.033, Residuals: -0.016\n",
      "Loss: 146.033, Residuals: -0.016\n",
      "Loss: 146.033, Residuals: -0.016\n",
      "Evidence 454.617\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.12e+00\n",
      "Loss: 146.224, Residuals: -0.014\n",
      "Loss: 146.207, Residuals: -0.015\n",
      "Loss: 146.200, Residuals: -0.014\n",
      "Loss: 146.196, Residuals: -0.014\n",
      "Loss: 146.195, Residuals: -0.014\n",
      "Loss: 146.193, Residuals: -0.014\n",
      "Loss: 146.193, Residuals: -0.014\n",
      "Loss: 146.190, Residuals: -0.014\n",
      "Loss: 146.189, Residuals: -0.014\n",
      "Loss: 146.187, Residuals: -0.014\n",
      "Loss: 146.185, Residuals: -0.014\n",
      "Loss: 146.185, Residuals: -0.014\n",
      "Evidence 455.070\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.304, Residuals: -0.060\n",
      "Loss: 7.784, Residuals: -0.040\n",
      "Loss: 4.991, Residuals: -0.026\n",
      "Loss: 4.266, Residuals: 0.006\n",
      "Loss: 3.997, Residuals: -0.027\n",
      "Loss: 3.925, Residuals: 0.020\n",
      "Loss: 3.788, Residuals: 0.005\n",
      "Loss: 3.544, Residuals: -0.013\n",
      "Loss: 3.497, Residuals: 0.024\n",
      "Loss: 3.408, Residuals: 0.006\n",
      "Loss: 3.256, Residuals: -0.013\n",
      "Loss: 3.129, Residuals: -0.025\n",
      "Loss: 3.117, Residuals: -0.042\n",
      "Loss: 3.092, Residuals: -0.047\n",
      "Loss: 3.050, Residuals: -0.054\n",
      "Loss: 3.038, Residuals: -0.047\n",
      "Loss: 3.016, Residuals: -0.051\n",
      "Loss: 2.977, Residuals: -0.058\n",
      "Loss: 2.976, Residuals: -0.052\n",
      "Loss: 2.929, Residuals: -0.062\n",
      "Loss: 2.926, Residuals: -0.057\n",
      "Loss: 2.921, Residuals: -0.058\n",
      "Loss: 2.912, Residuals: -0.059\n",
      "Loss: 2.909, Residuals: -0.057\n",
      "Loss: 2.884, Residuals: -0.063\n",
      "Loss: 2.883, Residuals: -0.059\n",
      "Loss: 2.875, Residuals: -0.061\n",
      "Loss: 2.860, Residuals: -0.067\n",
      "Loss: 2.857, Residuals: -0.071\n",
      "Loss: 2.857, Residuals: -0.072\n",
      "Evidence -411.182\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.19e-02\n",
      "Loss: 13.889, Residuals: -0.052\n",
      "Loss: 13.765, Residuals: -0.020\n",
      "Loss: 13.751, Residuals: -0.036\n",
      "Loss: 13.636, Residuals: -0.031\n",
      "Loss: 13.520, Residuals: -0.001\n",
      "Loss: 13.513, Residuals: -0.008\n",
      "Loss: 13.502, Residuals: -0.008\n",
      "Loss: 13.483, Residuals: -0.008\n",
      "Loss: 13.449, Residuals: -0.005\n",
      "Loss: 13.444, Residuals: -0.001\n",
      "Loss: 13.433, Residuals: -0.001\n",
      "Loss: 13.415, Residuals: 0.001\n",
      "Loss: 13.402, Residuals: 0.001\n",
      "Loss: 13.402, Residuals: 0.001\n",
      "Evidence 107.524\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.29e-01\n",
      "Loss: 43.159, Residuals: 0.000\n",
      "Loss: 43.076, Residuals: 0.002\n",
      "Loss: 42.948, Residuals: 0.004\n",
      "Loss: 42.848, Residuals: 0.014\n",
      "Loss: 42.818, Residuals: 0.014\n",
      "Loss: 42.763, Residuals: 0.014\n",
      "Loss: 42.681, Residuals: 0.016\n",
      "Loss: 42.675, Residuals: 0.016\n",
      "Loss: 42.663, Residuals: 0.016\n",
      "Loss: 42.642, Residuals: 0.017\n",
      "Loss: 42.611, Residuals: 0.017\n",
      "Loss: 42.610, Residuals: 0.017\n",
      "Loss: 42.608, Residuals: 0.017\n",
      "Loss: 42.606, Residuals: 0.017\n",
      "Loss: 42.588, Residuals: 0.017\n",
      "Loss: 42.588, Residuals: 0.017\n",
      "Loss: 42.583, Residuals: 0.017\n",
      "Loss: 42.575, Residuals: 0.016\n",
      "Loss: 42.573, Residuals: 0.017\n",
      "Loss: 42.572, Residuals: 0.017\n",
      "Loss: 42.570, Residuals: 0.017\n",
      "Loss: 42.567, Residuals: 0.016\n",
      "Loss: 42.567, Residuals: 0.016\n",
      "Loss: 42.567, Residuals: 0.017\n",
      "Loss: 42.566, Residuals: 0.017\n",
      "Loss: 42.564, Residuals: 0.016\n",
      "Loss: 42.563, Residuals: 0.016\n",
      "Loss: 42.563, Residuals: 0.016\n",
      "Loss: 42.563, Residuals: 0.016\n",
      "Loss: 42.563, Residuals: 0.016\n",
      "Loss: 42.563, Residuals: 0.016\n",
      "Loss: 42.563, Residuals: 0.016\n",
      "Evidence 304.836\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.89e-01\n",
      "Loss: 86.112, Residuals: 0.010\n",
      "Loss: 85.761, Residuals: 0.009\n",
      "Loss: 85.633, Residuals: 0.008\n",
      "Loss: 85.585, Residuals: 0.009\n",
      "Loss: 85.509, Residuals: 0.008\n",
      "Loss: 85.410, Residuals: 0.008\n",
      "Loss: 85.404, Residuals: 0.007\n",
      "Loss: 85.392, Residuals: 0.007\n",
      "Loss: 85.372, Residuals: 0.007\n",
      "Loss: 85.371, Residuals: 0.007\n",
      "Loss: 85.348, Residuals: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 85.347, Residuals: 0.007\n",
      "Loss: 85.324, Residuals: 0.007\n",
      "Loss: 85.323, Residuals: 0.007\n",
      "Loss: 85.321, Residuals: 0.006\n",
      "Loss: 85.270, Residuals: 0.007\n",
      "Loss: 85.264, Residuals: 0.006\n",
      "Loss: 85.260, Residuals: 0.007\n",
      "Loss: 85.256, Residuals: 0.006\n",
      "Loss: 85.255, Residuals: 0.006\n",
      "Loss: 85.213, Residuals: 0.006\n",
      "Loss: 85.203, Residuals: 0.006\n",
      "Loss: 85.197, Residuals: 0.006\n",
      "Loss: 85.190, Residuals: 0.006\n",
      "Loss: 85.186, Residuals: 0.006\n",
      "Loss: 84.796, Residuals: 0.006\n",
      "Loss: 84.729, Residuals: 0.009\n",
      "Loss: 84.691, Residuals: 0.009\n",
      "Loss: 84.635, Residuals: 0.008\n",
      "Loss: 84.599, Residuals: 0.006\n",
      "Loss: 84.593, Residuals: 0.006\n",
      "Loss: 84.585, Residuals: 0.006\n",
      "Loss: 84.572, Residuals: 0.006\n",
      "Loss: 84.552, Residuals: 0.006\n",
      "Loss: 84.550, Residuals: 0.006\n",
      "Loss: 84.547, Residuals: 0.006\n",
      "Loss: 84.546, Residuals: 0.006\n",
      "Loss: 84.540, Residuals: 0.006\n",
      "Loss: 84.540, Residuals: 0.006\n",
      "Loss: 84.530, Residuals: 0.007\n",
      "Loss: 84.530, Residuals: 0.006\n",
      "Loss: 84.526, Residuals: 0.007\n",
      "Loss: 84.526, Residuals: 0.007\n",
      "Loss: 84.523, Residuals: 0.007\n",
      "Loss: 84.523, Residuals: 0.007\n",
      "Loss: 84.521, Residuals: 0.007\n",
      "Loss: 84.521, Residuals: 0.007\n",
      "Loss: 84.521, Residuals: 0.007\n",
      "Loss: 84.520, Residuals: 0.008\n",
      "Loss: 84.520, Residuals: 0.008\n",
      "Loss: 84.520, Residuals: 0.008\n",
      "Evidence 421.716\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.48e+00\n",
      "Loss: 122.641, Residuals: 0.019\n",
      "Loss: 122.115, Residuals: 0.012\n",
      "Loss: 121.919, Residuals: 0.001\n",
      "Loss: 121.702, Residuals: 0.002\n",
      "Loss: 121.684, Residuals: 0.004\n",
      "Loss: 121.651, Residuals: 0.004\n",
      "Loss: 121.595, Residuals: 0.004\n",
      "Loss: 121.591, Residuals: 0.004\n",
      "Loss: 121.563, Residuals: 0.004\n",
      "Loss: 121.539, Residuals: 0.004\n",
      "Loss: 121.538, Residuals: 0.004\n",
      "Loss: 121.537, Residuals: 0.004\n",
      "Loss: 121.535, Residuals: 0.004\n",
      "Loss: 121.533, Residuals: 0.004\n",
      "Loss: 121.533, Residuals: 0.004\n",
      "Loss: 121.532, Residuals: 0.004\n",
      "Loss: 121.532, Residuals: 0.004\n",
      "Loss: 121.532, Residuals: 0.004\n",
      "Loss: 121.532, Residuals: 0.004\n",
      "Loss: 121.532, Residuals: 0.004\n",
      "Loss: 121.532, Residuals: 0.004\n",
      "Evidence 470.101\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.05e+00\n",
      "Loss: 143.172, Residuals: 0.016\n",
      "Loss: 142.758, Residuals: 0.011\n",
      "Loss: 142.566, Residuals: 0.002\n",
      "Loss: 142.511, Residuals: 0.008\n",
      "Loss: 142.435, Residuals: 0.006\n",
      "Loss: 142.337, Residuals: 0.005\n",
      "Loss: 142.332, Residuals: 0.005\n",
      "Loss: 142.323, Residuals: 0.005\n",
      "Loss: 142.309, Residuals: 0.004\n",
      "Loss: 142.303, Residuals: 0.004\n",
      "Loss: 142.293, Residuals: 0.004\n",
      "Loss: 142.292, Residuals: 0.004\n",
      "Loss: 142.287, Residuals: 0.004\n",
      "Loss: 142.287, Residuals: 0.004\n",
      "Loss: 142.286, Residuals: 0.004\n",
      "Loss: 142.284, Residuals: 0.004\n",
      "Loss: 142.284, Residuals: 0.004\n",
      "Loss: 142.284, Residuals: 0.004\n",
      "Loss: 142.284, Residuals: 0.004\n",
      "Loss: 142.283, Residuals: 0.004\n",
      "Loss: 142.283, Residuals: 0.004\n",
      "Loss: 142.283, Residuals: 0.004\n",
      "Loss: 142.283, Residuals: 0.004\n",
      "Loss: 142.283, Residuals: 0.004\n",
      "Loss: 142.283, Residuals: 0.004\n",
      "Loss: 142.283, Residuals: 0.004\n",
      "Evidence 484.383\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.24e+00\n",
      "Loss: 150.461, Residuals: 0.011\n",
      "Loss: 150.355, Residuals: 0.005\n",
      "Loss: 150.252, Residuals: 0.007\n",
      "Loss: 150.172, Residuals: 0.008\n",
      "Loss: 150.087, Residuals: 0.007\n",
      "Loss: 150.070, Residuals: 0.007\n",
      "Loss: 150.065, Residuals: 0.007\n",
      "Loss: 150.062, Residuals: 0.007\n",
      "Loss: 150.056, Residuals: 0.007\n",
      "Loss: 150.056, Residuals: 0.007\n",
      "Loss: 150.050, Residuals: 0.007\n",
      "Loss: 150.045, Residuals: 0.007\n",
      "Loss: 150.044, Residuals: 0.007\n",
      "Loss: 150.044, Residuals: 0.007\n",
      "Loss: 150.044, Residuals: 0.007\n",
      "Loss: 150.044, Residuals: 0.007\n",
      "Loss: 150.044, Residuals: 0.007\n",
      "Loss: 150.044, Residuals: 0.007\n",
      "Loss: 150.044, Residuals: 0.007\n",
      "Loss: 150.044, Residuals: 0.007\n",
      "Evidence 489.669\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.23e+00\n",
      "Loss: 153.297, Residuals: 0.011\n",
      "Loss: 153.188, Residuals: 0.010\n",
      "Loss: 153.171, Residuals: 0.010\n",
      "Loss: 153.146, Residuals: 0.010\n",
      "Loss: 153.110, Residuals: 0.010\n",
      "Loss: 153.105, Residuals: 0.010\n",
      "Loss: 153.097, Residuals: 0.010\n",
      "Loss: 153.097, Residuals: 0.010\n",
      "Loss: 153.093, Residuals: 0.010\n",
      "Loss: 153.091, Residuals: 0.010\n",
      "Loss: 153.090, Residuals: 0.010\n",
      "Loss: 153.090, Residuals: 0.010\n",
      "Loss: 153.090, Residuals: 0.010\n",
      "Loss: 153.090, Residuals: 0.010\n",
      "Loss: 153.090, Residuals: 0.010\n",
      "Evidence 492.293\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.16e+00\n",
      "Loss: 154.753, Residuals: 0.013\n",
      "Loss: 154.685, Residuals: 0.012\n",
      "Loss: 154.663, Residuals: 0.012\n",
      "Loss: 154.658, Residuals: 0.013\n",
      "Loss: 154.650, Residuals: 0.013\n",
      "Loss: 154.639, Residuals: 0.012\n",
      "Loss: 154.638, Residuals: 0.012\n",
      "Loss: 154.634, Residuals: 0.012\n",
      "Loss: 154.634, Residuals: 0.012\n",
      "Loss: 154.632, Residuals: 0.012\n",
      "Loss: 154.632, Residuals: 0.012\n",
      "Loss: 154.631, Residuals: 0.012\n",
      "Evidence 493.624\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.10e+00\n",
      "Loss: 155.533, Residuals: 0.013\n",
      "Loss: 155.511, Residuals: 0.014\n",
      "Loss: 155.504, Residuals: 0.014\n",
      "Loss: 155.493, Residuals: 0.014\n",
      "Loss: 155.492, Residuals: 0.014\n",
      "Loss: 155.488, Residuals: 0.014\n",
      "Loss: 155.484, Residuals: 0.013\n",
      "Loss: 155.483, Residuals: 0.014\n",
      "Loss: 155.483, Residuals: 0.014\n",
      "Loss: 155.483, Residuals: 0.013\n",
      "Loss: 155.483, Residuals: 0.013\n",
      "Loss: 155.483, Residuals: 0.013\n",
      "Loss: 155.483, Residuals: 0.013\n",
      "Loss: 155.482, Residuals: 0.013\n",
      "Evidence 494.371\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.02e+00\n",
      "Loss: 155.983, Residuals: 0.014\n",
      "Loss: 155.972, Residuals: 0.014\n",
      "Loss: 155.970, Residuals: 0.015\n",
      "Loss: 155.966, Residuals: 0.015\n",
      "Loss: 155.959, Residuals: 0.014\n",
      "Loss: 155.949, Residuals: 0.014\n",
      "Loss: 155.949, Residuals: 0.014\n",
      "Loss: 155.949, Residuals: 0.014\n",
      "Loss: 155.948, Residuals: 0.014\n",
      "Loss: 155.947, Residuals: 0.014\n",
      "Loss: 155.947, Residuals: 0.014\n",
      "Loss: 155.947, Residuals: 0.014\n",
      "Loss: 155.947, Residuals: 0.014\n",
      "Loss: 155.946, Residuals: 0.014\n",
      "Loss: 155.946, Residuals: 0.014\n",
      "Evidence 494.852\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.788, Residuals: -0.070\n",
      "Loss: 6.743, Residuals: -0.045\n",
      "Loss: 4.530, Residuals: -0.031\n",
      "Loss: 3.947, Residuals: -0.012\n",
      "Loss: 3.749, Residuals: -0.055\n",
      "Loss: 3.526, Residuals: 0.023\n",
      "Loss: 3.516, Residuals: 0.029\n",
      "Loss: 3.159, Residuals: 0.011\n",
      "Loss: 3.116, Residuals: 0.048\n",
      "Loss: 3.038, Residuals: 0.033\n",
      "Loss: 2.899, Residuals: 0.011\n",
      "Loss: 2.674, Residuals: -0.011\n",
      "Loss: 2.628, Residuals: 0.018\n",
      "Loss: 2.548, Residuals: 0.004\n",
      "Loss: 2.425, Residuals: -0.016\n",
      "Loss: 2.417, Residuals: -0.008\n",
      "Loss: 2.403, Residuals: -0.009\n",
      "Loss: 2.379, Residuals: -0.015\n",
      "Loss: 2.339, Residuals: -0.024\n",
      "Loss: 2.334, Residuals: -0.007\n",
      "Loss: 2.327, Residuals: -0.017\n",
      "Loss: 2.315, Residuals: -0.021\n",
      "Loss: 2.293, Residuals: -0.028\n",
      "Loss: 2.290, Residuals: -0.025\n",
      "Loss: 2.288, Residuals: -0.028\n",
      "Loss: 2.273, Residuals: -0.033\n",
      "Loss: 2.272, Residuals: -0.033\n",
      "Loss: 2.258, Residuals: -0.037\n",
      "Loss: 2.253, Residuals: -0.034\n",
      "Loss: 2.242, Residuals: -0.038\n",
      "Loss: 2.241, Residuals: -0.037\n",
      "Loss: 2.229, Residuals: -0.040\n",
      "Loss: 2.218, Residuals: -0.044\n",
      "Loss: 2.217, Residuals: -0.040\n",
      "Loss: 2.194, Residuals: -0.047\n",
      "Loss: 2.194, Residuals: -0.047\n",
      "Loss: 2.187, Residuals: -0.047\n",
      "Loss: 2.174, Residuals: -0.050\n",
      "Loss: 2.173, Residuals: -0.044\n",
      "Loss: 2.147, Residuals: -0.054\n",
      "Loss: 2.146, Residuals: -0.055\n",
      "Loss: 2.146, Residuals: -0.056\n",
      "Loss: 2.145, Residuals: -0.056\n",
      "Loss: 2.143, Residuals: -0.056\n",
      "Loss: 2.140, Residuals: -0.056\n",
      "Loss: 2.135, Residuals: -0.057\n",
      "Loss: 2.133, Residuals: -0.057\n",
      "Loss: 2.133, Residuals: -0.054\n",
      "Loss: 2.126, Residuals: -0.057\n",
      "Loss: 2.113, Residuals: -0.062\n",
      "Loss: 2.113, Residuals: -0.061\n",
      "Loss: 2.105, Residuals: -0.062\n",
      "Loss: 2.104, Residuals: -0.059\n",
      "Loss: 2.098, Residuals: -0.060\n",
      "Loss: 2.098, Residuals: -0.058\n",
      "Loss: 2.092, Residuals: -0.060\n",
      "Loss: 2.092, Residuals: -0.060\n",
      "Loss: 2.084, Residuals: -0.062\n",
      "Loss: 2.084, Residuals: -0.062\n",
      "Loss: 2.083, Residuals: -0.063\n",
      "Loss: 2.074, Residuals: -0.064\n",
      "Loss: 2.074, Residuals: -0.063\n",
      "Loss: 2.074, Residuals: -0.063\n",
      "Loss: 2.060, Residuals: -0.067\n",
      "Loss: 2.060, Residuals: -0.067\n",
      "Loss: 2.060, Residuals: -0.067\n",
      "Loss: 2.059, Residuals: -0.066\n",
      "Loss: 2.059, Residuals: -0.064\n",
      "Loss: 2.054, Residuals: -0.066\n",
      "Loss: 2.054, Residuals: -0.066\n",
      "Evidence -403.962\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 5.21e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.007, Residuals: -0.063\n",
      "Loss: 10.948, Residuals: -0.043\n",
      "Loss: 10.855, Residuals: -0.041\n",
      "Loss: 10.781, Residuals: -0.039\n",
      "Loss: 10.781, Residuals: -0.039\n",
      "Loss: 10.671, Residuals: -0.035\n",
      "Loss: 10.521, Residuals: -0.022\n",
      "Loss: 10.517, Residuals: -0.023\n",
      "Loss: 10.513, Residuals: -0.020\n",
      "Loss: 10.467, Residuals: -0.018\n",
      "Loss: 10.416, Residuals: -0.009\n",
      "Loss: 10.413, Residuals: -0.012\n",
      "Loss: 10.408, Residuals: -0.012\n",
      "Loss: 10.399, Residuals: -0.011\n",
      "Loss: 10.397, Residuals: -0.008\n",
      "Loss: 10.381, Residuals: -0.007\n",
      "Loss: 10.381, Residuals: -0.008\n",
      "Loss: 10.360, Residuals: -0.007\n",
      "Loss: 10.359, Residuals: -0.006\n",
      "Loss: 10.349, Residuals: -0.005\n",
      "Loss: 10.332, Residuals: -0.003\n",
      "Loss: 10.331, Residuals: -0.003\n",
      "Loss: 10.331, Residuals: -0.003\n",
      "Evidence 98.607\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.42e-02\n",
      "Loss: 38.775, Residuals: -0.003\n",
      "Loss: 38.768, Residuals: -0.003\n",
      "Loss: 38.701, Residuals: -0.002\n",
      "Loss: 38.585, Residuals: -0.001\n",
      "Loss: 38.436, Residuals: 0.002\n",
      "Loss: 38.333, Residuals: 0.003\n",
      "Loss: 38.304, Residuals: 0.003\n",
      "Loss: 38.058, Residuals: 0.007\n",
      "Loss: 38.054, Residuals: 0.007\n",
      "Loss: 38.054, Residuals: 0.007\n",
      "Evidence 295.443\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.16e-01\n",
      "Loss: 85.438, Residuals: 0.008\n",
      "Loss: 85.396, Residuals: 0.010\n",
      "Loss: 85.317, Residuals: 0.008\n",
      "Loss: 85.194, Residuals: 0.005\n",
      "Loss: 85.087, Residuals: 0.003\n",
      "Loss: 84.172, Residuals: 0.004\n",
      "Loss: 84.169, Residuals: 0.004\n",
      "Loss: 84.142, Residuals: 0.004\n",
      "Loss: 84.091, Residuals: 0.004\n",
      "Loss: 83.707, Residuals: 0.007\n",
      "Loss: 83.706, Residuals: 0.007\n",
      "Evidence 397.707\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.07e-01\n",
      "Loss: 124.165, Residuals: 0.008\n",
      "Loss: 124.065, Residuals: 0.007\n",
      "Loss: 123.912, Residuals: 0.006\n",
      "Loss: 123.674, Residuals: 0.004\n",
      "Loss: 123.249, Residuals: 0.005\n",
      "Loss: 122.612, Residuals: 0.006\n",
      "Loss: 122.609, Residuals: 0.006\n",
      "Loss: 122.603, Residuals: 0.005\n",
      "Loss: 122.594, Residuals: 0.004\n",
      "Loss: 122.278, Residuals: 0.005\n",
      "Loss: 122.275, Residuals: 0.006\n",
      "Loss: 122.158, Residuals: 0.006\n",
      "Loss: 122.158, Residuals: 0.006\n",
      "Evidence 430.548\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.62e-01\n",
      "Loss: 141.627, Residuals: 0.006\n",
      "Evidence 437.448\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.76e-01\n",
      "Loss: 148.310, Residuals: 0.005\n",
      "Loss: 148.008, Residuals: 0.001\n",
      "Loss: 148.007, Residuals: 0.001\n",
      "Evidence 439.179\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.80e-01\n",
      "Loss: 149.278, Residuals: 0.003\n",
      "Loss: 149.255, Residuals: 0.004\n",
      "Loss: 149.231, Residuals: 0.002\n",
      "Loss: 149.011, Residuals: 0.002\n",
      "Loss: 149.011, Residuals: 0.002\n",
      "Evidence 440.403\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.96e-01\n",
      "Loss: 150.027, Residuals: 0.002\n",
      "Evidence 441.144\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.97e-01\n",
      "Loss: 150.649, Residuals: 0.001\n",
      "Loss: 150.635, Residuals: 0.002\n",
      "Loss: 150.520, Residuals: 0.003\n",
      "Loss: 150.516, Residuals: 0.003\n",
      "Loss: 150.066, Residuals: 0.002\n",
      "Loss: 149.965, Residuals: 0.002\n",
      "Loss: 149.961, Residuals: 0.002\n",
      "Loss: 149.957, Residuals: 0.002\n",
      "Loss: 149.925, Residuals: 0.002\n",
      "Loss: 149.916, Residuals: 0.000\n",
      "Loss: 148.608, Residuals: 0.000\n",
      "Loss: 148.550, Residuals: 0.001\n",
      "Loss: 148.535, Residuals: 0.000\n",
      "Loss: 148.508, Residuals: -0.001\n",
      "Loss: 148.459, Residuals: -0.000\n",
      "Loss: 148.372, Residuals: -0.000\n",
      "Loss: 148.339, Residuals: -0.002\n",
      "Loss: 148.275, Residuals: -0.001\n",
      "Loss: 148.157, Residuals: -0.001\n",
      "Loss: 148.152, Residuals: -0.002\n",
      "Loss: 147.497, Residuals: -0.000\n",
      "Loss: 147.428, Residuals: -0.001\n",
      "Loss: 147.297, Residuals: -0.001\n",
      "Loss: 147.046, Residuals: -0.001\n",
      "Loss: 146.829, Residuals: 0.000\n",
      "Loss: 146.825, Residuals: -0.000\n",
      "Loss: 146.657, Residuals: 0.000\n",
      "Loss: 146.644, Residuals: 0.000\n",
      "Loss: 146.522, Residuals: 0.001\n",
      "Loss: 146.513, Residuals: 0.000\n",
      "Loss: 146.433, Residuals: 0.001\n",
      "Loss: 146.432, Residuals: 0.000\n",
      "Loss: 146.389, Residuals: 0.000\n",
      "Loss: 146.312, Residuals: 0.001\n",
      "Loss: 146.303, Residuals: -0.000\n",
      "Loss: 146.228, Residuals: 0.000\n",
      "Loss: 146.219, Residuals: 0.000\n",
      "Loss: 146.203, Residuals: 0.000\n",
      "Loss: 146.195, Residuals: 0.001\n",
      "Loss: 146.181, Residuals: 0.001\n",
      "Loss: 146.179, Residuals: -0.000\n",
      "Loss: 146.168, Residuals: 0.000\n",
      "Loss: 146.167, Residuals: 0.000\n",
      "Loss: 146.056, Residuals: 0.002\n",
      "Loss: 146.047, Residuals: 0.001\n",
      "Loss: 146.041, Residuals: 0.001\n",
      "Loss: 145.986, Residuals: 0.002\n",
      "Loss: 145.982, Residuals: 0.001\n",
      "Loss: 145.839, Residuals: 0.006\n",
      "Loss: 145.825, Residuals: 0.005\n",
      "Loss: 145.820, Residuals: 0.006\n",
      "Loss: 145.813, Residuals: 0.006\n",
      "Loss: 145.800, Residuals: 0.006\n",
      "Loss: 145.780, Residuals: 0.007\n",
      "Loss: 145.739, Residuals: 0.009\n",
      "Loss: 145.738, Residuals: 0.009\n",
      "Loss: 145.735, Residuals: 0.009\n",
      "Loss: 145.731, Residuals: 0.009\n",
      "Loss: 145.722, Residuals: 0.009\n",
      "Loss: 145.708, Residuals: 0.009\n",
      "Loss: 145.708, Residuals: 0.009\n",
      "Loss: 145.707, Residuals: 0.009\n",
      "Loss: 145.698, Residuals: 0.009\n",
      "Loss: 145.698, Residuals: 0.009\n",
      "Loss: 145.697, Residuals: 0.010\n",
      "Loss: 145.695, Residuals: 0.010\n",
      "Loss: 145.695, Residuals: 0.010\n",
      "Loss: 145.694, Residuals: 0.010\n",
      "Loss: 145.694, Residuals: 0.010\n",
      "Evidence 440.966\n",
      "Pass count  1\n",
      "Fail count  1\n",
      "Total samples: 37, Updated regularization: 1.00e-05\n",
      "Loss: 12.358, Residuals: -0.034\n",
      "Loss: 6.880, Residuals: -0.015\n",
      "Loss: 5.583, Residuals: -0.023\n",
      "Loss: 4.389, Residuals: 0.011\n",
      "Loss: 3.724, Residuals: -0.010\n",
      "Loss: 3.528, Residuals: -0.003\n",
      "Loss: 3.284, Residuals: -0.016\n",
      "Loss: 3.266, Residuals: 0.001\n",
      "Loss: 3.111, Residuals: -0.013\n",
      "Loss: 3.014, Residuals: -0.010\n",
      "Loss: 2.963, Residuals: -0.007\n",
      "Loss: 2.875, Residuals: -0.019\n",
      "Loss: 2.846, Residuals: -0.015\n",
      "Loss: 2.795, Residuals: -0.022\n",
      "Loss: 2.709, Residuals: -0.032\n",
      "Loss: 2.708, Residuals: -0.028\n",
      "Loss: 2.695, Residuals: -0.024\n",
      "Loss: 2.672, Residuals: -0.023\n",
      "Loss: 2.658, Residuals: -0.018\n",
      "Loss: 2.633, Residuals: -0.024\n",
      "Loss: 2.588, Residuals: -0.031\n",
      "Loss: 2.587, Residuals: -0.032\n",
      "Loss: 2.580, Residuals: -0.026\n",
      "Loss: 2.526, Residuals: -0.034\n",
      "Loss: 2.525, Residuals: -0.036\n",
      "Loss: 2.523, Residuals: -0.034\n",
      "Loss: 2.510, Residuals: -0.029\n",
      "Loss: 2.508, Residuals: -0.023\n",
      "Loss: 2.490, Residuals: -0.027\n",
      "Loss: 2.459, Residuals: -0.033\n",
      "Loss: 2.459, Residuals: -0.034\n",
      "Loss: 2.455, Residuals: -0.031\n",
      "Loss: 2.427, Residuals: -0.037\n",
      "Loss: 2.426, Residuals: -0.038\n",
      "Loss: 2.425, Residuals: -0.031\n",
      "Loss: 2.416, Residuals: -0.032\n",
      "Loss: 2.416, Residuals: -0.032\n",
      "Loss: 2.414, Residuals: -0.030\n",
      "Loss: 2.402, Residuals: -0.034\n",
      "Loss: 2.402, Residuals: -0.034\n",
      "Loss: 2.396, Residuals: -0.035\n",
      "Loss: 2.396, Residuals: -0.034\n",
      "Loss: 2.389, Residuals: -0.036\n",
      "Loss: 2.389, Residuals: -0.034\n",
      "Loss: 2.388, Residuals: -0.033\n",
      "Loss: 2.376, Residuals: -0.038\n",
      "Loss: 2.376, Residuals: -0.038\n",
      "Loss: 2.376, Residuals: -0.038\n",
      "Loss: 2.371, Residuals: -0.038\n",
      "Loss: 2.371, Residuals: -0.034\n",
      "Loss: 2.370, Residuals: -0.034\n",
      "Loss: 2.364, Residuals: -0.037\n",
      "Loss: 2.364, Residuals: -0.037\n",
      "Loss: 2.353, Residuals: -0.041\n",
      "Loss: 2.353, Residuals: -0.042\n",
      "Loss: 2.352, Residuals: -0.042\n",
      "Loss: 2.351, Residuals: -0.042\n",
      "Loss: 2.350, Residuals: -0.040\n",
      "Loss: 2.349, Residuals: -0.037\n",
      "Loss: 2.340, Residuals: -0.042\n",
      "Loss: 2.340, Residuals: -0.042\n",
      "Loss: 2.340, Residuals: -0.042\n",
      "Loss: 2.338, Residuals: -0.042\n",
      "Loss: 2.335, Residuals: -0.040\n",
      "Loss: 2.335, Residuals: -0.037\n",
      "Loss: 2.331, Residuals: -0.038\n",
      "Loss: 2.330, Residuals: -0.037\n",
      "Loss: 2.330, Residuals: -0.037\n",
      "Evidence -385.043\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 9.01e-03\n",
      "Loss: 10.246, Residuals: -0.049\n",
      "Loss: 10.215, Residuals: -0.047\n",
      "Loss: 10.180, Residuals: -0.035\n",
      "Loss: 10.118, Residuals: -0.030\n",
      "Loss: 10.110, Residuals: -0.033\n",
      "Loss: 10.046, Residuals: -0.027\n",
      "Loss: 10.024, Residuals: -0.022\n",
      "Loss: 10.023, Residuals: -0.022\n",
      "Loss: 10.021, Residuals: -0.023\n",
      "Loss: 10.016, Residuals: -0.024\n",
      "Loss: 10.008, Residuals: -0.023\n",
      "Loss: 9.993, Residuals: -0.021\n",
      "Loss: 9.972, Residuals: -0.014\n",
      "Loss: 9.971, Residuals: -0.014\n",
      "Loss: 9.969, Residuals: -0.014\n",
      "Loss: 9.966, Residuals: -0.015\n",
      "Loss: 9.966, Residuals: -0.015\n",
      "Loss: 9.965, Residuals: -0.015\n",
      "Loss: 9.963, Residuals: -0.015\n",
      "Loss: 9.959, Residuals: -0.014\n",
      "Loss: 9.959, Residuals: -0.014\n",
      "Loss: 9.959, Residuals: -0.014\n",
      "Loss: 9.958, Residuals: -0.014\n",
      "Loss: 9.958, Residuals: -0.014\n",
      "Loss: 9.958, Residuals: -0.014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.956, Residuals: -0.014\n",
      "Loss: 9.954, Residuals: -0.013\n",
      "Loss: 9.954, Residuals: -0.013\n",
      "Loss: 9.952, Residuals: -0.014\n",
      "Loss: 9.952, Residuals: -0.013\n",
      "Loss: 9.952, Residuals: -0.013\n",
      "Loss: 9.952, Residuals: -0.014\n",
      "Loss: 9.951, Residuals: -0.014\n",
      "Loss: 9.950, Residuals: -0.014\n",
      "Loss: 9.950, Residuals: -0.014\n",
      "Loss: 9.950, Residuals: -0.014\n",
      "Loss: 9.950, Residuals: -0.014\n",
      "Loss: 9.950, Residuals: -0.014\n",
      "Loss: 9.948, Residuals: -0.014\n",
      "Loss: 9.948, Residuals: -0.014\n",
      "Evidence 71.964\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 6.68e-02\n",
      "Loss: 34.865, Residuals: -0.008\n",
      "Loss: 34.804, Residuals: -0.008\n",
      "Loss: 34.788, Residuals: -0.009\n",
      "Loss: 34.642, Residuals: -0.007\n",
      "Loss: 34.513, Residuals: -0.004\n",
      "Loss: 34.508, Residuals: -0.009\n",
      "Loss: 34.459, Residuals: -0.007\n",
      "Loss: 34.376, Residuals: -0.005\n",
      "Loss: 34.363, Residuals: -0.002\n",
      "Loss: 34.339, Residuals: -0.001\n",
      "Loss: 34.299, Residuals: 0.000\n",
      "Loss: 34.286, Residuals: -0.000\n",
      "Loss: 34.286, Residuals: -0.001\n",
      "Loss: 34.266, Residuals: -0.001\n",
      "Loss: 34.236, Residuals: 0.001\n",
      "Loss: 34.234, Residuals: 0.003\n",
      "Loss: 34.231, Residuals: 0.003\n",
      "Loss: 34.203, Residuals: 0.003\n",
      "Loss: 34.201, Residuals: 0.003\n",
      "Loss: 34.186, Residuals: 0.003\n",
      "Loss: 34.185, Residuals: 0.003\n",
      "Loss: 34.175, Residuals: 0.004\n",
      "Loss: 34.174, Residuals: 0.004\n",
      "Loss: 34.167, Residuals: 0.004\n",
      "Loss: 34.165, Residuals: 0.004\n",
      "Loss: 34.165, Residuals: 0.004\n",
      "Loss: 34.157, Residuals: 0.005\n",
      "Loss: 34.156, Residuals: 0.005\n",
      "Loss: 34.152, Residuals: 0.005\n",
      "Loss: 34.147, Residuals: 0.006\n",
      "Loss: 34.146, Residuals: 0.006\n",
      "Loss: 34.145, Residuals: 0.006\n",
      "Loss: 34.145, Residuals: 0.006\n",
      "Loss: 34.140, Residuals: 0.006\n",
      "Loss: 34.134, Residuals: 0.007\n",
      "Loss: 34.133, Residuals: 0.007\n",
      "Loss: 34.133, Residuals: 0.007\n",
      "Loss: 34.132, Residuals: 0.007\n",
      "Loss: 34.132, Residuals: 0.007\n",
      "Loss: 34.131, Residuals: 0.007\n",
      "Loss: 34.131, Residuals: 0.007\n",
      "Loss: 34.129, Residuals: 0.007\n",
      "Loss: 34.129, Residuals: 0.007\n",
      "Loss: 34.128, Residuals: 0.008\n",
      "Loss: 34.128, Residuals: 0.008\n",
      "Loss: 34.128, Residuals: 0.008\n",
      "Loss: 34.128, Residuals: 0.008\n",
      "Loss: 34.127, Residuals: 0.008\n",
      "Loss: 34.127, Residuals: 0.008\n",
      "Loss: 34.126, Residuals: 0.008\n",
      "Loss: 34.126, Residuals: 0.008\n",
      "Loss: 34.126, Residuals: 0.008\n",
      "Loss: 34.126, Residuals: 0.008\n",
      "Evidence 260.989\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 3.81e-01\n",
      "Loss: 75.256, Residuals: 0.004\n",
      "Loss: 75.087, Residuals: 0.008\n",
      "Loss: 74.795, Residuals: 0.009\n",
      "Loss: 74.767, Residuals: 0.007\n",
      "Loss: 74.519, Residuals: 0.008\n",
      "Loss: 74.126, Residuals: 0.012\n",
      "Loss: 74.037, Residuals: 0.011\n",
      "Loss: 73.929, Residuals: 0.007\n",
      "Loss: 73.764, Residuals: 0.010\n",
      "Loss: 73.746, Residuals: 0.012\n",
      "Loss: 73.712, Residuals: 0.012\n",
      "Loss: 73.651, Residuals: 0.013\n",
      "Loss: 73.629, Residuals: 0.014\n",
      "Loss: 73.589, Residuals: 0.014\n",
      "Loss: 73.522, Residuals: 0.016\n",
      "Loss: 73.512, Residuals: 0.017\n",
      "Loss: 73.493, Residuals: 0.017\n",
      "Loss: 73.460, Residuals: 0.018\n",
      "Loss: 73.456, Residuals: 0.018\n",
      "Loss: 73.425, Residuals: 0.019\n",
      "Loss: 73.421, Residuals: 0.018\n",
      "Loss: 73.380, Residuals: 0.022\n",
      "Loss: 73.368, Residuals: 0.020\n",
      "Loss: 73.315, Residuals: 0.024\n",
      "Loss: 73.306, Residuals: 0.023\n",
      "Loss: 73.300, Residuals: 0.022\n",
      "Loss: 73.291, Residuals: 0.023\n",
      "Loss: 73.289, Residuals: 0.023\n",
      "Loss: 73.285, Residuals: 0.023\n",
      "Loss: 73.282, Residuals: 0.024\n",
      "Loss: 73.282, Residuals: 0.024\n",
      "Loss: 73.277, Residuals: 0.024\n",
      "Loss: 73.273, Residuals: 0.024\n",
      "Loss: 73.272, Residuals: 0.024\n",
      "Loss: 73.271, Residuals: 0.024\n",
      "Loss: 73.271, Residuals: 0.025\n",
      "Loss: 73.271, Residuals: 0.025\n",
      "Loss: 73.271, Residuals: 0.025\n",
      "Loss: 73.271, Residuals: 0.025\n",
      "Loss: 73.271, Residuals: 0.025\n",
      "Loss: 73.271, Residuals: 0.025\n",
      "Loss: 73.271, Residuals: 0.025\n",
      "Evidence 366.092\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.38e+00\n",
      "Loss: 110.327, Residuals: 0.024\n",
      "Loss: 109.888, Residuals: 0.023\n",
      "Loss: 109.375, Residuals: 0.025\n",
      "Loss: 109.075, Residuals: 0.019\n",
      "Loss: 109.033, Residuals: 0.025\n",
      "Loss: 108.971, Residuals: 0.024\n",
      "Loss: 108.935, Residuals: 0.023\n",
      "Loss: 108.933, Residuals: 0.023\n",
      "Loss: 108.932, Residuals: 0.022\n",
      "Loss: 108.930, Residuals: 0.022\n",
      "Loss: 108.928, Residuals: 0.022\n",
      "Loss: 108.928, Residuals: 0.022\n",
      "Loss: 108.928, Residuals: 0.022\n",
      "Loss: 108.928, Residuals: 0.022\n",
      "Loss: 108.928, Residuals: 0.022\n",
      "Loss: 108.928, Residuals: 0.022\n",
      "Loss: 108.928, Residuals: 0.022\n",
      "Loss: 108.928, Residuals: 0.022\n",
      "Loss: 108.928, Residuals: 0.022\n",
      "Evidence 419.138\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.87e+00\n",
      "Loss: 130.714, Residuals: 0.026\n",
      "Loss: 130.366, Residuals: 0.016\n",
      "Loss: 130.304, Residuals: 0.016\n",
      "Loss: 130.217, Residuals: 0.015\n",
      "Loss: 130.170, Residuals: 0.015\n",
      "Loss: 130.168, Residuals: 0.014\n",
      "Loss: 130.165, Residuals: 0.014\n",
      "Loss: 130.163, Residuals: 0.014\n",
      "Loss: 130.161, Residuals: 0.014\n",
      "Loss: 130.161, Residuals: 0.014\n",
      "Loss: 130.161, Residuals: 0.014\n",
      "Loss: 130.160, Residuals: 0.014\n",
      "Loss: 130.159, Residuals: 0.014\n",
      "Loss: 130.159, Residuals: 0.014\n",
      "Evidence 434.333\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.96e+00\n",
      "Loss: 139.315, Residuals: 0.019\n",
      "Loss: 139.180, Residuals: 0.010\n",
      "Loss: 139.124, Residuals: 0.010\n",
      "Loss: 139.116, Residuals: 0.010\n",
      "Loss: 139.103, Residuals: 0.009\n",
      "Loss: 139.094, Residuals: 0.008\n",
      "Loss: 139.093, Residuals: 0.008\n",
      "Loss: 139.092, Residuals: 0.008\n",
      "Loss: 139.092, Residuals: 0.008\n",
      "Loss: 139.092, Residuals: 0.008\n",
      "Loss: 139.092, Residuals: 0.008\n",
      "Loss: 139.092, Residuals: 0.008\n",
      "Loss: 139.092, Residuals: 0.008\n",
      "Loss: 139.092, Residuals: 0.008\n",
      "Evidence 439.071\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.95e+00\n",
      "Loss: 142.620, Residuals: 0.012\n",
      "Loss: 142.584, Residuals: 0.008\n",
      "Loss: 142.547, Residuals: 0.006\n",
      "Loss: 142.539, Residuals: 0.006\n",
      "Loss: 142.536, Residuals: 0.006\n",
      "Loss: 142.530, Residuals: 0.005\n",
      "Loss: 142.527, Residuals: 0.005\n",
      "Loss: 142.526, Residuals: 0.004\n",
      "Loss: 142.526, Residuals: 0.005\n",
      "Loss: 142.526, Residuals: 0.005\n",
      "Loss: 142.526, Residuals: 0.005\n",
      "Loss: 142.526, Residuals: 0.005\n",
      "Evidence 440.971\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.92e+00\n",
      "Loss: 144.006, Residuals: 0.007\n",
      "Loss: 143.988, Residuals: 0.005\n",
      "Loss: 143.975, Residuals: 0.003\n",
      "Loss: 143.973, Residuals: 0.003\n",
      "Loss: 143.970, Residuals: 0.003\n",
      "Loss: 143.970, Residuals: 0.003\n",
      "Loss: 143.970, Residuals: 0.003\n",
      "Loss: 143.969, Residuals: 0.003\n",
      "Loss: 143.969, Residuals: 0.003\n",
      "Loss: 143.969, Residuals: 0.003\n",
      "Loss: 143.969, Residuals: 0.003\n",
      "Loss: 143.969, Residuals: 0.003\n",
      "Evidence 441.898\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.89e+00\n",
      "Loss: 144.682, Residuals: 0.004\n",
      "Loss: 144.675, Residuals: 0.003\n",
      "Loss: 144.668, Residuals: 0.002\n",
      "Loss: 144.668, Residuals: 0.002\n",
      "Loss: 144.667, Residuals: 0.002\n",
      "Loss: 144.666, Residuals: 0.002\n",
      "Loss: 144.666, Residuals: 0.002\n",
      "Loss: 144.666, Residuals: 0.002\n",
      "Evidence 442.401\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.88e+00\n",
      "Loss: 145.060, Residuals: 0.003\n",
      "Loss: 145.054, Residuals: 0.002\n",
      "Loss: 145.053, Residuals: 0.001\n",
      "Loss: 145.051, Residuals: 0.001\n",
      "Loss: 145.051, Residuals: 0.001\n",
      "Loss: 145.051, Residuals: 0.001\n",
      "Loss: 145.051, Residuals: 0.001\n",
      "Loss: 145.051, Residuals: 0.001\n",
      "Loss: 145.051, Residuals: 0.001\n",
      "Evidence 442.704\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.672, Residuals: -0.069\n",
      "Loss: 7.507, Residuals: -0.038\n",
      "Loss: 5.157, Residuals: -0.034\n",
      "Loss: 4.596, Residuals: -0.040\n",
      "Loss: 4.021, Residuals: 0.010\n",
      "Loss: 3.855, Residuals: -0.036\n",
      "Loss: 3.611, Residuals: -0.036\n",
      "Loss: 3.447, Residuals: -0.067\n",
      "Loss: 3.435, Residuals: -0.071\n",
      "Loss: 3.340, Residuals: -0.067\n",
      "Loss: 3.212, Residuals: -0.069\n",
      "Loss: 3.190, Residuals: -0.055\n",
      "Loss: 3.151, Residuals: -0.060\n",
      "Loss: 3.142, Residuals: -0.057\n",
      "Loss: 3.127, Residuals: -0.056\n",
      "Loss: 3.099, Residuals: -0.060\n",
      "Loss: 3.097, Residuals: -0.052\n",
      "Loss: 3.081, Residuals: -0.055\n",
      "Loss: 3.052, Residuals: -0.061\n",
      "Loss: 3.046, Residuals: -0.056\n",
      "Loss: 3.035, Residuals: -0.058\n",
      "Loss: 3.025, Residuals: -0.067\n",
      "Loss: 3.007, Residuals: -0.071\n",
      "Loss: 2.977, Residuals: -0.074\n",
      "Loss: 2.976, Residuals: -0.073\n",
      "Loss: 2.976, Residuals: -0.069\n",
      "Loss: 2.949, Residuals: -0.074\n",
      "Loss: 2.949, Residuals: -0.075\n",
      "Loss: 2.949, Residuals: -0.074\n",
      "Loss: 2.948, Residuals: -0.073\n",
      "Loss: 2.942, Residuals: -0.075\n",
      "Loss: 2.936, Residuals: -0.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.934, Residuals: -0.070\n",
      "Loss: 2.934, Residuals: -0.073\n",
      "Loss: 2.934, Residuals: -0.072\n",
      "Loss: 2.912, Residuals: -0.076\n",
      "Loss: 2.912, Residuals: -0.077\n",
      "Loss: 2.893, Residuals: -0.080\n",
      "Loss: 2.892, Residuals: -0.079\n",
      "Loss: 2.889, Residuals: -0.079\n",
      "Loss: 2.884, Residuals: -0.079\n",
      "Loss: 2.882, Residuals: -0.079\n",
      "Loss: 2.856, Residuals: -0.084\n",
      "Loss: 2.855, Residuals: -0.085\n",
      "Loss: 2.815, Residuals: -0.084\n",
      "Loss: 2.805, Residuals: -0.081\n",
      "Loss: 2.800, Residuals: -0.080\n",
      "Loss: 2.794, Residuals: -0.073\n",
      "Loss: 2.744, Residuals: -0.083\n",
      "Loss: 2.741, Residuals: -0.080\n",
      "Loss: 2.738, Residuals: -0.082\n",
      "Loss: 2.734, Residuals: -0.079\n",
      "Loss: 2.728, Residuals: -0.079\n",
      "Loss: 2.717, Residuals: -0.078\n",
      "Loss: 2.713, Residuals: -0.081\n",
      "Loss: 2.713, Residuals: -0.077\n",
      "Loss: 2.712, Residuals: -0.079\n",
      "Loss: 2.679, Residuals: -0.084\n",
      "Loss: 2.679, Residuals: -0.084\n",
      "Loss: 2.679, Residuals: -0.084\n",
      "Loss: 2.677, Residuals: -0.084\n",
      "Loss: 2.674, Residuals: -0.083\n",
      "Loss: 2.674, Residuals: -0.078\n",
      "Loss: 2.634, Residuals: -0.087\n",
      "Loss: 2.631, Residuals: -0.084\n",
      "Loss: 2.630, Residuals: -0.086\n",
      "Loss: 2.630, Residuals: -0.087\n",
      "Loss: 2.630, Residuals: -0.087\n",
      "Loss: 2.627, Residuals: -0.087\n",
      "Loss: 2.626, Residuals: -0.087\n",
      "Loss: 2.590, Residuals: -0.094\n",
      "Loss: 2.588, Residuals: -0.092\n",
      "Loss: 2.588, Residuals: -0.093\n",
      "Loss: 2.587, Residuals: -0.094\n",
      "Loss: 2.587, Residuals: -0.095\n",
      "Loss: 2.587, Residuals: -0.095\n",
      "Loss: 2.587, Residuals: -0.093\n",
      "Loss: 2.564, Residuals: -0.098\n",
      "Loss: 2.564, Residuals: -0.097\n",
      "Loss: 2.564, Residuals: -0.097\n",
      "Loss: 2.563, Residuals: -0.097\n",
      "Loss: 2.542, Residuals: -0.100\n",
      "Loss: 2.541, Residuals: -0.100\n",
      "Loss: 2.541, Residuals: -0.100\n",
      "Loss: 2.539, Residuals: -0.099\n",
      "Loss: 2.537, Residuals: -0.099\n",
      "Loss: 2.532, Residuals: -0.098\n",
      "Loss: 2.519, Residuals: -0.094\n",
      "Loss: 2.518, Residuals: -0.094\n",
      "Loss: 2.518, Residuals: -0.093\n",
      "Loss: 2.518, Residuals: -0.094\n",
      "Loss: 2.517, Residuals: -0.093\n",
      "Loss: 2.515, Residuals: -0.094\n",
      "Loss: 2.511, Residuals: -0.095\n",
      "Loss: 2.504, Residuals: -0.096\n",
      "Loss: 2.494, Residuals: -0.097\n",
      "Loss: 2.493, Residuals: -0.097\n",
      "Loss: 2.482, Residuals: -0.099\n",
      "Loss: 2.463, Residuals: -0.102\n",
      "Loss: 2.463, Residuals: -0.102\n",
      "Loss: 2.462, Residuals: -0.102\n",
      "Loss: 2.450, Residuals: -0.103\n",
      "Loss: 2.449, Residuals: -0.098\n",
      "Loss: 2.449, Residuals: -0.099\n",
      "Loss: 2.428, Residuals: -0.105\n",
      "Loss: 2.428, Residuals: -0.105\n",
      "Loss: 2.428, Residuals: -0.105\n",
      "Loss: 2.428, Residuals: -0.105\n",
      "Loss: 2.427, Residuals: -0.105\n",
      "Loss: 2.426, Residuals: -0.105\n",
      "Loss: 2.401, Residuals: -0.110\n",
      "Loss: 2.401, Residuals: -0.110\n",
      "Loss: 2.401, Residuals: -0.109\n",
      "Loss: 2.399, Residuals: -0.110\n",
      "Loss: 2.397, Residuals: -0.110\n",
      "Loss: 2.397, Residuals: -0.110\n",
      "Evidence -395.736\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.87e-03\n",
      "Loss: 14.115, Residuals: -0.106\n",
      "Loss: 14.110, Residuals: -0.103\n",
      "Loss: 13.939, Residuals: -0.083\n",
      "Loss: 13.938, Residuals: -0.085\n",
      "Loss: 13.936, Residuals: -0.085\n",
      "Loss: 13.859, Residuals: -0.083\n",
      "Loss: 13.719, Residuals: -0.083\n",
      "Loss: 13.478, Residuals: -0.079\n",
      "Loss: 13.390, Residuals: -0.083\n",
      "Loss: 13.373, Residuals: -0.078\n",
      "Loss: 13.356, Residuals: -0.073\n",
      "Loss: 13.351, Residuals: -0.075\n",
      "Loss: 13.348, Residuals: -0.071\n",
      "Loss: 13.346, Residuals: -0.074\n",
      "Loss: 13.330, Residuals: -0.074\n",
      "Loss: 13.301, Residuals: -0.074\n",
      "Loss: 13.246, Residuals: -0.073\n",
      "Loss: 13.144, Residuals: -0.068\n",
      "Loss: 13.103, Residuals: -0.065\n",
      "Loss: 13.038, Residuals: -0.063\n",
      "Loss: 13.036, Residuals: -0.064\n",
      "Loss: 13.015, Residuals: -0.063\n",
      "Loss: 12.979, Residuals: -0.061\n",
      "Loss: 12.976, Residuals: -0.059\n",
      "Loss: 12.953, Residuals: -0.058\n",
      "Loss: 12.914, Residuals: -0.055\n",
      "Loss: 12.906, Residuals: -0.056\n",
      "Loss: 12.904, Residuals: -0.054\n",
      "Loss: 12.903, Residuals: -0.056\n",
      "Loss: 12.903, Residuals: -0.055\n",
      "Loss: 12.903, Residuals: -0.055\n",
      "Loss: 12.903, Residuals: -0.055\n",
      "Evidence 114.003\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.59e-03\n",
      "Loss: 46.720, Residuals: -0.055\n",
      "Loss: 46.661, Residuals: -0.055\n",
      "Loss: 46.589, Residuals: -0.055\n",
      "Loss: 46.458, Residuals: -0.053\n",
      "Loss: 46.255, Residuals: -0.049\n",
      "Loss: 46.212, Residuals: -0.050\n",
      "Loss: 45.828, Residuals: -0.046\n",
      "Loss: 45.691, Residuals: -0.042\n",
      "Loss: 45.679, Residuals: -0.047\n",
      "Loss: 45.575, Residuals: -0.045\n",
      "Loss: 45.411, Residuals: -0.041\n",
      "Loss: 45.408, Residuals: -0.041\n",
      "Loss: 44.609, Residuals: -0.037\n",
      "Loss: 44.522, Residuals: -0.042\n",
      "Loss: 44.485, Residuals: -0.036\n",
      "Loss: 44.199, Residuals: -0.040\n",
      "Loss: 43.812, Residuals: -0.038\n",
      "Loss: 43.810, Residuals: -0.038\n",
      "Loss: 43.807, Residuals: -0.038\n",
      "Loss: 43.801, Residuals: -0.038\n",
      "Loss: 43.790, Residuals: -0.037\n",
      "Loss: 43.697, Residuals: -0.037\n",
      "Loss: 43.684, Residuals: -0.037\n",
      "Loss: 43.573, Residuals: -0.037\n",
      "Loss: 43.572, Residuals: -0.037\n",
      "Loss: 43.571, Residuals: -0.036\n",
      "Loss: 43.420, Residuals: -0.036\n",
      "Loss: 43.418, Residuals: -0.036\n",
      "Loss: 43.417, Residuals: -0.036\n",
      "Loss: 43.220, Residuals: -0.035\n",
      "Loss: 43.215, Residuals: -0.035\n",
      "Loss: 43.212, Residuals: -0.035\n",
      "Loss: 43.207, Residuals: -0.035\n",
      "Loss: 43.033, Residuals: -0.033\n",
      "Loss: 43.027, Residuals: -0.032\n",
      "Loss: 43.020, Residuals: -0.033\n",
      "Loss: 43.015, Residuals: -0.034\n",
      "Loss: 43.006, Residuals: -0.033\n",
      "Loss: 42.728, Residuals: -0.027\n",
      "Loss: 42.628, Residuals: -0.034\n",
      "Loss: 42.613, Residuals: -0.029\n",
      "Loss: 42.588, Residuals: -0.029\n",
      "Loss: 42.556, Residuals: -0.030\n",
      "Loss: 42.553, Residuals: -0.030\n",
      "Loss: 42.529, Residuals: -0.030\n",
      "Loss: 42.300, Residuals: -0.027\n",
      "Loss: 42.274, Residuals: -0.028\n",
      "Loss: 42.237, Residuals: -0.026\n",
      "Loss: 42.227, Residuals: -0.026\n",
      "Loss: 41.910, Residuals: -0.021\n",
      "Loss: 41.853, Residuals: -0.020\n",
      "Loss: 41.798, Residuals: -0.018\n",
      "Loss: 41.789, Residuals: -0.020\n",
      "Loss: 41.718, Residuals: -0.019\n",
      "Loss: 41.715, Residuals: -0.017\n",
      "Loss: 41.688, Residuals: -0.017\n",
      "Loss: 41.639, Residuals: -0.016\n",
      "Loss: 41.615, Residuals: -0.015\n",
      "Loss: 41.610, Residuals: -0.015\n",
      "Loss: 41.575, Residuals: -0.014\n",
      "Loss: 41.574, Residuals: -0.013\n",
      "Loss: 41.525, Residuals: -0.013\n",
      "Loss: 41.523, Residuals: -0.013\n",
      "Loss: 41.465, Residuals: -0.012\n",
      "Loss: 41.463, Residuals: -0.012\n",
      "Loss: 41.462, Residuals: -0.012\n",
      "Loss: 41.460, Residuals: -0.012\n",
      "Loss: 41.459, Residuals: -0.012\n",
      "Loss: 41.453, Residuals: -0.012\n",
      "Loss: 41.453, Residuals: -0.012\n",
      "Loss: 41.450, Residuals: -0.012\n",
      "Loss: 41.447, Residuals: -0.011\n",
      "Loss: 41.447, Residuals: -0.012\n",
      "Loss: 41.447, Residuals: -0.012\n",
      "Loss: 41.443, Residuals: -0.012\n",
      "Loss: 41.443, Residuals: -0.012\n",
      "Loss: 41.440, Residuals: -0.012\n",
      "Loss: 41.440, Residuals: -0.012\n",
      "Evidence 318.431\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.18e-02\n",
      "Loss: 89.274, Residuals: -0.007\n",
      "Loss: 88.940, Residuals: -0.012\n",
      "Loss: 88.690, Residuals: -0.016\n",
      "Loss: 88.686, Residuals: -0.016\n",
      "Loss: 88.647, Residuals: -0.017\n",
      "Loss: 88.589, Residuals: -0.018\n",
      "Loss: 88.580, Residuals: -0.017\n",
      "Loss: 88.493, Residuals: -0.017\n",
      "Loss: 88.350, Residuals: -0.018\n",
      "Loss: 88.345, Residuals: -0.018\n",
      "Loss: 88.295, Residuals: -0.018\n",
      "Loss: 88.222, Residuals: -0.018\n",
      "Loss: 88.219, Residuals: -0.018\n",
      "Loss: 88.215, Residuals: -0.019\n",
      "Loss: 88.181, Residuals: -0.018\n",
      "Loss: 88.180, Residuals: -0.018\n",
      "Loss: 88.168, Residuals: -0.018\n",
      "Loss: 88.167, Residuals: -0.018\n",
      "Loss: 88.162, Residuals: -0.018\n",
      "Loss: 88.152, Residuals: -0.017\n",
      "Loss: 88.152, Residuals: -0.017\n",
      "Loss: 88.148, Residuals: -0.017\n",
      "Loss: 88.146, Residuals: -0.017\n",
      "Loss: 88.133, Residuals: -0.017\n",
      "Loss: 88.133, Residuals: -0.017\n",
      "Evidence 431.278\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.24e-01\n",
      "Loss: 128.905, Residuals: -0.012\n",
      "Loss: 128.652, Residuals: -0.016\n",
      "Loss: 128.332, Residuals: -0.023\n",
      "Loss: 128.282, Residuals: -0.026\n",
      "Loss: 128.187, Residuals: -0.027\n",
      "Loss: 128.023, Residuals: -0.027\n",
      "Loss: 127.820, Residuals: -0.028\n",
      "Loss: 127.811, Residuals: -0.030\n",
      "Loss: 127.798, Residuals: -0.029\n",
      "Loss: 127.692, Residuals: -0.029\n",
      "Loss: 127.690, Residuals: -0.029\n",
      "Loss: 127.605, Residuals: -0.028\n",
      "Loss: 127.604, Residuals: -0.028\n",
      "Evidence 466.300\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.80e-01\n",
      "Loss: 147.175, Residuals: -0.025\n",
      "Loss: 147.067, Residuals: -0.026\n",
      "Loss: 146.894, Residuals: -0.029\n",
      "Loss: 146.833, Residuals: -0.034\n",
      "Loss: 146.718, Residuals: -0.033\n",
      "Loss: 146.506, Residuals: -0.034\n",
      "Loss: 145.755, Residuals: -0.037\n",
      "Loss: 145.745, Residuals: -0.037\n",
      "Loss: 145.727, Residuals: -0.037\n",
      "Loss: 145.693, Residuals: -0.037\n",
      "Loss: 145.631, Residuals: -0.036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 145.066, Residuals: -0.033\n",
      "Loss: 145.060, Residuals: -0.033\n",
      "Loss: 145.006, Residuals: -0.032\n",
      "Loss: 144.506, Residuals: -0.030\n",
      "Loss: 144.500, Residuals: -0.029\n",
      "Loss: 144.489, Residuals: -0.030\n",
      "Loss: 144.470, Residuals: -0.030\n",
      "Loss: 144.445, Residuals: -0.032\n",
      "Loss: 144.204, Residuals: -0.031\n",
      "Loss: 144.182, Residuals: -0.032\n",
      "Loss: 144.149, Residuals: -0.031\n",
      "Loss: 143.858, Residuals: -0.030\n",
      "Loss: 143.856, Residuals: -0.029\n",
      "Loss: 143.844, Residuals: -0.030\n",
      "Loss: 143.727, Residuals: -0.029\n",
      "Loss: 143.712, Residuals: -0.031\n",
      "Loss: 143.594, Residuals: -0.030\n",
      "Loss: 143.585, Residuals: -0.031\n",
      "Loss: 143.573, Residuals: -0.029\n",
      "Loss: 143.552, Residuals: -0.029\n",
      "Loss: 143.519, Residuals: -0.029\n",
      "Loss: 143.516, Residuals: -0.029\n",
      "Loss: 143.513, Residuals: -0.029\n",
      "Loss: 143.509, Residuals: -0.029\n",
      "Loss: 143.508, Residuals: -0.029\n",
      "Loss: 143.501, Residuals: -0.029\n",
      "Loss: 143.494, Residuals: -0.028\n",
      "Loss: 143.494, Residuals: -0.029\n",
      "Loss: 143.493, Residuals: -0.029\n",
      "Loss: 143.489, Residuals: -0.028\n",
      "Loss: 143.487, Residuals: -0.028\n",
      "Loss: 143.487, Residuals: -0.028\n",
      "Loss: 143.486, Residuals: -0.028\n",
      "Loss: 143.478, Residuals: -0.028\n",
      "Loss: 143.478, Residuals: -0.028\n",
      "Loss: 143.478, Residuals: -0.028\n",
      "Loss: 143.476, Residuals: -0.028\n",
      "Loss: 143.476, Residuals: -0.028\n",
      "Evidence 473.610\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.57e-01\n",
      "Loss: 151.266, Residuals: -0.023\n",
      "Loss: 151.091, Residuals: -0.027\n",
      "Loss: 150.814, Residuals: -0.029\n",
      "Loss: 150.568, Residuals: -0.028\n",
      "Loss: 150.536, Residuals: -0.031\n",
      "Loss: 150.481, Residuals: -0.031\n",
      "Loss: 150.428, Residuals: -0.031\n",
      "Loss: 150.423, Residuals: -0.032\n",
      "Loss: 150.419, Residuals: -0.031\n",
      "Loss: 150.414, Residuals: -0.031\n",
      "Loss: 150.405, Residuals: -0.031\n",
      "Loss: 150.405, Residuals: -0.030\n",
      "Loss: 150.383, Residuals: -0.030\n",
      "Loss: 150.383, Residuals: -0.030\n",
      "Loss: 150.382, Residuals: -0.030\n",
      "Loss: 150.375, Residuals: -0.030\n",
      "Loss: 150.374, Residuals: -0.030\n",
      "Loss: 150.374, Residuals: -0.030\n",
      "Loss: 150.373, Residuals: -0.030\n",
      "Loss: 150.369, Residuals: -0.030\n",
      "Loss: 150.369, Residuals: -0.030\n",
      "Loss: 150.369, Residuals: -0.030\n",
      "Loss: 150.368, Residuals: -0.029\n",
      "Loss: 150.367, Residuals: -0.029\n",
      "Loss: 150.367, Residuals: -0.029\n",
      "Loss: 150.367, Residuals: -0.029\n",
      "Loss: 150.367, Residuals: -0.029\n",
      "Loss: 150.367, Residuals: -0.029\n",
      "Loss: 150.366, Residuals: -0.029\n",
      "Evidence 481.062\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.23e-01\n",
      "Loss: 153.986, Residuals: -0.026\n",
      "Loss: 153.918, Residuals: -0.027\n",
      "Loss: 153.825, Residuals: -0.028\n",
      "Loss: 153.732, Residuals: -0.028\n",
      "Loss: 153.721, Residuals: -0.031\n",
      "Loss: 153.703, Residuals: -0.031\n",
      "Loss: 153.680, Residuals: -0.030\n",
      "Loss: 153.679, Residuals: -0.031\n",
      "Loss: 153.678, Residuals: -0.031\n",
      "Loss: 153.665, Residuals: -0.030\n",
      "Loss: 153.658, Residuals: -0.030\n",
      "Loss: 153.657, Residuals: -0.031\n",
      "Loss: 153.654, Residuals: -0.030\n",
      "Loss: 153.654, Residuals: -0.030\n",
      "Loss: 153.650, Residuals: -0.030\n",
      "Loss: 153.642, Residuals: -0.030\n",
      "Loss: 153.642, Residuals: -0.030\n",
      "Loss: 153.639, Residuals: -0.030\n",
      "Loss: 153.635, Residuals: -0.030\n",
      "Loss: 153.635, Residuals: -0.030\n",
      "Loss: 153.635, Residuals: -0.030\n",
      "Loss: 153.634, Residuals: -0.030\n",
      "Loss: 153.634, Residuals: -0.030\n",
      "Evidence 483.257\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.77e-01\n",
      "Loss: 155.211, Residuals: -0.026\n",
      "Loss: 155.156, Residuals: -0.028\n",
      "Loss: 155.102, Residuals: -0.030\n",
      "Loss: 155.094, Residuals: -0.031\n",
      "Loss: 155.081, Residuals: -0.031\n",
      "Loss: 155.080, Residuals: -0.030\n",
      "Loss: 155.067, Residuals: -0.030\n",
      "Loss: 155.066, Residuals: -0.031\n",
      "Loss: 155.052, Residuals: -0.031\n",
      "Loss: 155.034, Residuals: -0.030\n",
      "Loss: 155.034, Residuals: -0.030\n",
      "Loss: 155.034, Residuals: -0.030\n",
      "Loss: 155.033, Residuals: -0.030\n",
      "Loss: 155.033, Residuals: -0.030\n",
      "Loss: 155.032, Residuals: -0.030\n",
      "Loss: 155.032, Residuals: -0.030\n",
      "Loss: 155.032, Residuals: -0.030\n",
      "Loss: 155.032, Residuals: -0.030\n",
      "Evidence 484.264\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.22e-01\n",
      "Loss: 155.767, Residuals: -0.030\n",
      "Loss: 155.752, Residuals: -0.031\n",
      "Loss: 155.731, Residuals: -0.031\n",
      "Loss: 155.711, Residuals: -0.032\n",
      "Loss: 155.710, Residuals: -0.032\n",
      "Loss: 155.709, Residuals: -0.032\n",
      "Loss: 155.709, Residuals: -0.032\n",
      "Loss: 155.701, Residuals: -0.032\n",
      "Loss: 155.692, Residuals: -0.031\n",
      "Loss: 155.692, Residuals: -0.032\n",
      "Loss: 155.692, Residuals: -0.032\n",
      "Loss: 155.691, Residuals: -0.032\n",
      "Loss: 155.691, Residuals: -0.031\n",
      "Loss: 155.690, Residuals: -0.031\n",
      "Loss: 155.690, Residuals: -0.031\n",
      "Loss: 155.689, Residuals: -0.031\n",
      "Loss: 155.689, Residuals: -0.031\n",
      "Loss: 155.689, Residuals: -0.031\n",
      "Evidence 484.895\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.47e-01\n",
      "Loss: 156.101, Residuals: -0.031\n",
      "Loss: 156.091, Residuals: -0.032\n",
      "Loss: 156.078, Residuals: -0.032\n",
      "Loss: 156.067, Residuals: -0.032\n",
      "Loss: 156.067, Residuals: -0.032\n",
      "Loss: 156.067, Residuals: -0.032\n",
      "Loss: 156.066, Residuals: -0.032\n",
      "Loss: 156.065, Residuals: -0.032\n",
      "Loss: 156.063, Residuals: -0.032\n",
      "Loss: 156.061, Residuals: -0.032\n",
      "Loss: 156.058, Residuals: -0.032\n",
      "Loss: 156.058, Residuals: -0.032\n",
      "Loss: 156.057, Residuals: -0.032\n",
      "Loss: 156.055, Residuals: -0.032\n",
      "Loss: 156.055, Residuals: -0.032\n",
      "Loss: 156.055, Residuals: -0.032\n",
      "Loss: 156.055, Residuals: -0.032\n",
      "Loss: 156.055, Residuals: -0.032\n",
      "Loss: 156.055, Residuals: -0.032\n",
      "Loss: 156.055, Residuals: -0.032\n",
      "Loss: 156.055, Residuals: -0.032\n",
      "Evidence 485.289\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.398, Residuals: -0.024\n",
      "Loss: 7.118, Residuals: -0.026\n",
      "Loss: 4.329, Residuals: -0.036\n",
      "Loss: 4.199, Residuals: 0.017\n",
      "Loss: 3.963, Residuals: -0.005\n",
      "Loss: 3.670, Residuals: -0.053\n",
      "Loss: 3.626, Residuals: -0.035\n",
      "Loss: 3.547, Residuals: -0.036\n",
      "Loss: 3.421, Residuals: -0.054\n",
      "Loss: 3.410, Residuals: -0.052\n",
      "Loss: 3.311, Residuals: -0.057\n",
      "Loss: 3.133, Residuals: -0.056\n",
      "Loss: 3.120, Residuals: -0.034\n",
      "Loss: 3.096, Residuals: -0.030\n",
      "Loss: 3.050, Residuals: -0.032\n",
      "Loss: 2.994, Residuals: -0.019\n",
      "Loss: 2.902, Residuals: -0.028\n",
      "Loss: 2.895, Residuals: -0.016\n",
      "Loss: 2.830, Residuals: -0.023\n",
      "Loss: 2.786, Residuals: -0.017\n",
      "Loss: 2.781, Residuals: -0.015\n",
      "Loss: 2.730, Residuals: -0.022\n",
      "Loss: 2.721, Residuals: -0.010\n",
      "Loss: 2.640, Residuals: -0.023\n",
      "Loss: 2.639, Residuals: -0.020\n",
      "Loss: 2.597, Residuals: -0.027\n",
      "Loss: 2.575, Residuals: -0.029\n",
      "Loss: 2.575, Residuals: -0.029\n",
      "Loss: 2.519, Residuals: -0.038\n",
      "Loss: 2.513, Residuals: -0.024\n",
      "Loss: 2.503, Residuals: -0.028\n",
      "Loss: 2.503, Residuals: -0.028\n",
      "Loss: 2.470, Residuals: -0.036\n",
      "Loss: 2.469, Residuals: -0.035\n",
      "Loss: 2.430, Residuals: -0.044\n",
      "Loss: 2.429, Residuals: -0.045\n",
      "Loss: 2.424, Residuals: -0.043\n",
      "Loss: 2.417, Residuals: -0.042\n",
      "Loss: 2.417, Residuals: -0.042\n",
      "Evidence -401.908\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.43e-02\n",
      "Loss: 12.288, Residuals: -0.035\n",
      "Loss: 12.284, Residuals: -0.035\n",
      "Loss: 12.243, Residuals: -0.032\n",
      "Loss: 12.171, Residuals: -0.027\n",
      "Loss: 12.127, Residuals: -0.018\n",
      "Loss: 12.047, Residuals: -0.014\n",
      "Loss: 11.939, Residuals: -0.005\n",
      "Loss: 11.927, Residuals: -0.001\n",
      "Loss: 11.924, Residuals: 0.000\n",
      "Loss: 11.824, Residuals: 0.002\n",
      "Loss: 11.823, Residuals: 0.002\n",
      "Loss: 11.773, Residuals: 0.002\n",
      "Loss: 11.742, Residuals: 0.007\n",
      "Loss: 11.740, Residuals: 0.009\n",
      "Loss: 11.670, Residuals: 0.006\n",
      "Loss: 11.667, Residuals: 0.008\n",
      "Loss: 11.661, Residuals: 0.007\n",
      "Loss: 11.649, Residuals: 0.007\n",
      "Loss: 11.635, Residuals: 0.006\n",
      "Loss: 11.633, Residuals: 0.006\n",
      "Loss: 11.632, Residuals: 0.006\n",
      "Loss: 11.626, Residuals: 0.005\n",
      "Loss: 11.614, Residuals: 0.003\n",
      "Loss: 11.614, Residuals: 0.004\n",
      "Loss: 11.613, Residuals: 0.004\n",
      "Loss: 11.604, Residuals: 0.001\n",
      "Loss: 11.604, Residuals: 0.002\n",
      "Loss: 11.603, Residuals: 0.002\n",
      "Loss: 11.600, Residuals: 0.001\n",
      "Loss: 11.596, Residuals: 0.000\n",
      "Loss: 11.596, Residuals: 0.000\n",
      "Loss: 11.596, Residuals: 0.000\n",
      "Loss: 11.592, Residuals: -0.001\n",
      "Loss: 11.592, Residuals: -0.001\n",
      "Loss: 11.591, Residuals: -0.001\n",
      "Loss: 11.591, Residuals: -0.001\n",
      "Loss: 11.591, Residuals: -0.001\n",
      "Loss: 11.590, Residuals: -0.001\n",
      "Loss: 11.589, Residuals: -0.001\n",
      "Loss: 11.587, Residuals: -0.003\n",
      "Loss: 11.587, Residuals: -0.002\n",
      "Loss: 11.587, Residuals: -0.002\n",
      "Loss: 11.587, Residuals: -0.002\n",
      "Loss: 11.587, Residuals: -0.002\n",
      "Loss: 11.587, Residuals: -0.002\n",
      "Loss: 11.586, Residuals: -0.002\n",
      "Loss: 11.586, Residuals: -0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.586, Residuals: -0.002\n",
      "Loss: 11.586, Residuals: -0.002\n",
      "Loss: 11.586, Residuals: -0.002\n",
      "Loss: 11.585, Residuals: -0.002\n",
      "Loss: 11.585, Residuals: -0.002\n",
      "Loss: 11.585, Residuals: -0.002\n",
      "Evidence 103.106\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.64e-02\n",
      "Loss: 39.694, Residuals: -0.010\n",
      "Loss: 39.624, Residuals: -0.009\n",
      "Loss: 39.501, Residuals: -0.005\n",
      "Loss: 39.347, Residuals: 0.008\n",
      "Loss: 39.333, Residuals: 0.007\n",
      "Loss: 39.307, Residuals: 0.007\n",
      "Loss: 39.260, Residuals: 0.008\n",
      "Loss: 39.187, Residuals: 0.008\n",
      "Loss: 39.063, Residuals: 0.009\n",
      "Loss: 39.058, Residuals: 0.009\n",
      "Loss: 39.047, Residuals: 0.009\n",
      "Loss: 39.028, Residuals: 0.009\n",
      "Loss: 38.992, Residuals: 0.010\n",
      "Loss: 38.961, Residuals: 0.009\n",
      "Loss: 38.906, Residuals: 0.010\n",
      "Loss: 38.904, Residuals: 0.009\n",
      "Loss: 38.827, Residuals: 0.012\n",
      "Loss: 38.822, Residuals: 0.010\n",
      "Loss: 38.813, Residuals: 0.011\n",
      "Loss: 38.798, Residuals: 0.012\n",
      "Loss: 38.769, Residuals: 0.013\n",
      "Loss: 38.764, Residuals: 0.014\n",
      "Loss: 38.721, Residuals: 0.014\n",
      "Loss: 38.718, Residuals: 0.013\n",
      "Loss: 38.693, Residuals: 0.014\n",
      "Loss: 38.672, Residuals: 0.014\n",
      "Loss: 38.668, Residuals: 0.015\n",
      "Loss: 38.637, Residuals: 0.016\n",
      "Loss: 38.636, Residuals: 0.016\n",
      "Loss: 38.620, Residuals: 0.016\n",
      "Loss: 38.592, Residuals: 0.017\n",
      "Loss: 38.589, Residuals: 0.017\n",
      "Loss: 38.585, Residuals: 0.017\n",
      "Loss: 38.547, Residuals: 0.018\n",
      "Loss: 38.544, Residuals: 0.018\n",
      "Loss: 38.538, Residuals: 0.018\n",
      "Loss: 38.528, Residuals: 0.018\n",
      "Loss: 38.511, Residuals: 0.018\n",
      "Loss: 38.508, Residuals: 0.019\n",
      "Loss: 38.503, Residuals: 0.019\n",
      "Loss: 38.493, Residuals: 0.019\n",
      "Loss: 38.483, Residuals: 0.019\n",
      "Loss: 38.481, Residuals: 0.018\n",
      "Loss: 38.465, Residuals: 0.019\n",
      "Loss: 38.453, Residuals: 0.019\n",
      "Loss: 38.434, Residuals: 0.020\n",
      "Loss: 38.432, Residuals: 0.020\n",
      "Loss: 38.414, Residuals: 0.021\n",
      "Loss: 38.400, Residuals: 0.020\n",
      "Loss: 38.375, Residuals: 0.020\n",
      "Loss: 38.374, Residuals: 0.020\n",
      "Loss: 38.321, Residuals: 0.021\n",
      "Loss: 38.315, Residuals: 0.021\n",
      "Loss: 38.303, Residuals: 0.021\n",
      "Loss: 38.283, Residuals: 0.021\n",
      "Loss: 38.251, Residuals: 0.021\n",
      "Loss: 38.250, Residuals: 0.021\n",
      "Loss: 38.236, Residuals: 0.021\n",
      "Loss: 38.211, Residuals: 0.020\n",
      "Loss: 38.193, Residuals: 0.021\n",
      "Loss: 38.167, Residuals: 0.020\n",
      "Loss: 38.165, Residuals: 0.020\n",
      "Loss: 38.144, Residuals: 0.020\n",
      "Loss: 38.130, Residuals: 0.021\n",
      "Loss: 38.109, Residuals: 0.020\n",
      "Loss: 38.107, Residuals: 0.020\n",
      "Loss: 38.103, Residuals: 0.020\n",
      "Loss: 38.097, Residuals: 0.020\n",
      "Loss: 38.092, Residuals: 0.020\n",
      "Loss: 38.091, Residuals: 0.020\n",
      "Loss: 38.086, Residuals: 0.019\n",
      "Loss: 38.086, Residuals: 0.020\n",
      "Loss: 38.083, Residuals: 0.019\n",
      "Loss: 38.080, Residuals: 0.019\n",
      "Loss: 38.080, Residuals: 0.019\n",
      "Loss: 38.079, Residuals: 0.019\n",
      "Loss: 38.078, Residuals: 0.019\n",
      "Loss: 38.078, Residuals: 0.019\n",
      "Loss: 38.078, Residuals: 0.019\n",
      "Loss: 38.078, Residuals: 0.019\n",
      "Loss: 38.077, Residuals: 0.019\n",
      "Loss: 38.077, Residuals: 0.019\n",
      "Loss: 38.077, Residuals: 0.019\n",
      "Loss: 38.077, Residuals: 0.019\n",
      "Loss: 38.077, Residuals: 0.019\n",
      "Loss: 38.076, Residuals: 0.019\n",
      "Loss: 38.076, Residuals: 0.019\n",
      "Loss: 38.076, Residuals: 0.019\n",
      "Loss: 38.076, Residuals: 0.019\n",
      "Loss: 38.076, Residuals: 0.019\n",
      "Loss: 38.076, Residuals: 0.019\n",
      "Loss: 38.076, Residuals: 0.019\n",
      "Loss: 38.076, Residuals: 0.019\n",
      "Loss: 38.076, Residuals: 0.019\n",
      "Evidence 303.111\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.19e-01\n",
      "Loss: 82.344, Residuals: 0.024\n",
      "Loss: 82.050, Residuals: 0.023\n",
      "Loss: 82.025, Residuals: 0.015\n",
      "Loss: 81.978, Residuals: 0.016\n",
      "Loss: 81.892, Residuals: 0.016\n",
      "Loss: 81.778, Residuals: 0.018\n",
      "Loss: 81.665, Residuals: 0.019\n",
      "Loss: 81.654, Residuals: 0.020\n",
      "Loss: 81.633, Residuals: 0.020\n",
      "Loss: 81.598, Residuals: 0.020\n",
      "Loss: 81.560, Residuals: 0.019\n",
      "Loss: 81.557, Residuals: 0.019\n",
      "Loss: 81.555, Residuals: 0.019\n",
      "Loss: 81.555, Residuals: 0.019\n",
      "Loss: 81.551, Residuals: 0.019\n",
      "Loss: 81.547, Residuals: 0.018\n",
      "Loss: 81.547, Residuals: 0.018\n",
      "Loss: 81.547, Residuals: 0.018\n",
      "Loss: 81.547, Residuals: 0.018\n",
      "Loss: 81.547, Residuals: 0.018\n",
      "Loss: 81.546, Residuals: 0.018\n",
      "Loss: 81.546, Residuals: 0.018\n",
      "Evidence 418.404\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.02e-01\n",
      "Loss: 121.297, Residuals: 0.019\n",
      "Loss: 120.991, Residuals: 0.013\n",
      "Loss: 120.905, Residuals: 0.012\n",
      "Loss: 120.816, Residuals: 0.014\n",
      "Loss: 120.812, Residuals: 0.015\n",
      "Loss: 120.779, Residuals: 0.015\n",
      "Loss: 120.717, Residuals: 0.015\n",
      "Loss: 120.632, Residuals: 0.016\n",
      "Loss: 120.630, Residuals: 0.016\n",
      "Loss: 120.626, Residuals: 0.016\n",
      "Loss: 120.620, Residuals: 0.015\n",
      "Loss: 120.609, Residuals: 0.015\n",
      "Loss: 120.608, Residuals: 0.015\n",
      "Loss: 120.605, Residuals: 0.015\n",
      "Loss: 120.602, Residuals: 0.015\n",
      "Loss: 120.602, Residuals: 0.015\n",
      "Loss: 120.600, Residuals: 0.014\n",
      "Loss: 120.598, Residuals: 0.014\n",
      "Loss: 120.598, Residuals: 0.014\n",
      "Loss: 120.598, Residuals: 0.014\n",
      "Loss: 120.597, Residuals: 0.014\n",
      "Loss: 120.596, Residuals: 0.014\n",
      "Loss: 120.594, Residuals: 0.014\n",
      "Loss: 120.594, Residuals: 0.014\n",
      "Loss: 120.594, Residuals: 0.014\n",
      "Loss: 120.594, Residuals: 0.014\n",
      "Loss: 120.594, Residuals: 0.014\n",
      "Loss: 120.593, Residuals: 0.014\n",
      "Loss: 120.593, Residuals: 0.014\n",
      "Loss: 120.593, Residuals: 0.014\n",
      "Loss: 120.593, Residuals: 0.014\n",
      "Loss: 120.592, Residuals: 0.014\n",
      "Evidence 457.614\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.48e-01\n",
      "Loss: 139.911, Residuals: 0.018\n",
      "Loss: 139.624, Residuals: 0.010\n",
      "Loss: 139.565, Residuals: 0.010\n",
      "Loss: 139.507, Residuals: 0.016\n",
      "Loss: 139.448, Residuals: 0.013\n",
      "Loss: 139.426, Residuals: 0.013\n",
      "Loss: 139.395, Residuals: 0.013\n",
      "Loss: 139.392, Residuals: 0.014\n",
      "Loss: 139.386, Residuals: 0.014\n",
      "Loss: 139.376, Residuals: 0.013\n",
      "Loss: 139.365, Residuals: 0.013\n",
      "Loss: 139.365, Residuals: 0.013\n",
      "Loss: 139.365, Residuals: 0.013\n",
      "Loss: 139.363, Residuals: 0.013\n",
      "Loss: 139.363, Residuals: 0.013\n",
      "Loss: 139.363, Residuals: 0.013\n",
      "Loss: 139.363, Residuals: 0.013\n",
      "Loss: 139.361, Residuals: 0.013\n",
      "Evidence 468.699\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.72e-01\n",
      "Loss: 146.490, Residuals: 0.017\n",
      "Loss: 146.246, Residuals: 0.013\n",
      "Loss: 146.145, Residuals: 0.013\n",
      "Loss: 146.123, Residuals: 0.016\n",
      "Loss: 146.096, Residuals: 0.012\n",
      "Loss: 146.081, Residuals: 0.015\n",
      "Loss: 146.064, Residuals: 0.014\n",
      "Loss: 146.050, Residuals: 0.013\n",
      "Loss: 146.048, Residuals: 0.012\n",
      "Loss: 146.047, Residuals: 0.014\n",
      "Loss: 146.044, Residuals: 0.013\n",
      "Loss: 146.044, Residuals: 0.013\n",
      "Loss: 146.042, Residuals: 0.013\n",
      "Loss: 146.038, Residuals: 0.013\n",
      "Loss: 146.038, Residuals: 0.013\n",
      "Loss: 146.037, Residuals: 0.013\n",
      "Loss: 146.037, Residuals: 0.012\n",
      "Loss: 146.037, Residuals: 0.013\n",
      "Loss: 146.036, Residuals: 0.012\n",
      "Loss: 146.036, Residuals: 0.012\n",
      "Evidence 473.445\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.81e-01\n",
      "Loss: 148.620, Residuals: 0.014\n",
      "Loss: 148.432, Residuals: 0.015\n",
      "Loss: 148.413, Residuals: 0.011\n",
      "Loss: 148.385, Residuals: 0.012\n",
      "Loss: 148.373, Residuals: 0.013\n",
      "Loss: 148.372, Residuals: 0.014\n",
      "Loss: 148.370, Residuals: 0.013\n",
      "Loss: 148.367, Residuals: 0.013\n",
      "Loss: 148.363, Residuals: 0.013\n",
      "Loss: 148.363, Residuals: 0.013\n",
      "Loss: 148.362, Residuals: 0.013\n",
      "Loss: 148.361, Residuals: 0.013\n",
      "Loss: 148.361, Residuals: 0.013\n",
      "Loss: 148.361, Residuals: 0.013\n",
      "Loss: 148.360, Residuals: 0.013\n",
      "Loss: 148.360, Residuals: 0.013\n",
      "Evidence 476.367\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.83e-01\n",
      "Loss: 149.412, Residuals: 0.012\n",
      "Loss: 149.404, Residuals: 0.012\n",
      "Loss: 149.389, Residuals: 0.013\n",
      "Loss: 149.363, Residuals: 0.013\n",
      "Loss: 149.341, Residuals: 0.014\n",
      "Loss: 149.341, Residuals: 0.013\n",
      "Loss: 149.337, Residuals: 0.013\n",
      "Loss: 149.337, Residuals: 0.013\n",
      "Loss: 149.332, Residuals: 0.013\n",
      "Loss: 149.329, Residuals: 0.013\n",
      "Loss: 149.329, Residuals: 0.012\n",
      "Loss: 149.329, Residuals: 0.012\n",
      "Loss: 149.328, Residuals: 0.012\n",
      "Loss: 149.328, Residuals: 0.012\n",
      "Loss: 149.328, Residuals: 0.012\n",
      "Loss: 149.328, Residuals: 0.012\n",
      "Evidence 478.298\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.81e-01\n",
      "Loss: 149.974, Residuals: 0.014\n",
      "Loss: 149.927, Residuals: 0.014\n",
      "Loss: 149.923, Residuals: 0.013\n",
      "Loss: 149.917, Residuals: 0.013\n",
      "Loss: 149.909, Residuals: 0.013\n",
      "Loss: 149.909, Residuals: 0.012\n",
      "Loss: 149.908, Residuals: 0.012\n",
      "Loss: 149.907, Residuals: 0.012\n",
      "Loss: 149.907, Residuals: 0.012\n",
      "Loss: 149.905, Residuals: 0.012\n",
      "Loss: 149.905, Residuals: 0.012\n",
      "Loss: 149.905, Residuals: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 149.904, Residuals: 0.012\n",
      "Loss: 149.904, Residuals: 0.012\n",
      "Loss: 149.904, Residuals: 0.012\n",
      "Loss: 149.904, Residuals: 0.012\n",
      "Evidence 479.509\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.78e-01\n",
      "Loss: 150.354, Residuals: 0.014\n",
      "Loss: 150.332, Residuals: 0.013\n",
      "Loss: 150.331, Residuals: 0.013\n",
      "Loss: 150.327, Residuals: 0.012\n",
      "Loss: 150.325, Residuals: 0.012\n",
      "Loss: 150.325, Residuals: 0.012\n",
      "Loss: 150.322, Residuals: 0.012\n",
      "Loss: 150.318, Residuals: 0.012\n",
      "Loss: 150.318, Residuals: 0.012\n",
      "Loss: 150.318, Residuals: 0.012\n",
      "Loss: 150.317, Residuals: 0.012\n",
      "Loss: 150.317, Residuals: 0.012\n",
      "Evidence 480.258\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.76e-01\n",
      "Loss: 150.638, Residuals: 0.013\n",
      "Loss: 150.629, Residuals: 0.012\n",
      "Loss: 150.627, Residuals: 0.012\n",
      "Loss: 150.626, Residuals: 0.012\n",
      "Loss: 150.625, Residuals: 0.012\n",
      "Loss: 150.622, Residuals: 0.012\n",
      "Loss: 150.622, Residuals: 0.011\n",
      "Loss: 150.620, Residuals: 0.011\n",
      "Loss: 150.617, Residuals: 0.011\n",
      "Loss: 150.617, Residuals: 0.011\n",
      "Loss: 150.616, Residuals: 0.011\n",
      "Loss: 150.616, Residuals: 0.011\n",
      "Loss: 150.615, Residuals: 0.011\n",
      "Loss: 150.615, Residuals: 0.011\n",
      "Loss: 150.614, Residuals: 0.011\n",
      "Loss: 150.614, Residuals: 0.011\n",
      "Loss: 150.613, Residuals: 0.011\n",
      "Loss: 150.613, Residuals: 0.011\n",
      "Evidence 480.719\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.101, Residuals: -0.077\n",
      "Loss: 7.453, Residuals: -0.040\n",
      "Loss: 4.456, Residuals: -0.059\n",
      "Loss: 4.244, Residuals: 0.038\n",
      "Loss: 3.866, Residuals: 0.003\n",
      "Loss: 3.386, Residuals: -0.044\n",
      "Loss: 3.279, Residuals: -0.018\n",
      "Loss: 3.143, Residuals: 0.005\n",
      "Loss: 2.939, Residuals: -0.016\n",
      "Loss: 2.926, Residuals: -0.014\n",
      "Loss: 2.901, Residuals: -0.017\n",
      "Loss: 2.715, Residuals: -0.035\n",
      "Loss: 2.701, Residuals: -0.010\n",
      "Loss: 2.675, Residuals: -0.014\n",
      "Loss: 2.626, Residuals: -0.022\n",
      "Loss: 2.544, Residuals: -0.036\n",
      "Loss: 2.528, Residuals: -0.025\n",
      "Loss: 2.501, Residuals: -0.034\n",
      "Loss: 2.490, Residuals: -0.032\n",
      "Loss: 2.470, Residuals: -0.038\n",
      "Loss: 2.434, Residuals: -0.048\n",
      "Loss: 2.431, Residuals: -0.038\n",
      "Loss: 2.399, Residuals: -0.048\n",
      "Loss: 2.355, Residuals: -0.056\n",
      "Loss: 2.351, Residuals: -0.053\n",
      "Loss: 2.346, Residuals: -0.042\n",
      "Loss: 2.339, Residuals: -0.044\n",
      "Loss: 2.285, Residuals: -0.057\n",
      "Loss: 2.284, Residuals: -0.054\n",
      "Loss: 2.282, Residuals: -0.054\n",
      "Loss: 2.279, Residuals: -0.050\n",
      "Loss: 2.273, Residuals: -0.051\n",
      "Loss: 2.263, Residuals: -0.052\n",
      "Loss: 2.179, Residuals: -0.072\n",
      "Loss: 2.175, Residuals: -0.070\n",
      "Loss: 2.169, Residuals: -0.069\n",
      "Loss: 2.157, Residuals: -0.067\n",
      "Loss: 2.141, Residuals: -0.060\n",
      "Loss: 2.141, Residuals: -0.061\n",
      "Loss: 2.141, Residuals: -0.060\n",
      "Loss: 2.139, Residuals: -0.059\n",
      "Loss: 2.124, Residuals: -0.059\n",
      "Loss: 2.123, Residuals: -0.052\n",
      "Loss: 2.094, Residuals: -0.062\n",
      "Loss: 2.094, Residuals: -0.061\n",
      "Loss: 2.093, Residuals: -0.061\n",
      "Loss: 2.092, Residuals: -0.060\n",
      "Loss: 2.091, Residuals: -0.060\n",
      "Loss: 2.077, Residuals: -0.064\n",
      "Loss: 2.077, Residuals: -0.064\n",
      "Loss: 2.064, Residuals: -0.069\n",
      "Loss: 2.064, Residuals: -0.069\n",
      "Evidence -412.557\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.43e-02\n",
      "Loss: 12.078, Residuals: -0.069\n",
      "Loss: 11.984, Residuals: -0.055\n",
      "Loss: 11.822, Residuals: -0.052\n",
      "Loss: 11.605, Residuals: -0.045\n",
      "Loss: 11.603, Residuals: -0.044\n",
      "Loss: 11.519, Residuals: -0.041\n",
      "Loss: 11.510, Residuals: -0.045\n",
      "Loss: 11.430, Residuals: -0.039\n",
      "Loss: 11.428, Residuals: -0.037\n",
      "Loss: 11.376, Residuals: -0.034\n",
      "Loss: 11.368, Residuals: -0.034\n",
      "Loss: 11.301, Residuals: -0.029\n",
      "Loss: 11.301, Residuals: -0.027\n",
      "Loss: 11.300, Residuals: -0.028\n",
      "Loss: 11.248, Residuals: -0.025\n",
      "Loss: 11.248, Residuals: -0.024\n",
      "Loss: 11.246, Residuals: -0.025\n",
      "Loss: 11.192, Residuals: -0.021\n",
      "Loss: 11.192, Residuals: -0.022\n",
      "Loss: 11.191, Residuals: -0.023\n",
      "Loss: 11.159, Residuals: -0.020\n",
      "Loss: 11.153, Residuals: -0.022\n",
      "Loss: 11.152, Residuals: -0.022\n",
      "Loss: 11.150, Residuals: -0.022\n",
      "Loss: 11.135, Residuals: -0.021\n",
      "Loss: 11.107, Residuals: -0.019\n",
      "Loss: 11.107, Residuals: -0.019\n",
      "Evidence 105.117\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.05e-01\n",
      "Loss: 40.989, Residuals: -0.021\n",
      "Loss: 40.807, Residuals: -0.017\n",
      "Loss: 40.617, Residuals: -0.008\n",
      "Loss: 40.371, Residuals: -0.003\n",
      "Loss: 40.334, Residuals: -0.002\n",
      "Loss: 40.334, Residuals: -0.001\n",
      "Loss: 40.328, Residuals: -0.002\n",
      "Loss: 40.118, Residuals: 0.002\n",
      "Loss: 40.064, Residuals: -0.000\n",
      "Loss: 40.050, Residuals: -0.001\n",
      "Loss: 40.047, Residuals: -0.000\n",
      "Loss: 40.046, Residuals: -0.001\n",
      "Loss: 40.043, Residuals: -0.001\n",
      "Loss: 39.942, Residuals: -0.000\n",
      "Loss: 39.798, Residuals: 0.002\n",
      "Loss: 39.797, Residuals: 0.003\n",
      "Loss: 39.795, Residuals: 0.002\n",
      "Loss: 39.792, Residuals: 0.002\n",
      "Loss: 39.786, Residuals: 0.002\n",
      "Loss: 39.776, Residuals: 0.002\n",
      "Loss: 39.699, Residuals: 0.003\n",
      "Loss: 39.692, Residuals: 0.005\n",
      "Loss: 39.691, Residuals: 0.004\n",
      "Loss: 39.689, Residuals: 0.004\n",
      "Loss: 39.687, Residuals: 0.003\n",
      "Loss: 39.682, Residuals: 0.003\n",
      "Loss: 39.676, Residuals: 0.003\n",
      "Loss: 39.676, Residuals: 0.002\n",
      "Loss: 39.607, Residuals: 0.004\n",
      "Loss: 39.597, Residuals: 0.007\n",
      "Loss: 39.590, Residuals: 0.004\n",
      "Loss: 39.582, Residuals: 0.004\n",
      "Loss: 39.570, Residuals: 0.005\n",
      "Loss: 39.569, Residuals: 0.005\n",
      "Loss: 39.527, Residuals: 0.006\n",
      "Loss: 39.524, Residuals: 0.005\n",
      "Loss: 39.520, Residuals: 0.005\n",
      "Loss: 39.475, Residuals: 0.007\n",
      "Loss: 39.471, Residuals: 0.007\n",
      "Loss: 39.464, Residuals: 0.007\n",
      "Loss: 39.338, Residuals: 0.009\n",
      "Loss: 39.273, Residuals: 0.016\n",
      "Loss: 39.178, Residuals: 0.009\n",
      "Loss: 39.119, Residuals: 0.014\n",
      "Loss: 39.019, Residuals: 0.013\n",
      "Loss: 38.883, Residuals: 0.015\n",
      "Loss: 38.868, Residuals: 0.014\n",
      "Loss: 38.754, Residuals: 0.015\n",
      "Loss: 38.734, Residuals: 0.017\n",
      "Loss: 38.695, Residuals: 0.017\n",
      "Loss: 38.631, Residuals: 0.018\n",
      "Loss: 38.620, Residuals: 0.019\n",
      "Loss: 38.600, Residuals: 0.019\n",
      "Loss: 38.569, Residuals: 0.019\n",
      "Loss: 38.567, Residuals: 0.020\n",
      "Loss: 38.553, Residuals: 0.020\n",
      "Loss: 38.549, Residuals: 0.020\n",
      "Loss: 38.544, Residuals: 0.020\n",
      "Loss: 38.538, Residuals: 0.020\n",
      "Loss: 38.537, Residuals: 0.020\n",
      "Loss: 38.537, Residuals: 0.020\n",
      "Loss: 38.537, Residuals: 0.020\n",
      "Loss: 38.537, Residuals: 0.020\n",
      "Loss: 38.536, Residuals: 0.020\n",
      "Loss: 38.536, Residuals: 0.020\n",
      "Loss: 38.536, Residuals: 0.021\n",
      "Evidence 315.487\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.96e-01\n",
      "Loss: 83.203, Residuals: 0.016\n",
      "Loss: 82.842, Residuals: 0.009\n",
      "Loss: 82.645, Residuals: 0.015\n",
      "Loss: 82.514, Residuals: 0.013\n",
      "Loss: 82.494, Residuals: 0.012\n",
      "Loss: 82.468, Residuals: 0.010\n",
      "Loss: 82.422, Residuals: 0.011\n",
      "Loss: 82.419, Residuals: 0.011\n",
      "Loss: 82.390, Residuals: 0.011\n",
      "Loss: 82.343, Residuals: 0.011\n",
      "Loss: 82.340, Residuals: 0.011\n",
      "Loss: 82.335, Residuals: 0.011\n",
      "Loss: 82.333, Residuals: 0.010\n",
      "Loss: 82.312, Residuals: 0.011\n",
      "Loss: 82.310, Residuals: 0.011\n",
      "Loss: 82.298, Residuals: 0.011\n",
      "Loss: 82.297, Residuals: 0.011\n",
      "Loss: 82.287, Residuals: 0.010\n",
      "Loss: 82.285, Residuals: 0.010\n",
      "Loss: 82.273, Residuals: 0.010\n",
      "Loss: 82.271, Residuals: 0.010\n",
      "Loss: 82.258, Residuals: 0.010\n",
      "Loss: 82.256, Residuals: 0.010\n",
      "Loss: 82.253, Residuals: 0.010\n",
      "Loss: 82.251, Residuals: 0.010\n",
      "Loss: 82.248, Residuals: 0.010\n",
      "Loss: 82.247, Residuals: 0.010\n",
      "Loss: 82.228, Residuals: 0.010\n",
      "Loss: 82.227, Residuals: 0.010\n",
      "Loss: 82.219, Residuals: 0.010\n",
      "Loss: 82.218, Residuals: 0.010\n",
      "Loss: 82.215, Residuals: 0.010\n",
      "Loss: 82.214, Residuals: 0.010\n",
      "Loss: 82.212, Residuals: 0.010\n",
      "Loss: 82.212, Residuals: 0.010\n",
      "Loss: 82.208, Residuals: 0.010\n",
      "Loss: 82.206, Residuals: 0.010\n",
      "Loss: 82.206, Residuals: 0.010\n",
      "Loss: 82.202, Residuals: 0.010\n",
      "Loss: 82.201, Residuals: 0.009\n",
      "Loss: 82.197, Residuals: 0.010\n",
      "Loss: 82.197, Residuals: 0.010\n",
      "Loss: 82.196, Residuals: 0.010\n",
      "Loss: 82.195, Residuals: 0.010\n",
      "Loss: 82.194, Residuals: 0.010\n",
      "Loss: 82.192, Residuals: 0.010\n",
      "Loss: 82.192, Residuals: 0.010\n",
      "Loss: 82.190, Residuals: 0.010\n",
      "Loss: 82.189, Residuals: 0.009\n",
      "Loss: 82.188, Residuals: 0.009\n",
      "Loss: 82.187, Residuals: 0.010\n",
      "Loss: 82.187, Residuals: 0.010\n",
      "Loss: 82.185, Residuals: 0.010\n",
      "Loss: 82.185, Residuals: 0.010\n",
      "Evidence 436.448\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.59e+00\n",
      "Loss: 123.559, Residuals: 0.004\n",
      "Loss: 123.373, Residuals: 0.003\n",
      "Loss: 123.124, Residuals: -0.003\n",
      "Loss: 122.995, Residuals: -0.005\n",
      "Loss: 122.945, Residuals: -0.005\n",
      "Loss: 122.923, Residuals: -0.006\n",
      "Loss: 122.919, Residuals: -0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 122.885, Residuals: -0.006\n",
      "Loss: 122.854, Residuals: -0.007\n",
      "Loss: 122.853, Residuals: -0.007\n",
      "Loss: 122.852, Residuals: -0.007\n",
      "Loss: 122.851, Residuals: -0.007\n",
      "Loss: 122.849, Residuals: -0.007\n",
      "Loss: 122.849, Residuals: -0.007\n",
      "Loss: 122.849, Residuals: -0.007\n",
      "Evidence 481.377\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.84e+00\n",
      "Loss: 144.688, Residuals: -0.012\n",
      "Loss: 144.612, Residuals: -0.013\n",
      "Loss: 144.504, Residuals: -0.014\n",
      "Loss: 144.396, Residuals: -0.018\n",
      "Loss: 144.394, Residuals: -0.017\n",
      "Loss: 144.389, Residuals: -0.017\n",
      "Loss: 144.382, Residuals: -0.018\n",
      "Loss: 144.372, Residuals: -0.018\n",
      "Loss: 144.371, Residuals: -0.019\n",
      "Loss: 144.369, Residuals: -0.019\n",
      "Loss: 144.364, Residuals: -0.019\n",
      "Loss: 144.360, Residuals: -0.020\n",
      "Loss: 144.360, Residuals: -0.020\n",
      "Loss: 144.360, Residuals: -0.019\n",
      "Loss: 144.360, Residuals: -0.019\n",
      "Loss: 144.359, Residuals: -0.019\n",
      "Loss: 144.359, Residuals: -0.019\n",
      "Loss: 144.359, Residuals: -0.019\n",
      "Evidence 492.493\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.84e+00\n",
      "Loss: 152.350, Residuals: -0.021\n",
      "Loss: 152.262, Residuals: -0.024\n",
      "Loss: 152.251, Residuals: -0.025\n",
      "Loss: 152.234, Residuals: -0.025\n",
      "Loss: 152.208, Residuals: -0.026\n",
      "Loss: 152.207, Residuals: -0.025\n",
      "Loss: 152.198, Residuals: -0.026\n",
      "Loss: 152.189, Residuals: -0.027\n",
      "Loss: 152.189, Residuals: -0.027\n",
      "Loss: 152.189, Residuals: -0.027\n",
      "Loss: 152.188, Residuals: -0.027\n",
      "Loss: 152.187, Residuals: -0.027\n",
      "Loss: 152.187, Residuals: -0.027\n",
      "Evidence 495.641\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.80e+00\n",
      "Loss: 154.895, Residuals: -0.026\n",
      "Loss: 154.851, Residuals: -0.030\n",
      "Loss: 154.844, Residuals: -0.030\n",
      "Loss: 154.831, Residuals: -0.030\n",
      "Loss: 154.816, Residuals: -0.031\n",
      "Loss: 154.815, Residuals: -0.031\n",
      "Loss: 154.812, Residuals: -0.031\n",
      "Loss: 154.812, Residuals: -0.031\n",
      "Loss: 154.811, Residuals: -0.031\n",
      "Loss: 154.810, Residuals: -0.031\n",
      "Evidence 496.964\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.77e+00\n",
      "Loss: 155.800, Residuals: -0.032\n",
      "Loss: 155.798, Residuals: -0.032\n",
      "Loss: 155.782, Residuals: -0.032\n",
      "Loss: 155.770, Residuals: -0.033\n",
      "Loss: 155.769, Residuals: -0.033\n",
      "Loss: 155.768, Residuals: -0.033\n",
      "Loss: 155.766, Residuals: -0.033\n",
      "Loss: 155.766, Residuals: -0.034\n",
      "Loss: 155.766, Residuals: -0.034\n",
      "Loss: 155.765, Residuals: -0.034\n",
      "Loss: 155.765, Residuals: -0.034\n",
      "Evidence 497.690\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.74e+00\n",
      "Loss: 156.192, Residuals: -0.035\n",
      "Loss: 156.191, Residuals: -0.035\n",
      "Loss: 156.188, Residuals: -0.035\n",
      "Loss: 156.183, Residuals: -0.035\n",
      "Loss: 156.176, Residuals: -0.035\n",
      "Loss: 156.175, Residuals: -0.035\n",
      "Loss: 156.174, Residuals: -0.035\n",
      "Loss: 156.172, Residuals: -0.035\n",
      "Loss: 156.170, Residuals: -0.035\n",
      "Loss: 156.169, Residuals: -0.035\n",
      "Loss: 156.169, Residuals: -0.036\n",
      "Loss: 156.169, Residuals: -0.036\n",
      "Loss: 156.168, Residuals: -0.036\n",
      "Loss: 156.168, Residuals: -0.036\n",
      "Evidence 498.152\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.731, Residuals: -0.015\n",
      "Loss: 7.568, Residuals: -0.035\n",
      "Loss: 5.165, Residuals: -0.049\n",
      "Loss: 4.633, Residuals: -0.047\n",
      "Loss: 4.077, Residuals: -0.028\n",
      "Loss: 3.928, Residuals: -0.027\n",
      "Loss: 3.692, Residuals: -0.015\n",
      "Loss: 3.514, Residuals: -0.016\n",
      "Loss: 3.482, Residuals: -0.027\n",
      "Loss: 3.438, Residuals: -0.034\n",
      "Loss: 3.359, Residuals: -0.042\n",
      "Loss: 3.225, Residuals: -0.056\n",
      "Loss: 3.209, Residuals: -0.029\n",
      "Loss: 3.073, Residuals: -0.045\n",
      "Loss: 3.021, Residuals: -0.046\n",
      "Loss: 3.018, Residuals: -0.049\n",
      "Loss: 2.985, Residuals: -0.053\n",
      "Loss: 2.925, Residuals: -0.060\n",
      "Loss: 2.912, Residuals: -0.031\n",
      "Loss: 2.806, Residuals: -0.051\n",
      "Loss: 2.802, Residuals: -0.045\n",
      "Loss: 2.793, Residuals: -0.047\n",
      "Loss: 2.780, Residuals: -0.048\n",
      "Loss: 2.753, Residuals: -0.054\n",
      "Loss: 2.704, Residuals: -0.063\n",
      "Loss: 2.695, Residuals: -0.054\n",
      "Loss: 2.695, Residuals: -0.055\n",
      "Evidence -396.610\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.95e-03\n",
      "Loss: 12.394, Residuals: -0.063\n",
      "Loss: 12.391, Residuals: -0.061\n",
      "Loss: 12.288, Residuals: -0.058\n",
      "Loss: 12.126, Residuals: -0.050\n",
      "Loss: 11.925, Residuals: -0.038\n",
      "Loss: 11.908, Residuals: -0.037\n",
      "Loss: 11.885, Residuals: -0.032\n",
      "Loss: 11.862, Residuals: -0.030\n",
      "Loss: 11.828, Residuals: -0.028\n",
      "Loss: 11.827, Residuals: -0.029\n",
      "Loss: 11.792, Residuals: -0.028\n",
      "Loss: 11.791, Residuals: -0.027\n",
      "Loss: 11.787, Residuals: -0.027\n",
      "Loss: 11.779, Residuals: -0.025\n",
      "Loss: 11.775, Residuals: -0.023\n",
      "Loss: 11.750, Residuals: -0.024\n",
      "Loss: 11.749, Residuals: -0.025\n",
      "Loss: 11.749, Residuals: -0.024\n",
      "Loss: 11.747, Residuals: -0.024\n",
      "Loss: 11.735, Residuals: -0.024\n",
      "Loss: 11.735, Residuals: -0.024\n",
      "Loss: 11.729, Residuals: -0.024\n",
      "Loss: 11.727, Residuals: -0.023\n",
      "Loss: 11.723, Residuals: -0.022\n",
      "Loss: 11.723, Residuals: -0.022\n",
      "Loss: 11.717, Residuals: -0.022\n",
      "Loss: 11.717, Residuals: -0.022\n",
      "Loss: 11.707, Residuals: -0.023\n",
      "Loss: 11.707, Residuals: -0.023\n",
      "Loss: 11.706, Residuals: -0.022\n",
      "Loss: 11.696, Residuals: -0.021\n",
      "Loss: 11.695, Residuals: -0.020\n",
      "Loss: 11.694, Residuals: -0.021\n",
      "Loss: 11.691, Residuals: -0.021\n",
      "Loss: 11.685, Residuals: -0.020\n",
      "Loss: 11.683, Residuals: -0.020\n",
      "Loss: 11.680, Residuals: -0.020\n",
      "Loss: 11.680, Residuals: -0.019\n",
      "Loss: 11.667, Residuals: -0.019\n",
      "Loss: 11.666, Residuals: -0.018\n",
      "Loss: 11.664, Residuals: -0.018\n",
      "Loss: 11.660, Residuals: -0.018\n",
      "Loss: 11.653, Residuals: -0.018\n",
      "Loss: 11.652, Residuals: -0.017\n",
      "Loss: 11.648, Residuals: -0.017\n",
      "Loss: 11.648, Residuals: -0.016\n",
      "Loss: 11.645, Residuals: -0.016\n",
      "Loss: 11.639, Residuals: -0.016\n",
      "Loss: 11.636, Residuals: -0.016\n",
      "Loss: 11.632, Residuals: -0.015\n",
      "Loss: 11.630, Residuals: -0.015\n",
      "Loss: 11.627, Residuals: -0.014\n",
      "Loss: 11.626, Residuals: -0.014\n",
      "Loss: 11.621, Residuals: -0.014\n",
      "Loss: 11.621, Residuals: -0.014\n",
      "Loss: 11.617, Residuals: -0.014\n",
      "Loss: 11.616, Residuals: -0.014\n",
      "Loss: 11.614, Residuals: -0.014\n",
      "Loss: 11.614, Residuals: -0.013\n",
      "Loss: 11.610, Residuals: -0.013\n",
      "Loss: 11.610, Residuals: -0.013\n",
      "Loss: 11.608, Residuals: -0.013\n",
      "Loss: 11.608, Residuals: -0.014\n",
      "Loss: 11.607, Residuals: -0.014\n",
      "Loss: 11.605, Residuals: -0.014\n",
      "Loss: 11.605, Residuals: -0.013\n",
      "Loss: 11.604, Residuals: -0.013\n",
      "Loss: 11.603, Residuals: -0.013\n",
      "Loss: 11.603, Residuals: -0.013\n",
      "Loss: 11.602, Residuals: -0.013\n",
      "Loss: 11.601, Residuals: -0.013\n",
      "Loss: 11.601, Residuals: -0.013\n",
      "Loss: 11.599, Residuals: -0.014\n",
      "Loss: 11.599, Residuals: -0.013\n",
      "Loss: 11.598, Residuals: -0.013\n",
      "Loss: 11.598, Residuals: -0.013\n",
      "Loss: 11.597, Residuals: -0.013\n",
      "Loss: 11.597, Residuals: -0.013\n",
      "Loss: 11.596, Residuals: -0.013\n",
      "Loss: 11.596, Residuals: -0.013\n",
      "Loss: 11.596, Residuals: -0.013\n",
      "Loss: 11.595, Residuals: -0.013\n",
      "Loss: 11.595, Residuals: -0.013\n",
      "Loss: 11.595, Residuals: -0.013\n",
      "Loss: 11.594, Residuals: -0.013\n",
      "Loss: 11.594, Residuals: -0.013\n",
      "Loss: 11.593, Residuals: -0.014\n",
      "Loss: 11.593, Residuals: -0.013\n",
      "Loss: 11.593, Residuals: -0.013\n",
      "Loss: 11.593, Residuals: -0.013\n",
      "Loss: 11.592, Residuals: -0.014\n",
      "Loss: 11.592, Residuals: -0.013\n",
      "Loss: 11.592, Residuals: -0.014\n",
      "Loss: 11.592, Residuals: -0.014\n",
      "Evidence 94.880\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.34e-02\n",
      "Loss: 39.112, Residuals: -0.004\n",
      "Loss: 38.919, Residuals: -0.006\n",
      "Loss: 38.774, Residuals: -0.000\n",
      "Loss: 38.724, Residuals: -0.005\n",
      "Loss: 38.676, Residuals: -0.003\n",
      "Loss: 38.599, Residuals: -0.002\n",
      "Loss: 38.590, Residuals: -0.001\n",
      "Loss: 38.517, Residuals: -0.001\n",
      "Loss: 38.472, Residuals: 0.001\n",
      "Loss: 38.467, Residuals: -0.001\n",
      "Loss: 38.461, Residuals: -0.000\n",
      "Loss: 38.450, Residuals: -0.000\n",
      "Loss: 38.440, Residuals: 0.001\n",
      "Loss: 38.438, Residuals: 0.001\n",
      "Loss: 38.436, Residuals: 0.001\n",
      "Loss: 38.436, Residuals: 0.001\n",
      "Loss: 38.435, Residuals: 0.001\n",
      "Loss: 38.433, Residuals: 0.001\n",
      "Loss: 38.433, Residuals: 0.001\n",
      "Loss: 38.432, Residuals: 0.001\n",
      "Loss: 38.432, Residuals: 0.001\n",
      "Loss: 38.431, Residuals: 0.001\n",
      "Loss: 38.431, Residuals: 0.001\n",
      "Loss: 38.429, Residuals: 0.001\n",
      "Loss: 38.429, Residuals: 0.001\n",
      "Evidence 296.184\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.32e-01\n",
      "Loss: 81.658, Residuals: 0.012\n",
      "Loss: 81.404, Residuals: -0.002\n",
      "Loss: 81.182, Residuals: -0.008\n",
      "Loss: 81.112, Residuals: -0.006\n",
      "Loss: 81.077, Residuals: -0.007\n",
      "Loss: 81.040, Residuals: -0.007\n",
      "Loss: 81.038, Residuals: -0.005\n",
      "Loss: 80.977, Residuals: -0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 80.886, Residuals: -0.007\n",
      "Loss: 80.882, Residuals: -0.007\n",
      "Loss: 80.852, Residuals: -0.008\n",
      "Loss: 80.850, Residuals: -0.008\n",
      "Loss: 80.828, Residuals: -0.008\n",
      "Loss: 80.827, Residuals: -0.008\n",
      "Loss: 80.822, Residuals: -0.008\n",
      "Loss: 80.821, Residuals: -0.009\n",
      "Loss: 80.811, Residuals: -0.009\n",
      "Loss: 80.810, Residuals: -0.009\n",
      "Loss: 80.801, Residuals: -0.009\n",
      "Loss: 80.801, Residuals: -0.009\n",
      "Loss: 80.793, Residuals: -0.009\n",
      "Loss: 80.793, Residuals: -0.009\n",
      "Loss: 80.787, Residuals: -0.009\n",
      "Loss: 80.786, Residuals: -0.009\n",
      "Loss: 80.785, Residuals: -0.009\n",
      "Loss: 80.784, Residuals: -0.009\n",
      "Loss: 80.778, Residuals: -0.009\n",
      "Loss: 80.777, Residuals: -0.009\n",
      "Loss: 80.775, Residuals: -0.009\n",
      "Loss: 80.775, Residuals: -0.009\n",
      "Loss: 80.771, Residuals: -0.009\n",
      "Loss: 80.771, Residuals: -0.009\n",
      "Loss: 80.771, Residuals: -0.009\n",
      "Loss: 80.771, Residuals: -0.009\n",
      "Loss: 80.770, Residuals: -0.009\n",
      "Loss: 80.770, Residuals: -0.010\n",
      "Evidence 408.380\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.74e-01\n",
      "Loss: 120.166, Residuals: -0.005\n",
      "Loss: 119.834, Residuals: -0.010\n",
      "Loss: 119.577, Residuals: -0.019\n",
      "Loss: 119.445, Residuals: -0.021\n",
      "Loss: 119.253, Residuals: -0.021\n",
      "Loss: 119.243, Residuals: -0.022\n",
      "Loss: 119.149, Residuals: -0.023\n",
      "Loss: 119.139, Residuals: -0.023\n",
      "Loss: 119.056, Residuals: -0.024\n",
      "Loss: 119.053, Residuals: -0.025\n",
      "Loss: 119.021, Residuals: -0.025\n",
      "Loss: 119.018, Residuals: -0.025\n",
      "Loss: 118.991, Residuals: -0.025\n",
      "Loss: 118.990, Residuals: -0.026\n",
      "Loss: 118.956, Residuals: -0.026\n",
      "Loss: 118.954, Residuals: -0.026\n",
      "Loss: 118.950, Residuals: -0.026\n",
      "Loss: 118.944, Residuals: -0.026\n",
      "Loss: 118.944, Residuals: -0.026\n",
      "Loss: 118.915, Residuals: -0.026\n",
      "Loss: 118.915, Residuals: -0.026\n",
      "Loss: 118.907, Residuals: -0.025\n",
      "Loss: 118.894, Residuals: -0.025\n",
      "Loss: 118.893, Residuals: -0.026\n",
      "Loss: 118.892, Residuals: -0.026\n",
      "Loss: 118.890, Residuals: -0.026\n",
      "Loss: 118.890, Residuals: -0.026\n",
      "Loss: 118.884, Residuals: -0.025\n",
      "Loss: 118.882, Residuals: -0.025\n",
      "Loss: 118.882, Residuals: -0.026\n",
      "Loss: 118.881, Residuals: -0.026\n",
      "Loss: 118.879, Residuals: -0.025\n",
      "Loss: 118.879, Residuals: -0.025\n",
      "Loss: 118.878, Residuals: -0.025\n",
      "Loss: 118.876, Residuals: -0.025\n",
      "Loss: 118.876, Residuals: -0.025\n",
      "Loss: 118.876, Residuals: -0.025\n",
      "Loss: 118.875, Residuals: -0.025\n",
      "Evidence 449.981\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.49e-01\n",
      "Loss: 139.692, Residuals: -0.025\n",
      "Loss: 139.558, Residuals: -0.027\n",
      "Loss: 139.362, Residuals: -0.032\n",
      "Loss: 139.124, Residuals: -0.035\n",
      "Loss: 139.112, Residuals: -0.035\n",
      "Loss: 139.022, Residuals: -0.036\n",
      "Loss: 139.005, Residuals: -0.037\n",
      "Loss: 138.974, Residuals: -0.037\n",
      "Loss: 138.925, Residuals: -0.038\n",
      "Loss: 138.922, Residuals: -0.038\n",
      "Loss: 138.916, Residuals: -0.038\n",
      "Loss: 138.905, Residuals: -0.038\n",
      "Loss: 138.888, Residuals: -0.038\n",
      "Loss: 138.886, Residuals: -0.038\n",
      "Loss: 138.876, Residuals: -0.038\n",
      "Loss: 138.873, Residuals: -0.038\n",
      "Loss: 138.873, Residuals: -0.038\n",
      "Loss: 138.869, Residuals: -0.038\n",
      "Loss: 138.864, Residuals: -0.038\n",
      "Loss: 138.863, Residuals: -0.038\n",
      "Loss: 138.863, Residuals: -0.038\n",
      "Loss: 138.862, Residuals: -0.037\n",
      "Loss: 138.861, Residuals: -0.038\n",
      "Loss: 138.861, Residuals: -0.038\n",
      "Loss: 138.861, Residuals: -0.038\n",
      "Loss: 138.861, Residuals: -0.038\n",
      "Loss: 138.861, Residuals: -0.037\n",
      "Loss: 138.861, Residuals: -0.037\n",
      "Evidence 461.150\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.56e-01\n",
      "Loss: 146.743, Residuals: -0.037\n",
      "Loss: 146.635, Residuals: -0.039\n",
      "Loss: 146.500, Residuals: -0.041\n",
      "Loss: 146.488, Residuals: -0.043\n",
      "Loss: 146.466, Residuals: -0.043\n",
      "Loss: 146.457, Residuals: -0.043\n",
      "Loss: 146.439, Residuals: -0.043\n",
      "Loss: 146.413, Residuals: -0.044\n",
      "Loss: 146.410, Residuals: -0.044\n",
      "Loss: 146.389, Residuals: -0.044\n",
      "Loss: 146.387, Residuals: -0.044\n",
      "Loss: 146.383, Residuals: -0.044\n",
      "Loss: 146.382, Residuals: -0.044\n",
      "Loss: 146.379, Residuals: -0.044\n",
      "Loss: 146.373, Residuals: -0.044\n",
      "Loss: 146.373, Residuals: -0.044\n",
      "Loss: 146.372, Residuals: -0.044\n",
      "Loss: 146.371, Residuals: -0.044\n",
      "Loss: 146.370, Residuals: -0.044\n",
      "Loss: 146.370, Residuals: -0.044\n",
      "Loss: 146.369, Residuals: -0.044\n",
      "Loss: 146.369, Residuals: -0.044\n",
      "Loss: 146.369, Residuals: -0.044\n",
      "Loss: 146.369, Residuals: -0.044\n",
      "Loss: 146.369, Residuals: -0.044\n",
      "Evidence 464.251\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.95e-01\n",
      "Loss: 149.190, Residuals: -0.042\n",
      "Loss: 149.131, Residuals: -0.043\n",
      "Loss: 149.102, Residuals: -0.047\n",
      "Loss: 149.057, Residuals: -0.047\n",
      "Loss: 149.053, Residuals: -0.047\n",
      "Loss: 149.026, Residuals: -0.047\n",
      "Loss: 149.010, Residuals: -0.047\n",
      "Loss: 149.008, Residuals: -0.047\n",
      "Loss: 149.006, Residuals: -0.047\n",
      "Loss: 149.002, Residuals: -0.047\n",
      "Loss: 149.001, Residuals: -0.047\n",
      "Loss: 148.999, Residuals: -0.047\n",
      "Loss: 148.996, Residuals: -0.047\n",
      "Loss: 148.996, Residuals: -0.047\n",
      "Loss: 148.995, Residuals: -0.047\n",
      "Loss: 148.995, Residuals: -0.047\n",
      "Loss: 148.995, Residuals: -0.047\n",
      "Loss: 148.994, Residuals: -0.047\n",
      "Loss: 148.994, Residuals: -0.047\n",
      "Loss: 148.994, Residuals: -0.047\n",
      "Loss: 148.994, Residuals: -0.047\n",
      "Evidence 465.490\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.11e-01\n",
      "Loss: 150.144, Residuals: -0.047\n",
      "Loss: 150.093, Residuals: -0.047\n",
      "Loss: 150.089, Residuals: -0.047\n",
      "Loss: 150.082, Residuals: -0.048\n",
      "Loss: 150.072, Residuals: -0.048\n",
      "Loss: 150.071, Residuals: -0.048\n",
      "Loss: 150.069, Residuals: -0.048\n",
      "Loss: 150.065, Residuals: -0.048\n",
      "Loss: 150.060, Residuals: -0.048\n",
      "Loss: 150.060, Residuals: -0.048\n",
      "Loss: 150.060, Residuals: -0.049\n",
      "Loss: 150.059, Residuals: -0.049\n",
      "Loss: 150.059, Residuals: -0.048\n",
      "Loss: 150.058, Residuals: -0.048\n",
      "Loss: 150.058, Residuals: -0.048\n",
      "Loss: 150.058, Residuals: -0.048\n",
      "Loss: 150.058, Residuals: -0.048\n",
      "Loss: 150.058, Residuals: -0.048\n",
      "Loss: 150.058, Residuals: -0.048\n",
      "Loss: 150.058, Residuals: -0.048\n",
      "Evidence 466.213\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.16e-01\n",
      "Loss: 150.662, Residuals: -0.048\n",
      "Loss: 150.636, Residuals: -0.049\n",
      "Loss: 150.634, Residuals: -0.049\n",
      "Loss: 150.629, Residuals: -0.049\n",
      "Loss: 150.622, Residuals: -0.049\n",
      "Loss: 150.622, Residuals: -0.049\n",
      "Loss: 150.622, Residuals: -0.049\n",
      "Loss: 150.621, Residuals: -0.049\n",
      "Loss: 150.620, Residuals: -0.049\n",
      "Loss: 150.620, Residuals: -0.049\n",
      "Loss: 150.619, Residuals: -0.049\n",
      "Loss: 150.619, Residuals: -0.049\n",
      "Evidence 466.721\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.13e-01\n",
      "Loss: 150.994, Residuals: -0.049\n",
      "Loss: 150.983, Residuals: -0.050\n",
      "Loss: 150.978, Residuals: -0.049\n",
      "Loss: 150.974, Residuals: -0.050\n",
      "Loss: 150.973, Residuals: -0.050\n",
      "Loss: 150.971, Residuals: -0.050\n",
      "Loss: 150.970, Residuals: -0.050\n",
      "Loss: 150.970, Residuals: -0.050\n",
      "Loss: 150.969, Residuals: -0.050\n",
      "Loss: 150.969, Residuals: -0.050\n",
      "Loss: 150.969, Residuals: -0.050\n",
      "Loss: 150.968, Residuals: -0.050\n",
      "Loss: 150.968, Residuals: -0.050\n",
      "Evidence 467.103\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.176, Residuals: -0.063\n",
      "Loss: 7.581, Residuals: -0.057\n",
      "Loss: 4.843, Residuals: -0.028\n",
      "Loss: 4.652, Residuals: 0.046\n",
      "Loss: 4.307, Residuals: 0.010\n",
      "Loss: 3.881, Residuals: -0.061\n",
      "Loss: 3.807, Residuals: -0.031\n",
      "Loss: 3.672, Residuals: -0.032\n",
      "Loss: 3.455, Residuals: -0.038\n",
      "Loss: 3.400, Residuals: -0.038\n",
      "Loss: 3.306, Residuals: -0.045\n",
      "Loss: 3.167, Residuals: -0.056\n",
      "Loss: 3.159, Residuals: -0.042\n",
      "Loss: 3.145, Residuals: -0.043\n",
      "Loss: 3.125, Residuals: -0.056\n",
      "Loss: 3.125, Residuals: -0.057\n",
      "Loss: 3.109, Residuals: -0.059\n",
      "Loss: 3.081, Residuals: -0.062\n",
      "Loss: 3.073, Residuals: -0.050\n",
      "Loss: 3.013, Residuals: -0.067\n",
      "Loss: 3.013, Residuals: -0.068\n",
      "Loss: 3.006, Residuals: -0.068\n",
      "Loss: 2.995, Residuals: -0.068\n",
      "Loss: 2.974, Residuals: -0.072\n",
      "Loss: 2.958, Residuals: -0.072\n",
      "Loss: 2.958, Residuals: -0.073\n",
      "Loss: 2.954, Residuals: -0.072\n",
      "Loss: 2.951, Residuals: -0.069\n",
      "Loss: 2.928, Residuals: -0.078\n",
      "Loss: 2.928, Residuals: -0.077\n",
      "Loss: 2.927, Residuals: -0.078\n",
      "Loss: 2.925, Residuals: -0.076\n",
      "Loss: 2.915, Residuals: -0.079\n",
      "Loss: 2.914, Residuals: -0.079\n",
      "Loss: 2.891, Residuals: -0.086\n",
      "Loss: 2.891, Residuals: -0.085\n",
      "Loss: 2.891, Residuals: -0.086\n",
      "Loss: 2.886, Residuals: -0.086\n",
      "Loss: 2.886, Residuals: -0.085\n",
      "Loss: 2.874, Residuals: -0.088\n",
      "Loss: 2.873, Residuals: -0.082\n",
      "Loss: 2.833, Residuals: -0.084\n",
      "Loss: 2.828, Residuals: -0.080\n",
      "Loss: 2.820, Residuals: -0.081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.812, Residuals: -0.078\n",
      "Loss: 2.803, Residuals: -0.073\n",
      "Loss: 2.802, Residuals: -0.074\n",
      "Loss: 2.795, Residuals: -0.074\n",
      "Loss: 2.783, Residuals: -0.073\n",
      "Loss: 2.767, Residuals: -0.072\n",
      "Loss: 2.767, Residuals: -0.073\n",
      "Loss: 2.766, Residuals: -0.073\n",
      "Loss: 2.764, Residuals: -0.072\n",
      "Loss: 2.761, Residuals: -0.071\n",
      "Loss: 2.761, Residuals: -0.071\n",
      "Evidence -389.493\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.72e-03\n",
      "Loss: 12.938, Residuals: -0.046\n",
      "Loss: 12.900, Residuals: -0.052\n",
      "Loss: 12.832, Residuals: -0.050\n",
      "Loss: 12.727, Residuals: -0.045\n",
      "Loss: 12.632, Residuals: -0.029\n",
      "Loss: 12.630, Residuals: -0.031\n",
      "Loss: 12.609, Residuals: -0.030\n",
      "Loss: 12.569, Residuals: -0.029\n",
      "Loss: 12.499, Residuals: -0.025\n",
      "Loss: 12.490, Residuals: -0.020\n",
      "Loss: 12.473, Residuals: -0.020\n",
      "Loss: 12.442, Residuals: -0.018\n",
      "Loss: 12.433, Residuals: -0.018\n",
      "Loss: 12.418, Residuals: -0.017\n",
      "Loss: 12.396, Residuals: -0.017\n",
      "Loss: 12.395, Residuals: -0.016\n",
      "Loss: 12.373, Residuals: -0.017\n",
      "Loss: 12.372, Residuals: -0.016\n",
      "Loss: 12.370, Residuals: -0.017\n",
      "Loss: 12.369, Residuals: -0.017\n",
      "Loss: 12.353, Residuals: -0.018\n",
      "Loss: 12.353, Residuals: -0.018\n",
      "Evidence 115.518\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.82e-03\n",
      "Loss: 42.382, Residuals: -0.022\n",
      "Loss: 42.338, Residuals: -0.015\n",
      "Loss: 42.270, Residuals: -0.013\n",
      "Loss: 42.214, Residuals: -0.012\n",
      "Loss: 42.139, Residuals: -0.010\n",
      "Loss: 42.055, Residuals: -0.009\n",
      "Loss: 42.047, Residuals: -0.008\n",
      "Loss: 42.033, Residuals: -0.008\n",
      "Loss: 42.010, Residuals: -0.008\n",
      "Loss: 41.968, Residuals: -0.007\n",
      "Loss: 41.954, Residuals: -0.008\n",
      "Loss: 41.954, Residuals: -0.008\n",
      "Loss: 41.873, Residuals: -0.006\n",
      "Loss: 41.872, Residuals: -0.006\n",
      "Loss: 41.870, Residuals: -0.006\n",
      "Loss: 41.867, Residuals: -0.006\n",
      "Loss: 41.863, Residuals: -0.006\n",
      "Loss: 41.858, Residuals: -0.006\n",
      "Loss: 41.851, Residuals: -0.006\n",
      "Loss: 41.841, Residuals: -0.005\n",
      "Loss: 41.841, Residuals: -0.005\n",
      "Loss: 41.840, Residuals: -0.005\n",
      "Loss: 41.840, Residuals: -0.005\n",
      "Loss: 41.824, Residuals: -0.006\n",
      "Loss: 41.824, Residuals: -0.006\n",
      "Loss: 41.824, Residuals: -0.006\n",
      "Loss: 41.816, Residuals: -0.006\n",
      "Loss: 41.816, Residuals: -0.006\n",
      "Loss: 41.813, Residuals: -0.006\n",
      "Loss: 41.810, Residuals: -0.006\n",
      "Loss: 41.810, Residuals: -0.006\n",
      "Loss: 41.809, Residuals: -0.006\n",
      "Loss: 41.809, Residuals: -0.006\n",
      "Loss: 41.809, Residuals: -0.006\n",
      "Loss: 41.809, Residuals: -0.006\n",
      "Loss: 41.806, Residuals: -0.006\n",
      "Loss: 41.806, Residuals: -0.006\n",
      "Loss: 41.805, Residuals: -0.006\n",
      "Loss: 41.805, Residuals: -0.006\n",
      "Loss: 41.804, Residuals: -0.006\n",
      "Evidence 321.618\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.61e-02\n",
      "Loss: 90.054, Residuals: -0.018\n",
      "Loss: 89.814, Residuals: -0.019\n",
      "Loss: 89.761, Residuals: -0.018\n",
      "Loss: 89.675, Residuals: -0.018\n",
      "Loss: 89.669, Residuals: -0.017\n",
      "Loss: 89.612, Residuals: -0.017\n",
      "Loss: 89.525, Residuals: -0.017\n",
      "Loss: 89.523, Residuals: -0.017\n",
      "Loss: 89.503, Residuals: -0.017\n",
      "Loss: 89.496, Residuals: -0.018\n",
      "Loss: 89.446, Residuals: -0.017\n",
      "Loss: 89.443, Residuals: -0.017\n",
      "Loss: 89.348, Residuals: -0.017\n",
      "Loss: 89.344, Residuals: -0.016\n",
      "Loss: 89.338, Residuals: -0.017\n",
      "Loss: 89.330, Residuals: -0.017\n",
      "Loss: 89.325, Residuals: -0.017\n",
      "Loss: 89.324, Residuals: -0.017\n",
      "Loss: 89.225, Residuals: -0.016\n",
      "Loss: 89.218, Residuals: -0.015\n",
      "Loss: 89.210, Residuals: -0.016\n",
      "Loss: 89.199, Residuals: -0.016\n",
      "Loss: 89.188, Residuals: -0.016\n",
      "Loss: 89.186, Residuals: -0.016\n",
      "Loss: 89.140, Residuals: -0.015\n",
      "Loss: 89.139, Residuals: -0.015\n",
      "Loss: 89.138, Residuals: -0.015\n",
      "Loss: 89.137, Residuals: -0.015\n",
      "Loss: 89.077, Residuals: -0.014\n",
      "Loss: 89.076, Residuals: -0.014\n",
      "Loss: 89.072, Residuals: -0.014\n",
      "Loss: 89.067, Residuals: -0.014\n",
      "Loss: 89.062, Residuals: -0.015\n",
      "Loss: 88.688, Residuals: -0.011\n",
      "Loss: 88.622, Residuals: -0.009\n",
      "Loss: 88.506, Residuals: -0.009\n",
      "Loss: 88.359, Residuals: -0.009\n",
      "Loss: 88.330, Residuals: -0.012\n",
      "Loss: 88.278, Residuals: -0.012\n",
      "Loss: 88.202, Residuals: -0.011\n",
      "Loss: 88.196, Residuals: -0.011\n",
      "Loss: 88.186, Residuals: -0.011\n",
      "Loss: 88.168, Residuals: -0.011\n",
      "Loss: 88.164, Residuals: -0.011\n",
      "Loss: 88.157, Residuals: -0.011\n",
      "Loss: 88.143, Residuals: -0.011\n",
      "Loss: 88.141, Residuals: -0.011\n",
      "Loss: 88.128, Residuals: -0.011\n",
      "Loss: 88.126, Residuals: -0.011\n",
      "Loss: 88.115, Residuals: -0.011\n",
      "Loss: 88.114, Residuals: -0.011\n",
      "Loss: 88.101, Residuals: -0.011\n",
      "Loss: 88.080, Residuals: -0.010\n",
      "Loss: 88.080, Residuals: -0.010\n",
      "Loss: 88.073, Residuals: -0.010\n",
      "Loss: 88.069, Residuals: -0.010\n",
      "Loss: 88.068, Residuals: -0.010\n",
      "Loss: 88.067, Residuals: -0.010\n",
      "Loss: 88.064, Residuals: -0.010\n",
      "Loss: 88.060, Residuals: -0.010\n",
      "Loss: 88.060, Residuals: -0.010\n",
      "Loss: 88.059, Residuals: -0.010\n",
      "Loss: 88.059, Residuals: -0.010\n",
      "Loss: 88.058, Residuals: -0.010\n",
      "Loss: 88.057, Residuals: -0.010\n",
      "Loss: 88.057, Residuals: -0.010\n",
      "Evidence 432.624\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.55e-02\n",
      "Loss: 129.049, Residuals: -0.012\n",
      "Loss: 128.714, Residuals: -0.025\n",
      "Loss: 128.295, Residuals: -0.022\n",
      "Loss: 128.250, Residuals: -0.024\n",
      "Loss: 128.177, Residuals: -0.023\n",
      "Loss: 128.081, Residuals: -0.023\n",
      "Loss: 128.065, Residuals: -0.023\n",
      "Loss: 128.058, Residuals: -0.024\n",
      "Loss: 128.045, Residuals: -0.024\n",
      "Loss: 128.024, Residuals: -0.023\n",
      "Loss: 127.991, Residuals: -0.023\n",
      "Loss: 127.991, Residuals: -0.023\n",
      "Loss: 127.985, Residuals: -0.023\n",
      "Loss: 127.979, Residuals: -0.022\n",
      "Loss: 127.979, Residuals: -0.023\n",
      "Loss: 127.979, Residuals: -0.023\n",
      "Loss: 127.977, Residuals: -0.023\n",
      "Loss: 127.975, Residuals: -0.023\n",
      "Loss: 127.972, Residuals: -0.023\n",
      "Loss: 127.972, Residuals: -0.022\n",
      "Loss: 127.972, Residuals: -0.022\n",
      "Loss: 127.972, Residuals: -0.023\n",
      "Loss: 127.971, Residuals: -0.023\n",
      "Loss: 127.964, Residuals: -0.023\n",
      "Loss: 127.964, Residuals: -0.023\n",
      "Loss: 127.960, Residuals: -0.023\n",
      "Loss: 127.960, Residuals: -0.022\n",
      "Loss: 127.960, Residuals: -0.022\n",
      "Evidence 473.916\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.84e-02\n",
      "Loss: 147.908, Residuals: -0.023\n",
      "Loss: 147.834, Residuals: -0.027\n",
      "Loss: 147.737, Residuals: -0.029\n",
      "Loss: 147.644, Residuals: -0.030\n",
      "Loss: 147.632, Residuals: -0.030\n",
      "Loss: 147.627, Residuals: -0.032\n",
      "Loss: 147.625, Residuals: -0.031\n",
      "Loss: 147.622, Residuals: -0.031\n",
      "Loss: 147.616, Residuals: -0.031\n",
      "Loss: 147.615, Residuals: -0.031\n",
      "Loss: 147.611, Residuals: -0.031\n",
      "Loss: 147.606, Residuals: -0.030\n",
      "Loss: 147.606, Residuals: -0.030\n",
      "Loss: 147.605, Residuals: -0.030\n",
      "Loss: 147.605, Residuals: -0.030\n",
      "Evidence 482.769\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.10e-01\n",
      "Loss: 154.441, Residuals: -0.030\n",
      "Loss: 154.417, Residuals: -0.034\n",
      "Loss: 154.385, Residuals: -0.034\n",
      "Loss: 154.366, Residuals: -0.034\n",
      "Loss: 154.362, Residuals: -0.034\n",
      "Loss: 154.359, Residuals: -0.035\n",
      "Loss: 154.358, Residuals: -0.035\n",
      "Loss: 154.343, Residuals: -0.035\n",
      "Loss: 154.320, Residuals: -0.035\n",
      "Loss: 154.319, Residuals: -0.035\n",
      "Evidence 484.183\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.71e-01\n",
      "Loss: 156.521, Residuals: -0.034\n",
      "Loss: 156.487, Residuals: -0.036\n",
      "Loss: 156.478, Residuals: -0.037\n",
      "Loss: 156.474, Residuals: -0.036\n",
      "Loss: 156.469, Residuals: -0.036\n",
      "Loss: 156.417, Residuals: -0.036\n",
      "Loss: 156.417, Residuals: -0.036\n",
      "Loss: 156.417, Residuals: -0.036\n",
      "Loss: 156.028, Residuals: -0.031\n",
      "Loss: 155.961, Residuals: -0.034\n",
      "Loss: 155.886, Residuals: -0.032\n",
      "Loss: 155.869, Residuals: -0.029\n",
      "Loss: 155.844, Residuals: -0.029\n",
      "Loss: 155.844, Residuals: -0.029\n",
      "Evidence 480.509\n",
      "Fail count  1\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.08e-01\n",
      "Loss: 157.076, Residuals: -0.025\n",
      "Loss: 157.034, Residuals: -0.028\n",
      "Loss: 156.966, Residuals: -0.027\n",
      "Loss: 156.908, Residuals: -0.025\n",
      "Loss: 156.907, Residuals: -0.025\n",
      "Evidence 483.675\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.93e-01\n",
      "Loss: 157.709, Residuals: -0.022\n",
      "Loss: 157.656, Residuals: -0.023\n",
      "Loss: 157.605, Residuals: -0.024\n",
      "Loss: 157.601, Residuals: -0.024\n",
      "Loss: 157.596, Residuals: -0.024\n",
      "Loss: 157.511, Residuals: -0.026\n",
      "Loss: 157.498, Residuals: -0.025\n",
      "Loss: 157.492, Residuals: -0.024\n",
      "Loss: 157.363, Residuals: -0.027\n",
      "Loss: 157.332, Residuals: -0.024\n",
      "Loss: 157.319, Residuals: -0.024\n",
      "Loss: 157.197, Residuals: -0.022\n",
      "Loss: 157.194, Residuals: -0.021\n",
      "Loss: 157.172, Residuals: -0.020\n",
      "Loss: 157.149, Residuals: -0.019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 157.141, Residuals: -0.019\n",
      "Loss: 157.139, Residuals: -0.019\n",
      "Loss: 157.048, Residuals: -0.018\n",
      "Loss: 157.048, Residuals: -0.019\n",
      "Evidence 481.810\n",
      "Fail count  1\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.83e-01\n",
      "Loss: 157.893, Residuals: -0.015\n",
      "Loss: 157.885, Residuals: -0.014\n",
      "Loss: 157.826, Residuals: -0.014\n",
      "Loss: 157.713, Residuals: -0.013\n",
      "Loss: 157.697, Residuals: -0.014\n",
      "Loss: 157.555, Residuals: -0.013\n",
      "Loss: 157.554, Residuals: -0.013\n",
      "Loss: 157.468, Residuals: -0.013\n",
      "Loss: 157.464, Residuals: -0.012\n",
      "Loss: 157.347, Residuals: -0.011\n",
      "Loss: 157.346, Residuals: -0.011\n",
      "Evidence 483.674\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.27e+00\n",
      "Loss: 158.293, Residuals: -0.009\n",
      "Loss: 158.274, Residuals: -0.008\n",
      "Loss: 158.118, Residuals: -0.007\n",
      "Loss: 158.110, Residuals: -0.007\n",
      "Loss: 158.097, Residuals: -0.007\n",
      "Loss: 158.072, Residuals: -0.007\n",
      "Loss: 158.033, Residuals: -0.006\n",
      "Loss: 158.031, Residuals: -0.005\n",
      "Loss: 158.014, Residuals: -0.005\n",
      "Loss: 158.014, Residuals: -0.005\n",
      "Loss: 158.013, Residuals: -0.005\n",
      "Loss: 158.011, Residuals: -0.005\n",
      "Loss: 158.010, Residuals: -0.005\n",
      "Loss: 158.009, Residuals: -0.005\n",
      "Loss: 158.007, Residuals: -0.005\n",
      "Loss: 158.007, Residuals: -0.005\n",
      "Loss: 158.007, Residuals: -0.005\n",
      "Evidence 483.723\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.416, Residuals: -0.080\n",
      "Loss: 7.783, Residuals: -0.034\n",
      "Loss: 6.494, Residuals: -0.042\n",
      "Loss: 4.903, Residuals: -0.027\n",
      "Loss: 4.846, Residuals: -0.005\n",
      "Loss: 4.368, Residuals: -0.020\n",
      "Loss: 4.318, Residuals: 0.019\n",
      "Loss: 3.916, Residuals: -0.008\n",
      "Loss: 3.894, Residuals: 0.011\n",
      "Loss: 3.692, Residuals: -0.008\n",
      "Loss: 3.581, Residuals: -0.017\n",
      "Loss: 3.435, Residuals: -0.029\n",
      "Loss: 3.429, Residuals: -0.031\n",
      "Loss: 3.371, Residuals: -0.037\n",
      "Loss: 3.278, Residuals: -0.051\n",
      "Loss: 3.270, Residuals: -0.030\n",
      "Loss: 3.205, Residuals: -0.042\n",
      "Loss: 3.203, Residuals: -0.038\n",
      "Loss: 3.157, Residuals: -0.046\n",
      "Loss: 3.152, Residuals: -0.034\n",
      "Loss: 3.111, Residuals: -0.043\n",
      "Loss: 3.111, Residuals: -0.044\n",
      "Loss: 3.105, Residuals: -0.044\n",
      "Loss: 3.096, Residuals: -0.046\n",
      "Loss: 3.080, Residuals: -0.051\n",
      "Loss: 3.077, Residuals: -0.044\n",
      "Loss: 3.055, Residuals: -0.051\n",
      "Loss: 3.047, Residuals: -0.055\n",
      "Loss: 3.046, Residuals: -0.053\n",
      "Loss: 3.036, Residuals: -0.055\n",
      "Loss: 3.028, Residuals: -0.055\n",
      "Loss: 3.028, Residuals: -0.055\n",
      "Loss: 3.022, Residuals: -0.057\n",
      "Loss: 3.013, Residuals: -0.060\n",
      "Loss: 3.012, Residuals: -0.058\n",
      "Loss: 3.012, Residuals: -0.059\n",
      "Loss: 3.004, Residuals: -0.061\n",
      "Loss: 3.004, Residuals: -0.061\n",
      "Evidence -412.745\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.00e-02\n",
      "Loss: 14.613, Residuals: -0.045\n",
      "Loss: 14.608, Residuals: -0.044\n",
      "Loss: 14.563, Residuals: -0.042\n",
      "Loss: 14.483, Residuals: -0.037\n",
      "Loss: 14.364, Residuals: -0.025\n",
      "Loss: 14.354, Residuals: -0.015\n",
      "Loss: 14.336, Residuals: -0.014\n",
      "Loss: 14.301, Residuals: -0.011\n",
      "Loss: 14.248, Residuals: -0.006\n",
      "Loss: 14.248, Residuals: -0.007\n",
      "Evidence 111.357\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.29e-01\n",
      "Loss: 45.558, Residuals: -0.007\n",
      "Loss: 45.502, Residuals: -0.008\n",
      "Loss: 45.402, Residuals: -0.006\n",
      "Loss: 45.251, Residuals: -0.002\n",
      "Loss: 44.990, Residuals: 0.003\n",
      "Loss: 44.984, Residuals: -0.000\n",
      "Loss: 44.778, Residuals: 0.005\n",
      "Loss: 44.778, Residuals: 0.005\n",
      "Evidence 308.207\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.85e-01\n",
      "Loss: 90.905, Residuals: 0.005\n",
      "Loss: 90.743, Residuals: 0.005\n",
      "Loss: 90.463, Residuals: 0.006\n",
      "Loss: 90.099, Residuals: 0.004\n",
      "Loss: 89.727, Residuals: -0.000\n",
      "Loss: 89.706, Residuals: -0.002\n",
      "Loss: 89.521, Residuals: -0.000\n",
      "Loss: 89.286, Residuals: 0.001\n",
      "Loss: 89.267, Residuals: 0.003\n",
      "Loss: 89.232, Residuals: 0.003\n",
      "Loss: 89.169, Residuals: 0.003\n",
      "Loss: 89.089, Residuals: 0.002\n",
      "Loss: 89.083, Residuals: 0.001\n",
      "Loss: 89.082, Residuals: 0.001\n",
      "Loss: 89.064, Residuals: 0.001\n",
      "Loss: 89.064, Residuals: 0.001\n",
      "Evidence 418.730\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.45e-01\n",
      "Loss: 128.938, Residuals: -0.004\n",
      "Loss: 128.585, Residuals: -0.004\n",
      "Loss: 128.511, Residuals: -0.008\n",
      "Loss: 128.388, Residuals: -0.008\n",
      "Loss: 128.383, Residuals: -0.006\n",
      "Loss: 128.170, Residuals: -0.007\n",
      "Loss: 128.166, Residuals: -0.007\n",
      "Loss: 128.007, Residuals: -0.008\n",
      "Loss: 127.995, Residuals: -0.007\n",
      "Loss: 127.880, Residuals: -0.008\n",
      "Loss: 127.862, Residuals: -0.007\n",
      "Loss: 127.266, Residuals: -0.010\n",
      "Loss: 127.089, Residuals: -0.004\n",
      "Loss: 126.976, Residuals: -0.002\n",
      "Loss: 126.867, Residuals: -0.005\n",
      "Loss: 126.663, Residuals: -0.006\n",
      "Loss: 126.328, Residuals: -0.006\n",
      "Loss: 126.318, Residuals: -0.005\n",
      "Loss: 126.220, Residuals: -0.006\n",
      "Loss: 126.084, Residuals: -0.007\n",
      "Loss: 126.076, Residuals: -0.008\n",
      "Loss: 126.071, Residuals: -0.007\n",
      "Loss: 126.027, Residuals: -0.007\n",
      "Loss: 126.026, Residuals: -0.008\n",
      "Loss: 126.002, Residuals: -0.007\n",
      "Loss: 125.965, Residuals: -0.006\n",
      "Loss: 125.964, Residuals: -0.006\n",
      "Loss: 125.963, Residuals: -0.006\n",
      "Loss: 125.962, Residuals: -0.006\n",
      "Loss: 125.960, Residuals: -0.006\n",
      "Loss: 125.960, Residuals: -0.006\n",
      "Loss: 125.957, Residuals: -0.005\n",
      "Evidence 462.387\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.70e+00\n",
      "Loss: 146.674, Residuals: -0.001\n",
      "Loss: 146.589, Residuals: -0.005\n",
      "Loss: 146.483, Residuals: -0.005\n",
      "Loss: 146.465, Residuals: -0.007\n",
      "Loss: 146.433, Residuals: -0.007\n",
      "Loss: 146.383, Residuals: -0.007\n",
      "Loss: 146.361, Residuals: -0.006\n",
      "Loss: 146.357, Residuals: -0.007\n",
      "Loss: 146.356, Residuals: -0.007\n",
      "Loss: 146.355, Residuals: -0.007\n",
      "Loss: 146.353, Residuals: -0.007\n",
      "Loss: 146.353, Residuals: -0.007\n",
      "Loss: 146.352, Residuals: -0.007\n",
      "Loss: 146.351, Residuals: -0.007\n",
      "Loss: 146.351, Residuals: -0.007\n",
      "Loss: 146.351, Residuals: -0.007\n",
      "Loss: 146.351, Residuals: -0.007\n",
      "Evidence 474.368\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.85e+00\n",
      "Loss: 154.192, Residuals: -0.003\n",
      "Loss: 154.160, Residuals: -0.006\n",
      "Loss: 154.112, Residuals: -0.006\n",
      "Loss: 154.083, Residuals: -0.006\n",
      "Loss: 154.080, Residuals: -0.007\n",
      "Loss: 154.075, Residuals: -0.007\n",
      "Loss: 154.069, Residuals: -0.008\n",
      "Loss: 154.069, Residuals: -0.008\n",
      "Loss: 154.069, Residuals: -0.008\n",
      "Loss: 154.068, Residuals: -0.008\n",
      "Loss: 154.068, Residuals: -0.008\n",
      "Loss: 154.067, Residuals: -0.008\n",
      "Evidence 477.666\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.86e+00\n",
      "Loss: 156.684, Residuals: -0.005\n",
      "Loss: 156.649, Residuals: -0.008\n",
      "Loss: 156.638, Residuals: -0.007\n",
      "Loss: 156.623, Residuals: -0.008\n",
      "Loss: 156.615, Residuals: -0.008\n",
      "Loss: 156.615, Residuals: -0.008\n",
      "Loss: 156.615, Residuals: -0.008\n",
      "Loss: 156.614, Residuals: -0.008\n",
      "Loss: 156.613, Residuals: -0.008\n",
      "Loss: 156.613, Residuals: -0.008\n",
      "Loss: 156.613, Residuals: -0.009\n",
      "Loss: 156.612, Residuals: -0.009\n",
      "Evidence 479.158\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.83e+00\n",
      "Loss: 157.575, Residuals: -0.007\n",
      "Loss: 157.548, Residuals: -0.009\n",
      "Loss: 157.541, Residuals: -0.008\n",
      "Loss: 157.532, Residuals: -0.008\n",
      "Loss: 157.531, Residuals: -0.009\n",
      "Loss: 157.527, Residuals: -0.009\n",
      "Loss: 157.527, Residuals: -0.009\n",
      "Loss: 157.526, Residuals: -0.009\n",
      "Loss: 157.525, Residuals: -0.010\n",
      "Loss: 157.525, Residuals: -0.010\n",
      "Loss: 157.525, Residuals: -0.010\n",
      "Evidence 480.096\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.78e+00\n",
      "Loss: 157.958, Residuals: -0.009\n",
      "Loss: 157.938, Residuals: -0.010\n",
      "Loss: 157.933, Residuals: -0.009\n",
      "Loss: 157.927, Residuals: -0.010\n",
      "Loss: 157.925, Residuals: -0.010\n",
      "Loss: 157.925, Residuals: -0.010\n",
      "Loss: 157.924, Residuals: -0.010\n",
      "Loss: 157.923, Residuals: -0.011\n",
      "Loss: 157.923, Residuals: -0.011\n",
      "Evidence 480.751\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.75e+00\n",
      "Loss: 158.165, Residuals: -0.010\n",
      "Loss: 158.151, Residuals: -0.010\n",
      "Loss: 158.148, Residuals: -0.010\n",
      "Loss: 158.144, Residuals: -0.010\n",
      "Loss: 158.139, Residuals: -0.011\n",
      "Loss: 158.139, Residuals: -0.011\n",
      "Loss: 158.139, Residuals: -0.011\n",
      "Loss: 158.138, Residuals: -0.011\n",
      "Loss: 158.138, Residuals: -0.012\n",
      "Loss: 158.138, Residuals: -0.012\n",
      "Loss: 158.138, Residuals: -0.012\n",
      "Evidence 481.272\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.71e+00\n",
      "Loss: 158.294, Residuals: -0.011\n",
      "Loss: 158.284, Residuals: -0.011\n",
      "Loss: 158.282, Residuals: -0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 158.279, Residuals: -0.011\n",
      "Loss: 158.277, Residuals: -0.012\n",
      "Loss: 158.277, Residuals: -0.012\n",
      "Loss: 158.276, Residuals: -0.012\n",
      "Loss: 158.275, Residuals: -0.012\n",
      "Loss: 158.275, Residuals: -0.012\n",
      "Loss: 158.275, Residuals: -0.012\n",
      "Loss: 158.275, Residuals: -0.012\n",
      "Loss: 158.274, Residuals: -0.012\n",
      "Loss: 158.274, Residuals: -0.012\n",
      "Loss: 158.274, Residuals: -0.012\n",
      "Loss: 158.274, Residuals: -0.012\n",
      "Loss: 158.274, Residuals: -0.012\n",
      "Evidence 481.685\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 13.411, Residuals: -0.028\n",
      "Loss: 7.639, Residuals: -0.020\n",
      "Loss: 6.251, Residuals: -0.022\n",
      "Loss: 4.981, Residuals: -0.024\n",
      "Loss: 4.269, Residuals: 0.011\n",
      "Loss: 4.006, Residuals: -0.030\n",
      "Loss: 3.880, Residuals: -0.025\n",
      "Loss: 3.682, Residuals: -0.029\n",
      "Loss: 3.653, Residuals: 0.013\n",
      "Loss: 3.426, Residuals: -0.012\n",
      "Loss: 3.182, Residuals: -0.053\n",
      "Loss: 3.149, Residuals: -0.048\n",
      "Loss: 3.141, Residuals: -0.037\n",
      "Loss: 3.073, Residuals: -0.039\n",
      "Loss: 3.037, Residuals: -0.030\n",
      "Loss: 3.030, Residuals: -0.025\n",
      "Loss: 2.976, Residuals: -0.033\n",
      "Loss: 2.975, Residuals: -0.031\n",
      "Loss: 2.942, Residuals: -0.038\n",
      "Loss: 2.938, Residuals: -0.025\n",
      "Loss: 2.903, Residuals: -0.035\n",
      "Loss: 2.902, Residuals: -0.034\n",
      "Loss: 2.878, Residuals: -0.041\n",
      "Loss: 2.863, Residuals: -0.044\n",
      "Loss: 2.863, Residuals: -0.044\n",
      "Loss: 2.849, Residuals: -0.048\n",
      "Loss: 2.825, Residuals: -0.057\n",
      "Loss: 2.824, Residuals: -0.051\n",
      "Loss: 2.823, Residuals: -0.047\n",
      "Loss: 2.809, Residuals: -0.052\n",
      "Loss: 2.784, Residuals: -0.062\n",
      "Loss: 2.784, Residuals: -0.063\n",
      "Loss: 2.784, Residuals: -0.062\n",
      "Loss: 2.777, Residuals: -0.061\n",
      "Loss: 2.777, Residuals: -0.060\n",
      "Loss: 2.756, Residuals: -0.069\n",
      "Loss: 2.755, Residuals: -0.069\n",
      "Loss: 2.755, Residuals: -0.069\n",
      "Loss: 2.754, Residuals: -0.068\n",
      "Loss: 2.753, Residuals: -0.068\n",
      "Loss: 2.752, Residuals: -0.067\n",
      "Loss: 2.744, Residuals: -0.071\n",
      "Loss: 2.744, Residuals: -0.069\n",
      "Loss: 2.730, Residuals: -0.075\n",
      "Loss: 2.730, Residuals: -0.076\n",
      "Loss: 2.730, Residuals: -0.075\n",
      "Loss: 2.729, Residuals: -0.075\n",
      "Loss: 2.728, Residuals: -0.075\n",
      "Loss: 2.727, Residuals: -0.074\n",
      "Loss: 2.722, Residuals: -0.077\n",
      "Loss: 2.714, Residuals: -0.079\n",
      "Loss: 2.714, Residuals: -0.079\n",
      "Evidence -403.904\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.99e-03\n",
      "Loss: 13.011, Residuals: -0.077\n",
      "Loss: 13.006, Residuals: -0.076\n",
      "Loss: 12.812, Residuals: -0.071\n",
      "Loss: 12.784, Residuals: -0.057\n",
      "Loss: 12.730, Residuals: -0.056\n",
      "Loss: 12.633, Residuals: -0.054\n",
      "Loss: 12.457, Residuals: -0.047\n",
      "Loss: 12.192, Residuals: -0.026\n",
      "Loss: 12.180, Residuals: -0.031\n",
      "Loss: 12.161, Residuals: -0.031\n",
      "Loss: 12.128, Residuals: -0.028\n",
      "Loss: 12.079, Residuals: -0.022\n",
      "Loss: 12.070, Residuals: -0.024\n",
      "Loss: 11.997, Residuals: -0.017\n",
      "Loss: 11.996, Residuals: -0.018\n",
      "Loss: 11.991, Residuals: -0.018\n",
      "Loss: 11.945, Residuals: -0.011\n",
      "Loss: 11.943, Residuals: -0.012\n",
      "Loss: 11.939, Residuals: -0.011\n",
      "Loss: 11.906, Residuals: -0.008\n",
      "Loss: 11.904, Residuals: -0.007\n",
      "Loss: 11.901, Residuals: -0.007\n",
      "Loss: 11.897, Residuals: -0.006\n",
      "Loss: 11.889, Residuals: -0.006\n",
      "Loss: 11.875, Residuals: -0.005\n",
      "Loss: 11.871, Residuals: -0.005\n",
      "Loss: 11.863, Residuals: -0.005\n",
      "Loss: 11.852, Residuals: -0.003\n",
      "Loss: 11.852, Residuals: -0.003\n",
      "Evidence 91.341\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.29e-02\n",
      "Loss: 40.457, Residuals: -0.004\n",
      "Loss: 40.222, Residuals: -0.004\n",
      "Loss: 39.928, Residuals: 0.004\n",
      "Loss: 39.811, Residuals: 0.003\n",
      "Loss: 39.764, Residuals: 0.006\n",
      "Loss: 39.681, Residuals: 0.007\n",
      "Loss: 39.553, Residuals: 0.009\n",
      "Loss: 39.552, Residuals: 0.009\n",
      "Loss: 39.550, Residuals: 0.009\n",
      "Loss: 39.478, Residuals: 0.009\n",
      "Loss: 39.477, Residuals: 0.008\n",
      "Loss: 39.469, Residuals: 0.008\n",
      "Loss: 39.403, Residuals: 0.009\n",
      "Loss: 39.403, Residuals: 0.009\n",
      "Evidence 289.597\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.01e-01\n",
      "Loss: 85.088, Residuals: 0.015\n",
      "Loss: 84.844, Residuals: 0.010\n",
      "Loss: 84.649, Residuals: 0.001\n",
      "Loss: 84.352, Residuals: 0.005\n",
      "Loss: 83.927, Residuals: 0.005\n",
      "Loss: 83.914, Residuals: 0.004\n",
      "Loss: 83.896, Residuals: 0.003\n",
      "Loss: 83.749, Residuals: 0.003\n",
      "Loss: 83.746, Residuals: 0.003\n",
      "Loss: 83.647, Residuals: 0.003\n",
      "Loss: 83.646, Residuals: 0.003\n",
      "Loss: 83.613, Residuals: 0.003\n",
      "Loss: 83.611, Residuals: 0.001\n",
      "Loss: 83.586, Residuals: 0.001\n",
      "Loss: 83.586, Residuals: 0.002\n",
      "Loss: 83.570, Residuals: 0.002\n",
      "Loss: 83.569, Residuals: 0.002\n",
      "Loss: 83.536, Residuals: 0.001\n",
      "Loss: 83.534, Residuals: 0.001\n",
      "Loss: 83.533, Residuals: 0.000\n",
      "Loss: 83.531, Residuals: 0.001\n",
      "Loss: 83.527, Residuals: 0.001\n",
      "Loss: 83.527, Residuals: 0.001\n",
      "Loss: 83.520, Residuals: 0.001\n",
      "Loss: 83.520, Residuals: 0.001\n",
      "Loss: 83.513, Residuals: 0.001\n",
      "Loss: 83.513, Residuals: 0.001\n",
      "Loss: 83.509, Residuals: 0.001\n",
      "Loss: 83.509, Residuals: 0.001\n",
      "Loss: 83.498, Residuals: 0.001\n",
      "Loss: 83.498, Residuals: 0.000\n",
      "Loss: 83.497, Residuals: 0.000\n",
      "Loss: 83.471, Residuals: 0.000\n",
      "Loss: 83.466, Residuals: -0.000\n",
      "Loss: 83.461, Residuals: 0.001\n",
      "Loss: 83.455, Residuals: 0.000\n",
      "Loss: 83.453, Residuals: 0.001\n",
      "Loss: 83.281, Residuals: -0.001\n",
      "Loss: 83.187, Residuals: 0.005\n",
      "Loss: 83.137, Residuals: 0.001\n",
      "Loss: 83.116, Residuals: 0.003\n",
      "Loss: 83.101, Residuals: 0.002\n",
      "Loss: 83.080, Residuals: 0.000\n",
      "Loss: 83.067, Residuals: 0.000\n",
      "Loss: 83.066, Residuals: -0.000\n",
      "Loss: 83.057, Residuals: -0.000\n",
      "Loss: 83.055, Residuals: 0.000\n",
      "Loss: 83.053, Residuals: -0.000\n",
      "Loss: 83.039, Residuals: 0.000\n",
      "Loss: 83.039, Residuals: -0.000\n",
      "Loss: 83.032, Residuals: -0.000\n",
      "Loss: 83.032, Residuals: -0.000\n",
      "Loss: 83.028, Residuals: -0.000\n",
      "Loss: 83.028, Residuals: -0.000\n",
      "Loss: 83.025, Residuals: -0.000\n",
      "Loss: 83.025, Residuals: -0.000\n",
      "Loss: 83.023, Residuals: 0.000\n",
      "Loss: 83.023, Residuals: -0.000\n",
      "Loss: 83.023, Residuals: -0.000\n",
      "Loss: 83.022, Residuals: 0.000\n",
      "Loss: 83.022, Residuals: 0.000\n",
      "Evidence 398.788\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.63e-01\n",
      "Loss: 121.733, Residuals: -0.006\n",
      "Loss: 121.492, Residuals: -0.007\n",
      "Loss: 121.216, Residuals: -0.005\n",
      "Loss: 121.204, Residuals: -0.009\n",
      "Loss: 121.109, Residuals: -0.008\n",
      "Loss: 121.016, Residuals: -0.008\n",
      "Loss: 121.013, Residuals: -0.008\n",
      "Loss: 121.009, Residuals: -0.008\n",
      "Loss: 121.002, Residuals: -0.008\n",
      "Loss: 120.992, Residuals: -0.008\n",
      "Loss: 120.992, Residuals: -0.007\n",
      "Loss: 120.989, Residuals: -0.007\n",
      "Loss: 120.983, Residuals: -0.007\n",
      "Loss: 120.977, Residuals: -0.007\n",
      "Loss: 120.977, Residuals: -0.007\n",
      "Loss: 120.976, Residuals: -0.007\n",
      "Loss: 120.976, Residuals: -0.007\n",
      "Loss: 120.976, Residuals: -0.007\n",
      "Loss: 120.976, Residuals: -0.007\n",
      "Loss: 120.975, Residuals: -0.007\n",
      "Loss: 120.975, Residuals: -0.007\n",
      "Loss: 120.975, Residuals: -0.007\n",
      "Loss: 120.975, Residuals: -0.007\n",
      "Evidence 438.805\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.43e+00\n",
      "Loss: 141.063, Residuals: -0.006\n",
      "Loss: 140.917, Residuals: -0.009\n",
      "Loss: 140.768, Residuals: -0.010\n",
      "Loss: 140.760, Residuals: -0.010\n",
      "Loss: 140.746, Residuals: -0.010\n",
      "Loss: 140.722, Residuals: -0.010\n",
      "Loss: 140.697, Residuals: -0.009\n",
      "Loss: 140.696, Residuals: -0.009\n",
      "Loss: 140.694, Residuals: -0.009\n",
      "Loss: 140.691, Residuals: -0.008\n",
      "Loss: 140.691, Residuals: -0.009\n",
      "Loss: 140.689, Residuals: -0.008\n",
      "Loss: 140.689, Residuals: -0.009\n",
      "Loss: 140.687, Residuals: -0.008\n",
      "Loss: 140.687, Residuals: -0.008\n",
      "Evidence 449.013\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.67e+00\n",
      "Loss: 148.090, Residuals: -0.006\n",
      "Loss: 148.011, Residuals: -0.008\n",
      "Loss: 147.943, Residuals: -0.005\n",
      "Loss: 147.929, Residuals: -0.009\n",
      "Loss: 147.910, Residuals: -0.008\n",
      "Loss: 147.909, Residuals: -0.008\n",
      "Loss: 147.906, Residuals: -0.008\n",
      "Loss: 147.902, Residuals: -0.008\n",
      "Loss: 147.902, Residuals: -0.007\n",
      "Loss: 147.901, Residuals: -0.007\n",
      "Loss: 147.900, Residuals: -0.007\n",
      "Loss: 147.900, Residuals: -0.007\n",
      "Loss: 147.899, Residuals: -0.007\n",
      "Loss: 147.899, Residuals: -0.007\n",
      "Loss: 147.899, Residuals: -0.007\n",
      "Loss: 147.899, Residuals: -0.007\n",
      "Loss: 147.899, Residuals: -0.007\n",
      "Loss: 147.899, Residuals: -0.007\n",
      "Evidence 452.039\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.79e+00\n",
      "Loss: 150.472, Residuals: -0.004\n",
      "Loss: 150.436, Residuals: -0.006\n",
      "Loss: 150.393, Residuals: -0.006\n",
      "Loss: 150.386, Residuals: -0.006\n",
      "Loss: 150.382, Residuals: -0.006\n",
      "Loss: 150.381, Residuals: -0.006\n",
      "Loss: 150.380, Residuals: -0.006\n",
      "Loss: 150.378, Residuals: -0.006\n",
      "Loss: 150.378, Residuals: -0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 150.378, Residuals: -0.006\n",
      "Evidence 453.471\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.83e+00\n",
      "Loss: 151.382, Residuals: -0.005\n",
      "Loss: 151.343, Residuals: -0.004\n",
      "Loss: 151.336, Residuals: -0.005\n",
      "Loss: 151.334, Residuals: -0.005\n",
      "Loss: 151.330, Residuals: -0.005\n",
      "Loss: 151.326, Residuals: -0.005\n",
      "Loss: 151.326, Residuals: -0.005\n",
      "Loss: 151.326, Residuals: -0.005\n",
      "Loss: 151.326, Residuals: -0.005\n",
      "Evidence 454.313\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.84e+00\n",
      "Loss: 151.804, Residuals: -0.005\n",
      "Loss: 151.775, Residuals: -0.004\n",
      "Loss: 151.771, Residuals: -0.005\n",
      "Loss: 151.766, Residuals: -0.005\n",
      "Loss: 151.766, Residuals: -0.005\n",
      "Loss: 151.765, Residuals: -0.005\n",
      "Loss: 151.765, Residuals: -0.005\n",
      "Loss: 151.765, Residuals: -0.005\n",
      "Loss: 151.765, Residuals: -0.005\n",
      "Evidence 454.892\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.85e+00\n",
      "Loss: 152.019, Residuals: -0.004\n",
      "Loss: 152.016, Residuals: -0.005\n",
      "Loss: 152.010, Residuals: -0.005\n",
      "Loss: 152.004, Residuals: -0.004\n",
      "Loss: 152.004, Residuals: -0.004\n",
      "Loss: 152.004, Residuals: -0.004\n",
      "Loss: 152.003, Residuals: -0.005\n",
      "Loss: 152.003, Residuals: -0.005\n",
      "Loss: 152.003, Residuals: -0.005\n",
      "Evidence 455.319\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.008, Residuals: -0.071\n",
      "Loss: 7.473, Residuals: -0.030\n",
      "Loss: 4.899, Residuals: -0.032\n",
      "Loss: 4.256, Residuals: -0.004\n",
      "Loss: 4.105, Residuals: -0.027\n",
      "Loss: 3.854, Residuals: -0.014\n",
      "Loss: 3.556, Residuals: -0.049\n",
      "Loss: 3.545, Residuals: -0.052\n",
      "Loss: 3.524, Residuals: -0.049\n",
      "Loss: 3.366, Residuals: -0.047\n",
      "Loss: 3.360, Residuals: -0.050\n",
      "Loss: 3.351, Residuals: -0.037\n",
      "Loss: 3.272, Residuals: -0.044\n",
      "Loss: 3.143, Residuals: -0.061\n",
      "Loss: 3.114, Residuals: -0.037\n",
      "Loss: 3.105, Residuals: -0.037\n",
      "Loss: 3.031, Residuals: -0.048\n",
      "Loss: 3.029, Residuals: -0.043\n",
      "Loss: 3.004, Residuals: -0.047\n",
      "Loss: 2.959, Residuals: -0.056\n",
      "Loss: 2.944, Residuals: -0.053\n",
      "Loss: 2.944, Residuals: -0.054\n",
      "Loss: 2.940, Residuals: -0.055\n",
      "Loss: 2.904, Residuals: -0.062\n",
      "Loss: 2.902, Residuals: -0.055\n",
      "Loss: 2.898, Residuals: -0.056\n",
      "Loss: 2.864, Residuals: -0.064\n",
      "Loss: 2.863, Residuals: -0.062\n",
      "Loss: 2.790, Residuals: -0.080\n",
      "Loss: 2.782, Residuals: -0.080\n",
      "Loss: 2.777, Residuals: -0.074\n",
      "Loss: 2.768, Residuals: -0.080\n",
      "Loss: 2.768, Residuals: -0.079\n",
      "Loss: 2.704, Residuals: -0.088\n",
      "Loss: 2.703, Residuals: -0.086\n",
      "Loss: 2.702, Residuals: -0.086\n",
      "Loss: 2.701, Residuals: -0.086\n",
      "Loss: 2.698, Residuals: -0.084\n",
      "Loss: 2.695, Residuals: -0.084\n",
      "Loss: 2.593, Residuals: -0.095\n",
      "Loss: 2.590, Residuals: -0.092\n",
      "Loss: 2.584, Residuals: -0.091\n",
      "Loss: 2.575, Residuals: -0.090\n",
      "Loss: 2.561, Residuals: -0.090\n",
      "Loss: 2.560, Residuals: -0.090\n",
      "Evidence -415.053\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.54e-02\n",
      "Loss: 13.380, Residuals: -0.042\n",
      "Loss: 13.318, Residuals: -0.040\n",
      "Loss: 13.209, Residuals: -0.047\n",
      "Loss: 13.065, Residuals: -0.062\n",
      "Loss: 13.057, Residuals: -0.067\n",
      "Loss: 12.781, Residuals: -0.058\n",
      "Loss: 12.771, Residuals: -0.060\n",
      "Loss: 12.754, Residuals: -0.060\n",
      "Loss: 12.726, Residuals: -0.057\n",
      "Loss: 12.673, Residuals: -0.055\n",
      "Loss: 12.663, Residuals: -0.048\n",
      "Loss: 12.580, Residuals: -0.045\n",
      "Loss: 12.579, Residuals: -0.048\n",
      "Loss: 12.531, Residuals: -0.045\n",
      "Loss: 12.455, Residuals: -0.038\n",
      "Loss: 12.453, Residuals: -0.041\n",
      "Loss: 12.450, Residuals: -0.039\n",
      "Loss: 12.423, Residuals: -0.038\n",
      "Loss: 12.413, Residuals: -0.034\n",
      "Loss: 12.412, Residuals: -0.036\n",
      "Loss: 12.398, Residuals: -0.035\n",
      "Loss: 12.373, Residuals: -0.036\n",
      "Loss: 12.372, Residuals: -0.034\n",
      "Loss: 12.334, Residuals: -0.035\n",
      "Loss: 12.333, Residuals: -0.036\n",
      "Loss: 12.332, Residuals: -0.036\n",
      "Loss: 12.319, Residuals: -0.036\n",
      "Loss: 12.318, Residuals: -0.035\n",
      "Loss: 12.304, Residuals: -0.036\n",
      "Loss: 12.304, Residuals: -0.036\n",
      "Loss: 12.304, Residuals: -0.035\n",
      "Loss: 12.295, Residuals: -0.036\n",
      "Loss: 12.295, Residuals: -0.036\n",
      "Loss: 12.294, Residuals: -0.036\n",
      "Loss: 12.285, Residuals: -0.036\n",
      "Loss: 12.284, Residuals: -0.036\n",
      "Loss: 12.284, Residuals: -0.036\n",
      "Loss: 12.274, Residuals: -0.036\n",
      "Loss: 12.274, Residuals: -0.037\n",
      "Loss: 12.273, Residuals: -0.036\n",
      "Loss: 12.273, Residuals: -0.036\n",
      "Loss: 12.272, Residuals: -0.036\n",
      "Loss: 12.270, Residuals: -0.035\n",
      "Loss: 12.270, Residuals: -0.035\n",
      "Loss: 12.263, Residuals: -0.036\n",
      "Loss: 12.263, Residuals: -0.036\n",
      "Loss: 12.263, Residuals: -0.036\n",
      "Loss: 12.263, Residuals: -0.036\n",
      "Loss: 12.262, Residuals: -0.036\n",
      "Loss: 12.251, Residuals: -0.037\n",
      "Loss: 12.250, Residuals: -0.037\n",
      "Loss: 12.250, Residuals: -0.037\n",
      "Loss: 12.250, Residuals: -0.037\n",
      "Loss: 12.250, Residuals: -0.036\n",
      "Loss: 12.237, Residuals: -0.037\n",
      "Loss: 12.237, Residuals: -0.037\n",
      "Loss: 12.237, Residuals: -0.036\n",
      "Loss: 12.237, Residuals: -0.036\n",
      "Loss: 12.237, Residuals: -0.036\n",
      "Loss: 12.237, Residuals: -0.036\n",
      "Loss: 12.236, Residuals: -0.036\n",
      "Loss: 12.227, Residuals: -0.036\n",
      "Loss: 12.226, Residuals: -0.037\n",
      "Loss: 12.226, Residuals: -0.036\n",
      "Loss: 12.226, Residuals: -0.035\n",
      "Loss: 12.226, Residuals: -0.035\n",
      "Loss: 12.225, Residuals: -0.035\n",
      "Loss: 12.225, Residuals: -0.035\n",
      "Loss: 12.224, Residuals: -0.035\n",
      "Loss: 12.221, Residuals: -0.035\n",
      "Loss: 12.221, Residuals: -0.035\n",
      "Loss: 12.221, Residuals: -0.035\n",
      "Loss: 12.219, Residuals: -0.035\n",
      "Loss: 12.219, Residuals: -0.035\n",
      "Evidence 108.231\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.21e-02\n",
      "Loss: 44.948, Residuals: -0.043\n",
      "Loss: 44.902, Residuals: -0.040\n",
      "Loss: 44.535, Residuals: -0.034\n",
      "Loss: 44.350, Residuals: -0.026\n",
      "Loss: 44.340, Residuals: -0.027\n",
      "Loss: 44.259, Residuals: -0.024\n",
      "Loss: 44.168, Residuals: -0.025\n",
      "Loss: 44.160, Residuals: -0.024\n",
      "Loss: 44.092, Residuals: -0.023\n",
      "Loss: 43.997, Residuals: -0.020\n",
      "Loss: 43.995, Residuals: -0.021\n",
      "Loss: 43.991, Residuals: -0.020\n",
      "Loss: 43.987, Residuals: -0.020\n",
      "Loss: 43.835, Residuals: -0.017\n",
      "Loss: 43.832, Residuals: -0.017\n",
      "Loss: 43.827, Residuals: -0.017\n",
      "Loss: 43.822, Residuals: -0.018\n",
      "Loss: 43.813, Residuals: -0.018\n",
      "Loss: 43.727, Residuals: -0.015\n",
      "Loss: 43.719, Residuals: -0.018\n",
      "Loss: 43.712, Residuals: -0.016\n",
      "Loss: 43.700, Residuals: -0.015\n",
      "Loss: 43.697, Residuals: -0.016\n",
      "Loss: 43.575, Residuals: -0.013\n",
      "Loss: 43.551, Residuals: -0.015\n",
      "Loss: 43.536, Residuals: -0.013\n",
      "Loss: 43.511, Residuals: -0.013\n",
      "Loss: 43.503, Residuals: -0.014\n",
      "Loss: 43.261, Residuals: -0.006\n",
      "Loss: 43.156, Residuals: -0.009\n",
      "Loss: 43.093, Residuals: -0.009\n",
      "Loss: 43.051, Residuals: -0.006\n",
      "Loss: 43.032, Residuals: -0.006\n",
      "Loss: 42.876, Residuals: -0.002\n",
      "Loss: 42.853, Residuals: -0.002\n",
      "Loss: 42.810, Residuals: -0.001\n",
      "Loss: 42.794, Residuals: 0.000\n",
      "Loss: 42.762, Residuals: 0.000\n",
      "Loss: 42.706, Residuals: 0.001\n",
      "Loss: 42.699, Residuals: 0.001\n",
      "Loss: 42.637, Residuals: 0.001\n",
      "Loss: 42.629, Residuals: 0.002\n",
      "Loss: 42.558, Residuals: 0.003\n",
      "Loss: 42.554, Residuals: 0.003\n",
      "Loss: 42.517, Residuals: 0.003\n",
      "Loss: 42.496, Residuals: 0.003\n",
      "Loss: 42.494, Residuals: 0.004\n",
      "Loss: 42.475, Residuals: 0.004\n",
      "Loss: 42.473, Residuals: 0.004\n",
      "Loss: 42.456, Residuals: 0.004\n",
      "Loss: 42.456, Residuals: 0.004\n",
      "Loss: 42.450, Residuals: 0.004\n",
      "Loss: 42.439, Residuals: 0.004\n",
      "Loss: 42.438, Residuals: 0.004\n",
      "Loss: 42.430, Residuals: 0.004\n",
      "Loss: 42.429, Residuals: 0.004\n",
      "Loss: 42.423, Residuals: 0.005\n",
      "Loss: 42.423, Residuals: 0.005\n",
      "Loss: 42.418, Residuals: 0.005\n",
      "Loss: 42.418, Residuals: 0.005\n",
      "Loss: 42.417, Residuals: 0.005\n",
      "Loss: 42.416, Residuals: 0.005\n",
      "Loss: 42.416, Residuals: 0.005\n",
      "Loss: 42.414, Residuals: 0.005\n",
      "Loss: 42.414, Residuals: 0.005\n",
      "Evidence 320.860\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.70e-01\n",
      "Loss: 90.156, Residuals: 0.003\n",
      "Loss: 89.730, Residuals: -0.001\n",
      "Loss: 89.232, Residuals: 0.002\n",
      "Loss: 89.193, Residuals: 0.004\n",
      "Loss: 89.119, Residuals: 0.004\n",
      "Loss: 88.990, Residuals: 0.004\n",
      "Loss: 88.915, Residuals: 0.005\n",
      "Loss: 88.907, Residuals: 0.005\n",
      "Loss: 88.838, Residuals: 0.005\n",
      "Loss: 88.722, Residuals: 0.006\n",
      "Loss: 88.720, Residuals: 0.005\n",
      "Loss: 88.653, Residuals: 0.006\n",
      "Loss: 88.651, Residuals: 0.005\n",
      "Loss: 88.648, Residuals: 0.005\n",
      "Loss: 88.624, Residuals: 0.005\n",
      "Loss: 88.624, Residuals: 0.005\n",
      "Evidence 436.486\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.52e-01\n",
      "Loss: 128.963, Residuals: 0.015\n",
      "Loss: 128.655, Residuals: 0.005\n",
      "Loss: 128.208, Residuals: 0.003\n",
      "Loss: 127.984, Residuals: 0.000\n",
      "Loss: 127.944, Residuals: -0.001\n",
      "Loss: 127.890, Residuals: -0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 127.792, Residuals: -0.001\n",
      "Loss: 127.635, Residuals: -0.001\n",
      "Loss: 127.628, Residuals: -0.002\n",
      "Loss: 127.570, Residuals: -0.001\n",
      "Loss: 127.569, Residuals: -0.001\n",
      "Loss: 127.545, Residuals: -0.001\n",
      "Loss: 127.509, Residuals: -0.001\n",
      "Loss: 127.507, Residuals: -0.002\n",
      "Loss: 127.506, Residuals: -0.001\n",
      "Loss: 127.503, Residuals: -0.001\n",
      "Loss: 127.502, Residuals: -0.001\n",
      "Loss: 127.502, Residuals: -0.001\n",
      "Loss: 127.499, Residuals: -0.001\n",
      "Loss: 127.499, Residuals: -0.001\n",
      "Loss: 127.494, Residuals: -0.001\n",
      "Loss: 127.494, Residuals: -0.001\n",
      "Evidence 476.744\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.29e-01\n",
      "Loss: 147.504, Residuals: -0.000\n",
      "Loss: 147.354, Residuals: -0.002\n",
      "Loss: 147.173, Residuals: -0.004\n",
      "Loss: 147.088, Residuals: -0.003\n",
      "Loss: 147.062, Residuals: -0.003\n",
      "Loss: 147.053, Residuals: -0.003\n",
      "Loss: 146.989, Residuals: -0.003\n",
      "Loss: 146.988, Residuals: -0.003\n",
      "Loss: 146.959, Residuals: -0.003\n",
      "Loss: 146.959, Residuals: -0.003\n",
      "Loss: 146.959, Residuals: -0.003\n",
      "Loss: 146.958, Residuals: -0.003\n",
      "Loss: 146.956, Residuals: -0.003\n",
      "Loss: 146.955, Residuals: -0.003\n",
      "Loss: 146.955, Residuals: -0.004\n",
      "Loss: 146.950, Residuals: -0.003\n",
      "Loss: 146.950, Residuals: -0.003\n",
      "Evidence 487.191\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.34e-01\n",
      "Loss: 154.348, Residuals: 0.001\n",
      "Loss: 154.262, Residuals: -0.004\n",
      "Loss: 154.244, Residuals: -0.002\n",
      "Loss: 154.212, Residuals: -0.002\n",
      "Loss: 154.161, Residuals: -0.002\n",
      "Loss: 154.160, Residuals: -0.002\n",
      "Loss: 154.123, Residuals: -0.002\n",
      "Loss: 154.113, Residuals: -0.002\n",
      "Loss: 154.112, Residuals: -0.002\n",
      "Loss: 154.081, Residuals: -0.002\n",
      "Loss: 154.081, Residuals: -0.002\n",
      "Loss: 154.069, Residuals: -0.002\n",
      "Loss: 154.050, Residuals: -0.002\n",
      "Loss: 154.049, Residuals: -0.002\n",
      "Loss: 154.049, Residuals: -0.002\n",
      "Loss: 154.047, Residuals: -0.002\n",
      "Loss: 154.045, Residuals: -0.002\n",
      "Loss: 154.045, Residuals: -0.002\n",
      "Loss: 154.040, Residuals: -0.002\n",
      "Loss: 154.040, Residuals: -0.002\n",
      "Evidence 490.423\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.89e-01\n",
      "Loss: 156.579, Residuals: 0.002\n",
      "Loss: 156.509, Residuals: -0.001\n",
      "Loss: 156.498, Residuals: 0.001\n",
      "Loss: 156.479, Residuals: 0.000\n",
      "Loss: 156.449, Residuals: 0.000\n",
      "Loss: 156.448, Residuals: 0.000\n",
      "Loss: 156.414, Residuals: 0.000\n",
      "Loss: 156.413, Residuals: -0.000\n",
      "Loss: 156.406, Residuals: -0.000\n",
      "Loss: 156.394, Residuals: -0.000\n",
      "Loss: 156.393, Residuals: -0.000\n",
      "Loss: 156.384, Residuals: 0.000\n",
      "Loss: 156.384, Residuals: 0.000\n",
      "Evidence 492.088\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.08e-01\n",
      "Loss: 157.409, Residuals: 0.000\n",
      "Loss: 157.385, Residuals: 0.002\n",
      "Loss: 157.357, Residuals: 0.001\n",
      "Loss: 157.353, Residuals: 0.001\n",
      "Loss: 157.346, Residuals: 0.001\n",
      "Loss: 157.334, Residuals: 0.001\n",
      "Loss: 157.320, Residuals: 0.001\n",
      "Loss: 157.319, Residuals: 0.001\n",
      "Loss: 157.318, Residuals: 0.001\n",
      "Loss: 157.317, Residuals: 0.001\n",
      "Loss: 157.315, Residuals: 0.001\n",
      "Loss: 157.315, Residuals: 0.001\n",
      "Loss: 157.315, Residuals: 0.001\n",
      "Loss: 157.315, Residuals: 0.001\n",
      "Evidence 493.081\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.04e-01\n",
      "Loss: 157.831, Residuals: 0.002\n",
      "Loss: 157.809, Residuals: 0.002\n",
      "Loss: 157.806, Residuals: 0.002\n",
      "Loss: 157.801, Residuals: 0.002\n",
      "Loss: 157.800, Residuals: 0.002\n",
      "Loss: 157.796, Residuals: 0.002\n",
      "Loss: 157.789, Residuals: 0.001\n",
      "Loss: 157.789, Residuals: 0.001\n",
      "Loss: 157.788, Residuals: 0.001\n",
      "Loss: 157.786, Residuals: 0.001\n",
      "Loss: 157.786, Residuals: 0.001\n",
      "Loss: 157.786, Residuals: 0.001\n",
      "Loss: 157.786, Residuals: 0.001\n",
      "Loss: 157.786, Residuals: 0.001\n",
      "Loss: 157.786, Residuals: 0.001\n",
      "Evidence 493.710\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.93e-01\n",
      "Loss: 158.103, Residuals: 0.002\n",
      "Loss: 158.094, Residuals: 0.002\n",
      "Loss: 158.093, Residuals: 0.002\n",
      "Loss: 158.088, Residuals: 0.002\n",
      "Loss: 158.088, Residuals: 0.002\n",
      "Loss: 158.086, Residuals: 0.001\n",
      "Loss: 158.085, Residuals: 0.001\n",
      "Loss: 158.085, Residuals: 0.001\n",
      "Loss: 158.085, Residuals: 0.001\n",
      "Loss: 158.084, Residuals: 0.001\n",
      "Loss: 158.084, Residuals: 0.001\n",
      "Evidence 494.101\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.050, Residuals: -0.078\n",
      "Loss: 7.336, Residuals: -0.034\n",
      "Loss: 4.901, Residuals: -0.034\n",
      "Loss: 4.308, Residuals: -0.049\n",
      "Loss: 4.221, Residuals: -0.028\n",
      "Loss: 4.065, Residuals: -0.026\n",
      "Loss: 3.807, Residuals: -0.029\n",
      "Loss: 3.521, Residuals: -0.052\n",
      "Loss: 3.492, Residuals: -0.036\n",
      "Loss: 3.440, Residuals: -0.034\n",
      "Loss: 3.376, Residuals: -0.001\n",
      "Loss: 3.262, Residuals: -0.017\n",
      "Loss: 3.172, Residuals: -0.047\n",
      "Loss: 3.150, Residuals: -0.057\n",
      "Loss: 3.120, Residuals: -0.046\n",
      "Loss: 3.067, Residuals: -0.052\n",
      "Loss: 3.041, Residuals: -0.039\n",
      "Loss: 2.992, Residuals: -0.048\n",
      "Loss: 2.911, Residuals: -0.058\n",
      "Loss: 2.893, Residuals: -0.051\n",
      "Loss: 2.889, Residuals: -0.047\n",
      "Loss: 2.861, Residuals: -0.053\n",
      "Loss: 2.814, Residuals: -0.062\n",
      "Loss: 2.811, Residuals: -0.062\n",
      "Loss: 2.784, Residuals: -0.066\n",
      "Loss: 2.771, Residuals: -0.060\n",
      "Loss: 2.747, Residuals: -0.063\n",
      "Loss: 2.743, Residuals: -0.058\n",
      "Loss: 2.712, Residuals: -0.064\n",
      "Loss: 2.712, Residuals: -0.059\n",
      "Loss: 2.684, Residuals: -0.064\n",
      "Loss: 2.684, Residuals: -0.065\n",
      "Loss: 2.667, Residuals: -0.066\n",
      "Loss: 2.665, Residuals: -0.062\n",
      "Loss: 2.654, Residuals: -0.066\n",
      "Loss: 2.651, Residuals: -0.068\n",
      "Loss: 2.650, Residuals: -0.074\n",
      "Loss: 2.626, Residuals: -0.079\n",
      "Loss: 2.625, Residuals: -0.080\n",
      "Loss: 2.625, Residuals: -0.080\n",
      "Loss: 2.624, Residuals: -0.074\n",
      "Loss: 2.610, Residuals: -0.077\n",
      "Loss: 2.610, Residuals: -0.077\n",
      "Evidence -419.485\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.61e-02\n",
      "Loss: 13.692, Residuals: -0.061\n",
      "Loss: 13.690, Residuals: -0.062\n",
      "Loss: 13.665, Residuals: -0.060\n",
      "Loss: 13.623, Residuals: -0.057\n",
      "Loss: 13.546, Residuals: -0.053\n",
      "Loss: 13.416, Residuals: -0.044\n",
      "Loss: 13.374, Residuals: -0.035\n",
      "Loss: 13.371, Residuals: -0.039\n",
      "Loss: 13.255, Residuals: -0.032\n",
      "Loss: 13.129, Residuals: -0.007\n",
      "Loss: 13.126, Residuals: -0.008\n",
      "Loss: 13.126, Residuals: -0.008\n",
      "Loss: 13.120, Residuals: -0.011\n",
      "Loss: 13.112, Residuals: -0.009\n",
      "Loss: 13.098, Residuals: -0.007\n",
      "Loss: 13.082, Residuals: -0.004\n",
      "Loss: 13.082, Residuals: -0.004\n",
      "Evidence 111.930\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.70e-02\n",
      "Loss: 43.755, Residuals: -0.005\n",
      "Loss: 43.632, Residuals: -0.004\n",
      "Loss: 43.457, Residuals: -0.002\n",
      "Loss: 43.221, Residuals: 0.006\n",
      "Loss: 42.969, Residuals: 0.012\n",
      "Loss: 42.946, Residuals: 0.005\n",
      "Loss: 42.917, Residuals: 0.006\n",
      "Loss: 42.884, Residuals: 0.008\n",
      "Loss: 42.832, Residuals: 0.011\n",
      "Loss: 42.825, Residuals: 0.011\n",
      "Loss: 42.812, Residuals: 0.012\n",
      "Loss: 42.790, Residuals: 0.012\n",
      "Loss: 42.786, Residuals: 0.011\n",
      "Loss: 42.778, Residuals: 0.011\n",
      "Loss: 42.775, Residuals: 0.011\n",
      "Loss: 42.769, Residuals: 0.011\n",
      "Loss: 42.759, Residuals: 0.012\n",
      "Loss: 42.757, Residuals: 0.011\n",
      "Loss: 42.753, Residuals: 0.011\n",
      "Loss: 42.747, Residuals: 0.012\n",
      "Loss: 42.746, Residuals: 0.012\n",
      "Loss: 42.743, Residuals: 0.012\n",
      "Loss: 42.737, Residuals: 0.012\n",
      "Loss: 42.736, Residuals: 0.011\n",
      "Loss: 42.736, Residuals: 0.012\n",
      "Loss: 42.733, Residuals: 0.012\n",
      "Loss: 42.731, Residuals: 0.012\n",
      "Loss: 42.731, Residuals: 0.011\n",
      "Loss: 42.731, Residuals: 0.011\n",
      "Loss: 42.730, Residuals: 0.011\n",
      "Loss: 42.729, Residuals: 0.011\n",
      "Loss: 42.729, Residuals: 0.011\n",
      "Loss: 42.729, Residuals: 0.011\n",
      "Loss: 42.728, Residuals: 0.011\n",
      "Loss: 42.727, Residuals: 0.011\n",
      "Loss: 42.727, Residuals: 0.011\n",
      "Loss: 42.727, Residuals: 0.011\n",
      "Loss: 42.727, Residuals: 0.011\n",
      "Loss: 42.726, Residuals: 0.011\n",
      "Loss: 42.726, Residuals: 0.011\n",
      "Evidence 314.138\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.30e-01\n",
      "Loss: 88.823, Residuals: 0.007\n",
      "Loss: 88.421, Residuals: 0.003\n",
      "Loss: 88.227, Residuals: -0.000\n",
      "Loss: 88.212, Residuals: -0.001\n",
      "Loss: 88.187, Residuals: -0.001\n",
      "Loss: 88.144, Residuals: -0.001\n",
      "Loss: 88.080, Residuals: -0.001\n",
      "Loss: 88.079, Residuals: -0.002\n",
      "Loss: 88.064, Residuals: -0.002\n",
      "Loss: 88.062, Residuals: -0.002\n",
      "Loss: 88.049, Residuals: -0.001\n",
      "Loss: 88.049, Residuals: -0.002\n",
      "Loss: 88.043, Residuals: -0.002\n",
      "Loss: 88.032, Residuals: -0.002\n",
      "Loss: 88.032, Residuals: -0.002\n",
      "Evidence 428.411\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.15e-01\n",
      "Loss: 128.781, Residuals: -0.008\n",
      "Loss: 128.323, Residuals: -0.010\n",
      "Loss: 128.242, Residuals: -0.014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 128.112, Residuals: -0.016\n",
      "Loss: 128.104, Residuals: -0.016\n",
      "Loss: 128.034, Residuals: -0.016\n",
      "Loss: 127.920, Residuals: -0.017\n",
      "Loss: 127.919, Residuals: -0.017\n",
      "Loss: 127.871, Residuals: -0.017\n",
      "Loss: 127.869, Residuals: -0.017\n",
      "Loss: 127.777, Residuals: -0.018\n",
      "Loss: 127.774, Residuals: -0.018\n",
      "Loss: 127.772, Residuals: -0.018\n",
      "Loss: 127.707, Residuals: -0.019\n",
      "Loss: 127.702, Residuals: -0.019\n",
      "Loss: 127.698, Residuals: -0.018\n",
      "Loss: 127.693, Residuals: -0.019\n",
      "Loss: 127.692, Residuals: -0.019\n",
      "Loss: 127.651, Residuals: -0.020\n",
      "Loss: 127.647, Residuals: -0.020\n",
      "Loss: 127.643, Residuals: -0.019\n",
      "Loss: 127.635, Residuals: -0.020\n",
      "Loss: 127.631, Residuals: -0.020\n",
      "Loss: 127.625, Residuals: -0.020\n",
      "Loss: 127.621, Residuals: -0.019\n",
      "Loss: 127.450, Residuals: -0.020\n",
      "Loss: 127.390, Residuals: -0.019\n",
      "Loss: 127.323, Residuals: -0.017\n",
      "Loss: 127.215, Residuals: -0.019\n",
      "Loss: 127.159, Residuals: -0.015\n",
      "Loss: 126.647, Residuals: -0.016\n",
      "Loss: 126.557, Residuals: -0.018\n",
      "Loss: 126.537, Residuals: -0.015\n",
      "Loss: 125.861, Residuals: -0.017\n",
      "Loss: 125.836, Residuals: -0.019\n",
      "Loss: 125.619, Residuals: -0.019\n",
      "Loss: 125.348, Residuals: -0.021\n",
      "Loss: 125.333, Residuals: -0.022\n",
      "Loss: 125.328, Residuals: -0.022\n",
      "Loss: 124.876, Residuals: -0.018\n",
      "Loss: 124.861, Residuals: -0.018\n",
      "Loss: 124.847, Residuals: -0.019\n",
      "Loss: 124.836, Residuals: -0.019\n",
      "Loss: 124.816, Residuals: -0.019\n",
      "Loss: 124.783, Residuals: -0.018\n",
      "Loss: 124.782, Residuals: -0.017\n",
      "Loss: 124.773, Residuals: -0.017\n",
      "Loss: 124.761, Residuals: -0.016\n",
      "Loss: 124.760, Residuals: -0.016\n",
      "Loss: 124.760, Residuals: -0.016\n",
      "Loss: 124.760, Residuals: -0.016\n",
      "Loss: 124.759, Residuals: -0.016\n",
      "Loss: 124.759, Residuals: -0.016\n",
      "Loss: 124.759, Residuals: -0.016\n",
      "Loss: 124.759, Residuals: -0.016\n",
      "Loss: 124.759, Residuals: -0.016\n",
      "Loss: 124.759, Residuals: -0.016\n",
      "Evidence 472.615\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.82e+00\n",
      "Loss: 146.130, Residuals: -0.019\n",
      "Loss: 145.949, Residuals: -0.022\n",
      "Loss: 145.913, Residuals: -0.022\n",
      "Loss: 145.856, Residuals: -0.023\n",
      "Loss: 145.797, Residuals: -0.022\n",
      "Loss: 145.784, Residuals: -0.022\n",
      "Loss: 145.781, Residuals: -0.021\n",
      "Loss: 145.775, Residuals: -0.021\n",
      "Loss: 145.772, Residuals: -0.021\n",
      "Loss: 145.772, Residuals: -0.021\n",
      "Loss: 145.771, Residuals: -0.021\n",
      "Loss: 145.771, Residuals: -0.021\n",
      "Loss: 145.771, Residuals: -0.021\n",
      "Loss: 145.771, Residuals: -0.021\n",
      "Loss: 145.771, Residuals: -0.021\n",
      "Evidence 486.053\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.91e+00\n",
      "Loss: 153.997, Residuals: -0.020\n",
      "Loss: 153.922, Residuals: -0.025\n",
      "Loss: 153.903, Residuals: -0.023\n",
      "Loss: 153.883, Residuals: -0.025\n",
      "Loss: 153.881, Residuals: -0.025\n",
      "Loss: 153.877, Residuals: -0.025\n",
      "Loss: 153.877, Residuals: -0.025\n",
      "Loss: 153.876, Residuals: -0.025\n",
      "Loss: 153.875, Residuals: -0.025\n",
      "Loss: 153.875, Residuals: -0.025\n",
      "Loss: 153.875, Residuals: -0.025\n",
      "Loss: 153.875, Residuals: -0.025\n",
      "Loss: 153.875, Residuals: -0.025\n",
      "Loss: 153.875, Residuals: -0.025\n",
      "Loss: 153.875, Residuals: -0.025\n",
      "Loss: 153.875, Residuals: -0.025\n",
      "Evidence 489.476\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.90e+00\n",
      "Loss: 156.591, Residuals: -0.024\n",
      "Loss: 156.560, Residuals: -0.028\n",
      "Loss: 156.553, Residuals: -0.026\n",
      "Loss: 156.544, Residuals: -0.027\n",
      "Loss: 156.543, Residuals: -0.027\n",
      "Loss: 156.542, Residuals: -0.027\n",
      "Loss: 156.542, Residuals: -0.027\n",
      "Loss: 156.541, Residuals: -0.028\n",
      "Loss: 156.540, Residuals: -0.028\n",
      "Evidence 490.902\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.88e+00\n",
      "Loss: 157.536, Residuals: -0.027\n",
      "Loss: 157.517, Residuals: -0.029\n",
      "Loss: 157.514, Residuals: -0.029\n",
      "Loss: 157.509, Residuals: -0.029\n",
      "Loss: 157.509, Residuals: -0.029\n",
      "Loss: 157.506, Residuals: -0.029\n",
      "Loss: 157.505, Residuals: -0.030\n",
      "Loss: 157.505, Residuals: -0.030\n",
      "Loss: 157.505, Residuals: -0.030\n",
      "Loss: 157.505, Residuals: -0.030\n",
      "Loss: 157.505, Residuals: -0.030\n",
      "Loss: 157.505, Residuals: -0.030\n",
      "Evidence 491.688\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.85e+00\n",
      "Loss: 157.956, Residuals: -0.029\n",
      "Loss: 157.943, Residuals: -0.030\n",
      "Loss: 157.941, Residuals: -0.030\n",
      "Loss: 157.940, Residuals: -0.030\n",
      "Loss: 157.938, Residuals: -0.031\n",
      "Loss: 157.938, Residuals: -0.031\n",
      "Loss: 157.938, Residuals: -0.031\n",
      "Loss: 157.937, Residuals: -0.031\n",
      "Loss: 157.937, Residuals: -0.031\n",
      "Loss: 157.937, Residuals: -0.031\n",
      "Loss: 157.937, Residuals: -0.031\n",
      "Loss: 157.937, Residuals: -0.031\n",
      "Evidence 492.192\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.83e+00\n",
      "Loss: 158.181, Residuals: -0.030\n",
      "Loss: 158.174, Residuals: -0.032\n",
      "Loss: 158.173, Residuals: -0.031\n",
      "Loss: 158.172, Residuals: -0.031\n",
      "Loss: 158.171, Residuals: -0.031\n",
      "Loss: 158.171, Residuals: -0.032\n",
      "Loss: 158.171, Residuals: -0.032\n",
      "Loss: 158.170, Residuals: -0.032\n",
      "Loss: 158.170, Residuals: -0.032\n",
      "Evidence 492.516\n",
      "Pass count  1\n",
      "Total samples: 39, Updated regularization: 1.00e-05\n",
      "Loss: 12.994, Residuals: -0.042\n",
      "Loss: 7.596, Residuals: -0.029\n",
      "Loss: 6.109, Residuals: -0.032\n",
      "Loss: 4.955, Residuals: -0.035\n",
      "Loss: 4.358, Residuals: -0.016\n",
      "Loss: 4.120, Residuals: 0.011\n",
      "Loss: 4.092, Residuals: -0.010\n",
      "Loss: 3.842, Residuals: -0.020\n",
      "Loss: 3.660, Residuals: -0.025\n",
      "Loss: 3.628, Residuals: -0.005\n",
      "Loss: 3.568, Residuals: -0.010\n",
      "Loss: 3.462, Residuals: -0.025\n",
      "Loss: 3.296, Residuals: -0.049\n",
      "Loss: 3.262, Residuals: -0.028\n",
      "Loss: 3.218, Residuals: -0.041\n",
      "Loss: 3.144, Residuals: -0.050\n",
      "Loss: 3.140, Residuals: -0.041\n",
      "Loss: 3.108, Residuals: -0.045\n",
      "Loss: 3.102, Residuals: -0.030\n",
      "Loss: 3.058, Residuals: -0.038\n",
      "Loss: 3.056, Residuals: -0.038\n",
      "Loss: 3.043, Residuals: -0.037\n",
      "Loss: 3.018, Residuals: -0.042\n",
      "Loss: 3.014, Residuals: -0.029\n",
      "Loss: 2.975, Residuals: -0.039\n",
      "Loss: 2.975, Residuals: -0.040\n",
      "Loss: 2.973, Residuals: -0.039\n",
      "Loss: 2.969, Residuals: -0.037\n",
      "Loss: 2.935, Residuals: -0.044\n",
      "Loss: 2.920, Residuals: -0.032\n",
      "Loss: 2.918, Residuals: -0.034\n",
      "Loss: 2.902, Residuals: -0.036\n",
      "Loss: 2.871, Residuals: -0.040\n",
      "Loss: 2.864, Residuals: -0.035\n",
      "Loss: 2.814, Residuals: -0.044\n",
      "Loss: 2.813, Residuals: -0.043\n",
      "Loss: 2.805, Residuals: -0.043\n",
      "Loss: 2.793, Residuals: -0.042\n",
      "Loss: 2.793, Residuals: -0.041\n",
      "Loss: 2.773, Residuals: -0.046\n",
      "Loss: 2.770, Residuals: -0.045\n",
      "Loss: 2.763, Residuals: -0.043\n",
      "Loss: 2.763, Residuals: -0.042\n",
      "Loss: 2.750, Residuals: -0.046\n",
      "Loss: 2.725, Residuals: -0.053\n",
      "Loss: 2.720, Residuals: -0.053\n",
      "Loss: 2.719, Residuals: -0.052\n",
      "Loss: 2.716, Residuals: -0.052\n",
      "Loss: 2.694, Residuals: -0.058\n",
      "Loss: 2.693, Residuals: -0.057\n",
      "Loss: 2.689, Residuals: -0.058\n",
      "Loss: 2.688, Residuals: -0.056\n",
      "Loss: 2.657, Residuals: -0.066\n",
      "Loss: 2.655, Residuals: -0.066\n",
      "Loss: 2.654, Residuals: -0.066\n",
      "Loss: 2.643, Residuals: -0.069\n",
      "Loss: 2.643, Residuals: -0.066\n",
      "Loss: 2.615, Residuals: -0.075\n",
      "Loss: 2.612, Residuals: -0.075\n",
      "Loss: 2.612, Residuals: -0.075\n",
      "Loss: 2.611, Residuals: -0.075\n",
      "Loss: 2.606, Residuals: -0.073\n",
      "Loss: 2.599, Residuals: -0.069\n",
      "Loss: 2.599, Residuals: -0.069\n",
      "Evidence -403.172\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 8.89e-03\n",
      "Loss: 12.841, Residuals: -0.070\n",
      "Loss: 12.783, Residuals: -0.053\n",
      "Loss: 12.757, Residuals: -0.056\n",
      "Loss: 12.561, Residuals: -0.048\n",
      "Loss: 12.556, Residuals: -0.047\n",
      "Loss: 12.512, Residuals: -0.045\n",
      "Loss: 12.470, Residuals: -0.042\n",
      "Loss: 12.450, Residuals: -0.047\n",
      "Loss: 12.416, Residuals: -0.044\n",
      "Loss: 12.362, Residuals: -0.038\n",
      "Loss: 12.359, Residuals: -0.036\n",
      "Loss: 12.250, Residuals: -0.031\n",
      "Loss: 12.247, Residuals: -0.030\n",
      "Loss: 12.242, Residuals: -0.028\n",
      "Loss: 12.198, Residuals: -0.025\n",
      "Loss: 12.197, Residuals: -0.024\n",
      "Loss: 12.167, Residuals: -0.022\n",
      "Loss: 12.115, Residuals: -0.019\n",
      "Loss: 12.113, Residuals: -0.020\n",
      "Loss: 12.091, Residuals: -0.020\n",
      "Loss: 12.088, Residuals: -0.020\n",
      "Loss: 12.064, Residuals: -0.019\n",
      "Loss: 12.061, Residuals: -0.018\n",
      "Loss: 12.039, Residuals: -0.018\n",
      "Loss: 12.036, Residuals: -0.017\n",
      "Loss: 12.032, Residuals: -0.017\n",
      "Loss: 12.026, Residuals: -0.017\n",
      "Loss: 12.025, Residuals: -0.016\n",
      "Loss: 12.025, Residuals: -0.016\n",
      "Loss: 12.025, Residuals: -0.016\n",
      "Loss: 12.025, Residuals: -0.016\n",
      "Loss: 12.015, Residuals: -0.016\n",
      "Loss: 12.014, Residuals: -0.016\n",
      "Loss: 12.014, Residuals: -0.016\n",
      "Loss: 12.014, Residuals: -0.016\n",
      "Evidence 101.804\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 5.70e-02\n",
      "Loss: 44.002, Residuals: -0.030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.943, Residuals: -0.020\n",
      "Loss: 43.834, Residuals: -0.019\n",
      "Loss: 43.650, Residuals: -0.015\n",
      "Loss: 43.418, Residuals: -0.007\n",
      "Loss: 43.281, Residuals: -0.005\n",
      "Loss: 43.062, Residuals: -0.003\n",
      "Loss: 43.047, Residuals: -0.002\n",
      "Loss: 42.914, Residuals: -0.000\n",
      "Loss: 42.718, Residuals: 0.004\n",
      "Loss: 42.717, Residuals: 0.005\n",
      "Loss: 42.711, Residuals: 0.004\n",
      "Loss: 42.700, Residuals: 0.003\n",
      "Loss: 42.686, Residuals: 0.004\n",
      "Loss: 42.660, Residuals: 0.005\n",
      "Loss: 42.653, Residuals: 0.006\n",
      "Loss: 42.639, Residuals: 0.006\n",
      "Loss: 42.613, Residuals: 0.006\n",
      "Loss: 42.612, Residuals: 0.006\n",
      "Loss: 42.612, Residuals: 0.005\n",
      "Loss: 42.569, Residuals: 0.007\n",
      "Loss: 42.568, Residuals: 0.005\n",
      "Loss: 42.567, Residuals: 0.007\n",
      "Loss: 42.566, Residuals: 0.007\n",
      "Loss: 42.564, Residuals: 0.006\n",
      "Loss: 42.560, Residuals: 0.006\n",
      "Loss: 42.560, Residuals: 0.006\n",
      "Loss: 42.552, Residuals: 0.006\n",
      "Loss: 42.551, Residuals: 0.006\n",
      "Loss: 42.543, Residuals: 0.007\n",
      "Loss: 42.543, Residuals: 0.006\n",
      "Loss: 42.541, Residuals: 0.006\n",
      "Loss: 42.530, Residuals: 0.007\n",
      "Loss: 42.530, Residuals: 0.007\n",
      "Loss: 42.530, Residuals: 0.007\n",
      "Loss: 42.527, Residuals: 0.007\n",
      "Loss: 42.526, Residuals: 0.007\n",
      "Loss: 42.520, Residuals: 0.008\n",
      "Loss: 42.520, Residuals: 0.008\n",
      "Loss: 42.520, Residuals: 0.007\n",
      "Loss: 42.519, Residuals: 0.007\n",
      "Loss: 42.514, Residuals: 0.007\n",
      "Loss: 42.514, Residuals: 0.008\n",
      "Loss: 42.514, Residuals: 0.007\n",
      "Loss: 42.511, Residuals: 0.008\n",
      "Loss: 42.511, Residuals: 0.008\n",
      "Loss: 42.507, Residuals: 0.008\n",
      "Loss: 42.507, Residuals: 0.008\n",
      "Loss: 42.507, Residuals: 0.008\n",
      "Loss: 42.505, Residuals: 0.008\n",
      "Loss: 42.505, Residuals: 0.008\n",
      "Loss: 42.505, Residuals: 0.008\n",
      "Loss: 42.504, Residuals: 0.008\n",
      "Loss: 42.501, Residuals: 0.008\n",
      "Loss: 42.501, Residuals: 0.008\n",
      "Loss: 42.501, Residuals: 0.008\n",
      "Loss: 42.501, Residuals: 0.008\n",
      "Loss: 42.501, Residuals: 0.008\n",
      "Loss: 42.500, Residuals: 0.008\n",
      "Loss: 42.500, Residuals: 0.008\n",
      "Loss: 42.499, Residuals: 0.008\n",
      "Loss: 42.498, Residuals: 0.008\n",
      "Loss: 42.498, Residuals: 0.008\n",
      "Loss: 42.497, Residuals: 0.008\n",
      "Loss: 42.497, Residuals: 0.008\n",
      "Loss: 42.497, Residuals: 0.008\n",
      "Loss: 42.497, Residuals: 0.008\n",
      "Loss: 42.496, Residuals: 0.008\n",
      "Loss: 42.495, Residuals: 0.008\n",
      "Loss: 42.495, Residuals: 0.008\n",
      "Loss: 42.494, Residuals: 0.008\n",
      "Loss: 42.494, Residuals: 0.009\n",
      "Loss: 42.494, Residuals: 0.008\n",
      "Loss: 42.494, Residuals: 0.008\n",
      "Loss: 42.493, Residuals: 0.008\n",
      "Loss: 42.493, Residuals: 0.008\n",
      "Loss: 42.493, Residuals: 0.008\n",
      "Loss: 42.493, Residuals: 0.008\n",
      "Loss: 42.493, Residuals: 0.008\n",
      "Loss: 42.492, Residuals: 0.008\n",
      "Loss: 42.492, Residuals: 0.008\n",
      "Loss: 42.491, Residuals: 0.009\n",
      "Loss: 42.491, Residuals: 0.009\n",
      "Loss: 42.491, Residuals: 0.008\n",
      "Loss: 42.491, Residuals: 0.008\n",
      "Loss: 42.490, Residuals: 0.009\n",
      "Loss: 42.490, Residuals: 0.009\n",
      "Loss: 42.490, Residuals: 0.009\n",
      "Loss: 42.489, Residuals: 0.009\n",
      "Loss: 42.489, Residuals: 0.009\n",
      "Loss: 42.489, Residuals: 0.009\n",
      "Loss: 42.489, Residuals: 0.009\n",
      "Loss: 42.489, Residuals: 0.009\n",
      "Loss: 42.489, Residuals: 0.009\n",
      "Loss: 42.488, Residuals: 0.009\n",
      "Loss: 42.488, Residuals: 0.009\n",
      "Loss: 42.488, Residuals: 0.009\n",
      "Loss: 42.488, Residuals: 0.009\n",
      "Loss: 42.487, Residuals: 0.009\n",
      "Loss: 42.487, Residuals: 0.009\n",
      "Loss: 42.487, Residuals: 0.009\n",
      "Loss: 42.485, Residuals: 0.009\n",
      "Loss: 42.485, Residuals: 0.009\n",
      "Loss: 42.485, Residuals: 0.009\n",
      "Loss: 42.485, Residuals: 0.009\n",
      "Loss: 42.484, Residuals: 0.009\n",
      "Loss: 42.484, Residuals: 0.009\n",
      "Loss: 42.484, Residuals: 0.009\n",
      "Loss: 42.482, Residuals: 0.009\n",
      "Loss: 42.481, Residuals: 0.009\n",
      "Loss: 42.481, Residuals: 0.009\n",
      "Loss: 42.481, Residuals: 0.009\n",
      "Loss: 42.479, Residuals: 0.009\n",
      "Loss: 42.478, Residuals: 0.009\n",
      "Loss: 42.478, Residuals: 0.009\n",
      "Loss: 42.476, Residuals: 0.009\n",
      "Loss: 42.476, Residuals: 0.009\n",
      "Loss: 42.470, Residuals: 0.010\n",
      "Loss: 42.467, Residuals: 0.010\n",
      "Loss: 42.466, Residuals: 0.009\n",
      "Loss: 42.466, Residuals: 0.009\n",
      "Loss: 42.461, Residuals: 0.010\n",
      "Loss: 42.460, Residuals: 0.009\n",
      "Loss: 42.453, Residuals: 0.010\n",
      "Loss: 42.453, Residuals: 0.010\n",
      "Loss: 42.452, Residuals: 0.009\n",
      "Loss: 42.422, Residuals: 0.012\n",
      "Loss: 42.405, Residuals: 0.012\n",
      "Loss: 42.397, Residuals: 0.010\n",
      "Loss: 42.384, Residuals: 0.010\n",
      "Loss: 42.382, Residuals: 0.010\n",
      "Loss: 42.313, Residuals: 0.013\n",
      "Loss: 42.289, Residuals: 0.014\n",
      "Loss: 42.276, Residuals: 0.011\n",
      "Loss: 42.250, Residuals: 0.011\n",
      "Loss: 42.202, Residuals: 0.012\n",
      "Loss: 42.194, Residuals: 0.012\n",
      "Loss: 42.185, Residuals: 0.012\n",
      "Loss: 42.119, Residuals: 0.014\n",
      "Loss: 42.107, Residuals: 0.014\n",
      "Loss: 42.100, Residuals: 0.014\n",
      "Loss: 42.089, Residuals: 0.014\n",
      "Loss: 42.068, Residuals: 0.014\n",
      "Loss: 42.065, Residuals: 0.014\n",
      "Loss: 42.044, Residuals: 0.014\n",
      "Loss: 42.041, Residuals: 0.013\n",
      "Loss: 42.034, Residuals: 0.013\n",
      "Loss: 42.022, Residuals: 0.014\n",
      "Loss: 42.020, Residuals: 0.013\n",
      "Loss: 42.009, Residuals: 0.014\n",
      "Loss: 42.008, Residuals: 0.014\n",
      "Loss: 41.999, Residuals: 0.014\n",
      "Loss: 41.998, Residuals: 0.013\n",
      "Loss: 41.997, Residuals: 0.014\n",
      "Loss: 41.997, Residuals: 0.013\n",
      "Loss: 41.994, Residuals: 0.013\n",
      "Loss: 41.991, Residuals: 0.014\n",
      "Loss: 41.990, Residuals: 0.013\n",
      "Loss: 41.990, Residuals: 0.013\n",
      "Loss: 41.990, Residuals: 0.013\n",
      "Loss: 41.985, Residuals: 0.014\n",
      "Loss: 41.985, Residuals: 0.013\n",
      "Loss: 41.979, Residuals: 0.014\n",
      "Loss: 41.978, Residuals: 0.014\n",
      "Loss: 41.978, Residuals: 0.014\n",
      "Loss: 41.955, Residuals: 0.019\n",
      "Loss: 41.947, Residuals: 0.017\n",
      "Loss: 41.941, Residuals: 0.018\n",
      "Loss: 41.934, Residuals: 0.018\n",
      "Loss: 41.933, Residuals: 0.018\n",
      "Loss: 41.933, Residuals: 0.018\n",
      "Loss: 41.926, Residuals: 0.019\n",
      "Loss: 41.926, Residuals: 0.019\n",
      "Loss: 41.924, Residuals: 0.020\n",
      "Loss: 41.924, Residuals: 0.020\n",
      "Loss: 41.923, Residuals: 0.020\n",
      "Loss: 41.923, Residuals: 0.020\n",
      "Loss: 41.923, Residuals: 0.020\n",
      "Loss: 41.923, Residuals: 0.020\n",
      "Loss: 41.922, Residuals: 0.020\n",
      "Loss: 41.922, Residuals: 0.020\n",
      "Loss: 41.922, Residuals: 0.020\n",
      "Loss: 41.922, Residuals: 0.020\n",
      "Loss: 41.922, Residuals: 0.020\n",
      "Loss: 41.922, Residuals: 0.020\n",
      "Loss: 41.922, Residuals: 0.020\n",
      "Evidence 296.062\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 8.53e-01\n",
      "Loss: 86.768, Residuals: 0.018\n",
      "Loss: 86.481, Residuals: 0.020\n",
      "Loss: 86.165, Residuals: 0.022\n",
      "Loss: 86.075, Residuals: 0.021\n",
      "Loss: 86.039, Residuals: 0.021\n",
      "Loss: 86.029, Residuals: 0.021\n",
      "Loss: 86.025, Residuals: 0.021\n",
      "Loss: 86.016, Residuals: 0.021\n",
      "Loss: 86.001, Residuals: 0.021\n",
      "Loss: 86.001, Residuals: 0.020\n",
      "Loss: 85.997, Residuals: 0.020\n",
      "Loss: 85.991, Residuals: 0.020\n",
      "Loss: 85.991, Residuals: 0.020\n",
      "Loss: 85.990, Residuals: 0.020\n",
      "Loss: 85.989, Residuals: 0.020\n",
      "Loss: 85.989, Residuals: 0.020\n",
      "Loss: 85.989, Residuals: 0.020\n",
      "Loss: 85.989, Residuals: 0.020\n",
      "Loss: 85.989, Residuals: 0.020\n",
      "Loss: 85.989, Residuals: 0.020\n",
      "Loss: 85.989, Residuals: 0.020\n",
      "Loss: 85.989, Residuals: 0.020\n",
      "Evidence 407.614\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.46e+00\n",
      "Loss: 124.623, Residuals: 0.026\n",
      "Loss: 124.338, Residuals: 0.019\n",
      "Loss: 124.146, Residuals: 0.016\n",
      "Loss: 124.100, Residuals: 0.016\n",
      "Loss: 124.044, Residuals: 0.015\n",
      "Loss: 124.041, Residuals: 0.014\n",
      "Loss: 124.036, Residuals: 0.014\n",
      "Loss: 124.026, Residuals: 0.014\n",
      "Loss: 124.013, Residuals: 0.014\n",
      "Loss: 124.012, Residuals: 0.014\n",
      "Loss: 124.010, Residuals: 0.014\n",
      "Loss: 124.008, Residuals: 0.013\n",
      "Loss: 124.008, Residuals: 0.013\n",
      "Loss: 124.007, Residuals: 0.013\n",
      "Loss: 124.007, Residuals: 0.013\n",
      "Loss: 124.007, Residuals: 0.013\n",
      "Loss: 124.007, Residuals: 0.013\n",
      "Evidence 444.827\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.62e+00\n",
      "Loss: 143.090, Residuals: 0.022\n",
      "Loss: 142.950, Residuals: 0.016\n",
      "Loss: 142.837, Residuals: 0.010\n",
      "Loss: 142.772, Residuals: 0.009\n",
      "Loss: 142.764, Residuals: 0.011\n",
      "Loss: 142.756, Residuals: 0.010\n",
      "Loss: 142.742, Residuals: 0.009\n",
      "Loss: 142.731, Residuals: 0.007\n",
      "Loss: 142.730, Residuals: 0.008\n",
      "Loss: 142.730, Residuals: 0.008\n",
      "Loss: 142.729, Residuals: 0.008\n",
      "Loss: 142.728, Residuals: 0.007\n",
      "Loss: 142.728, Residuals: 0.007\n",
      "Evidence 454.222\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.62e+00\n",
      "Loss: 149.496, Residuals: 0.009\n",
      "Loss: 149.437, Residuals: 0.005\n",
      "Loss: 149.393, Residuals: 0.006\n",
      "Loss: 149.387, Residuals: 0.006\n",
      "Loss: 149.379, Residuals: 0.006\n",
      "Loss: 149.366, Residuals: 0.005\n",
      "Loss: 149.366, Residuals: 0.005\n",
      "Loss: 149.364, Residuals: 0.005\n",
      "Loss: 149.361, Residuals: 0.005\n",
      "Loss: 149.361, Residuals: 0.005\n",
      "Loss: 149.361, Residuals: 0.005\n",
      "Loss: 149.360, Residuals: 0.004\n",
      "Loss: 149.360, Residuals: 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 149.360, Residuals: 0.004\n",
      "Loss: 149.359, Residuals: 0.004\n",
      "Evidence 457.137\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.58e+00\n",
      "Loss: 151.670, Residuals: 0.005\n",
      "Loss: 151.642, Residuals: 0.004\n",
      "Loss: 151.616, Residuals: 0.005\n",
      "Loss: 151.611, Residuals: 0.004\n",
      "Loss: 151.609, Residuals: 0.004\n",
      "Loss: 151.606, Residuals: 0.003\n",
      "Loss: 151.603, Residuals: 0.002\n",
      "Loss: 151.603, Residuals: 0.002\n",
      "Loss: 151.603, Residuals: 0.002\n",
      "Loss: 151.603, Residuals: 0.003\n",
      "Loss: 151.603, Residuals: 0.003\n",
      "Loss: 151.602, Residuals: 0.003\n",
      "Loss: 151.602, Residuals: 0.003\n",
      "Loss: 151.602, Residuals: 0.003\n",
      "Evidence 458.499\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.55e+00\n",
      "Loss: 152.523, Residuals: 0.004\n",
      "Loss: 152.507, Residuals: 0.003\n",
      "Loss: 152.494, Residuals: 0.004\n",
      "Loss: 152.492, Residuals: 0.003\n",
      "Loss: 152.490, Residuals: 0.003\n",
      "Loss: 152.488, Residuals: 0.002\n",
      "Loss: 152.488, Residuals: 0.002\n",
      "Loss: 152.487, Residuals: 0.002\n",
      "Loss: 152.487, Residuals: 0.002\n",
      "Loss: 152.487, Residuals: 0.002\n",
      "Evidence 459.293\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.54e+00\n",
      "Loss: 152.934, Residuals: 0.003\n",
      "Loss: 152.924, Residuals: 0.003\n",
      "Loss: 152.916, Residuals: 0.002\n",
      "Loss: 152.913, Residuals: 0.003\n",
      "Loss: 152.912, Residuals: 0.002\n",
      "Loss: 152.911, Residuals: 0.002\n",
      "Loss: 152.910, Residuals: 0.002\n",
      "Loss: 152.910, Residuals: 0.002\n",
      "Loss: 152.910, Residuals: 0.002\n",
      "Loss: 152.910, Residuals: 0.002\n",
      "Loss: 152.910, Residuals: 0.002\n",
      "Loss: 152.910, Residuals: 0.002\n",
      "Loss: 152.910, Residuals: 0.002\n",
      "Evidence 459.820\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.54e+00\n",
      "Loss: 153.166, Residuals: 0.003\n",
      "Loss: 153.158, Residuals: 0.003\n",
      "Loss: 153.151, Residuals: 0.002\n",
      "Loss: 153.150, Residuals: 0.003\n",
      "Loss: 153.150, Residuals: 0.003\n",
      "Loss: 153.149, Residuals: 0.003\n",
      "Loss: 153.149, Residuals: 0.003\n",
      "Loss: 153.148, Residuals: 0.003\n",
      "Loss: 153.147, Residuals: 0.002\n",
      "Loss: 153.147, Residuals: 0.002\n",
      "Loss: 153.147, Residuals: 0.002\n",
      "Loss: 153.147, Residuals: 0.002\n",
      "Loss: 153.147, Residuals: 0.002\n",
      "Evidence 460.209\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.071, Residuals: -0.066\n",
      "Loss: 7.549, Residuals: -0.020\n",
      "Loss: 4.592, Residuals: -0.042\n",
      "Loss: 4.433, Residuals: 0.016\n",
      "Loss: 4.140, Residuals: -0.007\n",
      "Loss: 3.727, Residuals: -0.052\n",
      "Loss: 3.717, Residuals: -0.056\n",
      "Loss: 3.697, Residuals: -0.044\n",
      "Loss: 3.530, Residuals: -0.054\n",
      "Loss: 3.516, Residuals: -0.031\n",
      "Loss: 3.390, Residuals: -0.039\n",
      "Loss: 3.205, Residuals: -0.053\n",
      "Loss: 3.196, Residuals: -0.046\n",
      "Loss: 3.181, Residuals: -0.040\n",
      "Loss: 3.155, Residuals: -0.038\n",
      "Loss: 3.108, Residuals: -0.042\n",
      "Loss: 3.027, Residuals: -0.049\n",
      "Loss: 3.007, Residuals: -0.033\n",
      "Loss: 2.973, Residuals: -0.039\n",
      "Loss: 2.960, Residuals: -0.035\n",
      "Loss: 2.955, Residuals: -0.034\n",
      "Loss: 2.919, Residuals: -0.042\n",
      "Loss: 2.901, Residuals: -0.052\n",
      "Loss: 2.899, Residuals: -0.048\n",
      "Loss: 2.875, Residuals: -0.054\n",
      "Loss: 2.874, Residuals: -0.053\n",
      "Loss: 2.843, Residuals: -0.062\n",
      "Loss: 2.843, Residuals: -0.062\n",
      "Loss: 2.827, Residuals: -0.067\n",
      "Loss: 2.825, Residuals: -0.065\n",
      "Loss: 2.802, Residuals: -0.073\n",
      "Loss: 2.802, Residuals: -0.072\n",
      "Loss: 2.789, Residuals: -0.072\n",
      "Loss: 2.789, Residuals: -0.072\n",
      "Loss: 2.788, Residuals: -0.073\n",
      "Loss: 2.781, Residuals: -0.075\n",
      "Loss: 2.777, Residuals: -0.074\n",
      "Loss: 2.775, Residuals: -0.078\n",
      "Loss: 2.759, Residuals: -0.082\n",
      "Loss: 2.758, Residuals: -0.083\n",
      "Loss: 2.738, Residuals: -0.088\n",
      "Loss: 2.735, Residuals: -0.085\n",
      "Loss: 2.731, Residuals: -0.086\n",
      "Loss: 2.725, Residuals: -0.087\n",
      "Loss: 2.713, Residuals: -0.092\n",
      "Loss: 2.712, Residuals: -0.090\n",
      "Loss: 2.710, Residuals: -0.090\n",
      "Loss: 2.693, Residuals: -0.093\n",
      "Loss: 2.693, Residuals: -0.092\n",
      "Loss: 2.693, Residuals: -0.090\n",
      "Loss: 2.675, Residuals: -0.093\n",
      "Loss: 2.674, Residuals: -0.093\n",
      "Loss: 2.674, Residuals: -0.093\n",
      "Loss: 2.635, Residuals: -0.101\n",
      "Loss: 2.632, Residuals: -0.100\n",
      "Loss: 2.631, Residuals: -0.101\n",
      "Loss: 2.630, Residuals: -0.100\n",
      "Loss: 2.628, Residuals: -0.100\n",
      "Loss: 2.624, Residuals: -0.101\n",
      "Loss: 2.618, Residuals: -0.101\n",
      "Loss: 2.617, Residuals: -0.096\n",
      "Loss: 2.611, Residuals: -0.099\n",
      "Loss: 2.569, Residuals: -0.107\n",
      "Loss: 2.560, Residuals: -0.105\n",
      "Loss: 2.557, Residuals: -0.108\n",
      "Loss: 2.556, Residuals: -0.106\n",
      "Loss: 2.555, Residuals: -0.108\n",
      "Loss: 2.554, Residuals: -0.104\n",
      "Loss: 2.522, Residuals: -0.109\n",
      "Loss: 2.520, Residuals: -0.108\n",
      "Loss: 2.518, Residuals: -0.110\n",
      "Loss: 2.518, Residuals: -0.109\n",
      "Loss: 2.518, Residuals: -0.109\n",
      "Loss: 2.516, Residuals: -0.111\n",
      "Loss: 2.512, Residuals: -0.111\n",
      "Loss: 2.505, Residuals: -0.114\n",
      "Loss: 2.505, Residuals: -0.114\n",
      "Loss: 2.505, Residuals: -0.113\n",
      "Loss: 2.504, Residuals: -0.113\n",
      "Loss: 2.497, Residuals: -0.116\n",
      "Loss: 2.497, Residuals: -0.115\n",
      "Loss: 2.480, Residuals: -0.118\n",
      "Loss: 2.480, Residuals: -0.118\n",
      "Loss: 2.480, Residuals: -0.118\n",
      "Evidence -414.934\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.99e-03\n",
      "Loss: 14.400, Residuals: -0.121\n",
      "Loss: 14.383, Residuals: -0.117\n",
      "Loss: 14.379, Residuals: -0.118\n",
      "Loss: 14.236, Residuals: -0.112\n",
      "Loss: 13.984, Residuals: -0.108\n",
      "Loss: 13.961, Residuals: -0.104\n",
      "Loss: 13.764, Residuals: -0.099\n",
      "Loss: 13.542, Residuals: -0.074\n",
      "Loss: 13.538, Residuals: -0.075\n",
      "Loss: 13.532, Residuals: -0.075\n",
      "Loss: 13.522, Residuals: -0.078\n",
      "Loss: 13.505, Residuals: -0.082\n",
      "Loss: 13.355, Residuals: -0.079\n",
      "Loss: 13.352, Residuals: -0.076\n",
      "Loss: 13.349, Residuals: -0.078\n",
      "Loss: 13.344, Residuals: -0.078\n",
      "Loss: 13.223, Residuals: -0.056\n",
      "Loss: 13.210, Residuals: -0.052\n",
      "Loss: 13.193, Residuals: -0.055\n",
      "Loss: 13.179, Residuals: -0.056\n",
      "Loss: 13.173, Residuals: -0.058\n",
      "Loss: 13.172, Residuals: -0.058\n",
      "Loss: 13.172, Residuals: -0.058\n",
      "Loss: 13.170, Residuals: -0.058\n",
      "Loss: 13.149, Residuals: -0.057\n",
      "Loss: 13.112, Residuals: -0.056\n",
      "Loss: 13.110, Residuals: -0.056\n",
      "Loss: 13.091, Residuals: -0.055\n",
      "Loss: 13.063, Residuals: -0.051\n",
      "Loss: 13.063, Residuals: -0.053\n",
      "Loss: 13.063, Residuals: -0.053\n",
      "Evidence 111.823\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.08e-02\n",
      "Loss: 46.380, Residuals: -0.052\n",
      "Loss: 46.234, Residuals: -0.035\n",
      "Loss: 46.224, Residuals: -0.035\n",
      "Loss: 46.212, Residuals: -0.037\n",
      "Loss: 46.101, Residuals: -0.037\n",
      "Loss: 45.945, Residuals: -0.036\n",
      "Loss: 45.944, Residuals: -0.036\n",
      "Loss: 45.904, Residuals: -0.036\n",
      "Loss: 45.555, Residuals: -0.031\n",
      "Loss: 45.552, Residuals: -0.032\n",
      "Loss: 45.520, Residuals: -0.032\n",
      "Loss: 45.470, Residuals: -0.030\n",
      "Loss: 45.470, Residuals: -0.030\n",
      "Evidence 312.790\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.25e-02\n",
      "Loss: 95.375, Residuals: -0.043\n",
      "Loss: 94.763, Residuals: -0.039\n",
      "Loss: 94.752, Residuals: -0.039\n",
      "Loss: 94.652, Residuals: -0.040\n",
      "Loss: 94.599, Residuals: -0.038\n",
      "Loss: 94.498, Residuals: -0.038\n",
      "Loss: 93.563, Residuals: -0.036\n",
      "Loss: 93.516, Residuals: -0.040\n",
      "Loss: 93.069, Residuals: -0.038\n",
      "Loss: 92.906, Residuals: -0.039\n",
      "Loss: 92.592, Residuals: -0.037\n",
      "Loss: 92.576, Residuals: -0.037\n",
      "Loss: 92.005, Residuals: -0.035\n",
      "Loss: 92.000, Residuals: -0.035\n",
      "Loss: 91.794, Residuals: -0.034\n",
      "Loss: 91.774, Residuals: -0.035\n",
      "Loss: 91.581, Residuals: -0.035\n",
      "Loss: 91.236, Residuals: -0.034\n",
      "Loss: 91.230, Residuals: -0.033\n",
      "Loss: 91.180, Residuals: -0.033\n",
      "Loss: 90.786, Residuals: -0.032\n",
      "Loss: 90.784, Residuals: -0.032\n",
      "Loss: 90.781, Residuals: -0.032\n",
      "Loss: 90.776, Residuals: -0.032\n",
      "Loss: 90.768, Residuals: -0.033\n",
      "Loss: 90.473, Residuals: -0.031\n",
      "Loss: 90.464, Residuals: -0.031\n",
      "Loss: 90.463, Residuals: -0.031\n",
      "Loss: 90.460, Residuals: -0.031\n",
      "Loss: 90.456, Residuals: -0.032\n",
      "Loss: 90.449, Residuals: -0.032\n",
      "Loss: 90.184, Residuals: -0.031\n",
      "Loss: 90.171, Residuals: -0.030\n",
      "Loss: 90.161, Residuals: -0.032\n",
      "Loss: 90.146, Residuals: -0.032\n",
      "Loss: 90.132, Residuals: -0.031\n",
      "Loss: 90.130, Residuals: -0.033\n",
      "Loss: 89.821, Residuals: -0.031\n",
      "Loss: 89.799, Residuals: -0.030\n",
      "Loss: 89.782, Residuals: -0.032\n",
      "Loss: 89.768, Residuals: -0.031\n",
      "Loss: 89.762, Residuals: -0.031\n",
      "Loss: 89.294, Residuals: -0.027\n",
      "Loss: 88.823, Residuals: -0.026\n",
      "Loss: 88.602, Residuals: -0.027\n",
      "Loss: 88.318, Residuals: -0.023\n",
      "Loss: 88.281, Residuals: -0.028\n",
      "Loss: 87.954, Residuals: -0.024\n",
      "Loss: 87.929, Residuals: -0.024\n",
      "Loss: 87.883, Residuals: -0.024\n",
      "Loss: 87.539, Residuals: -0.020\n",
      "Loss: 87.523, Residuals: -0.019\n",
      "Loss: 87.498, Residuals: -0.019\n",
      "Loss: 87.463, Residuals: -0.018\n",
      "Loss: 87.420, Residuals: -0.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 87.414, Residuals: -0.018\n",
      "Loss: 87.367, Residuals: -0.017\n",
      "Loss: 87.304, Residuals: -0.016\n",
      "Loss: 87.300, Residuals: -0.017\n",
      "Loss: 87.295, Residuals: -0.016\n",
      "Loss: 87.286, Residuals: -0.016\n",
      "Loss: 87.270, Residuals: -0.016\n",
      "Loss: 87.270, Residuals: -0.016\n",
      "Loss: 87.254, Residuals: -0.016\n",
      "Loss: 87.253, Residuals: -0.016\n",
      "Loss: 87.246, Residuals: -0.016\n",
      "Loss: 87.245, Residuals: -0.016\n",
      "Loss: 87.244, Residuals: -0.017\n",
      "Loss: 87.237, Residuals: -0.017\n",
      "Loss: 87.226, Residuals: -0.017\n",
      "Loss: 87.226, Residuals: -0.017\n",
      "Loss: 87.226, Residuals: -0.017\n",
      "Loss: 87.224, Residuals: -0.017\n",
      "Loss: 87.222, Residuals: -0.017\n",
      "Loss: 87.222, Residuals: -0.017\n",
      "Loss: 87.222, Residuals: -0.017\n",
      "Loss: 87.222, Residuals: -0.017\n",
      "Loss: 87.221, Residuals: -0.017\n",
      "Loss: 87.221, Residuals: -0.017\n",
      "Loss: 87.220, Residuals: -0.017\n",
      "Loss: 87.219, Residuals: -0.017\n",
      "Loss: 87.219, Residuals: -0.017\n",
      "Evidence 419.675\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.00e-01\n",
      "Loss: 126.802, Residuals: -0.012\n",
      "Loss: 126.200, Residuals: -0.013\n",
      "Loss: 125.590, Residuals: -0.017\n",
      "Loss: 125.574, Residuals: -0.020\n",
      "Loss: 125.436, Residuals: -0.020\n",
      "Loss: 125.266, Residuals: -0.018\n",
      "Loss: 125.261, Residuals: -0.019\n",
      "Loss: 125.227, Residuals: -0.019\n",
      "Loss: 125.225, Residuals: -0.019\n",
      "Loss: 125.205, Residuals: -0.019\n",
      "Loss: 125.188, Residuals: -0.020\n",
      "Loss: 125.187, Residuals: -0.020\n",
      "Loss: 125.187, Residuals: -0.020\n",
      "Loss: 125.186, Residuals: -0.020\n",
      "Loss: 125.186, Residuals: -0.020\n",
      "Loss: 125.185, Residuals: -0.020\n",
      "Loss: 125.185, Residuals: -0.020\n",
      "Loss: 125.184, Residuals: -0.020\n",
      "Loss: 125.184, Residuals: -0.020\n",
      "Evidence 468.216\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.56e-01\n",
      "Loss: 146.344, Residuals: -0.019\n",
      "Loss: 146.134, Residuals: -0.014\n",
      "Loss: 145.903, Residuals: -0.019\n",
      "Loss: 145.865, Residuals: -0.019\n",
      "Loss: 145.814, Residuals: -0.019\n",
      "Loss: 145.791, Residuals: -0.020\n",
      "Loss: 145.790, Residuals: -0.020\n",
      "Loss: 145.790, Residuals: -0.020\n",
      "Loss: 145.789, Residuals: -0.020\n",
      "Loss: 145.786, Residuals: -0.020\n",
      "Loss: 145.784, Residuals: -0.020\n",
      "Loss: 145.784, Residuals: -0.020\n",
      "Loss: 145.782, Residuals: -0.020\n",
      "Loss: 145.782, Residuals: -0.020\n",
      "Loss: 145.781, Residuals: -0.020\n",
      "Loss: 145.780, Residuals: -0.020\n",
      "Loss: 145.780, Residuals: -0.021\n",
      "Loss: 145.780, Residuals: -0.021\n",
      "Loss: 145.780, Residuals: -0.021\n",
      "Loss: 145.779, Residuals: -0.021\n",
      "Loss: 145.779, Residuals: -0.021\n",
      "Loss: 145.779, Residuals: -0.021\n",
      "Loss: 145.779, Residuals: -0.020\n",
      "Loss: 145.779, Residuals: -0.020\n",
      "Loss: 145.779, Residuals: -0.020\n",
      "Loss: 145.779, Residuals: -0.020\n",
      "Loss: 145.779, Residuals: -0.020\n",
      "Loss: 145.779, Residuals: -0.020\n",
      "Evidence 480.110\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.69e-01\n",
      "Loss: 153.844, Residuals: -0.014\n",
      "Loss: 153.734, Residuals: -0.021\n",
      "Loss: 153.705, Residuals: -0.018\n",
      "Loss: 153.661, Residuals: -0.018\n",
      "Loss: 153.636, Residuals: -0.019\n",
      "Loss: 153.636, Residuals: -0.019\n",
      "Loss: 153.633, Residuals: -0.019\n",
      "Loss: 153.628, Residuals: -0.019\n",
      "Loss: 153.628, Residuals: -0.020\n",
      "Loss: 153.626, Residuals: -0.020\n",
      "Loss: 153.626, Residuals: -0.020\n",
      "Loss: 153.625, Residuals: -0.020\n",
      "Loss: 153.625, Residuals: -0.020\n",
      "Loss: 153.624, Residuals: -0.020\n",
      "Loss: 153.624, Residuals: -0.020\n",
      "Loss: 153.624, Residuals: -0.020\n",
      "Loss: 153.624, Residuals: -0.020\n",
      "Loss: 153.623, Residuals: -0.020\n",
      "Loss: 153.623, Residuals: -0.020\n",
      "Loss: 153.623, Residuals: -0.020\n",
      "Loss: 153.623, Residuals: -0.020\n",
      "Loss: 153.623, Residuals: -0.020\n",
      "Loss: 153.623, Residuals: -0.020\n",
      "Evidence 483.732\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.27e-01\n",
      "Loss: 156.490, Residuals: -0.015\n",
      "Loss: 156.413, Residuals: -0.020\n",
      "Loss: 156.400, Residuals: -0.017\n",
      "Loss: 156.381, Residuals: -0.018\n",
      "Loss: 156.370, Residuals: -0.019\n",
      "Loss: 156.370, Residuals: -0.019\n",
      "Loss: 156.367, Residuals: -0.019\n",
      "Loss: 156.363, Residuals: -0.019\n",
      "Loss: 156.362, Residuals: -0.019\n",
      "Loss: 156.362, Residuals: -0.019\n",
      "Loss: 156.361, Residuals: -0.019\n",
      "Loss: 156.361, Residuals: -0.020\n",
      "Loss: 156.360, Residuals: -0.020\n",
      "Loss: 156.360, Residuals: -0.020\n",
      "Loss: 156.360, Residuals: -0.020\n",
      "Loss: 156.360, Residuals: -0.020\n",
      "Loss: 156.359, Residuals: -0.020\n",
      "Loss: 156.359, Residuals: -0.020\n",
      "Loss: 156.359, Residuals: -0.020\n",
      "Loss: 156.359, Residuals: -0.020\n",
      "Evidence 485.508\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.50e-01\n",
      "Loss: 157.464, Residuals: -0.021\n",
      "Loss: 157.442, Residuals: -0.018\n",
      "Loss: 157.434, Residuals: -0.019\n",
      "Loss: 157.423, Residuals: -0.019\n",
      "Loss: 157.417, Residuals: -0.020\n",
      "Loss: 157.416, Residuals: -0.020\n",
      "Loss: 157.416, Residuals: -0.020\n",
      "Loss: 157.414, Residuals: -0.020\n",
      "Loss: 157.412, Residuals: -0.020\n",
      "Loss: 157.412, Residuals: -0.020\n",
      "Loss: 157.411, Residuals: -0.020\n",
      "Loss: 157.411, Residuals: -0.020\n",
      "Loss: 157.411, Residuals: -0.020\n",
      "Loss: 157.411, Residuals: -0.020\n",
      "Loss: 157.411, Residuals: -0.020\n",
      "Loss: 157.411, Residuals: -0.020\n",
      "Evidence 486.657\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.54e-01\n",
      "Loss: 157.936, Residuals: -0.021\n",
      "Loss: 157.923, Residuals: -0.019\n",
      "Loss: 157.919, Residuals: -0.020\n",
      "Loss: 157.913, Residuals: -0.020\n",
      "Loss: 157.908, Residuals: -0.020\n",
      "Loss: 157.907, Residuals: -0.020\n",
      "Loss: 157.907, Residuals: -0.020\n",
      "Loss: 157.905, Residuals: -0.021\n",
      "Loss: 157.905, Residuals: -0.020\n",
      "Loss: 157.904, Residuals: -0.021\n",
      "Loss: 157.904, Residuals: -0.021\n",
      "Evidence 487.464\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.53e-01\n",
      "Loss: 158.195, Residuals: -0.020\n",
      "Loss: 158.192, Residuals: -0.020\n",
      "Loss: 158.188, Residuals: -0.020\n",
      "Loss: 158.187, Residuals: -0.020\n",
      "Loss: 158.185, Residuals: -0.020\n",
      "Loss: 158.182, Residuals: -0.021\n",
      "Loss: 158.182, Residuals: -0.021\n",
      "Loss: 158.182, Residuals: -0.021\n",
      "Loss: 158.181, Residuals: -0.021\n",
      "Loss: 158.181, Residuals: -0.021\n",
      "Loss: 158.181, Residuals: -0.021\n",
      "Loss: 158.181, Residuals: -0.021\n",
      "Loss: 158.181, Residuals: -0.021\n",
      "Evidence 488.012\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.54e-01\n",
      "Loss: 158.374, Residuals: -0.021\n",
      "Loss: 158.365, Residuals: -0.021\n",
      "Loss: 158.364, Residuals: -0.021\n",
      "Loss: 158.364, Residuals: -0.021\n",
      "Loss: 158.363, Residuals: -0.021\n",
      "Loss: 158.361, Residuals: -0.021\n",
      "Loss: 158.361, Residuals: -0.021\n",
      "Evidence 488.388\n",
      "Pass count  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 11.795, Residuals: -0.112\n",
      "Loss: 6.986, Residuals: -0.031\n",
      "Loss: 5.020, Residuals: -0.041\n",
      "Loss: 4.366, Residuals: -0.068\n",
      "Loss: 3.985, Residuals: -0.065\n",
      "Loss: 3.861, Residuals: 0.009\n",
      "Loss: 3.653, Residuals: -0.008\n",
      "Loss: 3.515, Residuals: -0.015\n",
      "Loss: 3.393, Residuals: -0.001\n",
      "Loss: 3.332, Residuals: 0.053\n",
      "Loss: 3.225, Residuals: 0.043\n",
      "Loss: 3.080, Residuals: 0.033\n",
      "Loss: 2.913, Residuals: 0.003\n",
      "Loss: 2.888, Residuals: 0.005\n",
      "Loss: 2.849, Residuals: 0.002\n",
      "Loss: 2.803, Residuals: -0.005\n",
      "Loss: 2.799, Residuals: 0.007\n",
      "Loss: 2.759, Residuals: 0.000\n",
      "Loss: 2.692, Residuals: -0.014\n",
      "Loss: 2.654, Residuals: -0.016\n",
      "Loss: 2.595, Residuals: -0.037\n",
      "Loss: 2.589, Residuals: -0.029\n",
      "Loss: 2.542, Residuals: -0.040\n",
      "Loss: 2.537, Residuals: -0.033\n",
      "Loss: 2.528, Residuals: -0.034\n",
      "Loss: 2.511, Residuals: -0.039\n",
      "Loss: 2.483, Residuals: -0.052\n",
      "Loss: 2.482, Residuals: -0.050\n",
      "Loss: 2.481, Residuals: -0.051\n",
      "Loss: 2.478, Residuals: -0.051\n",
      "Loss: 2.459, Residuals: -0.061\n",
      "Loss: 2.457, Residuals: -0.066\n",
      "Loss: 2.457, Residuals: -0.063\n",
      "Loss: 2.456, Residuals: -0.063\n",
      "Loss: 2.456, Residuals: -0.064\n",
      "Loss: 2.450, Residuals: -0.067\n",
      "Loss: 2.447, Residuals: -0.071\n",
      "Loss: 2.446, Residuals: -0.070\n",
      "Loss: 2.445, Residuals: -0.072\n",
      "Loss: 2.444, Residuals: -0.073\n",
      "Loss: 2.441, Residuals: -0.074\n",
      "Loss: 2.436, Residuals: -0.079\n",
      "Loss: 2.435, Residuals: -0.080\n",
      "Loss: 2.433, Residuals: -0.081\n",
      "Loss: 2.431, Residuals: -0.086\n",
      "Loss: 2.431, Residuals: -0.085\n",
      "Loss: 2.429, Residuals: -0.086\n",
      "Loss: 2.429, Residuals: -0.086\n",
      "Loss: 2.425, Residuals: -0.089\n",
      "Loss: 2.425, Residuals: -0.089\n",
      "Loss: 2.425, Residuals: -0.089\n",
      "Loss: 2.425, Residuals: -0.090\n",
      "Loss: 2.425, Residuals: -0.091\n",
      "Loss: 2.424, Residuals: -0.091\n",
      "Loss: 2.422, Residuals: -0.092\n",
      "Loss: 2.420, Residuals: -0.098\n",
      "Loss: 2.420, Residuals: -0.097\n",
      "Loss: 2.420, Residuals: -0.098\n",
      "Loss: 2.420, Residuals: -0.098\n",
      "Loss: 2.417, Residuals: -0.099\n",
      "Loss: 2.417, Residuals: -0.099\n",
      "Loss: 2.417, Residuals: -0.099\n",
      "Loss: 2.417, Residuals: -0.100\n",
      "Loss: 2.416, Residuals: -0.100\n",
      "Loss: 2.416, Residuals: -0.100\n",
      "Evidence -379.326\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.33e-03\n",
      "Loss: 10.545, Residuals: -0.079\n",
      "Loss: 10.458, Residuals: -0.083\n",
      "Loss: 10.316, Residuals: -0.077\n",
      "Loss: 10.303, Residuals: -0.077\n",
      "Loss: 10.187, Residuals: -0.073\n",
      "Loss: 10.185, Residuals: -0.072\n",
      "Loss: 10.115, Residuals: -0.068\n",
      "Loss: 10.066, Residuals: -0.056\n",
      "Loss: 10.063, Residuals: -0.058\n",
      "Loss: 10.056, Residuals: -0.057\n",
      "Loss: 10.008, Residuals: -0.051\n",
      "Loss: 10.004, Residuals: -0.049\n",
      "Loss: 9.974, Residuals: -0.046\n",
      "Loss: 9.974, Residuals: -0.046\n",
      "Loss: 9.955, Residuals: -0.042\n",
      "Loss: 9.954, Residuals: -0.041\n",
      "Loss: 9.944, Residuals: -0.039\n",
      "Loss: 9.941, Residuals: -0.038\n",
      "Loss: 9.908, Residuals: -0.036\n",
      "Loss: 9.907, Residuals: -0.037\n",
      "Loss: 9.907, Residuals: -0.036\n",
      "Loss: 9.907, Residuals: -0.036\n",
      "Loss: 9.888, Residuals: -0.034\n",
      "Loss: 9.888, Residuals: -0.035\n",
      "Loss: 9.888, Residuals: -0.034\n",
      "Loss: 9.885, Residuals: -0.033\n",
      "Loss: 9.885, Residuals: -0.033\n",
      "Loss: 9.880, Residuals: -0.032\n",
      "Loss: 9.879, Residuals: -0.032\n",
      "Loss: 9.877, Residuals: -0.031\n",
      "Loss: 9.874, Residuals: -0.030\n",
      "Loss: 9.874, Residuals: -0.030\n",
      "Loss: 9.871, Residuals: -0.029\n",
      "Loss: 9.867, Residuals: -0.026\n",
      "Loss: 9.867, Residuals: -0.026\n",
      "Loss: 9.866, Residuals: -0.027\n",
      "Loss: 9.866, Residuals: -0.026\n",
      "Loss: 9.865, Residuals: -0.026\n",
      "Loss: 9.864, Residuals: -0.026\n",
      "Loss: 9.863, Residuals: -0.025\n",
      "Loss: 9.862, Residuals: -0.025\n",
      "Loss: 9.860, Residuals: -0.024\n",
      "Loss: 9.860, Residuals: -0.023\n",
      "Loss: 9.860, Residuals: -0.023\n",
      "Loss: 9.859, Residuals: -0.023\n",
      "Loss: 9.858, Residuals: -0.023\n",
      "Loss: 9.858, Residuals: -0.022\n",
      "Loss: 9.857, Residuals: -0.022\n",
      "Loss: 9.857, Residuals: -0.022\n",
      "Loss: 9.856, Residuals: -0.022\n",
      "Loss: 9.856, Residuals: -0.021\n",
      "Loss: 9.854, Residuals: -0.021\n",
      "Loss: 9.854, Residuals: -0.020\n",
      "Loss: 9.853, Residuals: -0.020\n",
      "Loss: 9.853, Residuals: -0.020\n",
      "Loss: 9.851, Residuals: -0.020\n",
      "Loss: 9.850, Residuals: -0.019\n",
      "Loss: 9.850, Residuals: -0.020\n",
      "Loss: 9.850, Residuals: -0.019\n",
      "Loss: 9.848, Residuals: -0.019\n",
      "Loss: 9.847, Residuals: -0.018\n",
      "Loss: 9.846, Residuals: -0.019\n",
      "Loss: 9.842, Residuals: -0.018\n",
      "Loss: 9.841, Residuals: -0.017\n",
      "Loss: 9.840, Residuals: -0.017\n",
      "Loss: 9.838, Residuals: -0.017\n",
      "Loss: 9.834, Residuals: -0.016\n",
      "Loss: 9.833, Residuals: -0.015\n",
      "Loss: 9.829, Residuals: -0.015\n",
      "Loss: 9.829, Residuals: -0.015\n",
      "Loss: 9.827, Residuals: -0.015\n",
      "Loss: 9.827, Residuals: -0.014\n",
      "Loss: 9.824, Residuals: -0.015\n",
      "Loss: 9.824, Residuals: -0.014\n",
      "Loss: 9.823, Residuals: -0.014\n",
      "Loss: 9.822, Residuals: -0.014\n",
      "Loss: 9.822, Residuals: -0.014\n",
      "Loss: 9.822, Residuals: -0.014\n",
      "Loss: 9.822, Residuals: -0.014\n",
      "Loss: 9.821, Residuals: -0.014\n",
      "Loss: 9.821, Residuals: -0.014\n",
      "Loss: 9.821, Residuals: -0.013\n",
      "Loss: 9.821, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Loss: 9.820, Residuals: -0.013\n",
      "Evidence 78.271\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.33e-02\n",
      "Loss: 37.313, Residuals: -0.006\n",
      "Loss: 37.118, Residuals: -0.006\n",
      "Loss: 36.876, Residuals: -0.004\n",
      "Loss: 36.797, Residuals: -0.005\n",
      "Loss: 36.668, Residuals: -0.004\n",
      "Loss: 36.596, Residuals: -0.002\n",
      "Loss: 36.507, Residuals: -0.002\n",
      "Loss: 36.494, Residuals: -0.002\n",
      "Loss: 36.392, Residuals: 0.001\n",
      "Loss: 36.378, Residuals: 0.002\n",
      "Loss: 36.353, Residuals: 0.002\n",
      "Loss: 36.309, Residuals: 0.003\n",
      "Loss: 36.285, Residuals: 0.003\n",
      "Loss: 36.281, Residuals: 0.003\n",
      "Loss: 36.272, Residuals: 0.003\n",
      "Loss: 36.258, Residuals: 0.004\n",
      "Loss: 36.248, Residuals: 0.005\n",
      "Loss: 36.237, Residuals: 0.005\n",
      "Loss: 36.235, Residuals: 0.005\n",
      "Loss: 36.233, Residuals: 0.005\n",
      "Loss: 36.229, Residuals: 0.006\n",
      "Loss: 36.228, Residuals: 0.006\n",
      "Loss: 36.227, Residuals: 0.005\n",
      "Loss: 36.227, Residuals: 0.005\n",
      "Loss: 36.227, Residuals: 0.005\n",
      "Loss: 36.225, Residuals: 0.006\n",
      "Loss: 36.225, Residuals: 0.006\n",
      "Loss: 36.225, Residuals: 0.006\n",
      "Loss: 36.224, Residuals: 0.006\n",
      "Loss: 36.224, Residuals: 0.006\n",
      "Loss: 36.224, Residuals: 0.006\n",
      "Loss: 36.224, Residuals: 0.006\n",
      "Loss: 36.223, Residuals: 0.006\n",
      "Loss: 36.223, Residuals: 0.006\n",
      "Loss: 36.223, Residuals: 0.006\n",
      "Loss: 36.223, Residuals: 0.006\n",
      "Loss: 36.223, Residuals: 0.006\n",
      "Loss: 36.222, Residuals: 0.006\n",
      "Loss: 36.222, Residuals: 0.006\n",
      "Loss: 36.222, Residuals: 0.006\n",
      "Loss: 36.222, Residuals: 0.006\n",
      "Loss: 36.222, Residuals: 0.006\n",
      "Evidence 282.531\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.77e-01\n",
      "Loss: 84.848, Residuals: -0.001\n",
      "Loss: 84.366, Residuals: 0.005\n",
      "Loss: 84.319, Residuals: 0.004\n",
      "Loss: 84.254, Residuals: 0.005\n",
      "Loss: 84.136, Residuals: 0.006\n",
      "Loss: 83.956, Residuals: 0.009\n",
      "Loss: 83.906, Residuals: 0.009\n",
      "Loss: 83.839, Residuals: 0.011\n",
      "Loss: 83.833, Residuals: 0.010\n",
      "Loss: 83.822, Residuals: 0.011\n",
      "Loss: 83.805, Residuals: 0.011\n",
      "Loss: 83.798, Residuals: 0.011\n",
      "Loss: 83.787, Residuals: 0.011\n",
      "Loss: 83.779, Residuals: 0.012\n",
      "Loss: 83.778, Residuals: 0.012\n",
      "Loss: 83.777, Residuals: 0.012\n",
      "Loss: 83.776, Residuals: 0.012\n",
      "Loss: 83.769, Residuals: 0.012\n",
      "Loss: 83.769, Residuals: 0.012\n",
      "Evidence 388.750\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.73e-01\n",
      "Loss: 123.903, Residuals: 0.003\n",
      "Loss: 123.318, Residuals: 0.005\n",
      "Loss: 123.294, Residuals: 0.003\n",
      "Loss: 123.085, Residuals: 0.005\n",
      "Loss: 122.784, Residuals: 0.010\n",
      "Loss: 122.782, Residuals: 0.010\n",
      "Loss: 122.762, Residuals: 0.010\n",
      "Loss: 122.728, Residuals: 0.010\n",
      "Loss: 122.668, Residuals: 0.010\n",
      "Loss: 122.642, Residuals: 0.010\n",
      "Loss: 122.600, Residuals: 0.010\n",
      "Loss: 122.596, Residuals: 0.010\n",
      "Loss: 122.561, Residuals: 0.010\n",
      "Loss: 122.555, Residuals: 0.010\n",
      "Loss: 122.545, Residuals: 0.010\n",
      "Loss: 122.528, Residuals: 0.010\n",
      "Loss: 122.505, Residuals: 0.010\n",
      "Loss: 122.499, Residuals: 0.011\n",
      "Loss: 122.491, Residuals: 0.010\n",
      "Loss: 122.485, Residuals: 0.010\n",
      "Loss: 122.475, Residuals: 0.010\n",
      "Loss: 122.472, Residuals: 0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 122.445, Residuals: 0.010\n",
      "Loss: 122.444, Residuals: 0.010\n",
      "Loss: 122.443, Residuals: 0.010\n",
      "Loss: 122.429, Residuals: 0.010\n",
      "Loss: 122.423, Residuals: 0.010\n",
      "Loss: 122.416, Residuals: 0.010\n",
      "Loss: 122.409, Residuals: 0.010\n",
      "Loss: 122.404, Residuals: 0.010\n",
      "Loss: 122.402, Residuals: 0.010\n",
      "Loss: 122.381, Residuals: 0.010\n",
      "Loss: 122.377, Residuals: 0.010\n",
      "Loss: 122.369, Residuals: 0.010\n",
      "Loss: 122.363, Residuals: 0.010\n",
      "Loss: 122.352, Residuals: 0.009\n",
      "Loss: 122.346, Residuals: 0.009\n",
      "Loss: 122.344, Residuals: 0.010\n",
      "Loss: 122.329, Residuals: 0.010\n",
      "Loss: 122.325, Residuals: 0.009\n",
      "Loss: 122.320, Residuals: 0.009\n",
      "Loss: 122.311, Residuals: 0.009\n",
      "Loss: 122.307, Residuals: 0.009\n",
      "Loss: 122.306, Residuals: 0.009\n",
      "Loss: 122.296, Residuals: 0.009\n",
      "Loss: 122.280, Residuals: 0.009\n",
      "Loss: 122.279, Residuals: 0.009\n",
      "Loss: 122.273, Residuals: 0.009\n",
      "Loss: 122.270, Residuals: 0.009\n",
      "Loss: 122.270, Residuals: 0.009\n",
      "Loss: 122.263, Residuals: 0.009\n",
      "Loss: 122.258, Residuals: 0.009\n",
      "Loss: 122.257, Residuals: 0.009\n",
      "Loss: 122.256, Residuals: 0.009\n",
      "Loss: 122.250, Residuals: 0.009\n",
      "Loss: 122.250, Residuals: 0.009\n",
      "Loss: 122.243, Residuals: 0.009\n",
      "Loss: 122.242, Residuals: 0.009\n",
      "Loss: 122.242, Residuals: 0.009\n",
      "Loss: 122.241, Residuals: 0.009\n",
      "Loss: 122.241, Residuals: 0.009\n",
      "Loss: 122.240, Residuals: 0.009\n",
      "Loss: 122.238, Residuals: 0.009\n",
      "Loss: 122.238, Residuals: 0.009\n",
      "Loss: 122.238, Residuals: 0.009\n",
      "Loss: 122.238, Residuals: 0.009\n",
      "Loss: 122.237, Residuals: 0.009\n",
      "Loss: 122.237, Residuals: 0.009\n",
      "Loss: 122.237, Residuals: 0.009\n",
      "Loss: 122.237, Residuals: 0.009\n",
      "Loss: 122.236, Residuals: 0.009\n",
      "Loss: 122.236, Residuals: 0.009\n",
      "Loss: 122.236, Residuals: 0.009\n",
      "Evidence 421.590\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.23e-01\n",
      "Loss: 140.272, Residuals: 0.011\n",
      "Loss: 140.097, Residuals: 0.012\n",
      "Loss: 140.034, Residuals: 0.012\n",
      "Loss: 139.925, Residuals: 0.013\n",
      "Loss: 139.799, Residuals: 0.012\n",
      "Loss: 139.793, Residuals: 0.013\n",
      "Loss: 139.781, Residuals: 0.013\n",
      "Loss: 139.763, Residuals: 0.012\n",
      "Loss: 139.761, Residuals: 0.012\n",
      "Loss: 139.743, Residuals: 0.012\n",
      "Loss: 139.743, Residuals: 0.012\n",
      "Loss: 139.731, Residuals: 0.012\n",
      "Loss: 139.726, Residuals: 0.012\n",
      "Loss: 139.725, Residuals: 0.012\n",
      "Loss: 139.718, Residuals: 0.012\n",
      "Loss: 139.718, Residuals: 0.012\n",
      "Loss: 139.713, Residuals: 0.012\n",
      "Loss: 139.713, Residuals: 0.012\n",
      "Loss: 139.708, Residuals: 0.012\n",
      "Loss: 139.708, Residuals: 0.012\n",
      "Loss: 139.708, Residuals: 0.012\n",
      "Loss: 139.706, Residuals: 0.012\n",
      "Loss: 139.706, Residuals: 0.012\n",
      "Loss: 139.706, Residuals: 0.012\n",
      "Loss: 139.705, Residuals: 0.012\n",
      "Loss: 139.705, Residuals: 0.012\n",
      "Loss: 139.705, Residuals: 0.012\n",
      "Loss: 139.705, Residuals: 0.012\n",
      "Evidence 432.633\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.66e-01\n",
      "Loss: 147.063, Residuals: 0.017\n",
      "Loss: 146.986, Residuals: 0.016\n",
      "Loss: 146.895, Residuals: 0.017\n",
      "Loss: 146.842, Residuals: 0.015\n",
      "Loss: 146.836, Residuals: 0.015\n",
      "Loss: 146.829, Residuals: 0.015\n",
      "Loss: 146.829, Residuals: 0.015\n",
      "Loss: 146.823, Residuals: 0.015\n",
      "Loss: 146.817, Residuals: 0.015\n",
      "Loss: 146.817, Residuals: 0.015\n",
      "Loss: 146.813, Residuals: 0.015\n",
      "Loss: 146.813, Residuals: 0.015\n",
      "Loss: 146.809, Residuals: 0.015\n",
      "Loss: 146.809, Residuals: 0.015\n",
      "Evidence 435.876\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 9.21e-01\n",
      "Loss: 149.404, Residuals: 0.020\n",
      "Loss: 149.339, Residuals: 0.017\n",
      "Loss: 149.321, Residuals: 0.018\n",
      "Loss: 149.295, Residuals: 0.018\n",
      "Loss: 149.281, Residuals: 0.018\n",
      "Loss: 149.279, Residuals: 0.018\n",
      "Loss: 149.279, Residuals: 0.018\n",
      "Loss: 149.275, Residuals: 0.018\n",
      "Loss: 149.274, Residuals: 0.018\n",
      "Loss: 149.273, Residuals: 0.018\n",
      "Loss: 149.273, Residuals: 0.018\n",
      "Loss: 149.273, Residuals: 0.018\n",
      "Loss: 149.272, Residuals: 0.018\n",
      "Loss: 149.270, Residuals: 0.018\n",
      "Loss: 149.270, Residuals: 0.018\n",
      "Loss: 149.269, Residuals: 0.018\n",
      "Loss: 149.268, Residuals: 0.018\n",
      "Loss: 149.268, Residuals: 0.018\n",
      "Loss: 149.268, Residuals: 0.018\n",
      "Loss: 149.268, Residuals: 0.018\n",
      "Loss: 149.268, Residuals: 0.018\n",
      "Loss: 149.267, Residuals: 0.018\n",
      "Loss: 149.267, Residuals: 0.018\n",
      "Evidence 437.363\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 9.75e-01\n",
      "Loss: 150.342, Residuals: 0.020\n",
      "Loss: 150.306, Residuals: 0.020\n",
      "Loss: 150.297, Residuals: 0.020\n",
      "Loss: 150.284, Residuals: 0.020\n",
      "Loss: 150.274, Residuals: 0.020\n",
      "Loss: 150.274, Residuals: 0.020\n",
      "Loss: 150.271, Residuals: 0.020\n",
      "Loss: 150.270, Residuals: 0.020\n",
      "Loss: 150.269, Residuals: 0.020\n",
      "Loss: 150.269, Residuals: 0.020\n",
      "Loss: 150.268, Residuals: 0.020\n",
      "Loss: 150.268, Residuals: 0.020\n",
      "Loss: 150.267, Residuals: 0.020\n",
      "Loss: 150.266, Residuals: 0.020\n",
      "Loss: 150.266, Residuals: 0.020\n",
      "Loss: 150.265, Residuals: 0.020\n",
      "Evidence 438.214\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.02e+00\n",
      "Loss: 150.826, Residuals: 0.022\n",
      "Loss: 150.795, Residuals: 0.022\n",
      "Loss: 150.788, Residuals: 0.022\n",
      "Loss: 150.778, Residuals: 0.022\n",
      "Loss: 150.778, Residuals: 0.022\n",
      "Loss: 150.773, Residuals: 0.022\n",
      "Loss: 150.769, Residuals: 0.022\n",
      "Loss: 150.768, Residuals: 0.022\n",
      "Loss: 150.768, Residuals: 0.021\n",
      "Loss: 150.768, Residuals: 0.022\n",
      "Loss: 150.766, Residuals: 0.022\n",
      "Loss: 150.766, Residuals: 0.022\n",
      "Loss: 150.765, Residuals: 0.022\n",
      "Loss: 150.764, Residuals: 0.022\n",
      "Loss: 150.764, Residuals: 0.022\n",
      "Loss: 150.764, Residuals: 0.022\n",
      "Loss: 150.764, Residuals: 0.022\n",
      "Loss: 150.764, Residuals: 0.022\n",
      "Loss: 150.764, Residuals: 0.022\n",
      "Loss: 150.764, Residuals: 0.022\n",
      "Evidence 438.721\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.08e+00\n",
      "Loss: 151.114, Residuals: 0.023\n",
      "Loss: 151.089, Residuals: 0.023\n",
      "Loss: 151.077, Residuals: 0.023\n",
      "Loss: 151.075, Residuals: 0.023\n",
      "Loss: 151.073, Residuals: 0.023\n",
      "Loss: 151.072, Residuals: 0.023\n",
      "Loss: 151.070, Residuals: 0.023\n",
      "Loss: 151.066, Residuals: 0.023\n",
      "Loss: 151.065, Residuals: 0.023\n",
      "Loss: 151.064, Residuals: 0.023\n",
      "Loss: 151.063, Residuals: 0.023\n",
      "Loss: 151.063, Residuals: 0.023\n",
      "Loss: 151.061, Residuals: 0.023\n",
      "Loss: 151.061, Residuals: 0.023\n",
      "Loss: 151.061, Residuals: 0.023\n",
      "Loss: 151.060, Residuals: 0.023\n",
      "Loss: 151.060, Residuals: 0.023\n",
      "Evidence 439.007\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 11.112, Residuals: -0.095\n",
      "Loss: 6.455, Residuals: -0.062\n",
      "Loss: 5.512, Residuals: -0.059\n",
      "Loss: 4.668, Residuals: -0.053\n",
      "Loss: 4.064, Residuals: -0.089\n",
      "Loss: 3.863, Residuals: -0.013\n",
      "Loss: 3.605, Residuals: -0.028\n",
      "Loss: 3.279, Residuals: -0.039\n",
      "Loss: 3.223, Residuals: 0.001\n",
      "Loss: 3.121, Residuals: -0.012\n",
      "Loss: 2.974, Residuals: 0.077\n",
      "Loss: 2.785, Residuals: 0.057\n",
      "Loss: 2.765, Residuals: 0.029\n",
      "Loss: 2.730, Residuals: 0.025\n",
      "Loss: 2.672, Residuals: 0.018\n",
      "Loss: 2.583, Residuals: -0.000\n",
      "Loss: 2.560, Residuals: 0.006\n",
      "Loss: 2.528, Residuals: 0.005\n",
      "Loss: 2.526, Residuals: -0.003\n",
      "Loss: 2.505, Residuals: -0.010\n",
      "Loss: 2.471, Residuals: -0.023\n",
      "Loss: 2.466, Residuals: -0.021\n",
      "Loss: 2.457, Residuals: -0.024\n",
      "Loss: 2.442, Residuals: -0.031\n",
      "Loss: 2.432, Residuals: -0.040\n",
      "Loss: 2.431, Residuals: -0.040\n",
      "Loss: 2.430, Residuals: -0.040\n",
      "Loss: 2.419, Residuals: -0.045\n",
      "Loss: 2.418, Residuals: -0.048\n",
      "Loss: 2.407, Residuals: -0.052\n",
      "Loss: 2.407, Residuals: -0.051\n",
      "Loss: 2.401, Residuals: -0.055\n",
      "Loss: 2.401, Residuals: -0.054\n",
      "Loss: 2.394, Residuals: -0.058\n",
      "Loss: 2.394, Residuals: -0.058\n",
      "Loss: 2.394, Residuals: -0.057\n",
      "Loss: 2.394, Residuals: -0.057\n",
      "Loss: 2.372, Residuals: -0.067\n",
      "Loss: 2.371, Residuals: -0.064\n",
      "Loss: 2.370, Residuals: -0.062\n",
      "Loss: 2.368, Residuals: -0.062\n",
      "Loss: 2.366, Residuals: -0.064\n",
      "Loss: 2.365, Residuals: -0.063\n",
      "Loss: 2.362, Residuals: -0.065\n",
      "Loss: 2.355, Residuals: -0.067\n",
      "Loss: 2.355, Residuals: -0.067\n",
      "Loss: 2.354, Residuals: -0.067\n",
      "Loss: 2.353, Residuals: -0.066\n",
      "Loss: 2.349, Residuals: -0.068\n",
      "Loss: 2.349, Residuals: -0.068\n",
      "Evidence -389.710\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.58e-03\n",
      "Loss: 10.216, Residuals: -0.050\n",
      "Loss: 10.137, Residuals: -0.048\n",
      "Loss: 10.118, Residuals: -0.042\n",
      "Loss: 9.974, Residuals: -0.038\n",
      "Loss: 9.967, Residuals: -0.039\n",
      "Loss: 9.960, Residuals: -0.041\n",
      "Loss: 9.906, Residuals: -0.035\n",
      "Loss: 9.904, Residuals: -0.035\n",
      "Loss: 9.901, Residuals: -0.035\n",
      "Loss: 9.879, Residuals: -0.032\n",
      "Loss: 9.879, Residuals: -0.032\n",
      "Evidence 89.211\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.09e-02\n",
      "Loss: 37.546, Residuals: -0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 37.535, Residuals: -0.027\n",
      "Loss: 37.513, Residuals: -0.027\n",
      "Loss: 37.473, Residuals: -0.026\n",
      "Loss: 37.398, Residuals: -0.026\n",
      "Loss: 37.271, Residuals: -0.023\n",
      "Loss: 37.250, Residuals: -0.022\n",
      "Loss: 37.078, Residuals: -0.018\n",
      "Loss: 37.074, Residuals: -0.017\n",
      "Loss: 36.927, Residuals: -0.015\n",
      "Loss: 36.725, Residuals: -0.010\n",
      "Loss: 36.698, Residuals: -0.008\n",
      "Loss: 36.690, Residuals: -0.010\n",
      "Loss: 36.676, Residuals: -0.010\n",
      "Loss: 36.651, Residuals: -0.008\n",
      "Loss: 36.611, Residuals: -0.006\n",
      "Loss: 36.564, Residuals: -0.004\n",
      "Loss: 36.556, Residuals: -0.004\n",
      "Loss: 36.545, Residuals: -0.003\n",
      "Loss: 36.534, Residuals: -0.003\n",
      "Loss: 36.533, Residuals: -0.004\n",
      "Loss: 36.525, Residuals: -0.004\n",
      "Loss: 36.511, Residuals: -0.003\n",
      "Loss: 36.505, Residuals: -0.002\n",
      "Loss: 36.493, Residuals: -0.002\n",
      "Loss: 36.493, Residuals: -0.003\n",
      "Loss: 36.471, Residuals: -0.001\n",
      "Loss: 36.469, Residuals: -0.002\n",
      "Loss: 36.464, Residuals: -0.001\n",
      "Loss: 36.456, Residuals: -0.001\n",
      "Loss: 36.446, Residuals: -0.001\n",
      "Loss: 36.446, Residuals: -0.001\n",
      "Loss: 36.430, Residuals: -0.000\n",
      "Loss: 36.421, Residuals: 0.000\n",
      "Loss: 36.418, Residuals: 0.000\n",
      "Loss: 36.416, Residuals: -0.000\n",
      "Loss: 36.403, Residuals: 0.001\n",
      "Loss: 36.399, Residuals: 0.002\n",
      "Loss: 36.392, Residuals: 0.002\n",
      "Loss: 36.389, Residuals: 0.002\n",
      "Loss: 36.388, Residuals: 0.002\n",
      "Loss: 36.383, Residuals: 0.002\n",
      "Loss: 36.382, Residuals: 0.002\n",
      "Loss: 36.380, Residuals: 0.002\n",
      "Loss: 36.380, Residuals: 0.002\n",
      "Loss: 36.379, Residuals: 0.002\n",
      "Loss: 36.379, Residuals: 0.002\n",
      "Loss: 36.378, Residuals: 0.002\n",
      "Loss: 36.378, Residuals: 0.003\n",
      "Loss: 36.378, Residuals: 0.003\n",
      "Loss: 36.378, Residuals: 0.003\n",
      "Loss: 36.377, Residuals: 0.003\n",
      "Loss: 36.377, Residuals: 0.003\n",
      "Loss: 36.377, Residuals: 0.003\n",
      "Loss: 36.377, Residuals: 0.003\n",
      "Loss: 36.377, Residuals: 0.003\n",
      "Evidence 286.383\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.30e-01\n",
      "Loss: 85.048, Residuals: 0.005\n",
      "Loss: 84.761, Residuals: -0.001\n",
      "Loss: 84.293, Residuals: 0.002\n",
      "Loss: 84.054, Residuals: 0.005\n",
      "Loss: 83.999, Residuals: 0.003\n",
      "Loss: 83.989, Residuals: 0.001\n",
      "Loss: 83.911, Residuals: 0.001\n",
      "Loss: 83.827, Residuals: 0.002\n",
      "Loss: 83.805, Residuals: 0.006\n",
      "Loss: 83.768, Residuals: 0.005\n",
      "Loss: 83.742, Residuals: 0.004\n",
      "Loss: 83.698, Residuals: 0.005\n",
      "Loss: 83.695, Residuals: 0.006\n",
      "Loss: 83.674, Residuals: 0.007\n",
      "Loss: 83.637, Residuals: 0.008\n",
      "Loss: 83.625, Residuals: 0.008\n",
      "Loss: 83.604, Residuals: 0.008\n",
      "Loss: 83.577, Residuals: 0.010\n",
      "Loss: 83.575, Residuals: 0.010\n",
      "Loss: 83.572, Residuals: 0.009\n",
      "Loss: 83.569, Residuals: 0.009\n",
      "Loss: 83.565, Residuals: 0.009\n",
      "Loss: 83.564, Residuals: 0.009\n",
      "Loss: 83.562, Residuals: 0.009\n",
      "Loss: 83.558, Residuals: 0.009\n",
      "Loss: 83.558, Residuals: 0.009\n",
      "Loss: 83.558, Residuals: 0.009\n",
      "Loss: 83.557, Residuals: 0.009\n",
      "Loss: 83.557, Residuals: 0.009\n",
      "Loss: 83.556, Residuals: 0.009\n",
      "Loss: 83.556, Residuals: 0.009\n",
      "Loss: 83.556, Residuals: 0.009\n",
      "Loss: 83.556, Residuals: 0.009\n",
      "Loss: 83.556, Residuals: 0.009\n",
      "Loss: 83.556, Residuals: 0.009\n",
      "Loss: 83.556, Residuals: 0.009\n",
      "Loss: 83.556, Residuals: 0.009\n",
      "Loss: 83.556, Residuals: 0.009\n",
      "Loss: 83.556, Residuals: 0.009\n",
      "Evidence 391.076\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 9.95e-01\n",
      "Loss: 123.978, Residuals: 0.008\n",
      "Loss: 123.583, Residuals: 0.006\n",
      "Loss: 122.966, Residuals: 0.008\n",
      "Loss: 122.528, Residuals: 0.012\n",
      "Loss: 122.446, Residuals: 0.006\n",
      "Loss: 122.302, Residuals: 0.007\n",
      "Loss: 122.118, Residuals: 0.009\n",
      "Loss: 122.107, Residuals: 0.010\n",
      "Loss: 122.094, Residuals: 0.008\n",
      "Loss: 122.070, Residuals: 0.008\n",
      "Loss: 122.029, Residuals: 0.009\n",
      "Loss: 122.026, Residuals: 0.009\n",
      "Loss: 122.002, Residuals: 0.009\n",
      "Loss: 121.999, Residuals: 0.009\n",
      "Loss: 121.981, Residuals: 0.009\n",
      "Loss: 121.980, Residuals: 0.009\n",
      "Loss: 121.975, Residuals: 0.009\n",
      "Loss: 121.974, Residuals: 0.009\n",
      "Loss: 121.972, Residuals: 0.009\n",
      "Loss: 121.970, Residuals: 0.009\n",
      "Loss: 121.970, Residuals: 0.009\n",
      "Loss: 121.969, Residuals: 0.009\n",
      "Loss: 121.969, Residuals: 0.009\n",
      "Loss: 121.969, Residuals: 0.009\n",
      "Loss: 121.969, Residuals: 0.009\n",
      "Loss: 121.969, Residuals: 0.009\n",
      "Evidence 423.709\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.53e+00\n",
      "Loss: 140.519, Residuals: 0.011\n",
      "Loss: 140.110, Residuals: 0.009\n",
      "Loss: 139.615, Residuals: 0.011\n",
      "Loss: 139.558, Residuals: 0.011\n",
      "Loss: 139.466, Residuals: 0.011\n",
      "Loss: 139.435, Residuals: 0.010\n",
      "Loss: 139.384, Residuals: 0.011\n",
      "Loss: 139.367, Residuals: 0.010\n",
      "Loss: 139.338, Residuals: 0.011\n",
      "Loss: 139.335, Residuals: 0.011\n",
      "Loss: 139.307, Residuals: 0.011\n",
      "Loss: 139.283, Residuals: 0.011\n",
      "Loss: 139.280, Residuals: 0.011\n",
      "Loss: 139.277, Residuals: 0.011\n",
      "Loss: 139.275, Residuals: 0.010\n",
      "Loss: 139.274, Residuals: 0.010\n",
      "Loss: 139.271, Residuals: 0.010\n",
      "Loss: 139.268, Residuals: 0.010\n",
      "Loss: 139.268, Residuals: 0.010\n",
      "Loss: 139.267, Residuals: 0.010\n",
      "Loss: 139.267, Residuals: 0.010\n",
      "Loss: 139.267, Residuals: 0.010\n",
      "Loss: 139.267, Residuals: 0.010\n",
      "Loss: 139.267, Residuals: 0.010\n",
      "Loss: 139.267, Residuals: 0.010\n",
      "Loss: 139.267, Residuals: 0.010\n",
      "Loss: 139.267, Residuals: 0.010\n",
      "Evidence 433.067\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.94e+00\n",
      "Loss: 146.370, Residuals: 0.013\n",
      "Loss: 146.052, Residuals: 0.015\n",
      "Loss: 145.999, Residuals: 0.013\n",
      "Loss: 145.910, Residuals: 0.014\n",
      "Loss: 145.822, Residuals: 0.014\n",
      "Loss: 145.820, Residuals: 0.014\n",
      "Loss: 145.816, Residuals: 0.014\n",
      "Loss: 145.809, Residuals: 0.014\n",
      "Loss: 145.801, Residuals: 0.014\n",
      "Loss: 145.801, Residuals: 0.014\n",
      "Loss: 145.800, Residuals: 0.013\n",
      "Loss: 145.799, Residuals: 0.014\n",
      "Loss: 145.797, Residuals: 0.014\n",
      "Loss: 145.797, Residuals: 0.014\n",
      "Evidence 436.959\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.11e+00\n",
      "Loss: 148.723, Residuals: 0.017\n",
      "Loss: 148.512, Residuals: 0.017\n",
      "Loss: 148.474, Residuals: 0.016\n",
      "Loss: 148.417, Residuals: 0.016\n",
      "Loss: 148.393, Residuals: 0.016\n",
      "Loss: 148.390, Residuals: 0.016\n",
      "Loss: 148.389, Residuals: 0.016\n",
      "Loss: 148.389, Residuals: 0.016\n",
      "Loss: 148.389, Residuals: 0.016\n",
      "Loss: 148.388, Residuals: 0.016\n",
      "Loss: 148.388, Residuals: 0.016\n",
      "Evidence 438.847\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.17e+00\n",
      "Loss: 149.778, Residuals: 0.018\n",
      "Loss: 149.675, Residuals: 0.018\n",
      "Loss: 149.651, Residuals: 0.018\n",
      "Loss: 149.623, Residuals: 0.018\n",
      "Loss: 149.619, Residuals: 0.018\n",
      "Loss: 149.618, Residuals: 0.018\n",
      "Loss: 149.616, Residuals: 0.018\n",
      "Loss: 149.615, Residuals: 0.018\n",
      "Loss: 149.615, Residuals: 0.018\n",
      "Evidence 439.870\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.19e+00\n",
      "Loss: 150.385, Residuals: 0.019\n",
      "Loss: 150.341, Residuals: 0.020\n",
      "Loss: 150.320, Residuals: 0.019\n",
      "Loss: 150.318, Residuals: 0.019\n",
      "Loss: 150.316, Residuals: 0.019\n",
      "Loss: 150.315, Residuals: 0.019\n",
      "Loss: 150.315, Residuals: 0.019\n",
      "Loss: 150.314, Residuals: 0.019\n",
      "Loss: 150.314, Residuals: 0.019\n",
      "Evidence 440.458\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.19e+00\n",
      "Loss: 150.778, Residuals: 0.020\n",
      "Loss: 150.757, Residuals: 0.021\n",
      "Loss: 150.745, Residuals: 0.020\n",
      "Loss: 150.744, Residuals: 0.020\n",
      "Loss: 150.742, Residuals: 0.020\n",
      "Loss: 150.742, Residuals: 0.020\n",
      "Loss: 150.742, Residuals: 0.020\n",
      "Loss: 150.742, Residuals: 0.020\n",
      "Loss: 150.742, Residuals: 0.020\n",
      "Loss: 150.742, Residuals: 0.020\n",
      "Loss: 150.741, Residuals: 0.020\n",
      "Loss: 150.741, Residuals: 0.020\n",
      "Evidence 440.819\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 11.320, Residuals: -0.099\n",
      "Loss: 6.403, Residuals: -0.048\n",
      "Loss: 3.989, Residuals: -0.048\n",
      "Loss: 3.279, Residuals: -0.044\n",
      "Loss: 2.838, Residuals: -0.037\n",
      "Loss: 2.726, Residuals: -0.020\n",
      "Loss: 2.541, Residuals: -0.031\n",
      "Loss: 2.290, Residuals: -0.038\n",
      "Loss: 2.262, Residuals: 0.005\n",
      "Loss: 2.209, Residuals: -0.003\n",
      "Loss: 2.106, Residuals: -0.013\n",
      "Loss: 2.049, Residuals: -0.011\n",
      "Loss: 1.954, Residuals: -0.022\n",
      "Loss: 1.897, Residuals: -0.017\n",
      "Loss: 1.826, Residuals: -0.035\n",
      "Loss: 1.822, Residuals: -0.038\n",
      "Loss: 1.787, Residuals: -0.049\n",
      "Loss: 1.774, Residuals: -0.048\n",
      "Loss: 1.773, Residuals: -0.049\n",
      "Loss: 1.743, Residuals: -0.056\n",
      "Loss: 1.743, Residuals: -0.052\n",
      "Loss: 1.664, Residuals: -0.065\n",
      "Loss: 1.661, Residuals: -0.067\n",
      "Loss: 1.654, Residuals: -0.068\n",
      "Loss: 1.643, Residuals: -0.069\n",
      "Loss: 1.630, Residuals: -0.071\n",
      "Loss: 1.628, Residuals: -0.068\n",
      "Loss: 1.625, Residuals: -0.067\n",
      "Loss: 1.625, Residuals: -0.066\n",
      "Loss: 1.624, Residuals: -0.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.622, Residuals: -0.065\n",
      "Loss: 1.622, Residuals: -0.064\n",
      "Loss: 1.620, Residuals: -0.063\n",
      "Loss: 1.620, Residuals: -0.063\n",
      "Loss: 1.620, Residuals: -0.063\n",
      "Loss: 1.620, Residuals: -0.063\n",
      "Loss: 1.618, Residuals: -0.063\n",
      "Loss: 1.618, Residuals: -0.063\n",
      "Loss: 1.618, Residuals: -0.063\n",
      "Loss: 1.616, Residuals: -0.063\n",
      "Loss: 1.616, Residuals: -0.063\n",
      "Loss: 1.616, Residuals: -0.063\n",
      "Loss: 1.616, Residuals: -0.063\n",
      "Loss: 1.615, Residuals: -0.063\n",
      "Loss: 1.615, Residuals: -0.063\n",
      "Loss: 1.612, Residuals: -0.063\n",
      "Loss: 1.612, Residuals: -0.063\n",
      "Loss: 1.612, Residuals: -0.063\n",
      "Loss: 1.605, Residuals: -0.062\n",
      "Loss: 1.605, Residuals: -0.064\n",
      "Loss: 1.604, Residuals: -0.063\n",
      "Loss: 1.597, Residuals: -0.065\n",
      "Loss: 1.597, Residuals: -0.063\n",
      "Loss: 1.596, Residuals: -0.063\n",
      "Loss: 1.595, Residuals: -0.063\n",
      "Loss: 1.593, Residuals: -0.063\n",
      "Loss: 1.593, Residuals: -0.064\n",
      "Loss: 1.590, Residuals: -0.064\n",
      "Loss: 1.589, Residuals: -0.063\n",
      "Loss: 1.583, Residuals: -0.064\n",
      "Loss: 1.583, Residuals: -0.064\n",
      "Loss: 1.582, Residuals: -0.063\n",
      "Loss: 1.577, Residuals: -0.065\n",
      "Loss: 1.577, Residuals: -0.065\n",
      "Loss: 1.577, Residuals: -0.065\n",
      "Loss: 1.576, Residuals: -0.065\n",
      "Loss: 1.574, Residuals: -0.065\n",
      "Loss: 1.574, Residuals: -0.065\n",
      "Loss: 1.574, Residuals: -0.065\n",
      "Loss: 1.574, Residuals: -0.065\n",
      "Loss: 1.572, Residuals: -0.065\n",
      "Loss: 1.570, Residuals: -0.066\n",
      "Loss: 1.570, Residuals: -0.066\n",
      "Loss: 1.569, Residuals: -0.066\n",
      "Loss: 1.568, Residuals: -0.067\n",
      "Loss: 1.568, Residuals: -0.067\n",
      "Loss: 1.567, Residuals: -0.067\n",
      "Loss: 1.567, Residuals: -0.068\n",
      "Loss: 1.566, Residuals: -0.068\n",
      "Loss: 1.565, Residuals: -0.068\n",
      "Loss: 1.565, Residuals: -0.068\n",
      "Loss: 1.564, Residuals: -0.068\n",
      "Loss: 1.564, Residuals: -0.068\n",
      "Loss: 1.564, Residuals: -0.069\n",
      "Loss: 1.563, Residuals: -0.070\n",
      "Loss: 1.563, Residuals: -0.070\n",
      "Loss: 1.563, Residuals: -0.070\n",
      "Loss: 1.563, Residuals: -0.070\n",
      "Loss: 1.563, Residuals: -0.070\n",
      "Loss: 1.562, Residuals: -0.070\n",
      "Loss: 1.562, Residuals: -0.070\n",
      "Loss: 1.561, Residuals: -0.070\n",
      "Loss: 1.561, Residuals: -0.070\n",
      "Loss: 1.561, Residuals: -0.070\n",
      "Loss: 1.561, Residuals: -0.070\n",
      "Loss: 1.560, Residuals: -0.071\n",
      "Loss: 1.560, Residuals: -0.071\n",
      "Loss: 1.560, Residuals: -0.071\n",
      "Loss: 1.560, Residuals: -0.071\n",
      "Loss: 1.560, Residuals: -0.071\n",
      "Evidence -411.183\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.44e-03\n",
      "Loss: 9.342, Residuals: -0.046\n",
      "Loss: 9.278, Residuals: -0.041\n",
      "Loss: 9.164, Residuals: -0.035\n",
      "Loss: 9.159, Residuals: -0.031\n",
      "Loss: 9.110, Residuals: -0.028\n",
      "Loss: 9.029, Residuals: -0.021\n",
      "Loss: 9.029, Residuals: -0.021\n",
      "Evidence 111.423\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.94e-02\n",
      "Loss: 36.061, Residuals: 0.009\n",
      "Loss: 36.023, Residuals: 0.009\n",
      "Loss: 36.012, Residuals: 0.008\n",
      "Loss: 35.922, Residuals: 0.006\n",
      "Loss: 35.792, Residuals: 0.003\n",
      "Loss: 35.790, Residuals: 0.003\n",
      "Loss: 35.785, Residuals: 0.002\n",
      "Loss: 35.596, Residuals: 0.002\n",
      "Loss: 35.592, Residuals: 0.002\n",
      "Loss: 35.472, Residuals: 0.002\n",
      "Loss: 35.469, Residuals: 0.002\n",
      "Loss: 35.464, Residuals: 0.002\n",
      "Loss: 35.461, Residuals: 0.002\n",
      "Loss: 35.040, Residuals: 0.009\n",
      "Loss: 35.016, Residuals: 0.009\n",
      "Loss: 35.006, Residuals: 0.010\n",
      "Loss: 34.989, Residuals: 0.010\n",
      "Loss: 34.984, Residuals: 0.006\n",
      "Loss: 34.945, Residuals: 0.009\n",
      "Loss: 34.945, Residuals: 0.009\n",
      "Loss: 34.863, Residuals: 0.010\n",
      "Loss: 34.863, Residuals: 0.010\n",
      "Evidence 323.668\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.63e-01\n",
      "Loss: 82.869, Residuals: 0.007\n",
      "Loss: 82.750, Residuals: 0.013\n",
      "Loss: 82.573, Residuals: 0.012\n",
      "Loss: 82.560, Residuals: 0.009\n",
      "Loss: 82.073, Residuals: 0.009\n",
      "Loss: 82.072, Residuals: 0.009\n",
      "Evidence 444.468\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.22e-01\n",
      "Loss: 125.689, Residuals: 0.009\n",
      "Loss: 125.474, Residuals: 0.007\n",
      "Loss: 125.200, Residuals: 0.005\n",
      "Loss: 124.712, Residuals: 0.005\n",
      "Loss: 124.036, Residuals: 0.001\n",
      "Loss: 124.031, Residuals: 0.001\n",
      "Evidence 485.973\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.97e-01\n",
      "Loss: 145.832, Residuals: 0.001\n",
      "Evidence 494.324\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.19e-01\n",
      "Loss: 153.474, Residuals: 0.001\n",
      "Loss: 153.022, Residuals: 0.001\n",
      "Loss: 152.225, Residuals: 0.000\n",
      "Loss: 152.169, Residuals: 0.003\n",
      "Loss: 151.655, Residuals: 0.003\n",
      "Loss: 151.515, Residuals: 0.004\n",
      "Loss: 151.254, Residuals: 0.004\n",
      "Loss: 151.243, Residuals: 0.003\n",
      "Loss: 150.826, Residuals: 0.003\n",
      "Loss: 150.826, Residuals: 0.003\n",
      "Evidence 499.474\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.44e-01\n",
      "Loss: 153.735, Residuals: 0.004\n",
      "Loss: 153.593, Residuals: 0.005\n",
      "Loss: 153.592, Residuals: 0.005\n",
      "Evidence 502.363\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.55e-01\n",
      "Loss: 154.478, Residuals: 0.010\n",
      "Loss: 154.466, Residuals: 0.010\n",
      "Evidence 504.469\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.69e-01\n",
      "Loss: 155.591, Residuals: 0.010\n",
      "Loss: 155.444, Residuals: 0.010\n",
      "Loss: 155.184, Residuals: 0.010\n",
      "Loss: 155.085, Residuals: 0.011\n",
      "Loss: 155.081, Residuals: 0.012\n",
      "Loss: 154.908, Residuals: 0.012\n",
      "Loss: 154.908, Residuals: 0.012\n",
      "Evidence 506.254\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.85e-01\n",
      "Loss: 155.373, Residuals: 0.013\n",
      "Loss: 155.322, Residuals: 0.014\n",
      "Loss: 155.282, Residuals: 0.015\n",
      "Loss: 155.208, Residuals: 0.015\n",
      "Loss: 155.208, Residuals: 0.015\n",
      "Evidence 507.890\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.05e-01\n",
      "Loss: 155.861, Residuals: 0.016\n",
      "Loss: 155.758, Residuals: 0.014\n",
      "Loss: 155.738, Residuals: 0.016\n",
      "Loss: 155.566, Residuals: 0.016\n",
      "Loss: 155.564, Residuals: 0.016\n",
      "Evidence 509.167\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.18e-01\n",
      "Loss: 156.049, Residuals: 0.019\n",
      "Loss: 156.041, Residuals: 0.018\n",
      "Loss: 155.973, Residuals: 0.018\n",
      "Loss: 155.897, Residuals: 0.017\n",
      "Loss: 155.887, Residuals: 0.018\n",
      "Loss: 155.797, Residuals: 0.018\n",
      "Loss: 155.797, Residuals: 0.018\n",
      "Evidence 510.196\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.29e-01\n",
      "Loss: 156.198, Residuals: 0.021\n",
      "Loss: 156.116, Residuals: 0.020\n",
      "Loss: 156.107, Residuals: 0.019\n",
      "Loss: 156.030, Residuals: 0.020\n",
      "Loss: 156.029, Residuals: 0.020\n",
      "Evidence 511.055\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.35e-01\n",
      "Loss: 156.296, Residuals: 0.020\n",
      "Loss: 156.285, Residuals: 0.020\n",
      "Loss: 156.195, Residuals: 0.020\n",
      "Loss: 156.194, Residuals: 0.020\n",
      "Evidence 511.736\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.40e-01\n",
      "Loss: 156.391, Residuals: 0.020\n",
      "Loss: 156.386, Residuals: 0.020\n",
      "Loss: 156.337, Residuals: 0.020\n",
      "Evidence 512.299\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.42e-01\n",
      "Loss: 156.497, Residuals: 0.021\n",
      "Loss: 156.454, Residuals: 0.021\n",
      "Loss: 156.449, Residuals: 0.021\n",
      "Loss: 156.400, Residuals: 0.021\n",
      "Loss: 156.400, Residuals: 0.021\n",
      "Evidence 512.796\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 11.612, Residuals: -0.153\n",
      "Loss: 6.899, Residuals: -0.075\n",
      "Loss: 5.127, Residuals: -0.077\n",
      "Loss: 4.514, Residuals: -0.077\n",
      "Loss: 4.119, Residuals: -0.052\n",
      "Loss: 3.776, Residuals: -0.021\n",
      "Loss: 3.647, Residuals: -0.001\n",
      "Loss: 3.420, Residuals: -0.014\n",
      "Loss: 3.274, Residuals: 0.018\n",
      "Loss: 3.185, Residuals: 0.052\n",
      "Loss: 3.032, Residuals: 0.036\n",
      "Loss: 2.808, Residuals: 0.010\n",
      "Loss: 2.781, Residuals: 0.041\n",
      "Loss: 2.730, Residuals: 0.033\n",
      "Loss: 2.644, Residuals: 0.016\n",
      "Loss: 2.589, Residuals: 0.008\n",
      "Loss: 2.574, Residuals: 0.016\n",
      "Loss: 2.548, Residuals: 0.008\n",
      "Loss: 2.504, Residuals: -0.005\n",
      "Loss: 2.498, Residuals: -0.022\n",
      "Loss: 2.488, Residuals: -0.024\n",
      "Loss: 2.469, Residuals: -0.028\n",
      "Loss: 2.466, Residuals: -0.023\n",
      "Loss: 2.435, Residuals: -0.037\n",
      "Loss: 2.423, Residuals: -0.052\n",
      "Loss: 2.405, Residuals: -0.057\n",
      "Loss: 2.404, Residuals: -0.057\n",
      "Loss: 2.395, Residuals: -0.061\n",
      "Loss: 2.380, Residuals: -0.069\n",
      "Loss: 2.379, Residuals: -0.070\n",
      "Loss: 2.377, Residuals: -0.069\n",
      "Loss: 2.366, Residuals: -0.074\n",
      "Loss: 2.359, Residuals: -0.080\n",
      "Loss: 2.358, Residuals: -0.079\n",
      "Loss: 2.339, Residuals: -0.083\n",
      "Loss: 2.338, Residuals: -0.084\n",
      "Loss: 2.335, Residuals: -0.085\n",
      "Loss: 2.307, Residuals: -0.085\n",
      "Loss: 2.305, Residuals: -0.084\n",
      "Loss: 2.303, Residuals: -0.085\n",
      "Loss: 2.287, Residuals: -0.084\n",
      "Loss: 2.286, Residuals: -0.086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.285, Residuals: -0.084\n",
      "Loss: 2.276, Residuals: -0.084\n",
      "Loss: 2.276, Residuals: -0.084\n",
      "Loss: 2.270, Residuals: -0.084\n",
      "Loss: 2.268, Residuals: -0.084\n",
      "Loss: 2.255, Residuals: -0.084\n",
      "Loss: 2.255, Residuals: -0.085\n",
      "Loss: 2.254, Residuals: -0.083\n",
      "Loss: 2.242, Residuals: -0.082\n",
      "Loss: 2.241, Residuals: -0.084\n",
      "Loss: 2.241, Residuals: -0.083\n",
      "Loss: 2.240, Residuals: -0.082\n",
      "Loss: 2.239, Residuals: -0.082\n",
      "Loss: 2.230, Residuals: -0.082\n",
      "Loss: 2.230, Residuals: -0.083\n",
      "Loss: 2.230, Residuals: -0.081\n",
      "Loss: 2.229, Residuals: -0.080\n",
      "Loss: 2.224, Residuals: -0.083\n",
      "Loss: 2.224, Residuals: -0.083\n",
      "Loss: 2.217, Residuals: -0.083\n",
      "Loss: 2.216, Residuals: -0.084\n",
      "Loss: 2.215, Residuals: -0.083\n",
      "Loss: 2.209, Residuals: -0.086\n",
      "Loss: 2.209, Residuals: -0.086\n",
      "Loss: 2.208, Residuals: -0.085\n",
      "Loss: 2.204, Residuals: -0.087\n",
      "Loss: 2.204, Residuals: -0.085\n",
      "Loss: 2.203, Residuals: -0.086\n",
      "Loss: 2.201, Residuals: -0.088\n",
      "Loss: 2.201, Residuals: -0.088\n",
      "Loss: 2.195, Residuals: -0.092\n",
      "Loss: 2.195, Residuals: -0.092\n",
      "Loss: 2.195, Residuals: -0.092\n",
      "Loss: 2.195, Residuals: -0.092\n",
      "Loss: 2.192, Residuals: -0.094\n",
      "Loss: 2.192, Residuals: -0.094\n",
      "Loss: 2.188, Residuals: -0.097\n",
      "Loss: 2.188, Residuals: -0.097\n",
      "Loss: 2.188, Residuals: -0.097\n",
      "Loss: 2.187, Residuals: -0.097\n",
      "Loss: 2.187, Residuals: -0.098\n",
      "Loss: 2.184, Residuals: -0.101\n",
      "Loss: 2.184, Residuals: -0.101\n",
      "Loss: 2.184, Residuals: -0.101\n",
      "Loss: 2.184, Residuals: -0.101\n",
      "Loss: 2.182, Residuals: -0.102\n",
      "Loss: 2.181, Residuals: -0.102\n",
      "Evidence -377.090\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.45e-03\n",
      "Loss: 10.403, Residuals: -0.091\n",
      "Loss: 10.380, Residuals: -0.091\n",
      "Loss: 10.336, Residuals: -0.089\n",
      "Loss: 10.257, Residuals: -0.084\n",
      "Loss: 10.153, Residuals: -0.075\n",
      "Loss: 10.062, Residuals: -0.059\n",
      "Loss: 10.051, Residuals: -0.062\n",
      "Loss: 10.045, Residuals: -0.067\n",
      "Loss: 9.990, Residuals: -0.064\n",
      "Loss: 9.989, Residuals: -0.064\n",
      "Loss: 9.980, Residuals: -0.064\n",
      "Loss: 9.929, Residuals: -0.055\n",
      "Loss: 9.909, Residuals: -0.058\n",
      "Loss: 9.906, Residuals: -0.054\n",
      "Loss: 9.901, Residuals: -0.055\n",
      "Loss: 9.892, Residuals: -0.054\n",
      "Loss: 9.850, Residuals: -0.049\n",
      "Loss: 9.843, Residuals: -0.051\n",
      "Loss: 9.842, Residuals: -0.050\n",
      "Loss: 9.838, Residuals: -0.049\n",
      "Loss: 9.829, Residuals: -0.049\n",
      "Loss: 9.812, Residuals: -0.047\n",
      "Loss: 9.812, Residuals: -0.047\n",
      "Loss: 9.799, Residuals: -0.046\n",
      "Loss: 9.779, Residuals: -0.042\n",
      "Loss: 9.778, Residuals: -0.042\n",
      "Loss: 9.777, Residuals: -0.043\n",
      "Loss: 9.770, Residuals: -0.042\n",
      "Loss: 9.756, Residuals: -0.040\n",
      "Loss: 9.755, Residuals: -0.040\n",
      "Loss: 9.750, Residuals: -0.039\n",
      "Loss: 9.750, Residuals: -0.039\n",
      "Evidence 98.168\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.45e-02\n",
      "Loss: 39.199, Residuals: -0.042\n",
      "Loss: 39.197, Residuals: -0.041\n",
      "Loss: 38.938, Residuals: -0.039\n",
      "Loss: 38.936, Residuals: -0.039\n",
      "Loss: 38.847, Residuals: -0.038\n",
      "Loss: 38.693, Residuals: -0.035\n",
      "Loss: 38.692, Residuals: -0.036\n",
      "Loss: 38.644, Residuals: -0.034\n",
      "Loss: 38.560, Residuals: -0.033\n",
      "Loss: 38.559, Residuals: -0.032\n",
      "Loss: 38.509, Residuals: -0.031\n",
      "Loss: 38.421, Residuals: -0.029\n",
      "Loss: 38.410, Residuals: -0.030\n",
      "Loss: 38.308, Residuals: -0.028\n",
      "Loss: 38.307, Residuals: -0.027\n",
      "Loss: 38.090, Residuals: -0.023\n",
      "Loss: 38.089, Residuals: -0.023\n",
      "Loss: 38.078, Residuals: -0.023\n",
      "Loss: 37.842, Residuals: -0.018\n",
      "Loss: 37.835, Residuals: -0.019\n",
      "Loss: 37.823, Residuals: -0.020\n",
      "Loss: 37.808, Residuals: -0.021\n",
      "Loss: 37.677, Residuals: -0.016\n",
      "Loss: 37.675, Residuals: -0.017\n",
      "Loss: 37.671, Residuals: -0.018\n",
      "Loss: 37.663, Residuals: -0.018\n",
      "Loss: 37.603, Residuals: -0.015\n",
      "Loss: 37.592, Residuals: -0.016\n",
      "Loss: 37.575, Residuals: -0.016\n",
      "Loss: 37.548, Residuals: -0.015\n",
      "Loss: 37.545, Residuals: -0.015\n",
      "Loss: 37.523, Residuals: -0.013\n",
      "Loss: 37.520, Residuals: -0.014\n",
      "Loss: 37.514, Residuals: -0.013\n",
      "Loss: 37.505, Residuals: -0.013\n",
      "Loss: 37.502, Residuals: -0.013\n",
      "Loss: 37.498, Residuals: -0.012\n",
      "Loss: 37.492, Residuals: -0.011\n",
      "Loss: 37.491, Residuals: -0.011\n",
      "Loss: 37.490, Residuals: -0.011\n",
      "Loss: 37.488, Residuals: -0.011\n",
      "Loss: 37.487, Residuals: -0.011\n",
      "Loss: 37.487, Residuals: -0.011\n",
      "Loss: 37.487, Residuals: -0.011\n",
      "Loss: 37.487, Residuals: -0.011\n",
      "Loss: 37.487, Residuals: -0.011\n",
      "Loss: 37.487, Residuals: -0.011\n",
      "Loss: 37.486, Residuals: -0.010\n",
      "Loss: 37.486, Residuals: -0.010\n",
      "Loss: 37.486, Residuals: -0.010\n",
      "Loss: 37.486, Residuals: -0.010\n",
      "Loss: 37.486, Residuals: -0.010\n",
      "Loss: 37.486, Residuals: -0.010\n",
      "Loss: 37.485, Residuals: -0.010\n",
      "Loss: 37.485, Residuals: -0.010\n",
      "Loss: 37.485, Residuals: -0.010\n",
      "Loss: 37.485, Residuals: -0.010\n",
      "Loss: 37.485, Residuals: -0.010\n",
      "Loss: 37.485, Residuals: -0.010\n",
      "Loss: 37.485, Residuals: -0.010\n",
      "Loss: 37.485, Residuals: -0.010\n",
      "Loss: 37.485, Residuals: -0.010\n",
      "Evidence 302.744\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.23e-01\n",
      "Loss: 90.319, Residuals: -0.014\n",
      "Loss: 90.104, Residuals: -0.013\n",
      "Loss: 89.708, Residuals: -0.012\n",
      "Loss: 89.401, Residuals: -0.010\n",
      "Loss: 89.375, Residuals: -0.011\n",
      "Loss: 89.327, Residuals: -0.011\n",
      "Loss: 89.242, Residuals: -0.011\n",
      "Loss: 89.086, Residuals: -0.011\n",
      "Loss: 89.029, Residuals: -0.012\n",
      "Loss: 88.923, Residuals: -0.011\n",
      "Loss: 88.749, Residuals: -0.009\n",
      "Loss: 88.722, Residuals: -0.010\n",
      "Loss: 88.674, Residuals: -0.009\n",
      "Loss: 88.603, Residuals: -0.007\n",
      "Loss: 88.598, Residuals: -0.007\n",
      "Loss: 88.589, Residuals: -0.007\n",
      "Loss: 88.575, Residuals: -0.006\n",
      "Loss: 88.572, Residuals: -0.007\n",
      "Loss: 88.566, Residuals: -0.006\n",
      "Loss: 88.557, Residuals: -0.006\n",
      "Loss: 88.557, Residuals: -0.006\n",
      "Loss: 88.555, Residuals: -0.006\n",
      "Loss: 88.552, Residuals: -0.006\n",
      "Loss: 88.552, Residuals: -0.006\n",
      "Loss: 88.551, Residuals: -0.006\n",
      "Loss: 88.549, Residuals: -0.006\n",
      "Loss: 88.549, Residuals: -0.006\n",
      "Loss: 88.548, Residuals: -0.006\n",
      "Loss: 88.547, Residuals: -0.006\n",
      "Loss: 88.547, Residuals: -0.006\n",
      "Loss: 88.547, Residuals: -0.006\n",
      "Loss: 88.547, Residuals: -0.006\n",
      "Loss: 88.546, Residuals: -0.006\n",
      "Evidence 416.821\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.51e-01\n",
      "Loss: 130.239, Residuals: -0.010\n",
      "Loss: 130.108, Residuals: -0.012\n",
      "Loss: 129.877, Residuals: -0.011\n",
      "Loss: 129.546, Residuals: -0.008\n",
      "Loss: 129.495, Residuals: -0.008\n",
      "Loss: 129.414, Residuals: -0.007\n",
      "Loss: 129.373, Residuals: -0.007\n",
      "Loss: 129.366, Residuals: -0.007\n",
      "Loss: 129.363, Residuals: -0.007\n",
      "Loss: 129.357, Residuals: -0.007\n",
      "Loss: 129.351, Residuals: -0.006\n",
      "Loss: 129.351, Residuals: -0.006\n",
      "Loss: 129.350, Residuals: -0.006\n",
      "Loss: 129.350, Residuals: -0.006\n",
      "Loss: 129.348, Residuals: -0.006\n",
      "Loss: 129.348, Residuals: -0.006\n",
      "Loss: 129.347, Residuals: -0.006\n",
      "Loss: 129.346, Residuals: -0.006\n",
      "Evidence 449.621\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.01e-01\n",
      "Loss: 147.286, Residuals: -0.007\n",
      "Loss: 147.234, Residuals: -0.008\n",
      "Loss: 147.140, Residuals: -0.007\n",
      "Loss: 147.002, Residuals: -0.006\n",
      "Loss: 146.984, Residuals: -0.006\n",
      "Loss: 146.953, Residuals: -0.006\n",
      "Loss: 146.916, Residuals: -0.006\n",
      "Loss: 146.914, Residuals: -0.006\n",
      "Loss: 146.913, Residuals: -0.006\n",
      "Loss: 146.912, Residuals: -0.006\n",
      "Loss: 146.909, Residuals: -0.006\n",
      "Loss: 146.909, Residuals: -0.006\n",
      "Loss: 146.908, Residuals: -0.006\n",
      "Loss: 146.908, Residuals: -0.006\n",
      "Loss: 146.908, Residuals: -0.006\n",
      "Loss: 146.907, Residuals: -0.006\n",
      "Loss: 146.907, Residuals: -0.006\n",
      "Evidence 457.084\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.42e-01\n",
      "Loss: 152.966, Residuals: -0.003\n",
      "Loss: 152.938, Residuals: -0.006\n",
      "Loss: 152.890, Residuals: -0.005\n",
      "Loss: 152.827, Residuals: -0.004\n",
      "Loss: 152.824, Residuals: -0.004\n",
      "Loss: 152.817, Residuals: -0.004\n",
      "Loss: 152.806, Residuals: -0.004\n",
      "Loss: 152.804, Residuals: -0.004\n",
      "Loss: 152.801, Residuals: -0.004\n",
      "Loss: 152.796, Residuals: -0.004\n",
      "Loss: 152.795, Residuals: -0.004\n",
      "Loss: 152.795, Residuals: -0.004\n",
      "Loss: 152.793, Residuals: -0.004\n",
      "Loss: 152.792, Residuals: -0.004\n",
      "Loss: 152.792, Residuals: -0.004\n",
      "Evidence 459.265\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.49e-01\n",
      "Loss: 154.883, Residuals: -0.002\n",
      "Loss: 154.866, Residuals: -0.004\n",
      "Loss: 154.838, Residuals: -0.003\n",
      "Loss: 154.806, Residuals: -0.002\n",
      "Loss: 154.803, Residuals: -0.002\n",
      "Loss: 154.802, Residuals: -0.003\n",
      "Loss: 154.801, Residuals: -0.003\n",
      "Loss: 154.799, Residuals: -0.003\n",
      "Loss: 154.797, Residuals: -0.003\n",
      "Loss: 154.797, Residuals: -0.003\n",
      "Loss: 154.796, Residuals: -0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 154.793, Residuals: -0.003\n",
      "Loss: 154.793, Residuals: -0.003\n",
      "Loss: 154.793, Residuals: -0.003\n",
      "Evidence 460.251\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.36e-01\n",
      "Loss: 155.665, Residuals: -0.001\n",
      "Loss: 155.656, Residuals: -0.002\n",
      "Loss: 155.642, Residuals: -0.002\n",
      "Loss: 155.628, Residuals: -0.001\n",
      "Loss: 155.626, Residuals: -0.001\n",
      "Loss: 155.625, Residuals: -0.002\n",
      "Loss: 155.623, Residuals: -0.002\n",
      "Loss: 155.622, Residuals: -0.001\n",
      "Loss: 155.621, Residuals: -0.002\n",
      "Loss: 155.618, Residuals: -0.002\n",
      "Loss: 155.618, Residuals: -0.002\n",
      "Loss: 155.618, Residuals: -0.002\n",
      "Loss: 155.618, Residuals: -0.002\n",
      "Loss: 155.618, Residuals: -0.002\n",
      "Loss: 155.618, Residuals: -0.002\n",
      "Loss: 155.618, Residuals: -0.002\n",
      "Loss: 155.618, Residuals: -0.002\n",
      "Loss: 155.618, Residuals: -0.002\n",
      "Loss: 155.617, Residuals: -0.002\n",
      "Loss: 155.617, Residuals: -0.002\n",
      "Evidence 460.833\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.99e-01\n",
      "Loss: 156.061, Residuals: -0.001\n",
      "Loss: 156.057, Residuals: -0.001\n",
      "Loss: 156.050, Residuals: -0.001\n",
      "Loss: 156.045, Residuals: -0.001\n",
      "Loss: 156.044, Residuals: -0.001\n",
      "Loss: 156.044, Residuals: -0.001\n",
      "Loss: 156.043, Residuals: -0.001\n",
      "Loss: 156.043, Residuals: -0.001\n",
      "Loss: 156.042, Residuals: -0.001\n",
      "Loss: 156.042, Residuals: -0.001\n",
      "Loss: 156.041, Residuals: -0.001\n",
      "Loss: 156.041, Residuals: -0.001\n",
      "Loss: 156.041, Residuals: -0.001\n",
      "Loss: 156.040, Residuals: -0.001\n",
      "Evidence 461.200\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 11.731, Residuals: -0.143\n",
      "Loss: 6.923, Residuals: -0.071\n",
      "Loss: 4.918, Residuals: -0.061\n",
      "Loss: 4.221, Residuals: -0.032\n",
      "Loss: 4.039, Residuals: -0.037\n",
      "Loss: 3.978, Residuals: -0.037\n",
      "Loss: 3.861, Residuals: -0.039\n",
      "Loss: 3.654, Residuals: -0.043\n",
      "Loss: 3.570, Residuals: 0.017\n",
      "Loss: 3.427, Residuals: 0.004\n",
      "Loss: 3.349, Residuals: 0.003\n",
      "Loss: 3.235, Residuals: -0.020\n",
      "Loss: 3.224, Residuals: -0.003\n",
      "Loss: 3.137, Residuals: -0.021\n",
      "Loss: 3.125, Residuals: 0.004\n",
      "Loss: 2.791, Residuals: -0.030\n",
      "Loss: 2.753, Residuals: -0.032\n",
      "Loss: 2.693, Residuals: -0.027\n",
      "Loss: 2.651, Residuals: -0.011\n",
      "Loss: 2.632, Residuals: -0.024\n",
      "Loss: 2.606, Residuals: -0.020\n",
      "Loss: 2.575, Residuals: -0.019\n",
      "Loss: 2.573, Residuals: -0.019\n",
      "Loss: 2.569, Residuals: -0.019\n",
      "Loss: 2.561, Residuals: -0.020\n",
      "Loss: 2.548, Residuals: -0.024\n",
      "Loss: 2.527, Residuals: -0.031\n",
      "Loss: 2.527, Residuals: -0.031\n",
      "Evidence -391.383\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.20e-02\n",
      "Loss: 11.120, Residuals: -0.015\n",
      "Loss: 11.102, Residuals: -0.014\n",
      "Loss: 11.070, Residuals: -0.015\n",
      "Loss: 11.019, Residuals: -0.017\n",
      "Loss: 10.966, Residuals: -0.023\n",
      "Loss: 10.963, Residuals: -0.021\n",
      "Loss: 10.935, Residuals: -0.020\n",
      "Loss: 10.889, Residuals: -0.018\n",
      "Loss: 10.842, Residuals: -0.011\n",
      "Loss: 10.839, Residuals: -0.009\n",
      "Loss: 10.833, Residuals: -0.009\n",
      "Loss: 10.823, Residuals: -0.010\n",
      "Loss: 10.806, Residuals: -0.008\n",
      "Loss: 10.805, Residuals: -0.008\n",
      "Loss: 10.795, Residuals: -0.006\n",
      "Loss: 10.794, Residuals: -0.007\n",
      "Loss: 10.787, Residuals: -0.005\n",
      "Loss: 10.785, Residuals: -0.005\n",
      "Loss: 10.782, Residuals: -0.004\n",
      "Loss: 10.778, Residuals: -0.003\n",
      "Loss: 10.777, Residuals: -0.003\n",
      "Loss: 10.777, Residuals: -0.003\n",
      "Loss: 10.775, Residuals: -0.003\n",
      "Loss: 10.771, Residuals: -0.003\n",
      "Loss: 10.770, Residuals: -0.003\n",
      "Loss: 10.769, Residuals: -0.003\n",
      "Loss: 10.765, Residuals: -0.002\n",
      "Loss: 10.765, Residuals: -0.002\n",
      "Loss: 10.765, Residuals: -0.002\n",
      "Loss: 10.765, Residuals: -0.003\n",
      "Loss: 10.764, Residuals: -0.002\n",
      "Loss: 10.764, Residuals: -0.002\n",
      "Loss: 10.763, Residuals: -0.002\n",
      "Loss: 10.763, Residuals: -0.002\n",
      "Loss: 10.763, Residuals: -0.002\n",
      "Loss: 10.763, Residuals: -0.002\n",
      "Loss: 10.763, Residuals: -0.002\n",
      "Loss: 10.763, Residuals: -0.002\n",
      "Loss: 10.762, Residuals: -0.002\n",
      "Loss: 10.762, Residuals: -0.002\n",
      "Loss: 10.762, Residuals: -0.002\n",
      "Loss: 10.762, Residuals: -0.002\n",
      "Loss: 10.762, Residuals: -0.002\n",
      "Loss: 10.762, Residuals: -0.002\n",
      "Loss: 10.761, Residuals: -0.002\n",
      "Loss: 10.761, Residuals: -0.002\n",
      "Loss: 10.761, Residuals: -0.002\n",
      "Loss: 10.761, Residuals: -0.002\n",
      "Loss: 10.761, Residuals: -0.002\n",
      "Loss: 10.761, Residuals: -0.002\n",
      "Loss: 10.761, Residuals: -0.002\n",
      "Loss: 10.760, Residuals: -0.002\n",
      "Loss: 10.760, Residuals: -0.002\n",
      "Loss: 10.760, Residuals: -0.002\n",
      "Loss: 10.760, Residuals: -0.002\n",
      "Loss: 10.760, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.759, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.002\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Loss: 10.758, Residuals: -0.001\n",
      "Evidence 100.751\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.89e-02\n",
      "Loss: 39.363, Residuals: 0.000\n",
      "Loss: 39.312, Residuals: -0.001\n",
      "Loss: 39.215, Residuals: 0.001\n",
      "Loss: 39.066, Residuals: 0.004\n",
      "Loss: 39.051, Residuals: 0.009\n",
      "Loss: 39.022, Residuals: 0.010\n",
      "Loss: 38.974, Residuals: 0.011\n",
      "Loss: 38.950, Residuals: 0.009\n",
      "Loss: 38.914, Residuals: 0.011\n",
      "Loss: 38.911, Residuals: 0.012\n",
      "Loss: 38.904, Residuals: 0.013\n",
      "Loss: 38.892, Residuals: 0.013\n",
      "Loss: 38.888, Residuals: 0.013\n",
      "Loss: 38.882, Residuals: 0.013\n",
      "Loss: 38.871, Residuals: 0.013\n",
      "Loss: 38.871, Residuals: 0.013\n",
      "Loss: 38.870, Residuals: 0.013\n",
      "Loss: 38.868, Residuals: 0.013\n",
      "Loss: 38.866, Residuals: 0.013\n",
      "Loss: 38.865, Residuals: 0.013\n",
      "Loss: 38.864, Residuals: 0.013\n",
      "Loss: 38.863, Residuals: 0.013\n",
      "Loss: 38.863, Residuals: 0.013\n",
      "Loss: 38.863, Residuals: 0.013\n",
      "Loss: 38.862, Residuals: 0.013\n",
      "Loss: 38.862, Residuals: 0.013\n",
      "Loss: 38.861, Residuals: 0.014\n",
      "Loss: 38.861, Residuals: 0.014\n",
      "Loss: 38.861, Residuals: 0.014\n",
      "Loss: 38.861, Residuals: 0.014\n",
      "Loss: 38.861, Residuals: 0.014\n",
      "Loss: 38.861, Residuals: 0.014\n",
      "Loss: 38.861, Residuals: 0.014\n",
      "Evidence 307.124\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.92e-01\n",
      "Loss: 87.868, Residuals: 0.006\n",
      "Loss: 87.519, Residuals: 0.009\n",
      "Loss: 87.430, Residuals: 0.006\n",
      "Loss: 87.268, Residuals: 0.007\n",
      "Loss: 87.063, Residuals: 0.011\n",
      "Loss: 87.051, Residuals: 0.010\n",
      "Loss: 87.042, Residuals: 0.011\n",
      "Loss: 86.970, Residuals: 0.011\n",
      "Loss: 86.968, Residuals: 0.012\n",
      "Loss: 86.944, Residuals: 0.012\n",
      "Loss: 86.905, Residuals: 0.013\n",
      "Loss: 86.899, Residuals: 0.012\n",
      "Loss: 86.889, Residuals: 0.012\n",
      "Loss: 86.876, Residuals: 0.013\n",
      "Loss: 86.875, Residuals: 0.013\n",
      "Loss: 86.875, Residuals: 0.013\n",
      "Loss: 86.864, Residuals: 0.013\n",
      "Loss: 86.852, Residuals: 0.013\n",
      "Loss: 86.852, Residuals: 0.013\n",
      "Loss: 86.851, Residuals: 0.013\n",
      "Loss: 86.851, Residuals: 0.013\n",
      "Loss: 86.850, Residuals: 0.013\n",
      "Loss: 86.850, Residuals: 0.013\n",
      "Loss: 86.850, Residuals: 0.013\n",
      "Loss: 86.849, Residuals: 0.013\n",
      "Loss: 86.849, Residuals: 0.013\n",
      "Loss: 86.849, Residuals: 0.013\n",
      "Loss: 86.849, Residuals: 0.013\n",
      "Loss: 86.849, Residuals: 0.013\n",
      "Loss: 86.849, Residuals: 0.013\n",
      "Evidence 416.525\n",
      "Updating hyper-parameters...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 40, Updated regularization: 9.07e-01\n",
      "Loss: 127.236, Residuals: 0.013\n",
      "Loss: 126.931, Residuals: 0.011\n",
      "Loss: 126.517, Residuals: 0.012\n",
      "Loss: 126.090, Residuals: 0.012\n",
      "Loss: 126.085, Residuals: 0.012\n",
      "Loss: 126.042, Residuals: 0.012\n",
      "Loss: 125.977, Residuals: 0.012\n",
      "Loss: 125.864, Residuals: 0.012\n",
      "Loss: 125.851, Residuals: 0.010\n",
      "Loss: 125.739, Residuals: 0.011\n",
      "Loss: 125.650, Residuals: 0.012\n",
      "Loss: 125.639, Residuals: 0.010\n",
      "Loss: 125.623, Residuals: 0.010\n",
      "Loss: 125.608, Residuals: 0.010\n",
      "Loss: 125.583, Residuals: 0.010\n",
      "Loss: 125.569, Residuals: 0.010\n",
      "Loss: 125.557, Residuals: 0.010\n",
      "Loss: 125.536, Residuals: 0.011\n",
      "Loss: 125.526, Residuals: 0.011\n",
      "Loss: 125.506, Residuals: 0.011\n",
      "Loss: 125.489, Residuals: 0.010\n",
      "Loss: 125.459, Residuals: 0.011\n",
      "Loss: 125.435, Residuals: 0.010\n",
      "Loss: 125.426, Residuals: 0.010\n",
      "Loss: 125.361, Residuals: 0.011\n",
      "Loss: 125.330, Residuals: 0.011\n",
      "Loss: 125.306, Residuals: 0.010\n",
      "Loss: 125.266, Residuals: 0.011\n",
      "Loss: 125.256, Residuals: 0.011\n",
      "Loss: 125.243, Residuals: 0.010\n",
      "Loss: 125.222, Residuals: 0.011\n",
      "Loss: 125.218, Residuals: 0.011\n",
      "Loss: 125.211, Residuals: 0.011\n",
      "Loss: 125.199, Residuals: 0.011\n",
      "Loss: 125.185, Residuals: 0.011\n",
      "Loss: 125.182, Residuals: 0.011\n",
      "Loss: 125.181, Residuals: 0.011\n",
      "Loss: 125.180, Residuals: 0.011\n",
      "Loss: 125.178, Residuals: 0.011\n",
      "Loss: 125.178, Residuals: 0.011\n",
      "Loss: 125.177, Residuals: 0.011\n",
      "Loss: 125.177, Residuals: 0.011\n",
      "Loss: 125.176, Residuals: 0.011\n",
      "Loss: 125.176, Residuals: 0.011\n",
      "Loss: 125.176, Residuals: 0.011\n",
      "Loss: 125.176, Residuals: 0.011\n",
      "Loss: 125.176, Residuals: 0.011\n",
      "Loss: 125.176, Residuals: 0.011\n",
      "Evidence 451.280\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.64e+00\n",
      "Loss: 144.209, Residuals: 0.015\n",
      "Loss: 143.875, Residuals: 0.014\n",
      "Loss: 143.394, Residuals: 0.015\n",
      "Loss: 142.789, Residuals: 0.017\n",
      "Loss: 142.730, Residuals: 0.016\n",
      "Loss: 142.630, Residuals: 0.015\n",
      "Loss: 142.522, Residuals: 0.016\n",
      "Loss: 142.519, Residuals: 0.016\n",
      "Loss: 142.516, Residuals: 0.016\n",
      "Loss: 142.492, Residuals: 0.016\n",
      "Loss: 142.478, Residuals: 0.016\n",
      "Loss: 142.478, Residuals: 0.017\n",
      "Loss: 142.477, Residuals: 0.016\n",
      "Loss: 142.476, Residuals: 0.016\n",
      "Loss: 142.476, Residuals: 0.016\n",
      "Loss: 142.476, Residuals: 0.016\n",
      "Evidence 465.551\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.98e+00\n",
      "Loss: 150.940, Residuals: 0.019\n",
      "Loss: 150.803, Residuals: 0.020\n",
      "Loss: 150.596, Residuals: 0.022\n",
      "Loss: 150.349, Residuals: 0.022\n",
      "Loss: 150.328, Residuals: 0.020\n",
      "Loss: 150.324, Residuals: 0.021\n",
      "Loss: 150.288, Residuals: 0.021\n",
      "Loss: 150.263, Residuals: 0.021\n",
      "Loss: 150.262, Residuals: 0.021\n",
      "Loss: 150.259, Residuals: 0.021\n",
      "Loss: 150.256, Residuals: 0.021\n",
      "Loss: 150.255, Residuals: 0.021\n",
      "Loss: 150.254, Residuals: 0.021\n",
      "Loss: 150.253, Residuals: 0.021\n",
      "Loss: 150.253, Residuals: 0.021\n",
      "Loss: 150.252, Residuals: 0.021\n",
      "Loss: 150.251, Residuals: 0.021\n",
      "Loss: 150.251, Residuals: 0.021\n",
      "Evidence 470.132\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.11e+00\n",
      "Loss: 153.733, Residuals: 0.022\n",
      "Loss: 153.642, Residuals: 0.023\n",
      "Loss: 153.553, Residuals: 0.024\n",
      "Loss: 153.542, Residuals: 0.025\n",
      "Loss: 153.523, Residuals: 0.025\n",
      "Loss: 153.497, Residuals: 0.025\n",
      "Loss: 153.495, Residuals: 0.024\n",
      "Loss: 153.491, Residuals: 0.024\n",
      "Loss: 153.484, Residuals: 0.024\n",
      "Loss: 153.477, Residuals: 0.024\n",
      "Loss: 153.476, Residuals: 0.024\n",
      "Loss: 153.476, Residuals: 0.024\n",
      "Loss: 153.475, Residuals: 0.024\n",
      "Loss: 153.475, Residuals: 0.024\n",
      "Loss: 153.474, Residuals: 0.024\n",
      "Loss: 153.472, Residuals: 0.024\n",
      "Loss: 153.472, Residuals: 0.024\n",
      "Loss: 153.472, Residuals: 0.024\n",
      "Loss: 153.472, Residuals: 0.024\n",
      "Evidence 471.929\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.17e+00\n",
      "Loss: 154.990, Residuals: 0.025\n",
      "Loss: 154.933, Residuals: 0.027\n",
      "Loss: 154.903, Residuals: 0.026\n",
      "Loss: 154.898, Residuals: 0.026\n",
      "Loss: 154.889, Residuals: 0.026\n",
      "Loss: 154.888, Residuals: 0.026\n",
      "Loss: 154.886, Residuals: 0.026\n",
      "Loss: 154.883, Residuals: 0.026\n",
      "Loss: 154.883, Residuals: 0.026\n",
      "Loss: 154.882, Residuals: 0.026\n",
      "Loss: 154.879, Residuals: 0.026\n",
      "Loss: 154.879, Residuals: 0.026\n",
      "Loss: 154.877, Residuals: 0.026\n",
      "Loss: 154.877, Residuals: 0.026\n",
      "Loss: 154.877, Residuals: 0.026\n",
      "Loss: 154.876, Residuals: 0.026\n",
      "Evidence 472.838\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.19e+00\n",
      "Loss: 155.618, Residuals: 0.026\n",
      "Loss: 155.577, Residuals: 0.027\n",
      "Loss: 155.564, Residuals: 0.026\n",
      "Loss: 155.559, Residuals: 0.027\n",
      "Loss: 155.551, Residuals: 0.027\n",
      "Loss: 155.550, Residuals: 0.026\n",
      "Loss: 155.545, Residuals: 0.026\n",
      "Loss: 155.545, Residuals: 0.026\n",
      "Loss: 155.544, Residuals: 0.026\n",
      "Loss: 155.541, Residuals: 0.026\n",
      "Loss: 155.541, Residuals: 0.026\n",
      "Loss: 155.540, Residuals: 0.026\n",
      "Loss: 155.540, Residuals: 0.026\n",
      "Loss: 155.540, Residuals: 0.026\n",
      "Loss: 155.540, Residuals: 0.026\n",
      "Loss: 155.540, Residuals: 0.026\n",
      "Loss: 155.539, Residuals: 0.026\n",
      "Loss: 155.539, Residuals: 0.026\n",
      "Evidence 473.426\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.18e+00\n",
      "Loss: 155.942, Residuals: 0.027\n",
      "Loss: 155.921, Residuals: 0.027\n",
      "Loss: 155.918, Residuals: 0.026\n",
      "Loss: 155.914, Residuals: 0.026\n",
      "Loss: 155.908, Residuals: 0.027\n",
      "Loss: 155.908, Residuals: 0.027\n",
      "Loss: 155.904, Residuals: 0.027\n",
      "Loss: 155.904, Residuals: 0.027\n",
      "Loss: 155.902, Residuals: 0.026\n",
      "Loss: 155.902, Residuals: 0.026\n",
      "Loss: 155.901, Residuals: 0.026\n",
      "Loss: 155.901, Residuals: 0.026\n",
      "Loss: 155.901, Residuals: 0.026\n",
      "Loss: 155.901, Residuals: 0.026\n",
      "Loss: 155.901, Residuals: 0.026\n",
      "Loss: 155.901, Residuals: 0.026\n",
      "Loss: 155.901, Residuals: 0.026\n",
      "Loss: 155.901, Residuals: 0.026\n",
      "Loss: 155.901, Residuals: 0.026\n",
      "Loss: 155.901, Residuals: 0.026\n",
      "Loss: 155.900, Residuals: 0.026\n",
      "Evidence 473.842\n",
      "Pass count  1\n",
      "Total samples: 37, Updated regularization: 1.00e-05\n",
      "Loss: 11.703, Residuals: -0.120\n",
      "Loss: 6.669, Residuals: -0.021\n",
      "Loss: 5.114, Residuals: -0.021\n",
      "Loss: 4.393, Residuals: -0.044\n",
      "Loss: 3.789, Residuals: -0.056\n",
      "Loss: 3.577, Residuals: 0.011\n",
      "Loss: 3.255, Residuals: -0.021\n",
      "Loss: 3.153, Residuals: 0.044\n",
      "Loss: 2.982, Residuals: 0.036\n",
      "Loss: 2.812, Residuals: 0.023\n",
      "Loss: 2.760, Residuals: -0.009\n",
      "Loss: 2.750, Residuals: 0.011\n",
      "Loss: 2.665, Residuals: 0.000\n",
      "Loss: 2.547, Residuals: -0.023\n",
      "Loss: 2.546, Residuals: -0.021\n",
      "Loss: 2.538, Residuals: -0.020\n",
      "Loss: 2.527, Residuals: -0.017\n",
      "Loss: 2.511, Residuals: -0.019\n",
      "Loss: 2.508, Residuals: -0.017\n",
      "Loss: 2.484, Residuals: -0.026\n",
      "Loss: 2.469, Residuals: -0.046\n",
      "Loss: 2.466, Residuals: -0.040\n",
      "Loss: 2.460, Residuals: -0.040\n",
      "Loss: 2.453, Residuals: -0.040\n",
      "Loss: 2.453, Residuals: -0.047\n",
      "Loss: 2.447, Residuals: -0.048\n",
      "Loss: 2.438, Residuals: -0.051\n",
      "Loss: 2.438, Residuals: -0.049\n",
      "Loss: 2.430, Residuals: -0.050\n",
      "Loss: 2.429, Residuals: -0.052\n",
      "Loss: 2.428, Residuals: -0.053\n",
      "Loss: 2.417, Residuals: -0.055\n",
      "Loss: 2.417, Residuals: -0.054\n",
      "Loss: 2.415, Residuals: -0.054\n",
      "Loss: 2.413, Residuals: -0.056\n",
      "Loss: 2.413, Residuals: -0.056\n",
      "Loss: 2.406, Residuals: -0.057\n",
      "Loss: 2.406, Residuals: -0.056\n",
      "Loss: 2.397, Residuals: -0.058\n",
      "Loss: 2.397, Residuals: -0.056\n",
      "Loss: 2.396, Residuals: -0.054\n",
      "Loss: 2.390, Residuals: -0.055\n",
      "Loss: 2.390, Residuals: -0.054\n",
      "Loss: 2.387, Residuals: -0.056\n",
      "Loss: 2.387, Residuals: -0.056\n",
      "Loss: 2.381, Residuals: -0.057\n",
      "Loss: 2.381, Residuals: -0.057\n",
      "Loss: 2.379, Residuals: -0.058\n",
      "Loss: 2.379, Residuals: -0.058\n",
      "Loss: 2.375, Residuals: -0.060\n",
      "Loss: 2.375, Residuals: -0.058\n",
      "Loss: 2.360, Residuals: -0.064\n",
      "Loss: 2.360, Residuals: -0.063\n",
      "Loss: 2.359, Residuals: -0.060\n",
      "Loss: 2.357, Residuals: -0.063\n",
      "Loss: 2.355, Residuals: -0.066\n",
      "Loss: 2.355, Residuals: -0.066\n",
      "Loss: 2.354, Residuals: -0.067\n",
      "Loss: 2.345, Residuals: -0.071\n",
      "Loss: 2.345, Residuals: -0.070\n",
      "Loss: 2.345, Residuals: -0.070\n",
      "Loss: 2.345, Residuals: -0.069\n",
      "Loss: 2.341, Residuals: -0.070\n",
      "Loss: 2.341, Residuals: -0.070\n",
      "Loss: 2.340, Residuals: -0.071\n",
      "Loss: 2.334, Residuals: -0.074\n",
      "Loss: 2.333, Residuals: -0.073\n",
      "Loss: 2.333, Residuals: -0.074\n",
      "Loss: 2.333, Residuals: -0.074\n",
      "Loss: 2.333, Residuals: -0.074\n",
      "Loss: 2.333, Residuals: -0.074\n",
      "Loss: 2.332, Residuals: -0.074\n",
      "Loss: 2.332, Residuals: -0.076\n",
      "Loss: 2.329, Residuals: -0.077\n",
      "Loss: 2.329, Residuals: -0.077\n",
      "Evidence -373.644\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.61e-03\n",
      "Loss: 9.819, Residuals: -0.079\n",
      "Loss: 9.678, Residuals: -0.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.493, Residuals: -0.063\n",
      "Loss: 9.490, Residuals: -0.065\n",
      "Loss: 9.484, Residuals: -0.063\n",
      "Loss: 9.475, Residuals: -0.059\n",
      "Loss: 9.395, Residuals: -0.054\n",
      "Loss: 9.334, Residuals: -0.040\n",
      "Loss: 9.330, Residuals: -0.043\n",
      "Loss: 9.322, Residuals: -0.042\n",
      "Loss: 9.310, Residuals: -0.043\n",
      "Loss: 9.296, Residuals: -0.044\n",
      "Loss: 9.296, Residuals: -0.045\n",
      "Loss: 9.254, Residuals: -0.040\n",
      "Loss: 9.250, Residuals: -0.042\n",
      "Loss: 9.249, Residuals: -0.042\n",
      "Loss: 9.249, Residuals: -0.041\n",
      "Loss: 9.248, Residuals: -0.041\n",
      "Loss: 9.225, Residuals: -0.037\n",
      "Loss: 9.224, Residuals: -0.038\n",
      "Loss: 9.223, Residuals: -0.038\n",
      "Loss: 9.223, Residuals: -0.038\n",
      "Loss: 9.223, Residuals: -0.037\n",
      "Loss: 9.220, Residuals: -0.037\n",
      "Loss: 9.217, Residuals: -0.035\n",
      "Loss: 9.217, Residuals: -0.035\n",
      "Evidence 80.781\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.61e-02\n",
      "Loss: 34.487, Residuals: -0.037\n",
      "Loss: 34.376, Residuals: -0.036\n",
      "Loss: 34.195, Residuals: -0.035\n",
      "Loss: 33.988, Residuals: -0.030\n",
      "Loss: 33.987, Residuals: -0.031\n",
      "Loss: 33.985, Residuals: -0.031\n",
      "Loss: 33.980, Residuals: -0.030\n",
      "Loss: 33.972, Residuals: -0.030\n",
      "Loss: 33.893, Residuals: -0.029\n",
      "Loss: 33.744, Residuals: -0.026\n",
      "Loss: 33.743, Residuals: -0.027\n",
      "Loss: 33.620, Residuals: -0.024\n",
      "Loss: 33.405, Residuals: -0.019\n",
      "Loss: 33.404, Residuals: -0.019\n",
      "Loss: 33.304, Residuals: -0.017\n",
      "Loss: 33.303, Residuals: -0.017\n",
      "Loss: 33.295, Residuals: -0.016\n",
      "Loss: 33.295, Residuals: -0.016\n",
      "Evidence 272.809\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 7.27e-02\n",
      "Loss: 80.093, Residuals: -0.018\n",
      "Loss: 79.768, Residuals: -0.017\n",
      "Loss: 79.360, Residuals: -0.018\n",
      "Loss: 79.358, Residuals: -0.019\n",
      "Loss: 78.953, Residuals: -0.017\n",
      "Loss: 78.933, Residuals: -0.015\n",
      "Loss: 78.155, Residuals: -0.012\n",
      "Loss: 78.142, Residuals: -0.011\n",
      "Loss: 78.134, Residuals: -0.013\n",
      "Loss: 76.939, Residuals: -0.008\n",
      "Loss: 76.912, Residuals: -0.006\n",
      "Loss: 76.861, Residuals: -0.006\n",
      "Loss: 76.768, Residuals: -0.007\n",
      "Loss: 76.619, Residuals: -0.007\n",
      "Loss: 76.415, Residuals: -0.010\n",
      "Loss: 76.073, Residuals: -0.008\n",
      "Loss: 76.045, Residuals: -0.006\n",
      "Loss: 75.777, Residuals: -0.004\n",
      "Loss: 75.368, Residuals: -0.002\n",
      "Loss: 75.339, Residuals: 0.001\n",
      "Loss: 75.294, Residuals: -0.001\n",
      "Loss: 74.954, Residuals: 0.002\n",
      "Loss: 74.942, Residuals: 0.001\n",
      "Loss: 74.923, Residuals: 0.000\n",
      "Loss: 74.901, Residuals: 0.001\n",
      "Loss: 74.858, Residuals: 0.001\n",
      "Loss: 74.780, Residuals: 0.003\n",
      "Loss: 74.777, Residuals: 0.003\n",
      "Loss: 74.747, Residuals: 0.003\n",
      "Loss: 74.693, Residuals: 0.004\n",
      "Loss: 74.690, Residuals: 0.005\n",
      "Loss: 74.658, Residuals: 0.005\n",
      "Loss: 74.654, Residuals: 0.004\n",
      "Loss: 74.646, Residuals: 0.004\n",
      "Loss: 74.632, Residuals: 0.005\n",
      "Loss: 74.632, Residuals: 0.005\n",
      "Loss: 74.616, Residuals: 0.005\n",
      "Loss: 74.616, Residuals: 0.006\n",
      "Loss: 74.614, Residuals: 0.006\n",
      "Loss: 74.563, Residuals: 0.006\n",
      "Loss: 74.563, Residuals: 0.006\n",
      "Loss: 74.562, Residuals: 0.006\n",
      "Loss: 74.562, Residuals: 0.005\n",
      "Loss: 74.560, Residuals: 0.005\n",
      "Loss: 74.558, Residuals: 0.006\n",
      "Loss: 74.556, Residuals: 0.006\n",
      "Loss: 74.556, Residuals: 0.006\n",
      "Loss: 74.544, Residuals: 0.006\n",
      "Loss: 74.544, Residuals: 0.006\n",
      "Loss: 74.541, Residuals: 0.006\n",
      "Loss: 74.541, Residuals: 0.006\n",
      "Loss: 74.536, Residuals: 0.006\n",
      "Loss: 74.533, Residuals: 0.006\n",
      "Loss: 74.533, Residuals: 0.006\n",
      "Loss: 74.532, Residuals: 0.006\n",
      "Loss: 74.532, Residuals: 0.006\n",
      "Loss: 74.532, Residuals: 0.006\n",
      "Loss: 74.526, Residuals: 0.006\n",
      "Loss: 74.526, Residuals: 0.006\n",
      "Evidence 380.652\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.85e-01\n",
      "Loss: 114.500, Residuals: 0.009\n",
      "Loss: 113.983, Residuals: 0.008\n",
      "Loss: 113.826, Residuals: 0.003\n",
      "Loss: 113.752, Residuals: 0.007\n",
      "Loss: 113.625, Residuals: 0.006\n",
      "Loss: 113.476, Residuals: 0.006\n",
      "Loss: 113.464, Residuals: 0.006\n",
      "Loss: 113.454, Residuals: 0.005\n",
      "Loss: 113.437, Residuals: 0.006\n",
      "Loss: 113.417, Residuals: 0.006\n",
      "Loss: 113.415, Residuals: 0.006\n",
      "Loss: 113.414, Residuals: 0.006\n",
      "Loss: 113.412, Residuals: 0.006\n",
      "Loss: 113.408, Residuals: 0.006\n",
      "Loss: 113.408, Residuals: 0.006\n",
      "Loss: 113.403, Residuals: 0.006\n",
      "Loss: 113.403, Residuals: 0.006\n",
      "Loss: 113.402, Residuals: 0.006\n",
      "Loss: 112.647, Residuals: 0.007\n",
      "Loss: 112.480, Residuals: 0.007\n",
      "Loss: 112.304, Residuals: 0.011\n",
      "Loss: 112.260, Residuals: 0.009\n",
      "Loss: 112.193, Residuals: 0.009\n",
      "Loss: 112.107, Residuals: 0.010\n",
      "Loss: 112.097, Residuals: 0.011\n",
      "Loss: 112.078, Residuals: 0.010\n",
      "Loss: 112.045, Residuals: 0.010\n",
      "Loss: 112.040, Residuals: 0.010\n",
      "Loss: 112.030, Residuals: 0.010\n",
      "Loss: 112.011, Residuals: 0.010\n",
      "Loss: 112.011, Residuals: 0.010\n",
      "Loss: 112.003, Residuals: 0.010\n",
      "Loss: 111.989, Residuals: 0.010\n",
      "Loss: 111.988, Residuals: 0.010\n",
      "Loss: 111.979, Residuals: 0.010\n",
      "Loss: 111.977, Residuals: 0.010\n",
      "Loss: 111.972, Residuals: 0.010\n",
      "Loss: 111.970, Residuals: 0.010\n",
      "Loss: 111.969, Residuals: 0.010\n",
      "Loss: 111.967, Residuals: 0.010\n",
      "Loss: 111.967, Residuals: 0.011\n",
      "Loss: 111.965, Residuals: 0.010\n",
      "Loss: 111.961, Residuals: 0.010\n",
      "Loss: 111.961, Residuals: 0.011\n",
      "Evidence 425.442\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 5.49e-01\n",
      "Loss: 133.836, Residuals: 0.011\n",
      "Loss: 133.639, Residuals: 0.009\n",
      "Loss: 133.612, Residuals: 0.010\n",
      "Loss: 133.603, Residuals: 0.010\n",
      "Loss: 133.588, Residuals: 0.010\n",
      "Loss: 133.565, Residuals: 0.009\n",
      "Loss: 133.562, Residuals: 0.009\n",
      "Loss: 133.533, Residuals: 0.009\n",
      "Loss: 133.498, Residuals: 0.009\n",
      "Loss: 133.498, Residuals: 0.009\n",
      "Evidence 437.397\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 5.70e-01\n",
      "Loss: 141.874, Residuals: 0.012\n",
      "Loss: 141.856, Residuals: 0.009\n",
      "Loss: 141.826, Residuals: 0.009\n",
      "Loss: 141.811, Residuals: 0.008\n",
      "Loss: 141.806, Residuals: 0.008\n",
      "Loss: 141.798, Residuals: 0.008\n",
      "Loss: 141.784, Residuals: 0.008\n",
      "Loss: 141.783, Residuals: 0.009\n",
      "Loss: 141.773, Residuals: 0.009\n",
      "Loss: 141.773, Residuals: 0.009\n",
      "Loss: 141.770, Residuals: 0.009\n",
      "Loss: 141.765, Residuals: 0.009\n",
      "Loss: 141.765, Residuals: 0.009\n",
      "Loss: 141.764, Residuals: 0.009\n",
      "Loss: 141.764, Residuals: 0.009\n",
      "Loss: 141.763, Residuals: 0.009\n",
      "Loss: 141.762, Residuals: 0.009\n",
      "Loss: 141.762, Residuals: 0.009\n",
      "Evidence 440.405\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 5.49e-01\n",
      "Loss: 144.771, Residuals: 0.010\n",
      "Loss: 144.764, Residuals: 0.009\n",
      "Loss: 144.756, Residuals: 0.008\n",
      "Loss: 144.755, Residuals: 0.009\n",
      "Loss: 144.754, Residuals: 0.008\n",
      "Loss: 144.748, Residuals: 0.008\n",
      "Loss: 144.738, Residuals: 0.008\n",
      "Loss: 144.738, Residuals: 0.008\n",
      "Loss: 144.737, Residuals: 0.009\n",
      "Loss: 144.737, Residuals: 0.008\n",
      "Loss: 144.737, Residuals: 0.009\n",
      "Loss: 144.733, Residuals: 0.009\n",
      "Loss: 144.729, Residuals: 0.009\n",
      "Loss: 144.728, Residuals: 0.009\n",
      "Loss: 144.728, Residuals: 0.009\n",
      "Loss: 144.728, Residuals: 0.009\n",
      "Loss: 144.727, Residuals: 0.009\n",
      "Loss: 144.727, Residuals: 0.009\n",
      "Loss: 144.727, Residuals: 0.009\n",
      "Loss: 144.727, Residuals: 0.009\n",
      "Loss: 144.727, Residuals: 0.009\n",
      "Loss: 144.727, Residuals: 0.009\n",
      "Evidence 441.520\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 5.22e-01\n",
      "Loss: 145.867, Residuals: 0.009\n",
      "Loss: 145.863, Residuals: 0.008\n",
      "Loss: 145.860, Residuals: 0.008\n",
      "Loss: 145.854, Residuals: 0.008\n",
      "Loss: 145.846, Residuals: 0.008\n",
      "Loss: 145.846, Residuals: 0.008\n",
      "Loss: 145.845, Residuals: 0.008\n",
      "Loss: 145.845, Residuals: 0.009\n",
      "Loss: 145.845, Residuals: 0.008\n",
      "Loss: 145.844, Residuals: 0.008\n",
      "Loss: 145.844, Residuals: 0.009\n",
      "Loss: 145.844, Residuals: 0.009\n",
      "Evidence 442.106\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 5.04e-01\n",
      "Loss: 146.344, Residuals: 0.009\n",
      "Loss: 146.341, Residuals: 0.008\n",
      "Loss: 146.339, Residuals: 0.008\n",
      "Loss: 146.338, Residuals: 0.008\n",
      "Loss: 146.336, Residuals: 0.008\n",
      "Loss: 146.331, Residuals: 0.008\n",
      "Loss: 146.331, Residuals: 0.008\n",
      "Loss: 146.328, Residuals: 0.008\n",
      "Loss: 146.328, Residuals: 0.008\n",
      "Evidence 442.466\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.156, Residuals: -0.143\n",
      "Loss: 7.204, Residuals: -0.065\n",
      "Loss: 5.357, Residuals: -0.061\n",
      "Loss: 4.865, Residuals: -0.065\n",
      "Loss: 4.246, Residuals: -0.066\n",
      "Loss: 4.100, Residuals: -0.009\n",
      "Loss: 3.871, Residuals: -0.038\n",
      "Loss: 3.555, Residuals: -0.039\n",
      "Loss: 3.487, Residuals: -0.014\n",
      "Loss: 3.373, Residuals: -0.027\n",
      "Loss: 3.342, Residuals: -0.006\n",
      "Loss: 3.098, Residuals: -0.023\n",
      "Loss: 2.972, Residuals: 0.031\n",
      "Loss: 2.908, Residuals: 0.054\n",
      "Loss: 2.876, Residuals: 0.019\n",
      "Loss: 2.822, Residuals: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.745, Residuals: -0.002\n",
      "Loss: 2.733, Residuals: -0.013\n",
      "Loss: 2.726, Residuals: 0.001\n",
      "Loss: 2.722, Residuals: -0.009\n",
      "Loss: 2.714, Residuals: -0.010\n",
      "Loss: 2.700, Residuals: -0.013\n",
      "Loss: 2.677, Residuals: -0.018\n",
      "Loss: 2.672, Residuals: -0.023\n",
      "Loss: 2.666, Residuals: -0.019\n",
      "Loss: 2.657, Residuals: -0.022\n",
      "Loss: 2.655, Residuals: -0.030\n",
      "Loss: 2.641, Residuals: -0.033\n",
      "Loss: 2.629, Residuals: -0.042\n",
      "Loss: 2.629, Residuals: -0.043\n",
      "Loss: 2.627, Residuals: -0.043\n",
      "Loss: 2.625, Residuals: -0.042\n",
      "Loss: 2.601, Residuals: -0.046\n",
      "Loss: 2.599, Residuals: -0.044\n",
      "Loss: 2.532, Residuals: -0.049\n",
      "Loss: 2.530, Residuals: -0.052\n",
      "Loss: 2.509, Residuals: -0.051\n",
      "Loss: 2.502, Residuals: -0.045\n",
      "Loss: 2.490, Residuals: -0.048\n",
      "Loss: 2.476, Residuals: -0.053\n",
      "Loss: 2.475, Residuals: -0.049\n",
      "Loss: 2.463, Residuals: -0.052\n",
      "Loss: 2.448, Residuals: -0.057\n",
      "Loss: 2.448, Residuals: -0.053\n",
      "Loss: 2.447, Residuals: -0.054\n",
      "Loss: 2.446, Residuals: -0.055\n",
      "Loss: 2.444, Residuals: -0.058\n",
      "Loss: 2.440, Residuals: -0.059\n",
      "Loss: 2.439, Residuals: -0.063\n",
      "Loss: 2.438, Residuals: -0.060\n",
      "Loss: 2.438, Residuals: -0.064\n",
      "Loss: 2.436, Residuals: -0.064\n",
      "Loss: 2.432, Residuals: -0.066\n",
      "Loss: 2.431, Residuals: -0.068\n",
      "Loss: 2.431, Residuals: -0.068\n",
      "Loss: 2.428, Residuals: -0.069\n",
      "Loss: 2.427, Residuals: -0.071\n",
      "Loss: 2.425, Residuals: -0.071\n",
      "Loss: 2.423, Residuals: -0.075\n",
      "Loss: 2.423, Residuals: -0.074\n",
      "Loss: 2.422, Residuals: -0.076\n",
      "Loss: 2.422, Residuals: -0.074\n",
      "Loss: 2.418, Residuals: -0.075\n",
      "Loss: 2.418, Residuals: -0.074\n",
      "Loss: 2.417, Residuals: -0.074\n",
      "Loss: 2.416, Residuals: -0.075\n",
      "Loss: 2.416, Residuals: -0.074\n",
      "Loss: 2.413, Residuals: -0.075\n",
      "Loss: 2.413, Residuals: -0.075\n",
      "Loss: 2.412, Residuals: -0.075\n",
      "Loss: 2.410, Residuals: -0.075\n",
      "Loss: 2.410, Residuals: -0.074\n",
      "Loss: 2.409, Residuals: -0.074\n",
      "Loss: 2.409, Residuals: -0.074\n",
      "Loss: 2.408, Residuals: -0.075\n",
      "Loss: 2.408, Residuals: -0.075\n",
      "Loss: 2.407, Residuals: -0.075\n",
      "Loss: 2.404, Residuals: -0.075\n",
      "Loss: 2.404, Residuals: -0.074\n",
      "Loss: 2.404, Residuals: -0.074\n",
      "Loss: 2.403, Residuals: -0.075\n",
      "Loss: 2.403, Residuals: -0.075\n",
      "Loss: 2.401, Residuals: -0.075\n",
      "Loss: 2.400, Residuals: -0.075\n",
      "Loss: 2.400, Residuals: -0.074\n",
      "Loss: 2.400, Residuals: -0.074\n",
      "Loss: 2.398, Residuals: -0.074\n",
      "Loss: 2.398, Residuals: -0.074\n",
      "Loss: 2.398, Residuals: -0.074\n",
      "Loss: 2.396, Residuals: -0.074\n",
      "Loss: 2.396, Residuals: -0.076\n",
      "Loss: 2.396, Residuals: -0.075\n",
      "Loss: 2.396, Residuals: -0.074\n",
      "Loss: 2.395, Residuals: -0.074\n",
      "Loss: 2.395, Residuals: -0.075\n",
      "Loss: 2.394, Residuals: -0.075\n",
      "Loss: 2.394, Residuals: -0.075\n",
      "Loss: 2.392, Residuals: -0.075\n",
      "Loss: 2.392, Residuals: -0.075\n",
      "Loss: 2.391, Residuals: -0.075\n",
      "Loss: 2.391, Residuals: -0.075\n",
      "Loss: 2.391, Residuals: -0.074\n",
      "Loss: 2.391, Residuals: -0.074\n",
      "Loss: 2.391, Residuals: -0.074\n",
      "Loss: 2.390, Residuals: -0.074\n",
      "Loss: 2.390, Residuals: -0.074\n",
      "Loss: 2.390, Residuals: -0.074\n",
      "Loss: 2.390, Residuals: -0.074\n",
      "Loss: 2.390, Residuals: -0.074\n",
      "Loss: 2.389, Residuals: -0.074\n",
      "Loss: 2.389, Residuals: -0.074\n",
      "Loss: 2.388, Residuals: -0.074\n",
      "Evidence -379.584\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.60e-04\n",
      "Loss: 11.903, Residuals: -0.024\n",
      "Loss: 11.884, Residuals: -0.027\n",
      "Loss: 11.754, Residuals: -0.038\n",
      "Loss: 11.618, Residuals: -0.043\n",
      "Loss: 11.612, Residuals: -0.040\n",
      "Loss: 11.601, Residuals: -0.042\n",
      "Loss: 11.583, Residuals: -0.042\n",
      "Loss: 11.574, Residuals: -0.046\n",
      "Loss: 11.295, Residuals: -0.032\n",
      "Loss: 11.288, Residuals: -0.031\n",
      "Loss: 11.276, Residuals: -0.027\n",
      "Loss: 11.256, Residuals: -0.024\n",
      "Loss: 11.255, Residuals: -0.024\n",
      "Loss: 11.243, Residuals: -0.022\n",
      "Loss: 11.223, Residuals: -0.018\n",
      "Loss: 11.198, Residuals: -0.010\n",
      "Loss: 11.196, Residuals: -0.012\n",
      "Loss: 11.194, Residuals: -0.011\n",
      "Loss: 11.178, Residuals: -0.011\n",
      "Loss: 11.177, Residuals: -0.010\n",
      "Loss: 11.163, Residuals: -0.010\n",
      "Loss: 11.163, Residuals: -0.011\n",
      "Loss: 11.162, Residuals: -0.011\n",
      "Loss: 11.159, Residuals: -0.011\n",
      "Loss: 11.159, Residuals: -0.011\n",
      "Loss: 11.149, Residuals: -0.011\n",
      "Loss: 11.149, Residuals: -0.011\n",
      "Loss: 11.149, Residuals: -0.010\n",
      "Loss: 11.142, Residuals: -0.010\n",
      "Loss: 11.141, Residuals: -0.010\n",
      "Loss: 11.140, Residuals: -0.010\n",
      "Loss: 11.140, Residuals: -0.010\n",
      "Loss: 11.136, Residuals: -0.010\n",
      "Loss: 11.130, Residuals: -0.009\n",
      "Loss: 11.130, Residuals: -0.009\n",
      "Loss: 11.129, Residuals: -0.009\n",
      "Loss: 11.129, Residuals: -0.009\n",
      "Loss: 11.129, Residuals: -0.009\n",
      "Loss: 11.128, Residuals: -0.009\n",
      "Loss: 11.128, Residuals: -0.009\n",
      "Loss: 11.128, Residuals: -0.009\n",
      "Loss: 11.128, Residuals: -0.009\n",
      "Loss: 11.124, Residuals: -0.009\n",
      "Loss: 11.124, Residuals: -0.009\n",
      "Loss: 11.120, Residuals: -0.009\n",
      "Loss: 11.120, Residuals: -0.009\n",
      "Loss: 11.119, Residuals: -0.009\n",
      "Loss: 11.119, Residuals: -0.009\n",
      "Loss: 11.116, Residuals: -0.009\n",
      "Loss: 11.116, Residuals: -0.009\n",
      "Loss: 11.115, Residuals: -0.009\n",
      "Loss: 11.115, Residuals: -0.009\n",
      "Loss: 11.115, Residuals: -0.009\n",
      "Evidence 94.399\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.71e-03\n",
      "Loss: 42.054, Residuals: -0.006\n",
      "Loss: 41.926, Residuals: -0.009\n",
      "Loss: 41.900, Residuals: -0.009\n",
      "Loss: 41.893, Residuals: -0.010\n",
      "Loss: 41.680, Residuals: -0.007\n",
      "Loss: 41.672, Residuals: -0.006\n",
      "Loss: 41.602, Residuals: -0.004\n",
      "Loss: 41.595, Residuals: -0.002\n",
      "Loss: 41.530, Residuals: -0.001\n",
      "Loss: 41.528, Residuals: -0.002\n",
      "Loss: 41.505, Residuals: -0.001\n",
      "Loss: 41.465, Residuals: 0.000\n",
      "Loss: 41.463, Residuals: 0.000\n",
      "Loss: 41.416, Residuals: 0.002\n",
      "Loss: 41.412, Residuals: 0.001\n",
      "Loss: 41.374, Residuals: 0.001\n",
      "Loss: 41.373, Residuals: 0.001\n",
      "Loss: 41.365, Residuals: 0.001\n",
      "Loss: 41.361, Residuals: 0.003\n",
      "Loss: 41.361, Residuals: 0.003\n",
      "Loss: 41.341, Residuals: 0.002\n",
      "Loss: 41.341, Residuals: 0.002\n",
      "Evidence 301.123\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.84e-02\n",
      "Loss: 93.335, Residuals: -0.005\n",
      "Loss: 93.104, Residuals: -0.005\n",
      "Loss: 93.015, Residuals: -0.008\n",
      "Loss: 92.982, Residuals: -0.009\n",
      "Loss: 92.954, Residuals: -0.007\n",
      "Loss: 92.712, Residuals: -0.007\n",
      "Loss: 92.364, Residuals: -0.006\n",
      "Loss: 92.337, Residuals: -0.008\n",
      "Loss: 92.310, Residuals: -0.009\n",
      "Loss: 92.302, Residuals: -0.010\n",
      "Loss: 92.001, Residuals: -0.010\n",
      "Loss: 92.000, Residuals: -0.010\n",
      "Loss: 91.866, Residuals: -0.009\n",
      "Loss: 91.619, Residuals: -0.009\n",
      "Loss: 91.548, Residuals: -0.009\n",
      "Loss: 91.425, Residuals: -0.008\n",
      "Loss: 91.402, Residuals: -0.012\n",
      "Loss: 90.701, Residuals: -0.001\n",
      "Loss: 90.557, Residuals: -0.012\n",
      "Loss: 90.458, Residuals: -0.004\n",
      "Loss: 90.271, Residuals: -0.005\n",
      "Loss: 90.150, Residuals: -0.010\n",
      "Loss: 90.084, Residuals: -0.008\n",
      "Loss: 90.036, Residuals: -0.007\n",
      "Loss: 89.599, Residuals: -0.006\n",
      "Loss: 89.583, Residuals: -0.007\n",
      "Loss: 88.999, Residuals: -0.005\n",
      "Loss: 88.995, Residuals: -0.004\n",
      "Loss: 88.962, Residuals: -0.005\n",
      "Loss: 88.899, Residuals: -0.005\n",
      "Loss: 88.882, Residuals: -0.005\n",
      "Loss: 88.728, Residuals: -0.007\n",
      "Loss: 88.721, Residuals: -0.005\n",
      "Loss: 88.439, Residuals: -0.004\n",
      "Loss: 88.384, Residuals: -0.004\n",
      "Loss: 88.292, Residuals: -0.005\n",
      "Loss: 88.223, Residuals: -0.006\n",
      "Loss: 88.104, Residuals: -0.005\n",
      "Loss: 88.095, Residuals: -0.004\n",
      "Loss: 87.794, Residuals: -0.004\n",
      "Loss: 87.788, Residuals: -0.003\n",
      "Loss: 87.730, Residuals: -0.003\n",
      "Loss: 87.627, Residuals: -0.003\n",
      "Loss: 87.626, Residuals: -0.004\n",
      "Loss: 87.455, Residuals: -0.003\n",
      "Loss: 87.454, Residuals: -0.003\n",
      "Loss: 87.453, Residuals: -0.003\n",
      "Loss: 87.394, Residuals: -0.003\n",
      "Loss: 87.390, Residuals: -0.003\n",
      "Loss: 87.389, Residuals: -0.003\n",
      "Loss: 87.387, Residuals: -0.003\n",
      "Loss: 87.384, Residuals: -0.003\n",
      "Loss: 87.358, Residuals: -0.003\n",
      "Loss: 87.358, Residuals: -0.003\n",
      "Loss: 87.332, Residuals: -0.003\n",
      "Loss: 87.323, Residuals: -0.003\n",
      "Loss: 87.323, Residuals: -0.003\n",
      "Loss: 87.322, Residuals: -0.003\n",
      "Loss: 87.321, Residuals: -0.003\n",
      "Loss: 87.320, Residuals: -0.003\n",
      "Loss: 87.308, Residuals: -0.003\n",
      "Loss: 87.308, Residuals: -0.003\n",
      "Loss: 87.285, Residuals: -0.003\n",
      "Loss: 87.285, Residuals: -0.002\n",
      "Loss: 87.285, Residuals: -0.002\n",
      "Loss: 87.284, Residuals: -0.002\n",
      "Loss: 87.284, Residuals: -0.002\n",
      "Loss: 87.272, Residuals: -0.002\n",
      "Loss: 87.272, Residuals: -0.002\n",
      "Loss: 87.272, Residuals: -0.002\n",
      "Loss: 87.270, Residuals: -0.002\n",
      "Loss: 87.269, Residuals: -0.002\n",
      "Loss: 87.269, Residuals: -0.002\n",
      "Evidence 401.997\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.09e-01\n",
      "Loss: 128.986, Residuals: -0.010\n",
      "Loss: 128.807, Residuals: -0.013\n",
      "Loss: 128.485, Residuals: -0.012\n",
      "Loss: 127.980, Residuals: -0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 127.548, Residuals: -0.008\n",
      "Loss: 127.487, Residuals: -0.009\n",
      "Loss: 127.450, Residuals: -0.011\n",
      "Loss: 127.119, Residuals: -0.011\n",
      "Loss: 127.110, Residuals: -0.011\n",
      "Loss: 127.019, Residuals: -0.010\n",
      "Loss: 126.322, Residuals: -0.009\n",
      "Loss: 126.294, Residuals: -0.007\n",
      "Loss: 126.261, Residuals: -0.009\n",
      "Loss: 126.199, Residuals: -0.009\n",
      "Loss: 126.088, Residuals: -0.009\n",
      "Loss: 126.031, Residuals: -0.009\n",
      "Loss: 125.930, Residuals: -0.009\n",
      "Loss: 125.847, Residuals: -0.009\n",
      "Loss: 125.826, Residuals: -0.008\n",
      "Loss: 125.824, Residuals: -0.009\n",
      "Loss: 125.071, Residuals: -0.006\n",
      "Loss: 125.043, Residuals: -0.005\n",
      "Loss: 125.014, Residuals: -0.008\n",
      "Loss: 124.769, Residuals: -0.006\n",
      "Loss: 124.765, Residuals: -0.007\n",
      "Loss: 124.758, Residuals: -0.007\n",
      "Loss: 124.746, Residuals: -0.006\n",
      "Loss: 124.725, Residuals: -0.006\n",
      "Loss: 124.517, Residuals: -0.004\n",
      "Loss: 124.499, Residuals: -0.005\n",
      "Loss: 124.347, Residuals: -0.003\n",
      "Loss: 124.318, Residuals: -0.003\n",
      "Loss: 124.268, Residuals: -0.003\n",
      "Loss: 124.265, Residuals: -0.003\n",
      "Loss: 124.237, Residuals: -0.003\n",
      "Loss: 124.236, Residuals: -0.002\n",
      "Loss: 124.201, Residuals: -0.002\n",
      "Loss: 124.178, Residuals: -0.001\n",
      "Loss: 124.176, Residuals: -0.001\n",
      "Loss: 124.173, Residuals: -0.001\n",
      "Loss: 124.173, Residuals: -0.001\n",
      "Loss: 124.164, Residuals: -0.001\n",
      "Loss: 124.164, Residuals: -0.001\n",
      "Loss: 124.163, Residuals: -0.001\n",
      "Loss: 124.162, Residuals: -0.001\n",
      "Loss: 124.162, Residuals: -0.001\n",
      "Loss: 124.159, Residuals: -0.001\n",
      "Loss: 124.159, Residuals: -0.001\n",
      "Loss: 124.159, Residuals: -0.001\n",
      "Loss: 124.158, Residuals: -0.001\n",
      "Loss: 124.158, Residuals: -0.001\n",
      "Loss: 124.158, Residuals: -0.001\n",
      "Loss: 124.157, Residuals: -0.001\n",
      "Loss: 124.157, Residuals: -0.001\n",
      "Loss: 124.157, Residuals: -0.001\n",
      "Evidence 433.381\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.38e-01\n",
      "Loss: 144.492, Residuals: 0.004\n",
      "Loss: 144.174, Residuals: 0.001\n",
      "Loss: 143.651, Residuals: 0.002\n",
      "Loss: 143.274, Residuals: 0.004\n",
      "Loss: 143.221, Residuals: 0.003\n",
      "Loss: 143.146, Residuals: 0.003\n",
      "Loss: 143.025, Residuals: 0.004\n",
      "Loss: 143.023, Residuals: 0.004\n",
      "Loss: 142.971, Residuals: 0.004\n",
      "Loss: 142.895, Residuals: 0.004\n",
      "Loss: 142.889, Residuals: 0.004\n",
      "Loss: 142.887, Residuals: 0.004\n",
      "Loss: 142.884, Residuals: 0.004\n",
      "Loss: 142.878, Residuals: 0.004\n",
      "Loss: 142.867, Residuals: 0.004\n",
      "Loss: 142.859, Residuals: 0.004\n",
      "Loss: 142.858, Residuals: 0.004\n",
      "Loss: 142.850, Residuals: 0.004\n",
      "Loss: 142.849, Residuals: 0.004\n",
      "Loss: 142.838, Residuals: 0.004\n",
      "Loss: 142.834, Residuals: 0.004\n",
      "Loss: 142.833, Residuals: 0.004\n",
      "Loss: 142.829, Residuals: 0.004\n",
      "Loss: 142.829, Residuals: 0.004\n",
      "Loss: 142.827, Residuals: 0.004\n",
      "Loss: 142.825, Residuals: 0.004\n",
      "Loss: 142.825, Residuals: 0.004\n",
      "Loss: 142.822, Residuals: 0.004\n",
      "Loss: 142.821, Residuals: 0.004\n",
      "Loss: 142.816, Residuals: 0.004\n",
      "Loss: 142.814, Residuals: 0.004\n",
      "Loss: 142.811, Residuals: 0.003\n",
      "Loss: 142.811, Residuals: 0.003\n",
      "Loss: 142.806, Residuals: 0.004\n",
      "Loss: 142.806, Residuals: 0.003\n",
      "Loss: 142.804, Residuals: 0.003\n",
      "Loss: 142.801, Residuals: 0.003\n",
      "Loss: 142.801, Residuals: 0.003\n",
      "Loss: 142.797, Residuals: 0.003\n",
      "Loss: 142.797, Residuals: 0.003\n",
      "Loss: 142.793, Residuals: 0.003\n",
      "Loss: 142.793, Residuals: 0.003\n",
      "Loss: 142.789, Residuals: 0.003\n",
      "Loss: 142.789, Residuals: 0.003\n",
      "Loss: 142.783, Residuals: 0.003\n",
      "Loss: 142.783, Residuals: 0.003\n",
      "Loss: 142.782, Residuals: 0.003\n",
      "Loss: 142.778, Residuals: 0.003\n",
      "Loss: 142.778, Residuals: 0.003\n",
      "Loss: 142.778, Residuals: 0.003\n",
      "Loss: 142.777, Residuals: 0.003\n",
      "Loss: 142.777, Residuals: 0.003\n",
      "Loss: 142.775, Residuals: 0.003\n",
      "Loss: 142.775, Residuals: 0.003\n",
      "Loss: 142.772, Residuals: 0.003\n",
      "Loss: 142.772, Residuals: 0.003\n",
      "Loss: 142.771, Residuals: 0.003\n",
      "Loss: 142.771, Residuals: 0.003\n",
      "Loss: 142.769, Residuals: 0.002\n",
      "Loss: 142.769, Residuals: 0.002\n",
      "Loss: 142.766, Residuals: 0.002\n",
      "Loss: 142.766, Residuals: 0.002\n",
      "Evidence 455.381\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.70e-01\n",
      "Loss: 151.779, Residuals: 0.007\n",
      "Loss: 151.404, Residuals: 0.005\n",
      "Loss: 151.221, Residuals: 0.006\n",
      "Loss: 151.202, Residuals: 0.006\n",
      "Loss: 151.171, Residuals: 0.006\n",
      "Loss: 151.130, Residuals: 0.006\n",
      "Loss: 151.127, Residuals: 0.006\n",
      "Loss: 151.108, Residuals: 0.006\n",
      "Loss: 151.105, Residuals: 0.006\n",
      "Loss: 151.081, Residuals: 0.006\n",
      "Loss: 151.045, Residuals: 0.006\n",
      "Loss: 151.042, Residuals: 0.006\n",
      "Loss: 151.036, Residuals: 0.006\n",
      "Loss: 151.026, Residuals: 0.007\n",
      "Loss: 151.026, Residuals: 0.007\n",
      "Loss: 151.026, Residuals: 0.007\n",
      "Evidence 459.806\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.14e-01\n",
      "Loss: 154.271, Residuals: 0.009\n",
      "Loss: 154.185, Residuals: 0.009\n",
      "Loss: 154.080, Residuals: 0.009\n",
      "Loss: 154.030, Residuals: 0.010\n",
      "Loss: 154.022, Residuals: 0.009\n",
      "Loss: 154.019, Residuals: 0.009\n",
      "Loss: 153.997, Residuals: 0.009\n",
      "Loss: 153.963, Residuals: 0.009\n",
      "Loss: 153.960, Residuals: 0.009\n",
      "Loss: 153.940, Residuals: 0.009\n",
      "Loss: 153.940, Residuals: 0.009\n",
      "Loss: 153.936, Residuals: 0.009\n",
      "Loss: 153.928, Residuals: 0.009\n",
      "Loss: 153.928, Residuals: 0.009\n",
      "Loss: 153.926, Residuals: 0.009\n",
      "Loss: 153.926, Residuals: 0.009\n",
      "Loss: 153.926, Residuals: 0.009\n",
      "Loss: 153.926, Residuals: 0.009\n",
      "Loss: 153.925, Residuals: 0.009\n",
      "Loss: 153.924, Residuals: 0.009\n",
      "Evidence 461.525\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.70e-01\n",
      "Loss: 155.315, Residuals: 0.010\n",
      "Loss: 155.269, Residuals: 0.011\n",
      "Loss: 155.213, Residuals: 0.011\n",
      "Loss: 155.178, Residuals: 0.012\n",
      "Loss: 155.175, Residuals: 0.011\n",
      "Loss: 155.175, Residuals: 0.011\n",
      "Loss: 155.168, Residuals: 0.011\n",
      "Loss: 155.157, Residuals: 0.011\n",
      "Loss: 155.141, Residuals: 0.011\n",
      "Loss: 155.141, Residuals: 0.011\n",
      "Loss: 155.137, Residuals: 0.011\n",
      "Loss: 155.136, Residuals: 0.011\n",
      "Loss: 155.133, Residuals: 0.011\n",
      "Loss: 155.133, Residuals: 0.011\n",
      "Loss: 155.131, Residuals: 0.011\n",
      "Loss: 155.130, Residuals: 0.011\n",
      "Loss: 155.130, Residuals: 0.011\n",
      "Loss: 155.129, Residuals: 0.011\n",
      "Evidence 462.444\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.08e+00\n",
      "Loss: 155.906, Residuals: 0.012\n",
      "Loss: 155.870, Residuals: 0.012\n",
      "Loss: 155.840, Residuals: 0.013\n",
      "Loss: 155.835, Residuals: 0.013\n",
      "Loss: 155.827, Residuals: 0.013\n",
      "Loss: 155.814, Residuals: 0.013\n",
      "Loss: 155.812, Residuals: 0.013\n",
      "Loss: 155.808, Residuals: 0.013\n",
      "Loss: 155.807, Residuals: 0.013\n",
      "Loss: 155.806, Residuals: 0.013\n",
      "Loss: 155.803, Residuals: 0.013\n",
      "Loss: 155.803, Residuals: 0.013\n",
      "Evidence 462.924\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.16e+00\n",
      "Loss: 156.284, Residuals: 0.013\n",
      "Loss: 156.265, Residuals: 0.013\n",
      "Loss: 156.247, Residuals: 0.014\n",
      "Loss: 156.245, Residuals: 0.014\n",
      "Loss: 156.233, Residuals: 0.014\n",
      "Loss: 156.232, Residuals: 0.014\n",
      "Loss: 156.229, Residuals: 0.014\n",
      "Loss: 156.225, Residuals: 0.014\n",
      "Loss: 156.219, Residuals: 0.014\n",
      "Loss: 156.219, Residuals: 0.014\n",
      "Loss: 156.219, Residuals: 0.014\n",
      "Loss: 156.219, Residuals: 0.014\n",
      "Loss: 156.218, Residuals: 0.014\n",
      "Loss: 156.218, Residuals: 0.014\n",
      "Loss: 156.217, Residuals: 0.014\n",
      "Loss: 156.217, Residuals: 0.014\n",
      "Loss: 156.217, Residuals: 0.014\n",
      "Evidence 463.096\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 11.673, Residuals: -0.143\n",
      "Loss: 6.909, Residuals: -0.064\n",
      "Loss: 5.262, Residuals: -0.063\n",
      "Loss: 4.457, Residuals: -0.080\n",
      "Loss: 3.877, Residuals: -0.083\n",
      "Loss: 3.713, Residuals: -0.034\n",
      "Loss: 3.459, Residuals: -0.038\n",
      "Loss: 3.150, Residuals: -0.043\n",
      "Loss: 3.095, Residuals: -0.004\n",
      "Loss: 2.992, Residuals: -0.002\n",
      "Loss: 2.849, Residuals: 0.021\n",
      "Loss: 2.828, Residuals: 0.037\n",
      "Loss: 2.789, Residuals: 0.031\n",
      "Loss: 2.723, Residuals: 0.022\n",
      "Loss: 2.707, Residuals: 0.010\n",
      "Loss: 2.687, Residuals: 0.020\n",
      "Loss: 2.653, Residuals: 0.016\n",
      "Loss: 2.599, Residuals: 0.005\n",
      "Loss: 2.588, Residuals: -0.006\n",
      "Loss: 2.569, Residuals: -0.009\n",
      "Loss: 2.536, Residuals: -0.015\n",
      "Loss: 2.531, Residuals: -0.008\n",
      "Loss: 2.493, Residuals: -0.020\n",
      "Loss: 2.470, Residuals: -0.026\n",
      "Loss: 2.437, Residuals: -0.038\n",
      "Loss: 2.435, Residuals: -0.038\n",
      "Loss: 2.430, Residuals: -0.041\n",
      "Loss: 2.422, Residuals: -0.045\n",
      "Loss: 2.407, Residuals: -0.051\n",
      "Loss: 2.400, Residuals: -0.054\n",
      "Loss: 2.399, Residuals: -0.050\n",
      "Loss: 2.366, Residuals: -0.064\n",
      "Loss: 2.366, Residuals: -0.062\n",
      "Loss: 2.365, Residuals: -0.063\n",
      "Loss: 2.356, Residuals: -0.069\n",
      "Loss: 2.355, Residuals: -0.067\n",
      "Loss: 2.347, Residuals: -0.070\n",
      "Loss: 2.347, Residuals: -0.071\n",
      "Loss: 2.335, Residuals: -0.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.335, Residuals: -0.074\n",
      "Loss: 2.335, Residuals: -0.075\n",
      "Loss: 2.331, Residuals: -0.077\n",
      "Loss: 2.325, Residuals: -0.081\n",
      "Loss: 2.325, Residuals: -0.080\n",
      "Loss: 2.324, Residuals: -0.081\n",
      "Loss: 2.323, Residuals: -0.082\n",
      "Loss: 2.322, Residuals: -0.083\n",
      "Loss: 2.322, Residuals: -0.082\n",
      "Loss: 2.319, Residuals: -0.083\n",
      "Loss: 2.314, Residuals: -0.085\n",
      "Loss: 2.314, Residuals: -0.085\n",
      "Loss: 2.312, Residuals: -0.087\n",
      "Loss: 2.311, Residuals: -0.086\n",
      "Loss: 2.310, Residuals: -0.086\n",
      "Loss: 2.307, Residuals: -0.087\n",
      "Loss: 2.307, Residuals: -0.089\n",
      "Loss: 2.307, Residuals: -0.087\n",
      "Loss: 2.303, Residuals: -0.090\n",
      "Loss: 2.303, Residuals: -0.088\n",
      "Loss: 2.302, Residuals: -0.088\n",
      "Loss: 2.302, Residuals: -0.089\n",
      "Loss: 2.301, Residuals: -0.089\n",
      "Loss: 2.301, Residuals: -0.091\n",
      "Loss: 2.300, Residuals: -0.091\n",
      "Loss: 2.298, Residuals: -0.091\n",
      "Loss: 2.298, Residuals: -0.091\n",
      "Loss: 2.298, Residuals: -0.092\n",
      "Loss: 2.297, Residuals: -0.092\n",
      "Loss: 2.297, Residuals: -0.092\n",
      "Loss: 2.296, Residuals: -0.093\n",
      "Loss: 2.295, Residuals: -0.093\n",
      "Loss: 2.295, Residuals: -0.093\n",
      "Loss: 2.295, Residuals: -0.093\n",
      "Loss: 2.295, Residuals: -0.093\n",
      "Loss: 2.295, Residuals: -0.093\n",
      "Loss: 2.295, Residuals: -0.093\n",
      "Loss: 2.294, Residuals: -0.093\n",
      "Loss: 2.294, Residuals: -0.093\n",
      "Loss: 2.294, Residuals: -0.093\n",
      "Loss: 2.294, Residuals: -0.093\n",
      "Evidence -386.785\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.64e-03\n",
      "Loss: 10.063, Residuals: -0.073\n",
      "Loss: 9.968, Residuals: -0.081\n",
      "Loss: 9.909, Residuals: -0.074\n",
      "Loss: 9.819, Residuals: -0.068\n",
      "Loss: 9.818, Residuals: -0.069\n",
      "Loss: 9.816, Residuals: -0.068\n",
      "Loss: 9.798, Residuals: -0.065\n",
      "Loss: 9.764, Residuals: -0.063\n",
      "Loss: 9.760, Residuals: -0.055\n",
      "Loss: 9.715, Residuals: -0.052\n",
      "Loss: 9.715, Residuals: -0.054\n",
      "Loss: 9.688, Residuals: -0.051\n",
      "Loss: 9.685, Residuals: -0.049\n",
      "Loss: 9.684, Residuals: -0.048\n",
      "Loss: 9.643, Residuals: -0.042\n",
      "Loss: 9.640, Residuals: -0.043\n",
      "Loss: 9.639, Residuals: -0.041\n",
      "Loss: 9.638, Residuals: -0.044\n",
      "Loss: 9.624, Residuals: -0.040\n",
      "Loss: 9.623, Residuals: -0.039\n",
      "Loss: 9.622, Residuals: -0.039\n",
      "Loss: 9.621, Residuals: -0.038\n",
      "Loss: 9.617, Residuals: -0.038\n",
      "Loss: 9.613, Residuals: -0.035\n",
      "Loss: 9.613, Residuals: -0.036\n",
      "Loss: 9.611, Residuals: -0.036\n",
      "Loss: 9.607, Residuals: -0.035\n",
      "Loss: 9.606, Residuals: -0.034\n",
      "Loss: 9.606, Residuals: -0.034\n",
      "Loss: 9.604, Residuals: -0.034\n",
      "Loss: 9.603, Residuals: -0.033\n",
      "Loss: 9.602, Residuals: -0.032\n",
      "Loss: 9.599, Residuals: -0.032\n",
      "Loss: 9.598, Residuals: -0.031\n",
      "Loss: 9.598, Residuals: -0.031\n",
      "Loss: 9.597, Residuals: -0.031\n",
      "Loss: 9.594, Residuals: -0.030\n",
      "Loss: 9.594, Residuals: -0.030\n",
      "Loss: 9.594, Residuals: -0.030\n",
      "Loss: 9.593, Residuals: -0.029\n",
      "Loss: 9.593, Residuals: -0.029\n",
      "Loss: 9.593, Residuals: -0.029\n",
      "Loss: 9.593, Residuals: -0.029\n",
      "Loss: 9.593, Residuals: -0.029\n",
      "Loss: 9.592, Residuals: -0.029\n",
      "Loss: 9.592, Residuals: -0.028\n",
      "Loss: 9.592, Residuals: -0.028\n",
      "Loss: 9.591, Residuals: -0.028\n",
      "Loss: 9.591, Residuals: -0.028\n",
      "Loss: 9.590, Residuals: -0.028\n",
      "Loss: 9.590, Residuals: -0.027\n",
      "Loss: 9.590, Residuals: -0.027\n",
      "Loss: 9.589, Residuals: -0.027\n",
      "Loss: 9.589, Residuals: -0.026\n",
      "Loss: 9.589, Residuals: -0.026\n",
      "Loss: 9.589, Residuals: -0.026\n",
      "Loss: 9.588, Residuals: -0.026\n",
      "Loss: 9.588, Residuals: -0.026\n",
      "Loss: 9.588, Residuals: -0.026\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.026\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Loss: 9.588, Residuals: -0.024\n",
      "Loss: 9.588, Residuals: -0.025\n",
      "Evidence 83.714\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 9.47e-02\n",
      "Loss: 36.313, Residuals: -0.022\n",
      "Loss: 36.253, Residuals: -0.019\n",
      "Loss: 36.139, Residuals: -0.018\n",
      "Loss: 35.944, Residuals: -0.014\n",
      "Loss: 35.925, Residuals: -0.016\n",
      "Loss: 35.890, Residuals: -0.015\n",
      "Loss: 35.827, Residuals: -0.014\n",
      "Loss: 35.725, Residuals: -0.010\n",
      "Loss: 35.696, Residuals: -0.009\n",
      "Loss: 35.691, Residuals: -0.010\n",
      "Loss: 35.683, Residuals: -0.010\n",
      "Loss: 35.669, Residuals: -0.009\n",
      "Loss: 35.645, Residuals: -0.008\n",
      "Loss: 35.606, Residuals: -0.005\n",
      "Loss: 35.604, Residuals: -0.005\n",
      "Loss: 35.601, Residuals: -0.005\n",
      "Loss: 35.595, Residuals: -0.004\n",
      "Loss: 35.585, Residuals: -0.003\n",
      "Loss: 35.584, Residuals: -0.003\n",
      "Loss: 35.580, Residuals: -0.002\n",
      "Loss: 35.574, Residuals: -0.001\n",
      "Loss: 35.573, Residuals: -0.001\n",
      "Loss: 35.573, Residuals: -0.001\n",
      "Loss: 35.573, Residuals: -0.001\n",
      "Loss: 35.572, Residuals: -0.001\n",
      "Loss: 35.572, Residuals: -0.001\n",
      "Loss: 35.572, Residuals: -0.001\n",
      "Loss: 35.571, Residuals: -0.001\n",
      "Loss: 35.571, Residuals: -0.001\n",
      "Loss: 35.571, Residuals: -0.001\n",
      "Loss: 35.571, Residuals: -0.001\n",
      "Loss: 35.571, Residuals: -0.000\n",
      "Loss: 35.571, Residuals: -0.000\n",
      "Loss: 35.571, Residuals: -0.000\n",
      "Loss: 35.571, Residuals: -0.000\n",
      "Loss: 35.571, Residuals: -0.000\n",
      "Evidence 285.054\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.96e-01\n",
      "Loss: 83.403, Residuals: -0.013\n",
      "Loss: 82.960, Residuals: -0.007\n",
      "Loss: 82.782, Residuals: -0.001\n",
      "Loss: 82.636, Residuals: -0.007\n",
      "Loss: 82.402, Residuals: -0.005\n",
      "Loss: 82.242, Residuals: -0.001\n",
      "Loss: 82.230, Residuals: -0.001\n",
      "Loss: 82.219, Residuals: -0.002\n",
      "Loss: 82.212, Residuals: -0.002\n",
      "Loss: 82.210, Residuals: -0.001\n",
      "Loss: 82.207, Residuals: -0.001\n",
      "Loss: 82.207, Residuals: -0.001\n",
      "Loss: 82.206, Residuals: -0.001\n",
      "Loss: 82.205, Residuals: -0.001\n",
      "Loss: 82.205, Residuals: -0.001\n",
      "Loss: 82.205, Residuals: -0.001\n",
      "Loss: 82.205, Residuals: -0.001\n",
      "Loss: 82.205, Residuals: -0.001\n",
      "Loss: 82.204, Residuals: -0.001\n",
      "Loss: 82.204, Residuals: -0.001\n",
      "Loss: 82.204, Residuals: -0.001\n",
      "Evidence 390.994\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.93e-01\n",
      "Loss: 121.730, Residuals: -0.008\n",
      "Loss: 121.571, Residuals: -0.005\n",
      "Loss: 121.297, Residuals: -0.005\n",
      "Loss: 120.963, Residuals: -0.003\n",
      "Loss: 120.935, Residuals: -0.002\n",
      "Loss: 120.903, Residuals: -0.003\n",
      "Loss: 120.849, Residuals: -0.003\n",
      "Loss: 120.846, Residuals: -0.004\n",
      "Loss: 120.822, Residuals: -0.003\n",
      "Loss: 120.784, Residuals: -0.002\n",
      "Loss: 120.779, Residuals: -0.003\n",
      "Loss: 120.773, Residuals: -0.003\n",
      "Loss: 120.762, Residuals: -0.003\n",
      "Loss: 120.756, Residuals: -0.003\n",
      "Loss: 120.755, Residuals: -0.003\n",
      "Loss: 120.743, Residuals: -0.003\n",
      "Loss: 120.729, Residuals: -0.003\n",
      "Loss: 120.727, Residuals: -0.002\n",
      "Loss: 120.724, Residuals: -0.003\n",
      "Loss: 120.719, Residuals: -0.003\n",
      "Loss: 120.717, Residuals: -0.002\n",
      "Loss: 120.714, Residuals: -0.002\n",
      "Loss: 120.712, Residuals: -0.002\n",
      "Loss: 120.703, Residuals: -0.002\n",
      "Loss: 120.703, Residuals: -0.002\n",
      "Loss: 120.702, Residuals: -0.002\n",
      "Loss: 120.701, Residuals: -0.002\n",
      "Loss: 120.700, Residuals: -0.002\n",
      "Loss: 120.698, Residuals: -0.002\n",
      "Loss: 120.696, Residuals: -0.002\n",
      "Loss: 120.695, Residuals: -0.002\n",
      "Loss: 120.695, Residuals: -0.002\n",
      "Loss: 120.691, Residuals: -0.002\n",
      "Loss: 120.691, Residuals: -0.002\n",
      "Loss: 120.691, Residuals: -0.002\n",
      "Loss: 120.690, Residuals: -0.002\n",
      "Loss: 120.690, Residuals: -0.002\n",
      "Loss: 120.690, Residuals: -0.002\n",
      "Loss: 120.689, Residuals: -0.002\n",
      "Loss: 120.689, Residuals: -0.002\n",
      "Loss: 120.689, Residuals: -0.002\n",
      "Loss: 120.688, Residuals: -0.002\n",
      "Loss: 120.688, Residuals: -0.002\n",
      "Loss: 120.688, Residuals: -0.002\n",
      "Loss: 120.688, Residuals: -0.002\n",
      "Loss: 120.688, Residuals: -0.002\n",
      "Loss: 120.688, Residuals: -0.002\n",
      "Loss: 120.688, Residuals: -0.002\n",
      "Loss: 120.688, Residuals: -0.002\n",
      "Loss: 120.687, Residuals: -0.002\n",
      "Loss: 120.687, Residuals: -0.002\n",
      "Loss: 120.687, Residuals: -0.002\n",
      "Loss: 120.687, Residuals: -0.002\n",
      "Evidence 427.062\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.28e-01\n",
      "Loss: 139.171, Residuals: -0.003\n",
      "Loss: 138.932, Residuals: -0.002\n",
      "Loss: 138.870, Residuals: -0.000\n",
      "Loss: 138.766, Residuals: -0.001\n",
      "Loss: 138.637, Residuals: -0.002\n",
      "Loss: 138.627, Residuals: -0.002\n",
      "Loss: 138.617, Residuals: -0.001\n",
      "Loss: 138.598, Residuals: -0.002\n",
      "Loss: 138.594, Residuals: -0.002\n",
      "Loss: 138.551, Residuals: -0.002\n",
      "Loss: 138.548, Residuals: -0.002\n",
      "Loss: 138.520, Residuals: -0.002\n",
      "Loss: 138.481, Residuals: -0.002\n",
      "Loss: 138.479, Residuals: -0.002\n",
      "Loss: 138.476, Residuals: -0.002\n",
      "Loss: 138.474, Residuals: -0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 138.469, Residuals: -0.002\n",
      "Loss: 138.465, Residuals: -0.002\n",
      "Loss: 138.465, Residuals: -0.002\n",
      "Loss: 138.464, Residuals: -0.002\n",
      "Loss: 138.460, Residuals: -0.002\n",
      "Loss: 138.460, Residuals: -0.002\n",
      "Loss: 138.456, Residuals: -0.002\n",
      "Loss: 138.451, Residuals: -0.002\n",
      "Loss: 138.450, Residuals: -0.002\n",
      "Loss: 138.450, Residuals: -0.002\n",
      "Loss: 138.449, Residuals: -0.002\n",
      "Loss: 138.447, Residuals: -0.002\n",
      "Loss: 138.447, Residuals: -0.002\n",
      "Loss: 138.447, Residuals: -0.002\n",
      "Loss: 138.446, Residuals: -0.002\n",
      "Loss: 138.446, Residuals: -0.002\n",
      "Loss: 138.446, Residuals: -0.002\n",
      "Loss: 138.446, Residuals: -0.002\n",
      "Evidence 438.000\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.21e-01\n",
      "Loss: 146.100, Residuals: -0.002\n",
      "Loss: 145.994, Residuals: -0.003\n",
      "Loss: 145.863, Residuals: -0.003\n",
      "Loss: 145.856, Residuals: -0.002\n",
      "Loss: 145.845, Residuals: -0.002\n",
      "Loss: 145.824, Residuals: -0.002\n",
      "Loss: 145.788, Residuals: -0.002\n",
      "Loss: 145.770, Residuals: -0.001\n",
      "Loss: 145.765, Residuals: -0.001\n",
      "Loss: 145.730, Residuals: -0.001\n",
      "Loss: 145.729, Residuals: -0.002\n",
      "Loss: 145.728, Residuals: -0.001\n",
      "Loss: 145.713, Residuals: -0.001\n",
      "Loss: 145.712, Residuals: -0.001\n",
      "Loss: 145.702, Residuals: -0.001\n",
      "Loss: 145.687, Residuals: -0.002\n",
      "Loss: 145.686, Residuals: -0.001\n",
      "Loss: 145.684, Residuals: -0.002\n",
      "Loss: 145.681, Residuals: -0.002\n",
      "Loss: 145.681, Residuals: -0.001\n",
      "Loss: 145.681, Residuals: -0.001\n",
      "Loss: 145.679, Residuals: -0.001\n",
      "Loss: 145.676, Residuals: -0.001\n",
      "Loss: 145.676, Residuals: -0.002\n",
      "Loss: 145.674, Residuals: -0.002\n",
      "Loss: 145.673, Residuals: -0.001\n",
      "Loss: 145.672, Residuals: -0.002\n",
      "Loss: 145.671, Residuals: -0.002\n",
      "Loss: 145.671, Residuals: -0.002\n",
      "Evidence 441.534\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 5.15e-01\n",
      "Loss: 148.649, Residuals: -0.000\n",
      "Loss: 148.608, Residuals: -0.002\n",
      "Loss: 148.539, Residuals: -0.001\n",
      "Loss: 148.470, Residuals: -0.002\n",
      "Loss: 148.457, Residuals: -0.001\n",
      "Loss: 148.434, Residuals: -0.001\n",
      "Loss: 148.401, Residuals: -0.001\n",
      "Loss: 148.400, Residuals: -0.001\n",
      "Loss: 148.390, Residuals: -0.001\n",
      "Loss: 148.389, Residuals: -0.000\n",
      "Loss: 148.376, Residuals: -0.000\n",
      "Loss: 148.370, Residuals: -0.000\n",
      "Loss: 148.370, Residuals: -0.001\n",
      "Loss: 148.370, Residuals: -0.000\n",
      "Loss: 148.365, Residuals: -0.001\n",
      "Loss: 148.365, Residuals: -0.000\n",
      "Loss: 148.359, Residuals: -0.000\n",
      "Loss: 148.359, Residuals: -0.001\n",
      "Loss: 148.356, Residuals: -0.001\n",
      "Loss: 148.350, Residuals: -0.001\n",
      "Loss: 148.350, Residuals: -0.001\n",
      "Loss: 148.349, Residuals: -0.001\n",
      "Loss: 148.349, Residuals: -0.001\n",
      "Loss: 148.348, Residuals: -0.001\n",
      "Loss: 148.347, Residuals: -0.001\n",
      "Loss: 148.347, Residuals: -0.000\n",
      "Loss: 148.346, Residuals: -0.000\n",
      "Loss: 148.346, Residuals: -0.001\n",
      "Loss: 148.346, Residuals: -0.001\n",
      "Loss: 148.346, Residuals: -0.001\n",
      "Evidence 443.053\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.43e-01\n",
      "Loss: 149.603, Residuals: 0.003\n",
      "Loss: 149.528, Residuals: 0.000\n",
      "Loss: 149.468, Residuals: 0.000\n",
      "Loss: 149.460, Residuals: 0.001\n",
      "Loss: 149.445, Residuals: 0.001\n",
      "Loss: 149.427, Residuals: 0.001\n",
      "Loss: 149.425, Residuals: 0.001\n",
      "Loss: 149.414, Residuals: 0.001\n",
      "Loss: 149.414, Residuals: 0.001\n",
      "Loss: 149.408, Residuals: 0.001\n",
      "Loss: 149.399, Residuals: 0.001\n",
      "Loss: 149.399, Residuals: 0.001\n",
      "Loss: 149.398, Residuals: 0.001\n",
      "Loss: 149.390, Residuals: 0.000\n",
      "Loss: 149.390, Residuals: 0.001\n",
      "Loss: 149.389, Residuals: 0.001\n",
      "Loss: 149.389, Residuals: 0.001\n",
      "Evidence 443.901\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.04e-01\n",
      "Loss: 150.055, Residuals: 0.001\n",
      "Loss: 150.033, Residuals: 0.001\n",
      "Loss: 149.999, Residuals: 0.001\n",
      "Loss: 149.951, Residuals: 0.002\n",
      "Loss: 149.932, Residuals: 0.001\n",
      "Loss: 149.929, Residuals: 0.002\n",
      "Loss: 149.923, Residuals: 0.002\n",
      "Loss: 149.913, Residuals: 0.002\n",
      "Loss: 149.912, Residuals: 0.002\n",
      "Loss: 149.911, Residuals: 0.002\n",
      "Loss: 149.898, Residuals: 0.002\n",
      "Loss: 149.898, Residuals: 0.002\n",
      "Loss: 149.897, Residuals: 0.002\n",
      "Loss: 149.895, Residuals: 0.002\n",
      "Loss: 149.895, Residuals: 0.002\n",
      "Evidence 444.419\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.82e-01\n",
      "Loss: 150.298, Residuals: 0.002\n",
      "Loss: 150.283, Residuals: 0.002\n",
      "Loss: 150.259, Residuals: 0.002\n",
      "Loss: 150.233, Residuals: 0.002\n",
      "Loss: 150.230, Residuals: 0.003\n",
      "Loss: 150.226, Residuals: 0.003\n",
      "Loss: 150.218, Residuals: 0.003\n",
      "Loss: 150.218, Residuals: 0.003\n",
      "Evidence 444.724\n",
      "Pass count  1\n",
      "Total samples: 37, Updated regularization: 1.00e-05\n",
      "Loss: 10.599, Residuals: -0.081\n",
      "Loss: 6.229, Residuals: -0.012\n",
      "Loss: 5.160, Residuals: -0.035\n",
      "Loss: 4.545, Residuals: -0.047\n",
      "Loss: 4.017, Residuals: -0.054\n",
      "Loss: 3.449, Residuals: -0.083\n",
      "Loss: 3.306, Residuals: -0.008\n",
      "Loss: 3.063, Residuals: -0.016\n",
      "Loss: 2.810, Residuals: -0.020\n",
      "Loss: 2.773, Residuals: -0.028\n",
      "Loss: 2.734, Residuals: -0.022\n",
      "Loss: 2.674, Residuals: -0.025\n",
      "Loss: 2.659, Residuals: -0.017\n",
      "Loss: 2.652, Residuals: -0.010\n",
      "Loss: 2.641, Residuals: -0.013\n",
      "Loss: 2.620, Residuals: -0.018\n",
      "Loss: 2.615, Residuals: -0.011\n",
      "Loss: 2.575, Residuals: -0.025\n",
      "Loss: 2.534, Residuals: -0.026\n",
      "Loss: 2.466, Residuals: 0.011\n",
      "Loss: 2.387, Residuals: 0.034\n",
      "Loss: 2.274, Residuals: 0.031\n",
      "Loss: 2.261, Residuals: 0.019\n",
      "Loss: 2.238, Residuals: 0.017\n",
      "Loss: 2.201, Residuals: 0.012\n",
      "Loss: 2.152, Residuals: 0.001\n",
      "Loss: 2.136, Residuals: -0.007\n",
      "Loss: 2.129, Residuals: -0.005\n",
      "Loss: 2.118, Residuals: -0.012\n",
      "Loss: 2.101, Residuals: -0.018\n",
      "Loss: 2.099, Residuals: -0.024\n",
      "Loss: 2.085, Residuals: -0.030\n",
      "Loss: 2.075, Residuals: -0.039\n",
      "Loss: 2.074, Residuals: -0.036\n",
      "Loss: 2.073, Residuals: -0.039\n",
      "Loss: 2.066, Residuals: -0.041\n",
      "Loss: 2.053, Residuals: -0.048\n",
      "Loss: 2.052, Residuals: -0.047\n",
      "Loss: 2.043, Residuals: -0.050\n",
      "Loss: 2.043, Residuals: -0.050\n",
      "Loss: 2.037, Residuals: -0.052\n",
      "Loss: 2.031, Residuals: -0.057\n",
      "Loss: 2.031, Residuals: -0.059\n",
      "Loss: 2.031, Residuals: -0.058\n",
      "Loss: 2.030, Residuals: -0.058\n",
      "Loss: 2.029, Residuals: -0.058\n",
      "Loss: 2.018, Residuals: -0.060\n",
      "Loss: 2.017, Residuals: -0.059\n",
      "Loss: 2.012, Residuals: -0.061\n",
      "Loss: 2.005, Residuals: -0.067\n",
      "Loss: 2.005, Residuals: -0.067\n",
      "Loss: 2.001, Residuals: -0.067\n",
      "Loss: 1.994, Residuals: -0.069\n",
      "Loss: 1.994, Residuals: -0.067\n",
      "Loss: 1.993, Residuals: -0.067\n",
      "Loss: 1.988, Residuals: -0.068\n",
      "Loss: 1.988, Residuals: -0.069\n",
      "Loss: 1.984, Residuals: -0.071\n",
      "Loss: 1.984, Residuals: -0.071\n",
      "Loss: 1.981, Residuals: -0.072\n",
      "Loss: 1.980, Residuals: -0.072\n",
      "Loss: 1.980, Residuals: -0.071\n",
      "Loss: 1.975, Residuals: -0.073\n",
      "Loss: 1.975, Residuals: -0.074\n",
      "Loss: 1.974, Residuals: -0.074\n",
      "Loss: 1.972, Residuals: -0.074\n",
      "Loss: 1.971, Residuals: -0.075\n",
      "Loss: 1.971, Residuals: -0.075\n",
      "Loss: 1.969, Residuals: -0.076\n",
      "Loss: 1.969, Residuals: -0.076\n",
      "Loss: 1.967, Residuals: -0.076\n",
      "Loss: 1.967, Residuals: -0.075\n",
      "Loss: 1.964, Residuals: -0.077\n",
      "Loss: 1.964, Residuals: -0.078\n",
      "Loss: 1.963, Residuals: -0.078\n",
      "Loss: 1.962, Residuals: -0.078\n",
      "Loss: 1.962, Residuals: -0.077\n",
      "Loss: 1.962, Residuals: -0.078\n",
      "Loss: 1.962, Residuals: -0.078\n",
      "Loss: 1.961, Residuals: -0.079\n",
      "Loss: 1.961, Residuals: -0.079\n",
      "Loss: 1.960, Residuals: -0.080\n",
      "Loss: 1.960, Residuals: -0.080\n",
      "Loss: 1.960, Residuals: -0.081\n",
      "Loss: 1.959, Residuals: -0.080\n",
      "Loss: 1.959, Residuals: -0.081\n",
      "Loss: 1.959, Residuals: -0.081\n",
      "Loss: 1.957, Residuals: -0.082\n",
      "Loss: 1.957, Residuals: -0.082\n",
      "Evidence -380.813\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.95e-03\n",
      "Loss: 8.892, Residuals: -0.051\n",
      "Loss: 8.719, Residuals: -0.057\n",
      "Loss: 8.679, Residuals: -0.060\n",
      "Loss: 8.613, Residuals: -0.056\n",
      "Loss: 8.602, Residuals: -0.051\n",
      "Loss: 8.523, Residuals: -0.043\n",
      "Loss: 8.522, Residuals: -0.043\n",
      "Loss: 8.519, Residuals: -0.043\n",
      "Loss: 8.515, Residuals: -0.044\n",
      "Loss: 8.482, Residuals: -0.040\n",
      "Loss: 8.454, Residuals: -0.029\n",
      "Loss: 8.453, Residuals: -0.031\n",
      "Loss: 8.451, Residuals: -0.031\n",
      "Loss: 8.448, Residuals: -0.031\n",
      "Loss: 8.444, Residuals: -0.032\n",
      "Loss: 8.435, Residuals: -0.032\n",
      "Loss: 8.421, Residuals: -0.030\n",
      "Loss: 8.420, Residuals: -0.029\n",
      "Loss: 8.414, Residuals: -0.028\n",
      "Loss: 8.406, Residuals: -0.026\n",
      "Loss: 8.405, Residuals: -0.026\n",
      "Loss: 8.404, Residuals: -0.026\n",
      "Loss: 8.402, Residuals: -0.025\n",
      "Loss: 8.402, Residuals: -0.025\n",
      "Loss: 8.398, Residuals: -0.024\n",
      "Loss: 8.398, Residuals: -0.023\n",
      "Loss: 8.397, Residuals: -0.024\n",
      "Loss: 8.397, Residuals: -0.023\n",
      "Loss: 8.396, Residuals: -0.023\n",
      "Loss: 8.395, Residuals: -0.023\n",
      "Loss: 8.394, Residuals: -0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 8.393, Residuals: -0.022\n",
      "Loss: 8.393, Residuals: -0.022\n",
      "Loss: 8.392, Residuals: -0.022\n",
      "Loss: 8.392, Residuals: -0.021\n",
      "Loss: 8.392, Residuals: -0.022\n",
      "Loss: 8.392, Residuals: -0.021\n",
      "Loss: 8.391, Residuals: -0.021\n",
      "Loss: 8.391, Residuals: -0.020\n",
      "Loss: 8.391, Residuals: -0.020\n",
      "Loss: 8.390, Residuals: -0.020\n",
      "Loss: 8.390, Residuals: -0.020\n",
      "Loss: 8.390, Residuals: -0.021\n",
      "Loss: 8.389, Residuals: -0.020\n",
      "Loss: 8.389, Residuals: -0.020\n",
      "Loss: 8.389, Residuals: -0.020\n",
      "Loss: 8.389, Residuals: -0.020\n",
      "Loss: 8.389, Residuals: -0.020\n",
      "Loss: 8.389, Residuals: -0.019\n",
      "Loss: 8.386, Residuals: -0.017\n",
      "Loss: 8.386, Residuals: -0.017\n",
      "Loss: 8.385, Residuals: -0.017\n",
      "Loss: 8.384, Residuals: -0.017\n",
      "Loss: 8.383, Residuals: -0.017\n",
      "Loss: 8.383, Residuals: -0.017\n",
      "Loss: 8.381, Residuals: -0.016\n",
      "Loss: 8.381, Residuals: -0.016\n",
      "Loss: 8.378, Residuals: -0.016\n",
      "Loss: 8.377, Residuals: -0.015\n",
      "Loss: 8.377, Residuals: -0.015\n",
      "Loss: 8.375, Residuals: -0.014\n",
      "Loss: 8.375, Residuals: -0.014\n",
      "Loss: 8.371, Residuals: -0.013\n",
      "Loss: 8.371, Residuals: -0.012\n",
      "Loss: 8.370, Residuals: -0.013\n",
      "Loss: 8.368, Residuals: -0.012\n",
      "Loss: 8.368, Residuals: -0.011\n",
      "Loss: 8.366, Residuals: -0.011\n",
      "Loss: 8.365, Residuals: -0.011\n",
      "Loss: 8.365, Residuals: -0.011\n",
      "Loss: 8.365, Residuals: -0.011\n",
      "Loss: 8.364, Residuals: -0.011\n",
      "Loss: 8.364, Residuals: -0.010\n",
      "Loss: 8.364, Residuals: -0.010\n",
      "Loss: 8.363, Residuals: -0.010\n",
      "Loss: 8.363, Residuals: -0.010\n",
      "Loss: 8.363, Residuals: -0.010\n",
      "Loss: 8.362, Residuals: -0.009\n",
      "Loss: 8.362, Residuals: -0.009\n",
      "Loss: 8.362, Residuals: -0.009\n",
      "Loss: 8.362, Residuals: -0.009\n",
      "Loss: 8.362, Residuals: -0.009\n",
      "Loss: 8.362, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.008\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Loss: 8.361, Residuals: -0.009\n",
      "Evidence 74.891\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.70e-02\n",
      "Loss: 30.977, Residuals: -0.004\n",
      "Loss: 30.878, Residuals: 0.005\n",
      "Loss: 30.849, Residuals: -0.002\n",
      "Loss: 30.796, Residuals: 0.000\n",
      "Loss: 30.715, Residuals: 0.004\n",
      "Loss: 30.711, Residuals: 0.005\n",
      "Loss: 30.684, Residuals: 0.006\n",
      "Loss: 30.646, Residuals: 0.008\n",
      "Loss: 30.645, Residuals: 0.008\n",
      "Loss: 30.642, Residuals: 0.008\n",
      "Loss: 30.638, Residuals: 0.008\n",
      "Loss: 30.636, Residuals: 0.009\n",
      "Loss: 30.636, Residuals: 0.008\n",
      "Loss: 30.635, Residuals: 0.009\n",
      "Loss: 30.631, Residuals: 0.009\n",
      "Loss: 30.629, Residuals: 0.010\n",
      "Loss: 30.629, Residuals: 0.009\n",
      "Loss: 30.628, Residuals: 0.009\n",
      "Loss: 30.628, Residuals: 0.009\n",
      "Loss: 30.628, Residuals: 0.009\n",
      "Loss: 30.628, Residuals: 0.009\n",
      "Loss: 30.624, Residuals: 0.009\n",
      "Loss: 30.624, Residuals: 0.009\n",
      "Loss: 30.624, Residuals: 0.009\n",
      "Loss: 30.624, Residuals: 0.009\n",
      "Loss: 30.623, Residuals: 0.009\n",
      "Loss: 30.622, Residuals: 0.010\n",
      "Loss: 30.622, Residuals: 0.010\n",
      "Loss: 30.622, Residuals: 0.010\n",
      "Loss: 30.621, Residuals: 0.010\n",
      "Loss: 30.621, Residuals: 0.010\n",
      "Loss: 30.621, Residuals: 0.010\n",
      "Loss: 30.621, Residuals: 0.010\n",
      "Loss: 30.621, Residuals: 0.010\n",
      "Loss: 30.621, Residuals: 0.010\n",
      "Loss: 30.621, Residuals: 0.010\n",
      "Loss: 30.621, Residuals: 0.010\n",
      "Loss: 30.621, Residuals: 0.010\n",
      "Loss: 30.620, Residuals: 0.010\n",
      "Loss: 30.620, Residuals: 0.009\n",
      "Loss: 30.620, Residuals: 0.009\n",
      "Loss: 30.620, Residuals: 0.010\n",
      "Loss: 30.620, Residuals: 0.010\n",
      "Loss: 30.620, Residuals: 0.010\n",
      "Loss: 30.620, Residuals: 0.010\n",
      "Loss: 30.620, Residuals: 0.010\n",
      "Loss: 30.620, Residuals: 0.010\n",
      "Loss: 30.620, Residuals: 0.010\n",
      "Evidence 275.503\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 7.85e-02\n",
      "Loss: 72.500, Residuals: 0.014\n",
      "Loss: 72.354, Residuals: 0.007\n",
      "Loss: 72.316, Residuals: 0.008\n",
      "Loss: 72.252, Residuals: 0.008\n",
      "Loss: 72.158, Residuals: 0.009\n",
      "Loss: 72.149, Residuals: 0.009\n",
      "Loss: 72.132, Residuals: 0.009\n",
      "Loss: 72.111, Residuals: 0.010\n",
      "Loss: 72.110, Residuals: 0.010\n",
      "Loss: 72.109, Residuals: 0.011\n",
      "Loss: 72.095, Residuals: 0.011\n",
      "Loss: 72.075, Residuals: 0.011\n",
      "Loss: 72.074, Residuals: 0.011\n",
      "Loss: 72.074, Residuals: 0.010\n",
      "Loss: 72.073, Residuals: 0.011\n",
      "Loss: 72.070, Residuals: 0.011\n",
      "Loss: 72.070, Residuals: 0.011\n",
      "Loss: 72.068, Residuals: 0.011\n",
      "Loss: 72.067, Residuals: 0.011\n",
      "Loss: 72.066, Residuals: 0.011\n",
      "Loss: 72.066, Residuals: 0.011\n",
      "Loss: 72.065, Residuals: 0.011\n",
      "Loss: 72.065, Residuals: 0.011\n",
      "Loss: 72.064, Residuals: 0.011\n",
      "Loss: 72.063, Residuals: 0.011\n",
      "Loss: 72.063, Residuals: 0.011\n",
      "Loss: 72.062, Residuals: 0.011\n",
      "Loss: 72.062, Residuals: 0.011\n",
      "Loss: 72.062, Residuals: 0.011\n",
      "Loss: 72.062, Residuals: 0.011\n",
      "Evidence 390.539\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.73e-01\n",
      "Loss: 112.517, Residuals: 0.013\n",
      "Loss: 112.343, Residuals: 0.002\n",
      "Loss: 112.145, Residuals: 0.004\n",
      "Loss: 112.122, Residuals: 0.008\n",
      "Loss: 112.083, Residuals: 0.008\n",
      "Loss: 112.066, Residuals: 0.007\n",
      "Loss: 112.063, Residuals: 0.007\n",
      "Loss: 112.035, Residuals: 0.008\n",
      "Loss: 112.033, Residuals: 0.008\n",
      "Loss: 112.032, Residuals: 0.008\n",
      "Loss: 112.021, Residuals: 0.008\n",
      "Loss: 112.006, Residuals: 0.009\n",
      "Loss: 112.006, Residuals: 0.009\n",
      "Loss: 112.005, Residuals: 0.009\n",
      "Loss: 112.005, Residuals: 0.009\n",
      "Loss: 112.000, Residuals: 0.009\n",
      "Loss: 111.992, Residuals: 0.009\n",
      "Loss: 111.991, Residuals: 0.009\n",
      "Loss: 111.991, Residuals: 0.009\n",
      "Loss: 111.985, Residuals: 0.009\n",
      "Loss: 111.985, Residuals: 0.009\n",
      "Loss: 111.981, Residuals: 0.009\n",
      "Loss: 111.980, Residuals: 0.009\n",
      "Loss: 111.980, Residuals: 0.009\n",
      "Loss: 111.978, Residuals: 0.009\n",
      "Loss: 111.978, Residuals: 0.009\n",
      "Loss: 111.978, Residuals: 0.009\n",
      "Evidence 432.546\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.35e-01\n",
      "Loss: 132.941, Residuals: 0.014\n",
      "Loss: 132.837, Residuals: 0.008\n",
      "Loss: 132.687, Residuals: 0.005\n",
      "Loss: 132.530, Residuals: 0.008\n",
      "Loss: 132.482, Residuals: 0.008\n",
      "Loss: 132.468, Residuals: 0.008\n",
      "Loss: 132.463, Residuals: 0.009\n",
      "Loss: 132.426, Residuals: 0.009\n",
      "Loss: 132.413, Residuals: 0.008\n",
      "Loss: 132.411, Residuals: 0.009\n",
      "Loss: 132.391, Residuals: 0.009\n",
      "Loss: 132.383, Residuals: 0.009\n",
      "Loss: 132.383, Residuals: 0.009\n",
      "Loss: 132.377, Residuals: 0.009\n",
      "Loss: 132.376, Residuals: 0.009\n",
      "Loss: 132.361, Residuals: 0.009\n",
      "Loss: 132.358, Residuals: 0.009\n",
      "Loss: 132.357, Residuals: 0.009\n",
      "Loss: 132.357, Residuals: 0.009\n",
      "Loss: 132.356, Residuals: 0.009\n",
      "Loss: 132.352, Residuals: 0.009\n",
      "Loss: 132.352, Residuals: 0.009\n",
      "Evidence 443.876\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.65e-01\n",
      "Loss: 139.764, Residuals: 0.014\n",
      "Loss: 139.539, Residuals: 0.007\n",
      "Loss: 139.494, Residuals: 0.011\n",
      "Loss: 139.413, Residuals: 0.011\n",
      "Loss: 139.291, Residuals: 0.012\n",
      "Loss: 139.261, Residuals: 0.011\n",
      "Loss: 139.258, Residuals: 0.011\n",
      "Loss: 139.229, Residuals: 0.011\n",
      "Loss: 139.196, Residuals: 0.011\n",
      "Loss: 139.195, Residuals: 0.012\n",
      "Loss: 139.193, Residuals: 0.012\n",
      "Loss: 139.191, Residuals: 0.011\n",
      "Loss: 139.191, Residuals: 0.011\n",
      "Loss: 139.187, Residuals: 0.011\n",
      "Loss: 139.187, Residuals: 0.011\n",
      "Evidence 448.582\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.69e-01\n",
      "Loss: 142.180, Residuals: 0.014\n",
      "Loss: 142.097, Residuals: 0.009\n",
      "Loss: 142.023, Residuals: 0.011\n",
      "Loss: 142.020, Residuals: 0.011\n",
      "Loss: 141.991, Residuals: 0.011\n",
      "Loss: 141.959, Residuals: 0.011\n",
      "Loss: 141.959, Residuals: 0.012\n",
      "Loss: 141.958, Residuals: 0.011\n",
      "Loss: 141.956, Residuals: 0.011\n",
      "Loss: 141.956, Residuals: 0.011\n",
      "Loss: 141.955, Residuals: 0.011\n",
      "Loss: 141.954, Residuals: 0.011\n",
      "Loss: 141.954, Residuals: 0.011\n",
      "Loss: 141.953, Residuals: 0.011\n",
      "Loss: 141.952, Residuals: 0.011\n",
      "Loss: 141.952, Residuals: 0.011\n",
      "Loss: 141.952, Residuals: 0.011\n",
      "Loss: 141.951, Residuals: 0.011\n",
      "Evidence 450.506\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.75e-01\n",
      "Loss: 143.601, Residuals: 0.011\n",
      "Loss: 143.547, Residuals: 0.012\n",
      "Loss: 143.544, Residuals: 0.011\n",
      "Loss: 143.539, Residuals: 0.011\n",
      "Loss: 143.529, Residuals: 0.011\n",
      "Loss: 143.516, Residuals: 0.011\n",
      "Loss: 143.515, Residuals: 0.011\n",
      "Loss: 143.515, Residuals: 0.011\n",
      "Loss: 143.513, Residuals: 0.011\n",
      "Loss: 143.511, Residuals: 0.011\n",
      "Loss: 143.511, Residuals: 0.011\n",
      "Loss: 143.508, Residuals: 0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 143.508, Residuals: 0.011\n",
      "Loss: 143.508, Residuals: 0.011\n",
      "Loss: 143.507, Residuals: 0.011\n",
      "Loss: 143.507, Residuals: 0.011\n",
      "Loss: 143.507, Residuals: 0.011\n",
      "Loss: 143.507, Residuals: 0.011\n",
      "Loss: 143.506, Residuals: 0.011\n",
      "Loss: 143.506, Residuals: 0.011\n",
      "Evidence 451.045\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.85e-01\n",
      "Loss: 144.345, Residuals: 0.010\n",
      "Loss: 144.313, Residuals: 0.012\n",
      "Loss: 144.308, Residuals: 0.010\n",
      "Loss: 144.299, Residuals: 0.011\n",
      "Loss: 144.288, Residuals: 0.011\n",
      "Loss: 144.287, Residuals: 0.011\n",
      "Loss: 144.286, Residuals: 0.011\n",
      "Loss: 144.284, Residuals: 0.011\n",
      "Loss: 144.283, Residuals: 0.011\n",
      "Loss: 144.283, Residuals: 0.011\n",
      "Loss: 144.282, Residuals: 0.011\n",
      "Loss: 144.280, Residuals: 0.011\n",
      "Loss: 144.278, Residuals: 0.011\n",
      "Loss: 144.278, Residuals: 0.011\n",
      "Evidence 451.181\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 11.432, Residuals: -0.162\n",
      "Loss: 6.949, Residuals: -0.074\n",
      "Loss: 4.887, Residuals: -0.062\n",
      "Loss: 4.349, Residuals: -0.029\n",
      "Loss: 3.991, Residuals: -0.037\n",
      "Loss: 3.763, Residuals: -0.020\n",
      "Loss: 3.706, Residuals: 0.009\n",
      "Loss: 3.602, Residuals: 0.000\n",
      "Loss: 3.431, Residuals: -0.013\n",
      "Loss: 3.403, Residuals: 0.010\n",
      "Loss: 3.160, Residuals: -0.013\n",
      "Loss: 3.027, Residuals: 0.039\n",
      "Loss: 2.850, Residuals: 0.031\n",
      "Loss: 2.831, Residuals: 0.037\n",
      "Loss: 2.799, Residuals: 0.033\n",
      "Loss: 2.744, Residuals: 0.025\n",
      "Loss: 2.684, Residuals: 0.010\n",
      "Loss: 2.682, Residuals: 0.007\n",
      "Loss: 2.671, Residuals: 0.005\n",
      "Loss: 2.649, Residuals: -0.000\n",
      "Loss: 2.641, Residuals: -0.002\n",
      "Loss: 2.626, Residuals: -0.005\n",
      "Loss: 2.602, Residuals: -0.015\n",
      "Loss: 2.602, Residuals: -0.016\n",
      "Loss: 2.597, Residuals: -0.018\n",
      "Loss: 2.589, Residuals: -0.021\n",
      "Loss: 2.574, Residuals: -0.028\n",
      "Loss: 2.572, Residuals: -0.030\n",
      "Loss: 2.561, Residuals: -0.036\n",
      "Loss: 2.555, Residuals: -0.039\n",
      "Loss: 2.554, Residuals: -0.036\n",
      "Loss: 2.546, Residuals: -0.041\n",
      "Loss: 2.546, Residuals: -0.041\n",
      "Loss: 2.541, Residuals: -0.045\n",
      "Loss: 2.538, Residuals: -0.046\n",
      "Loss: 2.533, Residuals: -0.048\n",
      "Loss: 2.530, Residuals: -0.053\n",
      "Loss: 2.524, Residuals: -0.055\n",
      "Loss: 2.523, Residuals: -0.056\n",
      "Loss: 2.513, Residuals: -0.060\n",
      "Loss: 2.513, Residuals: -0.060\n",
      "Loss: 2.512, Residuals: -0.060\n",
      "Loss: 2.512, Residuals: -0.060\n",
      "Loss: 2.511, Residuals: -0.061\n",
      "Loss: 2.509, Residuals: -0.061\n",
      "Loss: 2.509, Residuals: -0.061\n",
      "Loss: 2.505, Residuals: -0.062\n",
      "Loss: 2.505, Residuals: -0.062\n",
      "Evidence -373.925\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.67e-03\n",
      "Loss: 10.849, Residuals: -0.051\n",
      "Loss: 10.684, Residuals: -0.032\n",
      "Loss: 10.683, Residuals: -0.033\n",
      "Loss: 10.668, Residuals: -0.031\n",
      "Loss: 10.641, Residuals: -0.030\n",
      "Loss: 10.592, Residuals: -0.029\n",
      "Loss: 10.583, Residuals: -0.025\n",
      "Loss: 10.567, Residuals: -0.024\n",
      "Loss: 10.538, Residuals: -0.022\n",
      "Loss: 10.536, Residuals: -0.022\n",
      "Loss: 10.521, Residuals: -0.021\n",
      "Loss: 10.505, Residuals: -0.018\n",
      "Loss: 10.503, Residuals: -0.019\n",
      "Loss: 10.489, Residuals: -0.018\n",
      "Loss: 10.469, Residuals: -0.014\n",
      "Loss: 10.468, Residuals: -0.013\n",
      "Loss: 10.467, Residuals: -0.013\n",
      "Loss: 10.464, Residuals: -0.013\n",
      "Loss: 10.460, Residuals: -0.013\n",
      "Loss: 10.454, Residuals: -0.014\n",
      "Loss: 10.453, Residuals: -0.015\n",
      "Loss: 10.448, Residuals: -0.014\n",
      "Loss: 10.446, Residuals: -0.013\n",
      "Loss: 10.443, Residuals: -0.013\n",
      "Loss: 10.437, Residuals: -0.012\n",
      "Loss: 10.437, Residuals: -0.011\n",
      "Loss: 10.434, Residuals: -0.012\n",
      "Loss: 10.432, Residuals: -0.012\n",
      "Loss: 10.428, Residuals: -0.012\n",
      "Loss: 10.428, Residuals: -0.012\n",
      "Loss: 10.419, Residuals: -0.011\n",
      "Loss: 10.418, Residuals: -0.010\n",
      "Loss: 10.414, Residuals: -0.010\n",
      "Loss: 10.414, Residuals: -0.010\n",
      "Loss: 10.409, Residuals: -0.010\n",
      "Loss: 10.409, Residuals: -0.010\n",
      "Loss: 10.396, Residuals: -0.011\n",
      "Loss: 10.395, Residuals: -0.011\n",
      "Loss: 10.394, Residuals: -0.011\n",
      "Loss: 10.393, Residuals: -0.011\n",
      "Loss: 10.391, Residuals: -0.010\n",
      "Loss: 10.389, Residuals: -0.011\n",
      "Loss: 10.388, Residuals: -0.010\n",
      "Loss: 10.382, Residuals: -0.011\n",
      "Loss: 10.382, Residuals: -0.011\n",
      "Loss: 10.374, Residuals: -0.011\n",
      "Loss: 10.373, Residuals: -0.010\n",
      "Loss: 10.373, Residuals: -0.010\n",
      "Loss: 10.371, Residuals: -0.010\n",
      "Loss: 10.371, Residuals: -0.010\n",
      "Loss: 10.367, Residuals: -0.010\n",
      "Loss: 10.367, Residuals: -0.010\n",
      "Loss: 10.360, Residuals: -0.011\n",
      "Loss: 10.360, Residuals: -0.011\n",
      "Loss: 10.359, Residuals: -0.011\n",
      "Loss: 10.359, Residuals: -0.011\n",
      "Loss: 10.356, Residuals: -0.011\n",
      "Loss: 10.355, Residuals: -0.012\n",
      "Loss: 10.355, Residuals: -0.011\n",
      "Loss: 10.352, Residuals: -0.012\n",
      "Loss: 10.352, Residuals: -0.012\n",
      "Loss: 10.351, Residuals: -0.012\n",
      "Loss: 10.351, Residuals: -0.012\n",
      "Loss: 10.350, Residuals: -0.012\n",
      "Loss: 10.350, Residuals: -0.012\n",
      "Loss: 10.349, Residuals: -0.012\n",
      "Loss: 10.349, Residuals: -0.013\n",
      "Loss: 10.349, Residuals: -0.012\n",
      "Loss: 10.348, Residuals: -0.013\n",
      "Loss: 10.348, Residuals: -0.013\n",
      "Loss: 10.348, Residuals: -0.013\n",
      "Loss: 10.347, Residuals: -0.013\n",
      "Loss: 10.347, Residuals: -0.013\n",
      "Loss: 10.347, Residuals: -0.013\n",
      "Loss: 10.347, Residuals: -0.013\n",
      "Loss: 10.347, Residuals: -0.013\n",
      "Loss: 10.346, Residuals: -0.013\n",
      "Loss: 10.346, Residuals: -0.013\n",
      "Loss: 10.346, Residuals: -0.013\n",
      "Loss: 10.346, Residuals: -0.013\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.345, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.344, Residuals: -0.014\n",
      "Loss: 10.343, Residuals: -0.014\n",
      "Loss: 10.343, Residuals: -0.014\n",
      "Loss: 10.343, Residuals: -0.014\n",
      "Loss: 10.343, Residuals: -0.014\n",
      "Loss: 10.343, Residuals: -0.014\n",
      "Loss: 10.343, Residuals: -0.014\n",
      "Loss: 10.343, Residuals: -0.014\n",
      "Loss: 10.342, Residuals: -0.014\n",
      "Loss: 10.342, Residuals: -0.014\n",
      "Loss: 10.342, Residuals: -0.014\n",
      "Loss: 10.342, Residuals: -0.014\n",
      "Loss: 10.342, Residuals: -0.014\n",
      "Loss: 10.341, Residuals: -0.014\n",
      "Loss: 10.341, Residuals: -0.014\n",
      "Loss: 10.341, Residuals: -0.014\n",
      "Loss: 10.341, Residuals: -0.014\n",
      "Loss: 10.341, Residuals: -0.014\n",
      "Loss: 10.341, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.340, Residuals: -0.014\n",
      "Loss: 10.339, Residuals: -0.014\n",
      "Loss: 10.339, Residuals: -0.014\n",
      "Loss: 10.339, Residuals: -0.014\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Loss: 10.339, Residuals: -0.015\n",
      "Evidence 96.992\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.08e-02\n",
      "Loss: 39.320, Residuals: -0.002\n",
      "Loss: 39.138, Residuals: -0.008\n",
      "Loss: 39.098, Residuals: -0.007\n",
      "Loss: 39.021, Residuals: -0.006\n",
      "Loss: 38.885, Residuals: -0.004\n",
      "Loss: 38.869, Residuals: -0.002\n",
      "Loss: 38.744, Residuals: 0.001\n",
      "Loss: 38.722, Residuals: 0.003\n",
      "Loss: 38.684, Residuals: 0.004\n",
      "Loss: 38.640, Residuals: 0.006\n",
      "Loss: 38.634, Residuals: 0.003\n",
      "Loss: 38.623, Residuals: 0.004\n",
      "Loss: 38.604, Residuals: 0.005\n",
      "Loss: 38.602, Residuals: 0.005\n",
      "Loss: 38.584, Residuals: 0.006\n",
      "Loss: 38.578, Residuals: 0.006\n",
      "Loss: 38.569, Residuals: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 38.568, Residuals: 0.007\n",
      "Loss: 38.559, Residuals: 0.007\n",
      "Loss: 38.557, Residuals: 0.007\n",
      "Loss: 38.548, Residuals: 0.007\n",
      "Loss: 38.547, Residuals: 0.007\n",
      "Loss: 38.538, Residuals: 0.007\n",
      "Loss: 38.537, Residuals: 0.007\n",
      "Loss: 38.536, Residuals: 0.007\n",
      "Loss: 38.533, Residuals: 0.007\n",
      "Loss: 38.532, Residuals: 0.007\n",
      "Loss: 38.524, Residuals: 0.007\n",
      "Loss: 38.522, Residuals: 0.007\n",
      "Loss: 38.509, Residuals: 0.007\n",
      "Loss: 38.507, Residuals: 0.007\n",
      "Loss: 38.502, Residuals: 0.007\n",
      "Loss: 38.495, Residuals: 0.007\n",
      "Loss: 38.494, Residuals: 0.006\n",
      "Loss: 38.483, Residuals: 0.007\n",
      "Loss: 38.482, Residuals: 0.006\n",
      "Loss: 38.471, Residuals: 0.007\n",
      "Loss: 38.470, Residuals: 0.007\n",
      "Loss: 38.469, Residuals: 0.007\n",
      "Loss: 38.463, Residuals: 0.008\n",
      "Loss: 38.462, Residuals: 0.007\n",
      "Loss: 38.457, Residuals: 0.008\n",
      "Loss: 38.455, Residuals: 0.008\n",
      "Loss: 38.453, Residuals: 0.008\n",
      "Loss: 38.453, Residuals: 0.008\n",
      "Loss: 38.453, Residuals: 0.008\n",
      "Loss: 38.451, Residuals: 0.008\n",
      "Loss: 38.450, Residuals: 0.008\n",
      "Loss: 38.449, Residuals: 0.008\n",
      "Loss: 38.448, Residuals: 0.008\n",
      "Loss: 38.448, Residuals: 0.008\n",
      "Loss: 38.447, Residuals: 0.008\n",
      "Loss: 38.446, Residuals: 0.008\n",
      "Loss: 38.445, Residuals: 0.009\n",
      "Loss: 38.445, Residuals: 0.008\n",
      "Loss: 38.445, Residuals: 0.008\n",
      "Loss: 38.444, Residuals: 0.008\n",
      "Loss: 38.443, Residuals: 0.009\n",
      "Loss: 38.443, Residuals: 0.008\n",
      "Loss: 38.442, Residuals: 0.009\n",
      "Loss: 38.442, Residuals: 0.009\n",
      "Loss: 38.442, Residuals: 0.008\n",
      "Loss: 38.441, Residuals: 0.008\n",
      "Loss: 38.441, Residuals: 0.009\n",
      "Loss: 38.441, Residuals: 0.009\n",
      "Loss: 38.440, Residuals: 0.009\n",
      "Loss: 38.439, Residuals: 0.009\n",
      "Loss: 38.439, Residuals: 0.009\n",
      "Loss: 38.439, Residuals: 0.009\n",
      "Loss: 38.439, Residuals: 0.009\n",
      "Loss: 38.439, Residuals: 0.009\n",
      "Loss: 38.438, Residuals: 0.009\n",
      "Loss: 38.438, Residuals: 0.009\n",
      "Loss: 38.438, Residuals: 0.009\n",
      "Loss: 38.438, Residuals: 0.009\n",
      "Loss: 38.437, Residuals: 0.009\n",
      "Loss: 38.437, Residuals: 0.009\n",
      "Loss: 38.437, Residuals: 0.009\n",
      "Loss: 38.437, Residuals: 0.009\n",
      "Loss: 38.436, Residuals: 0.009\n",
      "Loss: 38.436, Residuals: 0.009\n",
      "Loss: 38.436, Residuals: 0.009\n",
      "Loss: 38.436, Residuals: 0.009\n",
      "Loss: 38.436, Residuals: 0.009\n",
      "Loss: 38.435, Residuals: 0.009\n",
      "Loss: 38.435, Residuals: 0.009\n",
      "Loss: 38.435, Residuals: 0.009\n",
      "Loss: 38.435, Residuals: 0.009\n",
      "Loss: 38.435, Residuals: 0.009\n",
      "Loss: 38.435, Residuals: 0.009\n",
      "Loss: 38.435, Residuals: 0.009\n",
      "Loss: 38.434, Residuals: 0.009\n",
      "Loss: 38.434, Residuals: 0.009\n",
      "Loss: 38.434, Residuals: 0.009\n",
      "Loss: 38.434, Residuals: 0.009\n",
      "Loss: 38.434, Residuals: 0.009\n",
      "Loss: 38.434, Residuals: 0.009\n",
      "Loss: 38.434, Residuals: 0.009\n",
      "Loss: 38.434, Residuals: 0.009\n",
      "Loss: 38.433, Residuals: 0.009\n",
      "Loss: 38.433, Residuals: 0.009\n",
      "Loss: 38.433, Residuals: 0.009\n",
      "Loss: 38.433, Residuals: 0.009\n",
      "Loss: 38.433, Residuals: 0.009\n",
      "Loss: 38.433, Residuals: 0.009\n",
      "Loss: 38.433, Residuals: 0.009\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.433, Residuals: 0.009\n",
      "Loss: 38.433, Residuals: 0.009\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.433, Residuals: 0.010\n",
      "Loss: 38.432, Residuals: 0.010\n",
      "Loss: 38.432, Residuals: 0.010\n",
      "Loss: 38.432, Residuals: 0.010\n",
      "Loss: 38.432, Residuals: 0.010\n",
      "Loss: 38.432, Residuals: 0.010\n",
      "Loss: 38.432, Residuals: 0.010\n",
      "Evidence 311.995\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.62e-01\n",
      "Loss: 88.767, Residuals: 0.002\n",
      "Loss: 88.465, Residuals: 0.007\n",
      "Loss: 88.333, Residuals: 0.006\n",
      "Loss: 88.108, Residuals: 0.007\n",
      "Loss: 87.814, Residuals: 0.010\n",
      "Loss: 87.774, Residuals: 0.006\n",
      "Loss: 87.699, Residuals: 0.006\n",
      "Loss: 87.569, Residuals: 0.007\n",
      "Loss: 87.519, Residuals: 0.009\n",
      "Loss: 87.446, Residuals: 0.010\n",
      "Loss: 87.439, Residuals: 0.009\n",
      "Loss: 87.427, Residuals: 0.009\n",
      "Loss: 87.406, Residuals: 0.010\n",
      "Loss: 87.401, Residuals: 0.010\n",
      "Loss: 87.393, Residuals: 0.010\n",
      "Loss: 87.390, Residuals: 0.010\n",
      "Loss: 87.384, Residuals: 0.010\n",
      "Loss: 87.383, Residuals: 0.010\n",
      "Loss: 87.381, Residuals: 0.010\n",
      "Loss: 87.378, Residuals: 0.010\n",
      "Loss: 87.377, Residuals: 0.010\n",
      "Loss: 87.376, Residuals: 0.010\n",
      "Loss: 87.373, Residuals: 0.011\n",
      "Loss: 87.372, Residuals: 0.011\n",
      "Loss: 87.372, Residuals: 0.011\n",
      "Loss: 87.371, Residuals: 0.011\n",
      "Loss: 87.371, Residuals: 0.011\n",
      "Loss: 87.370, Residuals: 0.011\n",
      "Loss: 87.369, Residuals: 0.011\n",
      "Loss: 87.369, Residuals: 0.011\n",
      "Loss: 87.369, Residuals: 0.011\n",
      "Loss: 87.369, Residuals: 0.011\n",
      "Loss: 87.369, Residuals: 0.011\n",
      "Loss: 87.369, Residuals: 0.011\n",
      "Loss: 87.368, Residuals: 0.011\n",
      "Loss: 87.368, Residuals: 0.011\n",
      "Loss: 87.368, Residuals: 0.011\n",
      "Evidence 418.690\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.45e-01\n",
      "Loss: 128.341, Residuals: 0.004\n",
      "Loss: 127.619, Residuals: 0.009\n",
      "Loss: 126.753, Residuals: 0.012\n",
      "Loss: 126.647, Residuals: 0.015\n",
      "Loss: 126.472, Residuals: 0.012\n",
      "Loss: 126.268, Residuals: 0.012\n",
      "Loss: 126.231, Residuals: 0.014\n",
      "Loss: 126.213, Residuals: 0.013\n",
      "Loss: 126.181, Residuals: 0.013\n",
      "Loss: 126.132, Residuals: 0.014\n",
      "Loss: 126.122, Residuals: 0.014\n",
      "Loss: 126.115, Residuals: 0.013\n",
      "Loss: 126.101, Residuals: 0.014\n",
      "Loss: 126.092, Residuals: 0.013\n",
      "Loss: 126.088, Residuals: 0.014\n",
      "Loss: 126.082, Residuals: 0.014\n",
      "Loss: 126.079, Residuals: 0.013\n",
      "Loss: 126.073, Residuals: 0.014\n",
      "Loss: 126.068, Residuals: 0.014\n",
      "Loss: 126.065, Residuals: 0.014\n",
      "Loss: 126.064, Residuals: 0.014\n",
      "Loss: 126.057, Residuals: 0.014\n",
      "Loss: 126.055, Residuals: 0.014\n",
      "Loss: 126.052, Residuals: 0.014\n",
      "Loss: 126.051, Residuals: 0.014\n",
      "Loss: 126.051, Residuals: 0.014\n",
      "Loss: 126.048, Residuals: 0.014\n",
      "Loss: 126.047, Residuals: 0.014\n",
      "Loss: 126.046, Residuals: 0.014\n",
      "Loss: 126.046, Residuals: 0.014\n",
      "Loss: 126.046, Residuals: 0.014\n",
      "Loss: 126.044, Residuals: 0.014\n",
      "Loss: 126.043, Residuals: 0.014\n",
      "Loss: 126.043, Residuals: 0.014\n",
      "Loss: 126.042, Residuals: 0.014\n",
      "Loss: 126.042, Residuals: 0.014\n",
      "Loss: 126.042, Residuals: 0.014\n",
      "Loss: 126.042, Residuals: 0.014\n",
      "Loss: 126.042, Residuals: 0.014\n",
      "Loss: 126.042, Residuals: 0.014\n",
      "Loss: 126.042, Residuals: 0.014\n",
      "Loss: 126.041, Residuals: 0.014\n",
      "Loss: 126.041, Residuals: 0.014\n",
      "Loss: 126.041, Residuals: 0.014\n",
      "Evidence 453.349\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.44e-01\n",
      "Loss: 144.833, Residuals: 0.017\n",
      "Loss: 144.227, Residuals: 0.020\n",
      "Loss: 144.162, Residuals: 0.018\n",
      "Loss: 144.072, Residuals: 0.019\n",
      "Loss: 144.045, Residuals: 0.020\n",
      "Loss: 144.040, Residuals: 0.019\n",
      "Loss: 144.036, Residuals: 0.019\n",
      "Loss: 144.034, Residuals: 0.020\n",
      "Loss: 144.032, Residuals: 0.020\n",
      "Loss: 144.029, Residuals: 0.020\n",
      "Loss: 144.025, Residuals: 0.020\n",
      "Loss: 144.024, Residuals: 0.020\n",
      "Loss: 144.024, Residuals: 0.020\n",
      "Loss: 144.023, Residuals: 0.020\n",
      "Evidence 464.616\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.04e+00\n",
      "Loss: 151.757, Residuals: 0.027\n",
      "Loss: 151.592, Residuals: 0.023\n",
      "Loss: 151.574, Residuals: 0.023\n",
      "Loss: 151.546, Residuals: 0.023\n",
      "Loss: 151.530, Residuals: 0.024\n",
      "Loss: 151.527, Residuals: 0.024\n",
      "Loss: 151.523, Residuals: 0.024\n",
      "Loss: 151.517, Residuals: 0.024\n",
      "Loss: 151.516, Residuals: 0.024\n",
      "Loss: 151.516, Residuals: 0.024\n",
      "Loss: 151.515, Residuals: 0.024\n",
      "Loss: 151.515, Residuals: 0.024\n",
      "Evidence 467.648\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.08e+00\n",
      "Loss: 154.396, Residuals: 0.029\n",
      "Loss: 154.324, Residuals: 0.026\n",
      "Loss: 154.302, Residuals: 0.027\n",
      "Loss: 154.299, Residuals: 0.026\n",
      "Loss: 154.294, Residuals: 0.026\n",
      "Loss: 154.287, Residuals: 0.026\n",
      "Loss: 154.287, Residuals: 0.026\n",
      "Loss: 154.286, Residuals: 0.026\n",
      "Loss: 154.284, Residuals: 0.027\n",
      "Loss: 154.284, Residuals: 0.027\n",
      "Loss: 154.284, Residuals: 0.027\n",
      "Loss: 154.284, Residuals: 0.027\n",
      "Loss: 154.284, Residuals: 0.027\n",
      "Loss: 154.284, Residuals: 0.027\n",
      "Loss: 154.284, Residuals: 0.027\n",
      "Evidence 468.783\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.10e+00\n",
      "Loss: 155.450, Residuals: 0.029\n",
      "Loss: 155.417, Residuals: 0.027\n",
      "Loss: 155.412, Residuals: 0.027\n",
      "Loss: 155.405, Residuals: 0.028\n",
      "Loss: 155.401, Residuals: 0.028\n",
      "Loss: 155.399, Residuals: 0.028\n",
      "Loss: 155.399, Residuals: 0.028\n",
      "Loss: 155.399, Residuals: 0.028\n",
      "Loss: 155.398, Residuals: 0.028\n",
      "Loss: 155.398, Residuals: 0.028\n",
      "Loss: 155.398, Residuals: 0.028\n",
      "Loss: 155.398, Residuals: 0.028\n",
      "Loss: 155.398, Residuals: 0.028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence 469.375\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.11e+00\n",
      "Loss: 155.953, Residuals: 0.030\n",
      "Loss: 155.948, Residuals: 0.028\n",
      "Loss: 155.941, Residuals: 0.028\n",
      "Loss: 155.938, Residuals: 0.028\n",
      "Loss: 155.938, Residuals: 0.028\n",
      "Loss: 155.937, Residuals: 0.028\n",
      "Loss: 155.936, Residuals: 0.028\n",
      "Loss: 155.936, Residuals: 0.028\n",
      "Evidence 469.729\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 11.182, Residuals: -0.113\n",
      "Loss: 6.586, Residuals: -0.054\n",
      "Loss: 4.835, Residuals: -0.064\n",
      "Loss: 4.386, Residuals: -0.070\n",
      "Loss: 4.094, Residuals: -0.061\n",
      "Loss: 3.818, Residuals: -0.055\n",
      "Loss: 3.733, Residuals: -0.048\n",
      "Loss: 3.581, Residuals: -0.056\n",
      "Loss: 3.549, Residuals: -0.008\n",
      "Loss: 3.286, Residuals: -0.025\n",
      "Loss: 3.201, Residuals: 0.048\n",
      "Loss: 3.043, Residuals: 0.039\n",
      "Loss: 2.854, Residuals: 0.037\n",
      "Loss: 2.839, Residuals: 0.051\n",
      "Loss: 2.811, Residuals: 0.047\n",
      "Loss: 2.760, Residuals: 0.039\n",
      "Loss: 2.671, Residuals: 0.025\n",
      "Loss: 2.640, Residuals: 0.024\n",
      "Loss: 2.633, Residuals: 0.046\n",
      "Loss: 2.580, Residuals: 0.031\n",
      "Loss: 2.497, Residuals: 0.004\n",
      "Loss: 2.491, Residuals: 0.010\n",
      "Loss: 2.440, Residuals: 0.008\n",
      "Loss: 2.438, Residuals: 0.003\n",
      "Loss: 2.425, Residuals: 0.002\n",
      "Loss: 2.400, Residuals: -0.003\n",
      "Loss: 2.353, Residuals: -0.011\n",
      "Loss: 2.349, Residuals: -0.005\n",
      "Loss: 2.311, Residuals: -0.011\n",
      "Loss: 2.311, Residuals: -0.007\n",
      "Loss: 2.290, Residuals: -0.013\n",
      "Loss: 2.286, Residuals: -0.014\n",
      "Loss: 2.262, Residuals: -0.022\n",
      "Loss: 2.251, Residuals: -0.007\n",
      "Loss: 2.248, Residuals: -0.019\n",
      "Loss: 2.243, Residuals: -0.019\n",
      "Loss: 2.240, Residuals: -0.014\n",
      "Loss: 2.234, Residuals: -0.015\n",
      "Loss: 2.234, Residuals: -0.013\n",
      "Loss: 2.228, Residuals: -0.017\n",
      "Loss: 2.220, Residuals: -0.021\n",
      "Loss: 2.220, Residuals: -0.021\n",
      "Loss: 2.219, Residuals: -0.021\n",
      "Loss: 2.217, Residuals: -0.023\n",
      "Loss: 2.216, Residuals: -0.022\n",
      "Loss: 2.210, Residuals: -0.026\n",
      "Loss: 2.210, Residuals: -0.026\n",
      "Loss: 2.210, Residuals: -0.025\n",
      "Loss: 2.209, Residuals: -0.026\n",
      "Loss: 2.208, Residuals: -0.028\n",
      "Loss: 2.208, Residuals: -0.027\n",
      "Loss: 2.204, Residuals: -0.028\n",
      "Loss: 2.204, Residuals: -0.029\n",
      "Loss: 2.204, Residuals: -0.028\n",
      "Loss: 2.202, Residuals: -0.029\n",
      "Loss: 2.202, Residuals: -0.028\n",
      "Loss: 2.198, Residuals: -0.030\n",
      "Loss: 2.197, Residuals: -0.030\n",
      "Loss: 2.197, Residuals: -0.029\n",
      "Loss: 2.192, Residuals: -0.028\n",
      "Loss: 2.192, Residuals: -0.028\n",
      "Loss: 2.192, Residuals: -0.028\n",
      "Loss: 2.186, Residuals: -0.029\n",
      "Loss: 2.185, Residuals: -0.030\n",
      "Loss: 2.185, Residuals: -0.030\n",
      "Loss: 2.184, Residuals: -0.028\n",
      "Loss: 2.184, Residuals: -0.028\n",
      "Loss: 2.183, Residuals: -0.027\n",
      "Loss: 2.182, Residuals: -0.025\n",
      "Loss: 2.182, Residuals: -0.025\n",
      "Loss: 2.174, Residuals: -0.030\n",
      "Loss: 2.174, Residuals: -0.030\n",
      "Loss: 2.174, Residuals: -0.031\n",
      "Loss: 2.174, Residuals: -0.029\n",
      "Loss: 2.173, Residuals: -0.029\n",
      "Loss: 2.172, Residuals: -0.027\n",
      "Loss: 2.172, Residuals: -0.026\n",
      "Loss: 2.170, Residuals: -0.027\n",
      "Loss: 2.170, Residuals: -0.027\n",
      "Evidence -370.854\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.93e-03\n",
      "Loss: 9.430, Residuals: -0.028\n",
      "Loss: 9.370, Residuals: -0.026\n",
      "Loss: 9.271, Residuals: -0.025\n",
      "Loss: 9.201, Residuals: -0.011\n",
      "Loss: 9.187, Residuals: -0.015\n",
      "Loss: 9.166, Residuals: -0.013\n",
      "Loss: 9.129, Residuals: -0.013\n",
      "Loss: 9.113, Residuals: -0.011\n",
      "Loss: 9.087, Residuals: -0.010\n",
      "Loss: 9.046, Residuals: -0.009\n",
      "Loss: 9.044, Residuals: -0.012\n",
      "Loss: 9.025, Residuals: -0.009\n",
      "Loss: 9.020, Residuals: -0.005\n",
      "Loss: 9.018, Residuals: -0.009\n",
      "Loss: 9.017, Residuals: -0.008\n",
      "Loss: 8.981, Residuals: -0.006\n",
      "Loss: 8.947, Residuals: -0.004\n",
      "Loss: 8.945, Residuals: -0.007\n",
      "Loss: 8.942, Residuals: -0.007\n",
      "Loss: 8.937, Residuals: -0.007\n",
      "Loss: 8.931, Residuals: -0.007\n",
      "Loss: 8.926, Residuals: -0.009\n",
      "Loss: 8.902, Residuals: -0.015\n",
      "Loss: 8.870, Residuals: -0.013\n",
      "Loss: 8.853, Residuals: -0.008\n",
      "Loss: 8.844, Residuals: -0.008\n",
      "Loss: 8.833, Residuals: -0.010\n",
      "Loss: 8.831, Residuals: -0.009\n",
      "Loss: 8.817, Residuals: -0.009\n",
      "Loss: 8.817, Residuals: -0.009\n",
      "Loss: 8.799, Residuals: -0.007\n",
      "Loss: 8.799, Residuals: -0.008\n",
      "Loss: 8.798, Residuals: -0.008\n",
      "Loss: 8.798, Residuals: -0.008\n",
      "Loss: 8.795, Residuals: -0.007\n",
      "Loss: 8.794, Residuals: -0.007\n",
      "Loss: 8.788, Residuals: -0.006\n",
      "Loss: 8.788, Residuals: -0.006\n",
      "Loss: 8.785, Residuals: -0.006\n",
      "Loss: 8.785, Residuals: -0.006\n",
      "Loss: 8.784, Residuals: -0.006\n",
      "Loss: 8.782, Residuals: -0.006\n",
      "Loss: 8.782, Residuals: -0.006\n",
      "Loss: 8.781, Residuals: -0.006\n",
      "Loss: 8.780, Residuals: -0.006\n",
      "Loss: 8.780, Residuals: -0.006\n",
      "Loss: 8.779, Residuals: -0.005\n",
      "Loss: 8.779, Residuals: -0.005\n",
      "Loss: 8.778, Residuals: -0.005\n",
      "Loss: 8.778, Residuals: -0.005\n",
      "Loss: 8.778, Residuals: -0.005\n",
      "Loss: 8.778, Residuals: -0.005\n",
      "Loss: 8.778, Residuals: -0.005\n",
      "Loss: 8.778, Residuals: -0.005\n",
      "Loss: 8.777, Residuals: -0.005\n",
      "Loss: 8.777, Residuals: -0.005\n",
      "Loss: 8.777, Residuals: -0.005\n",
      "Loss: 8.777, Residuals: -0.005\n",
      "Evidence 77.939\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.56e-02\n",
      "Loss: 35.445, Residuals: -0.009\n",
      "Loss: 35.302, Residuals: -0.009\n",
      "Loss: 35.097, Residuals: -0.009\n",
      "Loss: 35.055, Residuals: -0.000\n",
      "Loss: 34.976, Residuals: -0.000\n",
      "Loss: 34.839, Residuals: -0.001\n",
      "Loss: 34.827, Residuals: -0.005\n",
      "Loss: 34.715, Residuals: -0.003\n",
      "Loss: 34.547, Residuals: 0.001\n",
      "Loss: 34.510, Residuals: -0.001\n",
      "Loss: 34.461, Residuals: -0.000\n",
      "Loss: 34.457, Residuals: -0.003\n",
      "Loss: 34.310, Residuals: -0.001\n",
      "Loss: 34.138, Residuals: 0.002\n",
      "Loss: 34.130, Residuals: 0.001\n",
      "Loss: 33.878, Residuals: 0.004\n",
      "Loss: 33.861, Residuals: 0.006\n",
      "Loss: 33.829, Residuals: 0.006\n",
      "Loss: 33.768, Residuals: 0.007\n",
      "Loss: 33.738, Residuals: 0.008\n",
      "Loss: 33.734, Residuals: 0.010\n",
      "Loss: 33.178, Residuals: 0.013\n",
      "Loss: 33.156, Residuals: 0.011\n",
      "Loss: 33.123, Residuals: 0.012\n",
      "Loss: 33.077, Residuals: 0.013\n",
      "Loss: 33.009, Residuals: 0.016\n",
      "Loss: 32.929, Residuals: 0.017\n",
      "Loss: 32.925, Residuals: 0.016\n",
      "Loss: 32.889, Residuals: 0.017\n",
      "Loss: 32.888, Residuals: 0.017\n",
      "Loss: 32.729, Residuals: 0.023\n",
      "Loss: 32.717, Residuals: 0.021\n",
      "Loss: 32.706, Residuals: 0.021\n",
      "Loss: 32.685, Residuals: 0.021\n",
      "Loss: 32.648, Residuals: 0.022\n",
      "Loss: 32.613, Residuals: 0.022\n",
      "Loss: 32.612, Residuals: 0.022\n",
      "Loss: 32.596, Residuals: 0.022\n",
      "Loss: 32.581, Residuals: 0.023\n",
      "Loss: 32.580, Residuals: 0.022\n",
      "Loss: 32.579, Residuals: 0.022\n",
      "Loss: 32.567, Residuals: 0.022\n",
      "Loss: 32.566, Residuals: 0.022\n",
      "Loss: 32.553, Residuals: 0.022\n",
      "Loss: 32.552, Residuals: 0.022\n",
      "Loss: 32.547, Residuals: 0.022\n",
      "Loss: 32.546, Residuals: 0.022\n",
      "Loss: 32.544, Residuals: 0.022\n",
      "Loss: 32.540, Residuals: 0.022\n",
      "Loss: 32.540, Residuals: 0.022\n",
      "Loss: 32.537, Residuals: 0.022\n",
      "Loss: 32.533, Residuals: 0.022\n",
      "Loss: 32.532, Residuals: 0.023\n",
      "Loss: 32.531, Residuals: 0.023\n",
      "Loss: 32.529, Residuals: 0.022\n",
      "Loss: 32.528, Residuals: 0.022\n",
      "Loss: 32.527, Residuals: 0.022\n",
      "Loss: 32.526, Residuals: 0.022\n",
      "Loss: 32.524, Residuals: 0.022\n",
      "Loss: 32.524, Residuals: 0.022\n",
      "Loss: 32.522, Residuals: 0.022\n",
      "Loss: 32.521, Residuals: 0.022\n",
      "Loss: 32.519, Residuals: 0.022\n",
      "Loss: 32.519, Residuals: 0.022\n",
      "Loss: 32.517, Residuals: 0.022\n",
      "Loss: 32.517, Residuals: 0.022\n",
      "Loss: 32.517, Residuals: 0.022\n",
      "Loss: 32.513, Residuals: 0.022\n",
      "Loss: 32.513, Residuals: 0.022\n",
      "Loss: 32.512, Residuals: 0.022\n",
      "Loss: 32.511, Residuals: 0.022\n",
      "Loss: 32.511, Residuals: 0.022\n",
      "Loss: 32.509, Residuals: 0.022\n",
      "Loss: 32.509, Residuals: 0.022\n",
      "Loss: 32.508, Residuals: 0.022\n",
      "Loss: 32.507, Residuals: 0.022\n",
      "Loss: 32.506, Residuals: 0.021\n",
      "Loss: 32.506, Residuals: 0.021\n",
      "Loss: 32.506, Residuals: 0.021\n",
      "Loss: 32.505, Residuals: 0.021\n",
      "Loss: 32.504, Residuals: 0.021\n",
      "Loss: 32.503, Residuals: 0.021\n",
      "Loss: 32.503, Residuals: 0.021\n",
      "Loss: 32.501, Residuals: 0.021\n",
      "Loss: 32.500, Residuals: 0.021\n",
      "Loss: 32.500, Residuals: 0.021\n",
      "Loss: 32.499, Residuals: 0.021\n",
      "Loss: 32.499, Residuals: 0.021\n",
      "Loss: 32.497, Residuals: 0.021\n",
      "Loss: 32.495, Residuals: 0.021\n",
      "Loss: 32.494, Residuals: 0.021\n",
      "Loss: 32.494, Residuals: 0.021\n",
      "Loss: 32.493, Residuals: 0.021\n",
      "Loss: 32.492, Residuals: 0.021\n",
      "Loss: 32.491, Residuals: 0.021\n",
      "Loss: 32.489, Residuals: 0.021\n",
      "Loss: 32.488, Residuals: 0.021\n",
      "Loss: 32.484, Residuals: 0.021\n",
      "Loss: 32.484, Residuals: 0.021\n",
      "Loss: 32.482, Residuals: 0.021\n",
      "Loss: 32.480, Residuals: 0.021\n",
      "Loss: 32.480, Residuals: 0.021\n",
      "Loss: 32.475, Residuals: 0.021\n",
      "Loss: 32.474, Residuals: 0.020\n",
      "Loss: 32.472, Residuals: 0.020\n",
      "Loss: 32.469, Residuals: 0.020\n",
      "Loss: 32.469, Residuals: 0.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 32.463, Residuals: 0.020\n",
      "Loss: 32.462, Residuals: 0.020\n",
      "Loss: 32.452, Residuals: 0.020\n",
      "Loss: 32.450, Residuals: 0.021\n",
      "Loss: 32.447, Residuals: 0.020\n",
      "Loss: 32.442, Residuals: 0.020\n",
      "Loss: 32.441, Residuals: 0.020\n",
      "Loss: 32.432, Residuals: 0.020\n",
      "Loss: 32.428, Residuals: 0.020\n",
      "Loss: 32.421, Residuals: 0.020\n",
      "Loss: 32.420, Residuals: 0.020\n",
      "Loss: 32.397, Residuals: 0.019\n",
      "Loss: 32.391, Residuals: 0.020\n",
      "Loss: 32.390, Residuals: 0.019\n",
      "Loss: 32.376, Residuals: 0.019\n",
      "Loss: 32.372, Residuals: 0.019\n",
      "Loss: 32.371, Residuals: 0.019\n",
      "Loss: 32.361, Residuals: 0.019\n",
      "Loss: 32.358, Residuals: 0.019\n",
      "Loss: 32.357, Residuals: 0.019\n",
      "Loss: 32.356, Residuals: 0.019\n",
      "Loss: 32.345, Residuals: 0.019\n",
      "Loss: 32.343, Residuals: 0.019\n",
      "Loss: 32.332, Residuals: 0.019\n",
      "Loss: 32.329, Residuals: 0.018\n",
      "Loss: 32.328, Residuals: 0.018\n",
      "Loss: 32.322, Residuals: 0.018\n",
      "Loss: 32.322, Residuals: 0.019\n",
      "Loss: 32.318, Residuals: 0.019\n",
      "Loss: 32.312, Residuals: 0.018\n",
      "Loss: 32.311, Residuals: 0.018\n",
      "Loss: 32.309, Residuals: 0.018\n",
      "Loss: 32.304, Residuals: 0.018\n",
      "Loss: 32.303, Residuals: 0.018\n",
      "Evidence 292.769\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.36e-01\n",
      "Loss: 78.792, Residuals: 0.012\n",
      "Loss: 78.656, Residuals: 0.019\n",
      "Loss: 78.422, Residuals: 0.019\n",
      "Loss: 78.125, Residuals: 0.021\n",
      "Loss: 78.093, Residuals: 0.017\n",
      "Loss: 78.081, Residuals: 0.018\n",
      "Loss: 77.983, Residuals: 0.019\n",
      "Loss: 77.977, Residuals: 0.020\n",
      "Loss: 77.922, Residuals: 0.020\n",
      "Loss: 77.847, Residuals: 0.021\n",
      "Loss: 77.846, Residuals: 0.021\n",
      "Loss: 77.844, Residuals: 0.021\n",
      "Loss: 77.822, Residuals: 0.021\n",
      "Loss: 77.783, Residuals: 0.021\n",
      "Loss: 77.782, Residuals: 0.021\n",
      "Loss: 77.779, Residuals: 0.021\n",
      "Loss: 77.749, Residuals: 0.020\n",
      "Loss: 77.747, Residuals: 0.020\n",
      "Loss: 77.746, Residuals: 0.020\n",
      "Loss: 77.737, Residuals: 0.020\n",
      "Loss: 77.737, Residuals: 0.020\n",
      "Loss: 77.736, Residuals: 0.020\n",
      "Loss: 77.725, Residuals: 0.020\n",
      "Loss: 77.725, Residuals: 0.020\n",
      "Loss: 77.708, Residuals: 0.020\n",
      "Loss: 77.708, Residuals: 0.020\n",
      "Evidence 417.958\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.57e-01\n",
      "Loss: 121.263, Residuals: 0.021\n",
      "Loss: 121.125, Residuals: 0.020\n",
      "Loss: 120.890, Residuals: 0.019\n",
      "Loss: 120.630, Residuals: 0.017\n",
      "Loss: 120.580, Residuals: 0.014\n",
      "Loss: 120.491, Residuals: 0.015\n",
      "Loss: 120.361, Residuals: 0.017\n",
      "Loss: 120.348, Residuals: 0.018\n",
      "Loss: 120.323, Residuals: 0.018\n",
      "Loss: 120.279, Residuals: 0.018\n",
      "Loss: 120.277, Residuals: 0.018\n",
      "Loss: 120.260, Residuals: 0.018\n",
      "Loss: 120.230, Residuals: 0.018\n",
      "Loss: 120.229, Residuals: 0.018\n",
      "Loss: 120.205, Residuals: 0.018\n",
      "Loss: 120.163, Residuals: 0.018\n",
      "Loss: 120.163, Residuals: 0.018\n",
      "Evidence 457.746\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.68e-01\n",
      "Loss: 141.238, Residuals: 0.018\n",
      "Loss: 141.140, Residuals: 0.018\n",
      "Loss: 140.987, Residuals: 0.018\n",
      "Loss: 140.821, Residuals: 0.015\n",
      "Loss: 140.765, Residuals: 0.017\n",
      "Loss: 140.681, Residuals: 0.018\n",
      "Loss: 140.565, Residuals: 0.017\n",
      "Loss: 140.564, Residuals: 0.017\n",
      "Evidence 466.559\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.71e-01\n",
      "Loss: 147.820, Residuals: 0.016\n",
      "Loss: 147.682, Residuals: 0.016\n",
      "Loss: 147.538, Residuals: 0.018\n",
      "Loss: 147.519, Residuals: 0.016\n",
      "Loss: 146.569, Residuals: 0.019\n",
      "Loss: 146.552, Residuals: 0.019\n",
      "Loss: 146.520, Residuals: 0.019\n",
      "Loss: 146.462, Residuals: 0.018\n",
      "Loss: 146.375, Residuals: 0.018\n",
      "Loss: 146.229, Residuals: 0.018\n",
      "Loss: 146.030, Residuals: 0.018\n",
      "Loss: 146.009, Residuals: 0.016\n",
      "Loss: 145.252, Residuals: 0.017\n",
      "Loss: 145.243, Residuals: 0.017\n",
      "Loss: 145.161, Residuals: 0.017\n",
      "Loss: 145.060, Residuals: 0.017\n",
      "Loss: 145.031, Residuals: 0.016\n",
      "Loss: 145.025, Residuals: 0.016\n",
      "Loss: 144.786, Residuals: 0.016\n",
      "Loss: 144.582, Residuals: 0.017\n",
      "Loss: 144.534, Residuals: 0.019\n",
      "Loss: 144.516, Residuals: 0.016\n",
      "Loss: 144.482, Residuals: 0.016\n",
      "Loss: 144.418, Residuals: 0.017\n",
      "Loss: 144.378, Residuals: 0.017\n",
      "Loss: 144.319, Residuals: 0.017\n",
      "Loss: 144.303, Residuals: 0.016\n",
      "Loss: 144.271, Residuals: 0.016\n",
      "Loss: 144.214, Residuals: 0.016\n",
      "Loss: 144.186, Residuals: 0.015\n",
      "Loss: 144.180, Residuals: 0.016\n",
      "Loss: 144.122, Residuals: 0.016\n",
      "Loss: 144.053, Residuals: 0.015\n",
      "Loss: 144.046, Residuals: 0.015\n",
      "Loss: 144.044, Residuals: 0.015\n",
      "Loss: 144.040, Residuals: 0.015\n",
      "Loss: 144.034, Residuals: 0.015\n",
      "Loss: 144.034, Residuals: 0.016\n",
      "Loss: 144.031, Residuals: 0.015\n",
      "Loss: 144.027, Residuals: 0.015\n",
      "Loss: 144.025, Residuals: 0.015\n",
      "Loss: 144.025, Residuals: 0.015\n",
      "Loss: 144.023, Residuals: 0.015\n",
      "Loss: 144.022, Residuals: 0.015\n",
      "Loss: 144.021, Residuals: 0.015\n",
      "Loss: 144.021, Residuals: 0.015\n",
      "Loss: 144.020, Residuals: 0.015\n",
      "Loss: 144.020, Residuals: 0.015\n",
      "Evidence 470.689\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.85e-01\n",
      "Loss: 147.108, Residuals: 0.024\n",
      "Loss: 146.362, Residuals: 0.022\n",
      "Loss: 146.198, Residuals: 0.016\n",
      "Loss: 145.937, Residuals: 0.015\n",
      "Loss: 145.639, Residuals: 0.013\n",
      "Loss: 145.629, Residuals: 0.013\n",
      "Loss: 145.620, Residuals: 0.013\n",
      "Loss: 145.611, Residuals: 0.012\n",
      "Loss: 145.610, Residuals: 0.012\n",
      "Loss: 145.605, Residuals: 0.012\n",
      "Loss: 145.597, Residuals: 0.012\n",
      "Loss: 145.596, Residuals: 0.012\n",
      "Loss: 145.595, Residuals: 0.012\n",
      "Loss: 145.584, Residuals: 0.012\n",
      "Loss: 145.584, Residuals: 0.012\n",
      "Loss: 145.583, Residuals: 0.012\n",
      "Loss: 145.583, Residuals: 0.012\n",
      "Loss: 145.583, Residuals: 0.012\n",
      "Loss: 145.579, Residuals: 0.012\n",
      "Loss: 145.579, Residuals: 0.013\n",
      "Evidence 477.922\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.98e-01\n",
      "Loss: 148.405, Residuals: 0.018\n",
      "Loss: 148.183, Residuals: 0.015\n",
      "Loss: 147.907, Residuals: 0.011\n",
      "Loss: 147.890, Residuals: 0.010\n",
      "Loss: 147.859, Residuals: 0.010\n",
      "Loss: 147.813, Residuals: 0.011\n",
      "Loss: 147.809, Residuals: 0.011\n",
      "Loss: 147.801, Residuals: 0.011\n",
      "Loss: 147.786, Residuals: 0.011\n",
      "Loss: 147.773, Residuals: 0.010\n",
      "Loss: 147.771, Residuals: 0.010\n",
      "Loss: 147.771, Residuals: 0.010\n",
      "Loss: 147.755, Residuals: 0.010\n",
      "Loss: 147.755, Residuals: 0.010\n",
      "Loss: 147.739, Residuals: 0.011\n",
      "Loss: 147.737, Residuals: 0.010\n",
      "Loss: 147.737, Residuals: 0.010\n",
      "Loss: 147.736, Residuals: 0.010\n",
      "Loss: 147.732, Residuals: 0.010\n",
      "Loss: 147.732, Residuals: 0.011\n",
      "Loss: 147.730, Residuals: 0.011\n",
      "Loss: 147.728, Residuals: 0.011\n",
      "Loss: 147.727, Residuals: 0.011\n",
      "Loss: 147.727, Residuals: 0.011\n",
      "Loss: 147.726, Residuals: 0.011\n",
      "Loss: 147.726, Residuals: 0.011\n",
      "Evidence 481.120\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.25e-01\n",
      "Loss: 149.397, Residuals: 0.012\n",
      "Loss: 149.222, Residuals: 0.009\n",
      "Loss: 149.205, Residuals: 0.010\n",
      "Loss: 149.175, Residuals: 0.010\n",
      "Loss: 149.133, Residuals: 0.009\n",
      "Loss: 149.132, Residuals: 0.010\n",
      "Loss: 149.127, Residuals: 0.010\n",
      "Loss: 149.118, Residuals: 0.009\n",
      "Loss: 149.116, Residuals: 0.009\n",
      "Loss: 149.112, Residuals: 0.009\n",
      "Loss: 149.105, Residuals: 0.009\n",
      "Loss: 149.104, Residuals: 0.009\n",
      "Loss: 149.094, Residuals: 0.009\n",
      "Loss: 149.093, Residuals: 0.009\n",
      "Loss: 149.086, Residuals: 0.009\n",
      "Loss: 149.086, Residuals: 0.009\n",
      "Loss: 149.078, Residuals: 0.009\n",
      "Loss: 149.077, Residuals: 0.009\n",
      "Loss: 149.077, Residuals: 0.009\n",
      "Loss: 149.077, Residuals: 0.009\n",
      "Loss: 149.076, Residuals: 0.009\n",
      "Loss: 149.076, Residuals: 0.009\n",
      "Loss: 149.076, Residuals: 0.009\n",
      "Evidence 483.024\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.40e-01\n",
      "Loss: 149.950, Residuals: 0.010\n",
      "Loss: 149.900, Residuals: 0.008\n",
      "Loss: 149.826, Residuals: 0.008\n",
      "Loss: 149.822, Residuals: 0.009\n",
      "Loss: 149.814, Residuals: 0.009\n",
      "Loss: 149.807, Residuals: 0.008\n",
      "Loss: 149.806, Residuals: 0.008\n",
      "Loss: 149.796, Residuals: 0.008\n",
      "Loss: 149.780, Residuals: 0.007\n",
      "Loss: 149.779, Residuals: 0.007\n",
      "Loss: 149.776, Residuals: 0.008\n",
      "Loss: 149.776, Residuals: 0.008\n",
      "Loss: 149.770, Residuals: 0.008\n",
      "Loss: 149.760, Residuals: 0.008\n",
      "Loss: 149.759, Residuals: 0.008\n",
      "Loss: 149.758, Residuals: 0.008\n",
      "Loss: 149.756, Residuals: 0.008\n",
      "Loss: 149.753, Residuals: 0.007\n",
      "Loss: 149.753, Residuals: 0.007\n",
      "Loss: 149.752, Residuals: 0.007\n",
      "Loss: 149.752, Residuals: 0.008\n",
      "Loss: 149.746, Residuals: 0.008\n",
      "Loss: 149.746, Residuals: 0.008\n",
      "Loss: 149.746, Residuals: 0.008\n",
      "Loss: 149.741, Residuals: 0.008\n",
      "Loss: 149.732, Residuals: 0.008\n",
      "Loss: 149.732, Residuals: 0.008\n",
      "Loss: 149.726, Residuals: 0.008\n",
      "Loss: 149.725, Residuals: 0.008\n",
      "Loss: 149.725, Residuals: 0.008\n",
      "Loss: 149.725, Residuals: 0.008\n",
      "Loss: 149.725, Residuals: 0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence 484.127\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.55e-01\n",
      "Loss: 150.246, Residuals: 0.008\n",
      "Loss: 150.214, Residuals: 0.007\n",
      "Loss: 150.165, Residuals: 0.007\n",
      "Loss: 150.163, Residuals: 0.008\n",
      "Loss: 150.145, Residuals: 0.008\n",
      "Loss: 150.126, Residuals: 0.007\n",
      "Loss: 150.124, Residuals: 0.007\n",
      "Loss: 150.119, Residuals: 0.007\n",
      "Loss: 150.118, Residuals: 0.007\n",
      "Loss: 150.112, Residuals: 0.007\n",
      "Loss: 150.112, Residuals: 0.007\n",
      "Loss: 150.109, Residuals: 0.007\n",
      "Loss: 150.108, Residuals: 0.007\n",
      "Loss: 150.105, Residuals: 0.007\n",
      "Loss: 150.105, Residuals: 0.007\n",
      "Evidence 485.050\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.59e-01\n",
      "Loss: 150.502, Residuals: 0.008\n",
      "Loss: 150.484, Residuals: 0.008\n",
      "Loss: 150.456, Residuals: 0.007\n",
      "Loss: 150.437, Residuals: 0.006\n",
      "Loss: 150.436, Residuals: 0.007\n",
      "Loss: 150.425, Residuals: 0.007\n",
      "Loss: 150.421, Residuals: 0.006\n",
      "Loss: 150.420, Residuals: 0.006\n",
      "Loss: 150.420, Residuals: 0.006\n",
      "Loss: 150.419, Residuals: 0.006\n",
      "Loss: 150.419, Residuals: 0.006\n",
      "Loss: 150.417, Residuals: 0.006\n",
      "Loss: 150.413, Residuals: 0.006\n",
      "Loss: 150.413, Residuals: 0.006\n",
      "Loss: 150.413, Residuals: 0.006\n",
      "Evidence 485.699\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.62e-01\n",
      "Loss: 150.732, Residuals: 0.007\n",
      "Loss: 150.720, Residuals: 0.007\n",
      "Loss: 150.702, Residuals: 0.007\n",
      "Loss: 150.691, Residuals: 0.006\n",
      "Loss: 150.690, Residuals: 0.006\n",
      "Loss: 150.681, Residuals: 0.006\n",
      "Loss: 150.680, Residuals: 0.006\n",
      "Loss: 150.675, Residuals: 0.006\n",
      "Loss: 150.675, Residuals: 0.006\n",
      "Loss: 150.674, Residuals: 0.006\n",
      "Loss: 150.674, Residuals: 0.006\n",
      "Loss: 150.674, Residuals: 0.006\n",
      "Loss: 150.674, Residuals: 0.006\n",
      "Loss: 150.672, Residuals: 0.006\n",
      "Loss: 150.672, Residuals: 0.006\n",
      "Loss: 150.672, Residuals: 0.006\n",
      "Evidence 486.159\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 11.745, Residuals: -0.157\n",
      "Loss: 7.003, Residuals: -0.077\n",
      "Loss: 5.333, Residuals: -0.074\n",
      "Loss: 4.887, Residuals: -0.048\n",
      "Loss: 4.256, Residuals: -0.059\n",
      "Loss: 3.712, Residuals: -0.038\n",
      "Loss: 3.564, Residuals: -0.018\n",
      "Loss: 3.324, Residuals: -0.028\n",
      "Loss: 3.217, Residuals: -0.025\n",
      "Loss: 3.077, Residuals: -0.038\n",
      "Loss: 3.061, Residuals: -0.024\n",
      "Loss: 3.032, Residuals: -0.030\n",
      "Loss: 2.983, Residuals: -0.045\n",
      "Loss: 2.976, Residuals: -0.031\n",
      "Loss: 2.913, Residuals: -0.048\n",
      "Loss: 2.695, Residuals: 0.007\n",
      "Loss: 2.660, Residuals: -0.005\n",
      "Loss: 2.611, Residuals: -0.002\n",
      "Loss: 2.534, Residuals: -0.010\n",
      "Loss: 2.515, Residuals: -0.006\n",
      "Loss: 2.482, Residuals: -0.009\n",
      "Loss: 2.434, Residuals: -0.017\n",
      "Loss: 2.423, Residuals: -0.024\n",
      "Loss: 2.404, Residuals: -0.027\n",
      "Loss: 2.397, Residuals: -0.027\n",
      "Loss: 2.394, Residuals: -0.032\n",
      "Loss: 2.387, Residuals: -0.033\n",
      "Loss: 2.377, Residuals: -0.035\n",
      "Loss: 2.376, Residuals: -0.034\n",
      "Loss: 2.370, Residuals: -0.035\n",
      "Loss: 2.361, Residuals: -0.037\n",
      "Loss: 2.348, Residuals: -0.044\n",
      "Loss: 2.348, Residuals: -0.045\n",
      "Loss: 2.345, Residuals: -0.045\n",
      "Loss: 2.341, Residuals: -0.048\n",
      "Loss: 2.334, Residuals: -0.049\n",
      "Loss: 2.332, Residuals: -0.051\n",
      "Loss: 2.328, Residuals: -0.053\n",
      "Loss: 2.323, Residuals: -0.056\n",
      "Loss: 2.322, Residuals: -0.056\n",
      "Loss: 2.319, Residuals: -0.057\n",
      "Loss: 2.314, Residuals: -0.059\n",
      "Loss: 2.313, Residuals: -0.058\n",
      "Loss: 2.311, Residuals: -0.059\n",
      "Loss: 2.307, Residuals: -0.061\n",
      "Loss: 2.306, Residuals: -0.061\n",
      "Loss: 2.304, Residuals: -0.062\n",
      "Loss: 2.301, Residuals: -0.062\n",
      "Loss: 2.295, Residuals: -0.067\n",
      "Loss: 2.294, Residuals: -0.066\n",
      "Loss: 2.292, Residuals: -0.066\n",
      "Loss: 2.290, Residuals: -0.068\n",
      "Loss: 2.290, Residuals: -0.067\n",
      "Loss: 2.283, Residuals: -0.068\n",
      "Loss: 2.283, Residuals: -0.068\n",
      "Loss: 2.282, Residuals: -0.068\n",
      "Loss: 2.274, Residuals: -0.070\n",
      "Loss: 2.274, Residuals: -0.069\n",
      "Loss: 2.274, Residuals: -0.069\n",
      "Loss: 2.273, Residuals: -0.069\n",
      "Loss: 2.272, Residuals: -0.070\n",
      "Loss: 2.271, Residuals: -0.070\n",
      "Loss: 2.271, Residuals: -0.070\n",
      "Loss: 2.265, Residuals: -0.071\n",
      "Loss: 2.265, Residuals: -0.071\n",
      "Loss: 2.263, Residuals: -0.072\n",
      "Loss: 2.261, Residuals: -0.073\n",
      "Loss: 2.261, Residuals: -0.074\n",
      "Loss: 2.258, Residuals: -0.075\n",
      "Loss: 2.258, Residuals: -0.074\n",
      "Loss: 2.255, Residuals: -0.075\n",
      "Loss: 2.255, Residuals: -0.076\n",
      "Loss: 2.255, Residuals: -0.075\n",
      "Loss: 2.253, Residuals: -0.075\n",
      "Loss: 2.253, Residuals: -0.075\n",
      "Loss: 2.253, Residuals: -0.075\n",
      "Loss: 2.250, Residuals: -0.076\n",
      "Loss: 2.249, Residuals: -0.076\n",
      "Loss: 2.249, Residuals: -0.076\n",
      "Loss: 2.247, Residuals: -0.077\n",
      "Loss: 2.247, Residuals: -0.076\n",
      "Evidence -390.475\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.16e-03\n",
      "Loss: 10.252, Residuals: -0.063\n",
      "Loss: 10.222, Residuals: -0.052\n",
      "Loss: 10.166, Residuals: -0.051\n",
      "Loss: 10.085, Residuals: -0.046\n",
      "Loss: 10.082, Residuals: -0.040\n",
      "Loss: 10.075, Residuals: -0.042\n",
      "Loss: 10.022, Residuals: -0.039\n",
      "Loss: 10.021, Residuals: -0.042\n",
      "Loss: 9.981, Residuals: -0.039\n",
      "Loss: 9.974, Residuals: -0.036\n",
      "Loss: 9.961, Residuals: -0.035\n",
      "Loss: 9.938, Residuals: -0.034\n",
      "Loss: 9.934, Residuals: -0.033\n",
      "Loss: 9.903, Residuals: -0.033\n",
      "Loss: 9.894, Residuals: -0.031\n",
      "Loss: 9.877, Residuals: -0.030\n",
      "Loss: 9.851, Residuals: -0.027\n",
      "Loss: 9.850, Residuals: -0.027\n",
      "Loss: 9.847, Residuals: -0.027\n",
      "Loss: 9.830, Residuals: -0.026\n",
      "Loss: 9.816, Residuals: -0.024\n",
      "Loss: 9.816, Residuals: -0.024\n",
      "Loss: 9.815, Residuals: -0.024\n",
      "Loss: 9.808, Residuals: -0.025\n",
      "Loss: 9.808, Residuals: -0.024\n",
      "Loss: 9.804, Residuals: -0.024\n",
      "Loss: 9.799, Residuals: -0.024\n",
      "Loss: 9.799, Residuals: -0.025\n",
      "Evidence 87.679\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.23e-02\n",
      "Loss: 37.624, Residuals: -0.020\n",
      "Loss: 37.537, Residuals: -0.013\n",
      "Loss: 37.375, Residuals: -0.013\n",
      "Loss: 37.163, Residuals: -0.007\n",
      "Loss: 37.136, Residuals: -0.008\n",
      "Loss: 37.084, Residuals: -0.008\n",
      "Loss: 36.993, Residuals: -0.007\n",
      "Loss: 36.965, Residuals: -0.007\n",
      "Loss: 36.951, Residuals: -0.009\n",
      "Loss: 36.924, Residuals: -0.009\n",
      "Loss: 36.918, Residuals: -0.007\n",
      "Loss: 36.865, Residuals: -0.007\n",
      "Loss: 36.771, Residuals: -0.006\n",
      "Loss: 36.769, Residuals: -0.006\n",
      "Loss: 36.765, Residuals: -0.006\n",
      "Loss: 36.759, Residuals: -0.006\n",
      "Loss: 36.569, Residuals: -0.005\n",
      "Loss: 36.562, Residuals: -0.005\n",
      "Loss: 36.550, Residuals: -0.006\n",
      "Loss: 36.527, Residuals: -0.006\n",
      "Loss: 36.489, Residuals: -0.005\n",
      "Loss: 36.420, Residuals: -0.005\n",
      "Loss: 36.406, Residuals: -0.006\n",
      "Loss: 36.284, Residuals: -0.006\n",
      "Loss: 36.132, Residuals: -0.005\n",
      "Loss: 36.126, Residuals: -0.003\n",
      "Loss: 36.078, Residuals: -0.004\n",
      "Loss: 36.017, Residuals: -0.007\n",
      "Loss: 36.015, Residuals: -0.007\n",
      "Loss: 36.012, Residuals: -0.006\n",
      "Loss: 36.009, Residuals: -0.006\n",
      "Loss: 36.002, Residuals: -0.006\n",
      "Loss: 36.001, Residuals: -0.005\n",
      "Loss: 35.996, Residuals: -0.005\n",
      "Loss: 35.985, Residuals: -0.005\n",
      "Loss: 35.985, Residuals: -0.005\n",
      "Evidence 294.495\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.95e-01\n",
      "Loss: 83.849, Residuals: -0.005\n",
      "Loss: 83.548, Residuals: -0.009\n",
      "Loss: 83.368, Residuals: -0.013\n",
      "Loss: 83.298, Residuals: -0.015\n",
      "Loss: 83.167, Residuals: -0.014\n",
      "Loss: 83.135, Residuals: -0.014\n",
      "Loss: 82.873, Residuals: -0.013\n",
      "Loss: 82.855, Residuals: -0.016\n",
      "Loss: 82.702, Residuals: -0.015\n",
      "Loss: 82.699, Residuals: -0.014\n",
      "Loss: 82.597, Residuals: -0.013\n",
      "Loss: 82.576, Residuals: -0.012\n",
      "Loss: 82.535, Residuals: -0.012\n",
      "Loss: 82.534, Residuals: -0.012\n",
      "Loss: 82.487, Residuals: -0.012\n",
      "Loss: 82.403, Residuals: -0.012\n",
      "Loss: 82.402, Residuals: -0.012\n",
      "Loss: 82.347, Residuals: -0.011\n",
      "Loss: 82.332, Residuals: -0.012\n",
      "Loss: 82.331, Residuals: -0.012\n",
      "Loss: 82.301, Residuals: -0.011\n",
      "Loss: 82.279, Residuals: -0.012\n",
      "Loss: 82.278, Residuals: -0.012\n",
      "Loss: 82.276, Residuals: -0.012\n",
      "Loss: 82.203, Residuals: -0.011\n",
      "Loss: 82.200, Residuals: -0.011\n",
      "Loss: 82.195, Residuals: -0.012\n",
      "Loss: 82.186, Residuals: -0.012\n",
      "Loss: 82.184, Residuals: -0.011\n",
      "Loss: 81.996, Residuals: -0.009\n",
      "Loss: 81.956, Residuals: -0.011\n",
      "Loss: 81.885, Residuals: -0.012\n",
      "Loss: 81.776, Residuals: -0.014\n",
      "Loss: 81.697, Residuals: -0.010\n",
      "Loss: 81.688, Residuals: -0.011\n",
      "Loss: 81.613, Residuals: -0.012\n",
      "Loss: 81.552, Residuals: -0.012\n",
      "Loss: 81.545, Residuals: -0.012\n",
      "Loss: 81.539, Residuals: -0.012\n",
      "Loss: 81.483, Residuals: -0.012\n",
      "Loss: 81.483, Residuals: -0.013\n",
      "Loss: 81.469, Residuals: -0.013\n",
      "Loss: 81.445, Residuals: -0.012\n",
      "Loss: 81.444, Residuals: -0.013\n",
      "Loss: 81.441, Residuals: -0.012\n",
      "Loss: 81.440, Residuals: -0.012\n",
      "Loss: 81.435, Residuals: -0.012\n",
      "Loss: 81.426, Residuals: -0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 81.426, Residuals: -0.012\n",
      "Loss: 81.424, Residuals: -0.012\n",
      "Loss: 81.424, Residuals: -0.012\n",
      "Loss: 81.419, Residuals: -0.012\n",
      "Loss: 81.419, Residuals: -0.012\n",
      "Evidence 414.310\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.23e-01\n",
      "Loss: 123.367, Residuals: -0.015\n",
      "Loss: 122.837, Residuals: -0.018\n",
      "Loss: 121.934, Residuals: -0.019\n",
      "Loss: 121.681, Residuals: -0.025\n",
      "Loss: 121.198, Residuals: -0.024\n",
      "Loss: 120.339, Residuals: -0.023\n",
      "Loss: 120.267, Residuals: -0.022\n",
      "Loss: 119.612, Residuals: -0.021\n",
      "Loss: 119.347, Residuals: -0.020\n",
      "Loss: 118.863, Residuals: -0.021\n",
      "Loss: 118.091, Residuals: -0.020\n",
      "Loss: 118.019, Residuals: -0.021\n",
      "Loss: 117.972, Residuals: -0.020\n",
      "Loss: 117.545, Residuals: -0.018\n",
      "Loss: 117.540, Residuals: -0.018\n",
      "Loss: 117.351, Residuals: -0.017\n",
      "Loss: 117.349, Residuals: -0.018\n",
      "Loss: 117.259, Residuals: -0.017\n",
      "Loss: 117.110, Residuals: -0.015\n",
      "Loss: 117.108, Residuals: -0.015\n",
      "Loss: 117.097, Residuals: -0.015\n",
      "Loss: 117.005, Residuals: -0.014\n",
      "Loss: 116.998, Residuals: -0.015\n",
      "Loss: 116.987, Residuals: -0.015\n",
      "Loss: 116.986, Residuals: -0.015\n",
      "Loss: 116.968, Residuals: -0.014\n",
      "Loss: 116.966, Residuals: -0.014\n",
      "Loss: 116.964, Residuals: -0.014\n",
      "Loss: 116.962, Residuals: -0.014\n",
      "Loss: 116.961, Residuals: -0.014\n",
      "Loss: 116.955, Residuals: -0.014\n",
      "Loss: 116.955, Residuals: -0.014\n",
      "Loss: 116.954, Residuals: -0.014\n",
      "Loss: 116.953, Residuals: -0.014\n",
      "Loss: 116.953, Residuals: -0.014\n",
      "Loss: 116.953, Residuals: -0.014\n",
      "Loss: 116.952, Residuals: -0.014\n",
      "Loss: 116.952, Residuals: -0.013\n",
      "Loss: 116.952, Residuals: -0.014\n",
      "Loss: 116.951, Residuals: -0.013\n",
      "Loss: 116.951, Residuals: -0.013\n",
      "Loss: 116.951, Residuals: -0.013\n",
      "Loss: 116.951, Residuals: -0.013\n",
      "Loss: 116.951, Residuals: -0.013\n",
      "Loss: 116.951, Residuals: -0.013\n",
      "Evidence 463.515\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.41e+00\n",
      "Loss: 140.528, Residuals: -0.011\n",
      "Loss: 139.767, Residuals: -0.015\n",
      "Loss: 139.729, Residuals: -0.015\n",
      "Loss: 139.656, Residuals: -0.014\n",
      "Loss: 139.528, Residuals: -0.014\n",
      "Loss: 139.364, Residuals: -0.013\n",
      "Loss: 139.362, Residuals: -0.012\n",
      "Loss: 139.336, Residuals: -0.012\n",
      "Loss: 139.326, Residuals: -0.012\n",
      "Loss: 139.309, Residuals: -0.012\n",
      "Loss: 139.308, Residuals: -0.012\n",
      "Loss: 139.299, Residuals: -0.012\n",
      "Loss: 139.299, Residuals: -0.012\n",
      "Loss: 139.298, Residuals: -0.012\n",
      "Loss: 139.295, Residuals: -0.012\n",
      "Loss: 139.293, Residuals: -0.012\n",
      "Loss: 139.293, Residuals: -0.012\n",
      "Evidence 484.110\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.63e+00\n",
      "Loss: 150.245, Residuals: -0.009\n",
      "Loss: 150.031, Residuals: -0.013\n",
      "Loss: 149.979, Residuals: -0.011\n",
      "Loss: 149.963, Residuals: -0.013\n",
      "Loss: 149.959, Residuals: -0.012\n",
      "Loss: 149.950, Residuals: -0.012\n",
      "Loss: 149.936, Residuals: -0.012\n",
      "Loss: 149.922, Residuals: -0.012\n",
      "Loss: 149.922, Residuals: -0.012\n",
      "Loss: 149.922, Residuals: -0.012\n",
      "Loss: 149.921, Residuals: -0.012\n",
      "Loss: 149.921, Residuals: -0.012\n",
      "Loss: 149.920, Residuals: -0.012\n",
      "Loss: 149.920, Residuals: -0.012\n",
      "Evidence 488.759\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.66e+00\n",
      "Loss: 153.932, Residuals: -0.010\n",
      "Loss: 153.871, Residuals: -0.012\n",
      "Loss: 153.862, Residuals: -0.012\n",
      "Loss: 153.848, Residuals: -0.012\n",
      "Loss: 153.840, Residuals: -0.013\n",
      "Loss: 153.840, Residuals: -0.012\n",
      "Loss: 153.838, Residuals: -0.012\n",
      "Loss: 153.837, Residuals: -0.012\n",
      "Loss: 153.837, Residuals: -0.013\n",
      "Loss: 153.837, Residuals: -0.013\n",
      "Loss: 153.837, Residuals: -0.013\n",
      "Loss: 153.837, Residuals: -0.013\n",
      "Loss: 153.837, Residuals: -0.013\n",
      "Evidence 490.150\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.66e+00\n",
      "Loss: 155.321, Residuals: -0.011\n",
      "Loss: 155.294, Residuals: -0.012\n",
      "Loss: 155.292, Residuals: -0.012\n",
      "Loss: 155.289, Residuals: -0.012\n",
      "Loss: 155.288, Residuals: -0.012\n",
      "Loss: 155.288, Residuals: -0.012\n",
      "Loss: 155.288, Residuals: -0.012\n",
      "Evidence 490.738\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.66e+00\n",
      "Loss: 155.921, Residuals: -0.011\n",
      "Loss: 155.904, Residuals: -0.012\n",
      "Loss: 155.903, Residuals: -0.012\n",
      "Loss: 155.901, Residuals: -0.012\n",
      "Loss: 155.901, Residuals: -0.012\n",
      "Loss: 155.901, Residuals: -0.012\n",
      "Loss: 155.900, Residuals: -0.012\n",
      "Loss: 155.900, Residuals: -0.012\n",
      "Loss: 155.900, Residuals: -0.012\n",
      "Evidence 491.055\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 11.382, Residuals: -0.101\n",
      "Loss: 6.958, Residuals: -0.058\n",
      "Loss: 4.852, Residuals: -0.070\n",
      "Loss: 4.304, Residuals: -0.048\n",
      "Loss: 4.028, Residuals: -0.025\n",
      "Loss: 3.714, Residuals: -0.051\n",
      "Loss: 3.650, Residuals: -0.023\n",
      "Loss: 3.532, Residuals: -0.025\n",
      "Loss: 3.332, Residuals: -0.031\n",
      "Loss: 3.270, Residuals: -0.016\n",
      "Loss: 3.167, Residuals: -0.031\n",
      "Loss: 3.026, Residuals: -0.059\n",
      "Loss: 3.020, Residuals: -0.056\n",
      "Loss: 3.011, Residuals: -0.051\n",
      "Loss: 2.928, Residuals: -0.064\n",
      "Loss: 2.846, Residuals: 0.004\n",
      "Loss: 2.826, Residuals: -0.008\n",
      "Loss: 2.690, Residuals: -0.003\n",
      "Loss: 2.553, Residuals: -0.004\n",
      "Loss: 2.546, Residuals: -0.007\n",
      "Loss: 2.536, Residuals: -0.011\n",
      "Loss: 2.519, Residuals: -0.014\n",
      "Loss: 2.490, Residuals: -0.019\n",
      "Loss: 2.485, Residuals: -0.027\n",
      "Loss: 2.478, Residuals: -0.023\n",
      "Loss: 2.466, Residuals: -0.025\n",
      "Loss: 2.445, Residuals: -0.029\n",
      "Loss: 2.422, Residuals: -0.044\n",
      "Loss: 2.419, Residuals: -0.037\n",
      "Loss: 2.418, Residuals: -0.043\n",
      "Loss: 2.407, Residuals: -0.045\n",
      "Loss: 2.390, Residuals: -0.049\n",
      "Loss: 2.389, Residuals: -0.052\n",
      "Loss: 2.386, Residuals: -0.054\n",
      "Loss: 2.382, Residuals: -0.055\n",
      "Loss: 2.373, Residuals: -0.057\n",
      "Loss: 2.370, Residuals: -0.057\n",
      "Loss: 2.368, Residuals: -0.058\n",
      "Loss: 2.354, Residuals: -0.065\n",
      "Loss: 2.353, Residuals: -0.063\n",
      "Loss: 2.353, Residuals: -0.062\n",
      "Loss: 2.349, Residuals: -0.064\n",
      "Loss: 2.348, Residuals: -0.069\n",
      "Loss: 2.347, Residuals: -0.065\n",
      "Loss: 2.340, Residuals: -0.068\n",
      "Loss: 2.339, Residuals: -0.068\n",
      "Loss: 2.334, Residuals: -0.072\n",
      "Loss: 2.334, Residuals: -0.071\n",
      "Loss: 2.334, Residuals: -0.071\n",
      "Loss: 2.331, Residuals: -0.072\n",
      "Loss: 2.330, Residuals: -0.071\n",
      "Loss: 2.327, Residuals: -0.072\n",
      "Loss: 2.322, Residuals: -0.075\n",
      "Loss: 2.322, Residuals: -0.074\n",
      "Evidence -379.198\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.80e-03\n",
      "Loss: 9.638, Residuals: -0.066\n",
      "Loss: 9.544, Residuals: -0.063\n",
      "Loss: 9.405, Residuals: -0.056\n",
      "Loss: 9.339, Residuals: -0.048\n",
      "Loss: 9.336, Residuals: -0.045\n",
      "Loss: 9.330, Residuals: -0.045\n",
      "Loss: 9.324, Residuals: -0.044\n",
      "Loss: 9.278, Residuals: -0.043\n",
      "Loss: 9.277, Residuals: -0.042\n",
      "Loss: 9.275, Residuals: -0.041\n",
      "Loss: 9.263, Residuals: -0.040\n",
      "Loss: 9.243, Residuals: -0.038\n",
      "Loss: 9.243, Residuals: -0.037\n",
      "Loss: 9.242, Residuals: -0.037\n",
      "Loss: 9.240, Residuals: -0.036\n",
      "Loss: 9.228, Residuals: -0.036\n",
      "Loss: 9.227, Residuals: -0.035\n",
      "Loss: 9.226, Residuals: -0.035\n",
      "Loss: 9.215, Residuals: -0.034\n",
      "Loss: 9.206, Residuals: -0.032\n",
      "Loss: 9.204, Residuals: -0.030\n",
      "Loss: 9.201, Residuals: -0.030\n",
      "Loss: 9.200, Residuals: -0.031\n",
      "Loss: 9.192, Residuals: -0.030\n",
      "Loss: 9.183, Residuals: -0.029\n",
      "Loss: 9.180, Residuals: -0.030\n",
      "Loss: 9.178, Residuals: -0.029\n",
      "Loss: 9.164, Residuals: -0.029\n",
      "Loss: 9.160, Residuals: -0.027\n",
      "Loss: 9.154, Residuals: -0.027\n",
      "Loss: 9.152, Residuals: -0.027\n",
      "Loss: 9.150, Residuals: -0.027\n",
      "Loss: 9.145, Residuals: -0.027\n",
      "Loss: 9.138, Residuals: -0.027\n",
      "Loss: 9.136, Residuals: -0.026\n",
      "Loss: 9.134, Residuals: -0.026\n",
      "Loss: 9.129, Residuals: -0.025\n",
      "Loss: 9.126, Residuals: -0.026\n",
      "Loss: 9.122, Residuals: -0.025\n",
      "Loss: 9.121, Residuals: -0.024\n",
      "Loss: 9.113, Residuals: -0.024\n",
      "Loss: 9.112, Residuals: -0.024\n",
      "Loss: 9.111, Residuals: -0.024\n",
      "Loss: 9.109, Residuals: -0.024\n",
      "Loss: 9.109, Residuals: -0.024\n",
      "Loss: 9.103, Residuals: -0.023\n",
      "Loss: 9.102, Residuals: -0.023\n",
      "Loss: 9.100, Residuals: -0.023\n",
      "Loss: 9.100, Residuals: -0.023\n",
      "Loss: 9.096, Residuals: -0.023\n",
      "Loss: 9.096, Residuals: -0.022\n",
      "Loss: 9.096, Residuals: -0.023\n",
      "Loss: 9.094, Residuals: -0.023\n",
      "Loss: 9.094, Residuals: -0.023\n",
      "Loss: 9.091, Residuals: -0.023\n",
      "Loss: 9.091, Residuals: -0.022\n",
      "Loss: 9.091, Residuals: -0.023\n",
      "Loss: 9.089, Residuals: -0.023\n",
      "Loss: 9.088, Residuals: -0.022\n",
      "Loss: 9.088, Residuals: -0.022\n",
      "Loss: 9.086, Residuals: -0.022\n",
      "Loss: 9.086, Residuals: -0.022\n",
      "Loss: 9.086, Residuals: -0.022\n",
      "Loss: 9.086, Residuals: -0.022\n",
      "Loss: 9.085, Residuals: -0.022\n",
      "Loss: 9.083, Residuals: -0.022\n",
      "Loss: 9.083, Residuals: -0.022\n",
      "Loss: 9.083, Residuals: -0.022\n",
      "Loss: 9.082, Residuals: -0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.082, Residuals: -0.022\n",
      "Loss: 9.082, Residuals: -0.022\n",
      "Loss: 9.081, Residuals: -0.022\n",
      "Loss: 9.080, Residuals: -0.022\n",
      "Loss: 9.080, Residuals: -0.022\n",
      "Loss: 9.080, Residuals: -0.022\n",
      "Loss: 9.079, Residuals: -0.022\n",
      "Loss: 9.079, Residuals: -0.022\n",
      "Loss: 9.079, Residuals: -0.022\n",
      "Loss: 9.079, Residuals: -0.022\n",
      "Loss: 9.079, Residuals: -0.022\n",
      "Loss: 9.078, Residuals: -0.022\n",
      "Loss: 9.078, Residuals: -0.022\n",
      "Loss: 9.078, Residuals: -0.022\n",
      "Loss: 9.078, Residuals: -0.022\n",
      "Loss: 9.077, Residuals: -0.022\n",
      "Loss: 9.077, Residuals: -0.022\n",
      "Loss: 9.077, Residuals: -0.022\n",
      "Loss: 9.077, Residuals: -0.022\n",
      "Loss: 9.077, Residuals: -0.022\n",
      "Loss: 9.077, Residuals: -0.022\n",
      "Loss: 9.077, Residuals: -0.022\n",
      "Loss: 9.077, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.023\n",
      "Loss: 9.076, Residuals: -0.023\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.023\n",
      "Loss: 9.076, Residuals: -0.023\n",
      "Loss: 9.076, Residuals: -0.023\n",
      "Loss: 9.076, Residuals: -0.023\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.023\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Loss: 9.076, Residuals: -0.022\n",
      "Evidence 82.291\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.21e-02\n",
      "Loss: 36.581, Residuals: -0.023\n",
      "Loss: 36.363, Residuals: -0.020\n",
      "Loss: 36.099, Residuals: -0.010\n",
      "Loss: 36.037, Residuals: -0.011\n",
      "Loss: 35.924, Residuals: -0.010\n",
      "Loss: 35.743, Residuals: -0.008\n",
      "Loss: 35.736, Residuals: -0.007\n",
      "Loss: 35.722, Residuals: -0.007\n",
      "Loss: 35.616, Residuals: -0.005\n",
      "Loss: 35.604, Residuals: -0.006\n",
      "Loss: 35.580, Residuals: -0.005\n",
      "Loss: 35.537, Residuals: -0.004\n",
      "Loss: 35.527, Residuals: -0.002\n",
      "Loss: 35.509, Residuals: -0.002\n",
      "Loss: 35.483, Residuals: -0.001\n",
      "Loss: 35.483, Residuals: -0.001\n",
      "Loss: 35.466, Residuals: -0.001\n",
      "Loss: 35.462, Residuals: -0.000\n",
      "Loss: 35.454, Residuals: -0.000\n",
      "Loss: 35.441, Residuals: 0.000\n",
      "Loss: 35.440, Residuals: -0.001\n",
      "Loss: 35.429, Residuals: -0.001\n",
      "Loss: 35.410, Residuals: -0.000\n",
      "Loss: 35.409, Residuals: 0.001\n",
      "Loss: 35.407, Residuals: 0.001\n",
      "Loss: 35.395, Residuals: 0.001\n",
      "Loss: 35.393, Residuals: 0.001\n",
      "Loss: 35.392, Residuals: 0.000\n",
      "Loss: 35.392, Residuals: 0.000\n",
      "Loss: 35.383, Residuals: 0.000\n",
      "Loss: 35.383, Residuals: 0.001\n",
      "Loss: 35.380, Residuals: 0.001\n",
      "Loss: 35.375, Residuals: 0.001\n",
      "Loss: 35.375, Residuals: 0.001\n",
      "Loss: 35.375, Residuals: 0.001\n",
      "Loss: 35.375, Residuals: 0.001\n",
      "Loss: 35.375, Residuals: 0.001\n",
      "Loss: 35.369, Residuals: 0.001\n",
      "Loss: 35.369, Residuals: 0.001\n",
      "Loss: 35.367, Residuals: 0.001\n",
      "Loss: 35.367, Residuals: 0.001\n",
      "Loss: 35.367, Residuals: 0.001\n",
      "Loss: 35.365, Residuals: 0.001\n",
      "Loss: 35.365, Residuals: 0.001\n",
      "Loss: 35.365, Residuals: 0.001\n",
      "Loss: 35.365, Residuals: 0.001\n",
      "Loss: 35.364, Residuals: 0.001\n",
      "Loss: 35.364, Residuals: 0.001\n",
      "Loss: 35.364, Residuals: 0.001\n",
      "Loss: 35.363, Residuals: 0.001\n",
      "Loss: 35.363, Residuals: 0.001\n",
      "Loss: 35.363, Residuals: 0.001\n",
      "Loss: 35.363, Residuals: 0.001\n",
      "Evidence 293.805\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.05e-01\n",
      "Loss: 84.987, Residuals: -0.006\n",
      "Loss: 84.664, Residuals: -0.005\n",
      "Loss: 84.541, Residuals: -0.007\n",
      "Loss: 84.317, Residuals: -0.006\n",
      "Loss: 83.983, Residuals: -0.002\n",
      "Loss: 83.966, Residuals: 0.001\n",
      "Loss: 83.829, Residuals: 0.002\n",
      "Loss: 83.819, Residuals: 0.000\n",
      "Loss: 83.737, Residuals: 0.001\n",
      "Loss: 83.722, Residuals: 0.000\n",
      "Loss: 83.718, Residuals: 0.001\n",
      "Loss: 83.712, Residuals: 0.001\n",
      "Loss: 83.662, Residuals: 0.001\n",
      "Loss: 83.659, Residuals: 0.002\n",
      "Loss: 83.657, Residuals: 0.001\n",
      "Loss: 83.656, Residuals: 0.001\n",
      "Loss: 83.643, Residuals: 0.001\n",
      "Loss: 83.623, Residuals: 0.001\n",
      "Loss: 83.622, Residuals: 0.001\n",
      "Loss: 83.622, Residuals: 0.001\n",
      "Loss: 83.610, Residuals: 0.001\n",
      "Loss: 83.609, Residuals: 0.001\n",
      "Loss: 83.609, Residuals: 0.001\n",
      "Loss: 83.602, Residuals: 0.001\n",
      "Loss: 83.602, Residuals: 0.001\n",
      "Loss: 83.601, Residuals: 0.001\n",
      "Loss: 83.600, Residuals: 0.001\n",
      "Loss: 83.600, Residuals: 0.001\n",
      "Loss: 83.597, Residuals: 0.001\n",
      "Loss: 83.597, Residuals: 0.001\n",
      "Loss: 83.597, Residuals: 0.001\n",
      "Loss: 83.596, Residuals: 0.001\n",
      "Loss: 83.596, Residuals: 0.001\n",
      "Evidence 400.221\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.71e-01\n",
      "Loss: 123.784, Residuals: -0.007\n",
      "Loss: 123.398, Residuals: -0.006\n",
      "Loss: 123.143, Residuals: -0.003\n",
      "Loss: 123.067, Residuals: -0.004\n",
      "Loss: 123.036, Residuals: -0.002\n",
      "Loss: 122.773, Residuals: -0.001\n",
      "Loss: 122.469, Residuals: -0.001\n",
      "Loss: 122.454, Residuals: -0.001\n",
      "Loss: 122.434, Residuals: -0.001\n",
      "Loss: 122.397, Residuals: -0.001\n",
      "Loss: 122.378, Residuals: -0.003\n",
      "Loss: 122.343, Residuals: -0.002\n",
      "Loss: 122.340, Residuals: -0.002\n",
      "Loss: 122.310, Residuals: -0.002\n",
      "Loss: 122.259, Residuals: -0.002\n",
      "Loss: 122.253, Residuals: -0.002\n",
      "Loss: 122.208, Residuals: -0.002\n",
      "Loss: 122.202, Residuals: -0.002\n",
      "Loss: 122.192, Residuals: -0.003\n",
      "Loss: 122.175, Residuals: -0.003\n",
      "Loss: 122.170, Residuals: -0.003\n",
      "Loss: 122.169, Residuals: -0.003\n",
      "Loss: 122.158, Residuals: -0.003\n",
      "Loss: 122.138, Residuals: -0.003\n",
      "Loss: 122.134, Residuals: -0.003\n",
      "Loss: 122.129, Residuals: -0.004\n",
      "Loss: 122.127, Residuals: -0.004\n",
      "Loss: 122.109, Residuals: -0.003\n",
      "Loss: 122.104, Residuals: -0.003\n",
      "Loss: 122.103, Residuals: -0.004\n",
      "Loss: 122.089, Residuals: -0.004\n",
      "Loss: 122.081, Residuals: -0.004\n",
      "Loss: 122.079, Residuals: -0.004\n",
      "Loss: 122.059, Residuals: -0.004\n",
      "Loss: 122.051, Residuals: -0.005\n",
      "Loss: 122.042, Residuals: -0.005\n",
      "Loss: 122.039, Residuals: -0.005\n",
      "Loss: 122.016, Residuals: -0.005\n",
      "Loss: 122.007, Residuals: -0.005\n",
      "Loss: 121.991, Residuals: -0.005\n",
      "Loss: 121.978, Residuals: -0.005\n",
      "Loss: 121.974, Residuals: -0.005\n",
      "Loss: 121.942, Residuals: -0.005\n",
      "Loss: 121.929, Residuals: -0.005\n",
      "Loss: 121.908, Residuals: -0.005\n",
      "Loss: 121.896, Residuals: -0.006\n",
      "Loss: 121.894, Residuals: -0.006\n",
      "Loss: 121.876, Residuals: -0.006\n",
      "Loss: 121.844, Residuals: -0.006\n",
      "Loss: 121.832, Residuals: -0.006\n",
      "Loss: 121.818, Residuals: -0.006\n",
      "Loss: 121.816, Residuals: -0.007\n",
      "Loss: 121.795, Residuals: -0.006\n",
      "Loss: 121.761, Residuals: -0.006\n",
      "Loss: 121.758, Residuals: -0.006\n",
      "Loss: 121.752, Residuals: -0.006\n",
      "Loss: 121.742, Residuals: -0.006\n",
      "Loss: 121.738, Residuals: -0.006\n",
      "Loss: 121.732, Residuals: -0.006\n",
      "Loss: 121.731, Residuals: -0.006\n",
      "Loss: 121.699, Residuals: -0.006\n",
      "Loss: 121.696, Residuals: -0.006\n",
      "Loss: 121.690, Residuals: -0.006\n",
      "Loss: 121.689, Residuals: -0.006\n",
      "Loss: 121.667, Residuals: -0.006\n",
      "Loss: 121.664, Residuals: -0.006\n",
      "Loss: 121.658, Residuals: -0.006\n",
      "Loss: 121.657, Residuals: -0.005\n",
      "Loss: 121.652, Residuals: -0.006\n",
      "Loss: 121.651, Residuals: -0.006\n",
      "Loss: 121.650, Residuals: -0.006\n",
      "Loss: 121.639, Residuals: -0.006\n",
      "Loss: 121.632, Residuals: -0.006\n",
      "Loss: 121.631, Residuals: -0.006\n",
      "Loss: 121.630, Residuals: -0.006\n",
      "Loss: 121.629, Residuals: -0.006\n",
      "Loss: 121.629, Residuals: -0.006\n",
      "Loss: 121.625, Residuals: -0.006\n",
      "Loss: 121.619, Residuals: -0.006\n",
      "Loss: 121.618, Residuals: -0.006\n",
      "Loss: 121.616, Residuals: -0.006\n",
      "Loss: 121.613, Residuals: -0.006\n",
      "Loss: 121.613, Residuals: -0.006\n",
      "Loss: 121.613, Residuals: -0.006\n",
      "Evidence 433.744\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.87e-01\n",
      "Loss: 139.378, Residuals: -0.005\n",
      "Loss: 138.714, Residuals: -0.002\n",
      "Loss: 138.694, Residuals: -0.004\n",
      "Loss: 138.523, Residuals: -0.003\n",
      "Loss: 138.313, Residuals: -0.001\n",
      "Loss: 138.300, Residuals: -0.001\n",
      "Loss: 138.199, Residuals: -0.001\n",
      "Loss: 138.180, Residuals: -0.001\n",
      "Loss: 138.176, Residuals: 0.000\n",
      "Loss: 138.139, Residuals: 0.000\n",
      "Loss: 138.097, Residuals: 0.000\n",
      "Loss: 138.096, Residuals: 0.000\n",
      "Loss: 138.094, Residuals: 0.000\n",
      "Loss: 138.092, Residuals: 0.000\n",
      "Loss: 138.088, Residuals: 0.000\n",
      "Loss: 138.088, Residuals: 0.000\n",
      "Loss: 138.087, Residuals: 0.000\n",
      "Loss: 138.086, Residuals: 0.000\n",
      "Loss: 138.086, Residuals: 0.000\n",
      "Loss: 138.086, Residuals: 0.000\n",
      "Loss: 138.085, Residuals: 0.000\n",
      "Loss: 138.085, Residuals: 0.000\n",
      "Loss: 138.085, Residuals: 0.000\n",
      "Loss: 138.085, Residuals: 0.000\n",
      "Loss: 138.085, Residuals: 0.000\n",
      "Loss: 138.085, Residuals: 0.000\n",
      "Loss: 138.085, Residuals: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence 447.129\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.18e+00\n",
      "Loss: 145.622, Residuals: 0.001\n",
      "Loss: 145.269, Residuals: 0.005\n",
      "Loss: 145.238, Residuals: 0.003\n",
      "Loss: 145.199, Residuals: 0.003\n",
      "Loss: 145.165, Residuals: 0.004\n",
      "Loss: 145.161, Residuals: 0.004\n",
      "Loss: 145.154, Residuals: 0.004\n",
      "Loss: 145.143, Residuals: 0.004\n",
      "Loss: 145.130, Residuals: 0.004\n",
      "Loss: 145.130, Residuals: 0.004\n",
      "Loss: 145.129, Residuals: 0.004\n",
      "Loss: 145.128, Residuals: 0.004\n",
      "Loss: 145.127, Residuals: 0.004\n",
      "Loss: 145.127, Residuals: 0.004\n",
      "Loss: 145.127, Residuals: 0.004\n",
      "Loss: 145.127, Residuals: 0.004\n",
      "Loss: 145.127, Residuals: 0.004\n",
      "Loss: 145.127, Residuals: 0.004\n",
      "Loss: 145.127, Residuals: 0.004\n",
      "Evidence 452.095\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.32e+00\n",
      "Loss: 148.179, Residuals: 0.007\n",
      "Loss: 148.064, Residuals: 0.005\n",
      "Loss: 148.042, Residuals: 0.008\n",
      "Loss: 148.015, Residuals: 0.006\n",
      "Loss: 148.014, Residuals: 0.007\n",
      "Loss: 148.007, Residuals: 0.007\n",
      "Loss: 147.997, Residuals: 0.007\n",
      "Loss: 147.996, Residuals: 0.007\n",
      "Loss: 147.995, Residuals: 0.006\n",
      "Loss: 147.993, Residuals: 0.006\n",
      "Loss: 147.990, Residuals: 0.007\n",
      "Loss: 147.990, Residuals: 0.007\n",
      "Loss: 147.990, Residuals: 0.007\n",
      "Loss: 147.990, Residuals: 0.007\n",
      "Loss: 147.989, Residuals: 0.007\n",
      "Loss: 147.989, Residuals: 0.007\n",
      "Evidence 454.428\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.38e+00\n",
      "Loss: 149.440, Residuals: 0.009\n",
      "Loss: 149.393, Residuals: 0.008\n",
      "Loss: 149.375, Residuals: 0.008\n",
      "Loss: 149.371, Residuals: 0.008\n",
      "Loss: 149.366, Residuals: 0.008\n",
      "Loss: 149.360, Residuals: 0.008\n",
      "Loss: 149.359, Residuals: 0.008\n",
      "Loss: 149.357, Residuals: 0.008\n",
      "Loss: 149.357, Residuals: 0.008\n",
      "Loss: 149.357, Residuals: 0.008\n",
      "Loss: 149.356, Residuals: 0.008\n",
      "Loss: 149.356, Residuals: 0.008\n",
      "Loss: 149.356, Residuals: 0.008\n",
      "Evidence 455.708\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.42e+00\n",
      "Loss: 150.172, Residuals: 0.009\n",
      "Loss: 150.149, Residuals: 0.009\n",
      "Loss: 150.138, Residuals: 0.009\n",
      "Loss: 150.135, Residuals: 0.009\n",
      "Loss: 150.134, Residuals: 0.009\n",
      "Loss: 150.133, Residuals: 0.009\n",
      "Loss: 150.131, Residuals: 0.009\n",
      "Loss: 150.131, Residuals: 0.009\n",
      "Loss: 150.130, Residuals: 0.009\n",
      "Loss: 150.129, Residuals: 0.009\n",
      "Loss: 150.129, Residuals: 0.009\n",
      "Evidence 456.493\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.44e+00\n",
      "Loss: 150.638, Residuals: 0.010\n",
      "Loss: 150.625, Residuals: 0.009\n",
      "Loss: 150.620, Residuals: 0.010\n",
      "Loss: 150.618, Residuals: 0.009\n",
      "Loss: 150.618, Residuals: 0.010\n",
      "Loss: 150.616, Residuals: 0.010\n",
      "Loss: 150.614, Residuals: 0.009\n",
      "Loss: 150.614, Residuals: 0.009\n",
      "Loss: 150.614, Residuals: 0.009\n",
      "Loss: 150.614, Residuals: 0.009\n",
      "Loss: 150.613, Residuals: 0.009\n",
      "Loss: 150.613, Residuals: 0.009\n",
      "Loss: 150.613, Residuals: 0.009\n",
      "Loss: 150.613, Residuals: 0.009\n",
      "Loss: 150.613, Residuals: 0.009\n",
      "Evidence 457.019\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.45e+00\n",
      "Loss: 150.941, Residuals: 0.010\n",
      "Loss: 150.933, Residuals: 0.010\n",
      "Loss: 150.930, Residuals: 0.010\n",
      "Loss: 150.928, Residuals: 0.010\n",
      "Loss: 150.927, Residuals: 0.010\n",
      "Loss: 150.926, Residuals: 0.010\n",
      "Loss: 150.926, Residuals: 0.010\n",
      "Loss: 150.926, Residuals: 0.010\n",
      "Loss: 150.926, Residuals: 0.010\n",
      "Loss: 150.926, Residuals: 0.009\n",
      "Loss: 150.926, Residuals: 0.009\n",
      "Loss: 150.926, Residuals: 0.009\n",
      "Loss: 150.926, Residuals: 0.009\n",
      "Loss: 150.926, Residuals: 0.009\n",
      "Evidence 457.406\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 11.709, Residuals: -0.134\n",
      "Loss: 6.863, Residuals: -0.080\n",
      "Loss: 5.041, Residuals: -0.072\n",
      "Loss: 4.338, Residuals: -0.053\n",
      "Loss: 4.012, Residuals: -0.051\n",
      "Loss: 3.873, Residuals: 0.000\n",
      "Loss: 3.638, Residuals: -0.018\n",
      "Loss: 3.550, Residuals: -0.032\n",
      "Loss: 3.516, Residuals: -0.012\n",
      "Loss: 3.454, Residuals: -0.019\n",
      "Loss: 3.354, Residuals: -0.033\n",
      "Loss: 3.214, Residuals: -0.055\n",
      "Loss: 3.186, Residuals: -0.032\n",
      "Loss: 3.077, Residuals: 0.007\n",
      "Loss: 3.001, Residuals: 0.014\n",
      "Loss: 2.908, Residuals: 0.017\n",
      "Loss: 2.893, Residuals: -0.003\n",
      "Loss: 2.866, Residuals: -0.006\n",
      "Loss: 2.821, Residuals: -0.009\n",
      "Loss: 2.764, Residuals: -0.018\n",
      "Loss: 2.749, Residuals: -0.034\n",
      "Loss: 2.743, Residuals: -0.019\n",
      "Loss: 2.731, Residuals: -0.023\n",
      "Loss: 2.713, Residuals: -0.032\n",
      "Loss: 2.711, Residuals: -0.033\n",
      "Loss: 2.708, Residuals: -0.034\n",
      "Loss: 2.702, Residuals: -0.036\n",
      "Loss: 2.691, Residuals: -0.039\n",
      "Loss: 2.686, Residuals: -0.045\n",
      "Loss: 2.684, Residuals: -0.044\n",
      "Loss: 2.680, Residuals: -0.046\n",
      "Loss: 2.674, Residuals: -0.049\n",
      "Loss: 2.665, Residuals: -0.061\n",
      "Loss: 2.664, Residuals: -0.060\n",
      "Loss: 2.660, Residuals: -0.061\n",
      "Loss: 2.653, Residuals: -0.064\n",
      "Loss: 2.652, Residuals: -0.069\n",
      "Loss: 2.646, Residuals: -0.071\n",
      "Loss: 2.641, Residuals: -0.080\n",
      "Loss: 2.641, Residuals: -0.079\n",
      "Loss: 2.641, Residuals: -0.079\n",
      "Loss: 2.640, Residuals: -0.079\n",
      "Loss: 2.639, Residuals: -0.079\n",
      "Loss: 2.638, Residuals: -0.079\n",
      "Loss: 2.636, Residuals: -0.079\n",
      "Loss: 2.632, Residuals: -0.080\n",
      "Loss: 2.632, Residuals: -0.080\n",
      "Loss: 2.630, Residuals: -0.081\n",
      "Loss: 2.627, Residuals: -0.080\n",
      "Loss: 2.627, Residuals: -0.079\n",
      "Loss: 2.624, Residuals: -0.080\n",
      "Loss: 2.621, Residuals: -0.080\n",
      "Loss: 2.621, Residuals: -0.078\n",
      "Loss: 2.620, Residuals: -0.079\n",
      "Loss: 2.617, Residuals: -0.080\n",
      "Loss: 2.616, Residuals: -0.081\n",
      "Loss: 2.613, Residuals: -0.080\n",
      "Loss: 2.613, Residuals: -0.081\n",
      "Loss: 2.612, Residuals: -0.080\n",
      "Loss: 2.612, Residuals: -0.080\n",
      "Loss: 2.607, Residuals: -0.082\n",
      "Loss: 2.607, Residuals: -0.081\n",
      "Loss: 2.606, Residuals: -0.081\n",
      "Loss: 2.605, Residuals: -0.080\n",
      "Loss: 2.605, Residuals: -0.079\n",
      "Loss: 2.604, Residuals: -0.079\n",
      "Loss: 2.604, Residuals: -0.078\n",
      "Loss: 2.601, Residuals: -0.079\n",
      "Loss: 2.599, Residuals: -0.081\n",
      "Loss: 2.599, Residuals: -0.080\n",
      "Loss: 2.598, Residuals: -0.080\n",
      "Loss: 2.596, Residuals: -0.081\n",
      "Loss: 2.596, Residuals: -0.081\n",
      "Loss: 2.594, Residuals: -0.082\n",
      "Loss: 2.594, Residuals: -0.082\n",
      "Loss: 2.592, Residuals: -0.083\n",
      "Loss: 2.592, Residuals: -0.083\n",
      "Loss: 2.588, Residuals: -0.084\n",
      "Loss: 2.588, Residuals: -0.084\n",
      "Loss: 2.578, Residuals: -0.081\n",
      "Loss: 2.576, Residuals: -0.077\n",
      "Loss: 2.575, Residuals: -0.078\n",
      "Loss: 2.573, Residuals: -0.078\n",
      "Loss: 2.572, Residuals: -0.077\n",
      "Loss: 2.572, Residuals: -0.077\n",
      "Loss: 2.572, Residuals: -0.078\n",
      "Loss: 2.571, Residuals: -0.078\n",
      "Loss: 2.569, Residuals: -0.078\n",
      "Loss: 2.567, Residuals: -0.079\n",
      "Loss: 2.566, Residuals: -0.079\n",
      "Loss: 2.566, Residuals: -0.079\n",
      "Loss: 2.564, Residuals: -0.080\n",
      "Loss: 2.564, Residuals: -0.080\n",
      "Loss: 2.563, Residuals: -0.081\n",
      "Loss: 2.562, Residuals: -0.081\n",
      "Loss: 2.561, Residuals: -0.082\n",
      "Loss: 2.561, Residuals: -0.082\n",
      "Loss: 2.561, Residuals: -0.082\n",
      "Loss: 2.560, Residuals: -0.083\n",
      "Loss: 2.559, Residuals: -0.084\n",
      "Loss: 2.559, Residuals: -0.083\n",
      "Loss: 2.558, Residuals: -0.084\n",
      "Loss: 2.558, Residuals: -0.084\n",
      "Loss: 2.558, Residuals: -0.084\n",
      "Loss: 2.557, Residuals: -0.085\n",
      "Loss: 2.556, Residuals: -0.085\n",
      "Loss: 2.556, Residuals: -0.085\n",
      "Loss: 2.556, Residuals: -0.085\n",
      "Loss: 2.556, Residuals: -0.085\n",
      "Loss: 2.556, Residuals: -0.086\n",
      "Loss: 2.556, Residuals: -0.086\n",
      "Loss: 2.556, Residuals: -0.085\n",
      "Loss: 2.556, Residuals: -0.086\n",
      "Loss: 2.555, Residuals: -0.086\n",
      "Loss: 2.555, Residuals: -0.086\n",
      "Loss: 2.555, Residuals: -0.086\n",
      "Loss: 2.555, Residuals: -0.087\n",
      "Loss: 2.555, Residuals: -0.087\n",
      "Loss: 2.555, Residuals: -0.086\n",
      "Loss: 2.555, Residuals: -0.086\n",
      "Loss: 2.555, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.087\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.554, Residuals: -0.088\n",
      "Loss: 2.553, Residuals: -0.088\n",
      "Loss: 2.553, Residuals: -0.088\n",
      "Loss: 2.553, Residuals: -0.088\n",
      "Loss: 2.553, Residuals: -0.088\n",
      "Loss: 2.553, Residuals: -0.088\n",
      "Loss: 2.553, Residuals: -0.088\n",
      "Loss: 2.553, Residuals: -0.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.553, Residuals: -0.087\n",
      "Loss: 2.552, Residuals: -0.087\n",
      "Loss: 2.552, Residuals: -0.087\n",
      "Evidence -364.256\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.53e-04\n",
      "Loss: 11.416, Residuals: -0.074\n",
      "Loss: 11.213, Residuals: -0.062\n",
      "Loss: 11.207, Residuals: -0.061\n",
      "Loss: 11.197, Residuals: -0.060\n",
      "Loss: 11.181, Residuals: -0.058\n",
      "Loss: 11.161, Residuals: -0.056\n",
      "Loss: 11.129, Residuals: -0.056\n",
      "Loss: 11.129, Residuals: -0.056\n",
      "Loss: 11.056, Residuals: -0.052\n",
      "Loss: 11.055, Residuals: -0.053\n",
      "Loss: 11.040, Residuals: -0.050\n",
      "Loss: 11.037, Residuals: -0.045\n",
      "Loss: 11.011, Residuals: -0.044\n",
      "Loss: 11.010, Residuals: -0.045\n",
      "Loss: 11.000, Residuals: -0.044\n",
      "Loss: 10.987, Residuals: -0.041\n",
      "Loss: 10.987, Residuals: -0.041\n",
      "Evidence 97.728\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.46e-03\n",
      "Loss: 42.119, Residuals: -0.029\n",
      "Loss: 41.993, Residuals: -0.029\n",
      "Loss: 41.790, Residuals: -0.030\n",
      "Loss: 41.542, Residuals: -0.033\n",
      "Loss: 41.532, Residuals: -0.032\n",
      "Loss: 41.518, Residuals: -0.035\n",
      "Loss: 41.030, Residuals: -0.029\n",
      "Loss: 41.027, Residuals: -0.029\n",
      "Loss: 41.022, Residuals: -0.028\n",
      "Loss: 41.012, Residuals: -0.027\n",
      "Loss: 40.679, Residuals: -0.022\n",
      "Loss: 40.678, Residuals: -0.021\n",
      "Loss: 40.664, Residuals: -0.021\n",
      "Loss: 40.644, Residuals: -0.020\n",
      "Loss: 40.609, Residuals: -0.019\n",
      "Loss: 40.307, Residuals: -0.015\n",
      "Loss: 40.305, Residuals: -0.015\n",
      "Loss: 40.286, Residuals: -0.013\n",
      "Loss: 40.262, Residuals: -0.017\n",
      "Loss: 40.223, Residuals: -0.015\n",
      "Loss: 40.149, Residuals: -0.014\n",
      "Loss: 40.143, Residuals: -0.015\n",
      "Loss: 40.084, Residuals: -0.014\n",
      "Loss: 40.030, Residuals: -0.012\n",
      "Loss: 40.030, Residuals: -0.012\n",
      "Evidence 304.944\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.67e-02\n",
      "Loss: 92.271, Residuals: -0.007\n",
      "Loss: 91.948, Residuals: -0.009\n",
      "Loss: 91.746, Residuals: -0.019\n",
      "Loss: 91.745, Residuals: -0.019\n",
      "Evidence 416.520\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.56e-02\n",
      "Loss: 134.298, Residuals: -0.020\n",
      "Evidence 444.773\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.68e-02\n",
      "Loss: 151.937, Residuals: -0.021\n",
      "Loss: 151.481, Residuals: -0.021\n",
      "Loss: 150.894, Residuals: -0.025\n",
      "Loss: 150.888, Residuals: -0.025\n",
      "Evidence 450.883\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.90e-02\n",
      "Loss: 156.444, Residuals: -0.025\n",
      "Loss: 155.572, Residuals: -0.023\n",
      "Loss: 154.482, Residuals: -0.020\n",
      "Loss: 154.474, Residuals: -0.020\n",
      "Evidence 452.982\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.13e-02\n",
      "Loss: 157.140, Residuals: -0.020\n",
      "Loss: 157.128, Residuals: -0.020\n",
      "Evidence 454.286\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.18e-02\n",
      "Loss: 157.079, Residuals: -0.012\n",
      "Loss: 156.793, Residuals: -0.011\n",
      "Loss: 156.781, Residuals: -0.011\n",
      "Evidence 453.827\n",
      "Fail count  1\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.53e-02\n",
      "Loss: 157.500, Residuals: -0.013\n",
      "Loss: 157.498, Residuals: -0.013\n",
      "Evidence 455.865\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.58e-02\n",
      "Loss: 158.178, Residuals: -0.016\n",
      "Loss: 158.151, Residuals: -0.016\n",
      "Evidence 456.416\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.61e-02\n",
      "Loss: 158.573, Residuals: -0.016\n",
      "Evidence 456.650\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.184, Residuals: -0.164\n",
      "Loss: 7.150, Residuals: -0.070\n",
      "Loss: 5.374, Residuals: -0.068\n",
      "Loss: 4.925, Residuals: -0.073\n",
      "Loss: 4.333, Residuals: -0.068\n",
      "Loss: 3.924, Residuals: -0.052\n",
      "Loss: 3.809, Residuals: -0.032\n",
      "Loss: 3.614, Residuals: -0.036\n",
      "Loss: 3.579, Residuals: 0.001\n",
      "Loss: 3.515, Residuals: -0.005\n",
      "Loss: 3.408, Residuals: -0.020\n",
      "Loss: 3.393, Residuals: -0.002\n",
      "Loss: 3.265, Residuals: -0.023\n",
      "Loss: 3.096, Residuals: 0.036\n",
      "Loss: 3.032, Residuals: 0.046\n",
      "Loss: 2.929, Residuals: 0.033\n",
      "Loss: 2.915, Residuals: 0.016\n",
      "Loss: 2.890, Residuals: 0.014\n",
      "Loss: 2.844, Residuals: 0.010\n",
      "Loss: 2.775, Residuals: 0.002\n",
      "Loss: 2.735, Residuals: 0.001\n",
      "Loss: 2.721, Residuals: -0.004\n",
      "Loss: 2.698, Residuals: -0.009\n",
      "Loss: 2.661, Residuals: -0.027\n",
      "Loss: 2.659, Residuals: -0.027\n",
      "Loss: 2.641, Residuals: -0.032\n",
      "Loss: 2.612, Residuals: -0.045\n",
      "Loss: 2.610, Residuals: -0.047\n",
      "Loss: 2.588, Residuals: -0.057\n",
      "Loss: 2.587, Residuals: -0.061\n",
      "Loss: 2.559, Residuals: -0.070\n",
      "Loss: 2.556, Residuals: -0.067\n",
      "Loss: 2.553, Residuals: -0.069\n",
      "Loss: 2.530, Residuals: -0.069\n",
      "Loss: 2.530, Residuals: -0.069\n",
      "Loss: 2.527, Residuals: -0.071\n",
      "Loss: 2.522, Residuals: -0.073\n",
      "Loss: 2.521, Residuals: -0.071\n",
      "Loss: 2.509, Residuals: -0.075\n",
      "Loss: 2.509, Residuals: -0.075\n",
      "Loss: 2.507, Residuals: -0.076\n",
      "Loss: 2.504, Residuals: -0.077\n",
      "Loss: 2.503, Residuals: -0.079\n",
      "Loss: 2.503, Residuals: -0.078\n",
      "Loss: 2.499, Residuals: -0.079\n",
      "Loss: 2.498, Residuals: -0.081\n",
      "Loss: 2.492, Residuals: -0.083\n",
      "Loss: 2.492, Residuals: -0.082\n",
      "Loss: 2.491, Residuals: -0.082\n",
      "Loss: 2.484, Residuals: -0.085\n",
      "Loss: 2.484, Residuals: -0.085\n",
      "Loss: 2.484, Residuals: -0.085\n",
      "Loss: 2.484, Residuals: -0.085\n",
      "Loss: 2.483, Residuals: -0.085\n",
      "Loss: 2.482, Residuals: -0.085\n",
      "Loss: 2.482, Residuals: -0.085\n",
      "Loss: 2.480, Residuals: -0.086\n",
      "Loss: 2.479, Residuals: -0.087\n",
      "Loss: 2.477, Residuals: -0.087\n",
      "Loss: 2.477, Residuals: -0.087\n",
      "Loss: 2.475, Residuals: -0.088\n",
      "Loss: 2.475, Residuals: -0.089\n",
      "Loss: 2.475, Residuals: -0.089\n",
      "Loss: 2.475, Residuals: -0.089\n",
      "Loss: 2.474, Residuals: -0.090\n",
      "Loss: 2.474, Residuals: -0.090\n",
      "Loss: 2.473, Residuals: -0.090\n",
      "Loss: 2.473, Residuals: -0.090\n",
      "Loss: 2.472, Residuals: -0.091\n",
      "Loss: 2.472, Residuals: -0.092\n",
      "Loss: 2.472, Residuals: -0.092\n",
      "Loss: 2.472, Residuals: -0.092\n",
      "Loss: 2.471, Residuals: -0.093\n",
      "Loss: 2.471, Residuals: -0.093\n",
      "Loss: 2.470, Residuals: -0.093\n",
      "Loss: 2.470, Residuals: -0.094\n",
      "Loss: 2.470, Residuals: -0.094\n",
      "Loss: 2.470, Residuals: -0.094\n",
      "Loss: 2.470, Residuals: -0.094\n",
      "Loss: 2.470, Residuals: -0.094\n",
      "Loss: 2.469, Residuals: -0.094\n",
      "Loss: 2.469, Residuals: -0.093\n",
      "Loss: 2.469, Residuals: -0.093\n",
      "Loss: 2.469, Residuals: -0.093\n",
      "Loss: 2.468, Residuals: -0.094\n",
      "Loss: 2.468, Residuals: -0.094\n",
      "Loss: 2.468, Residuals: -0.094\n",
      "Loss: 2.468, Residuals: -0.094\n",
      "Evidence -384.042\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.34e-03\n",
      "Loss: 11.228, Residuals: -0.062\n",
      "Loss: 11.172, Residuals: -0.052\n",
      "Loss: 11.099, Residuals: -0.058\n",
      "Loss: 11.056, Residuals: -0.065\n",
      "Loss: 10.979, Residuals: -0.060\n",
      "Loss: 10.978, Residuals: -0.062\n",
      "Loss: 10.931, Residuals: -0.058\n",
      "Loss: 10.930, Residuals: -0.059\n",
      "Loss: 10.909, Residuals: -0.057\n",
      "Loss: 10.873, Residuals: -0.052\n",
      "Loss: 10.872, Residuals: -0.052\n",
      "Loss: 10.830, Residuals: -0.046\n",
      "Loss: 10.830, Residuals: -0.046\n",
      "Loss: 10.825, Residuals: -0.044\n",
      "Loss: 10.792, Residuals: -0.038\n",
      "Loss: 10.791, Residuals: -0.039\n",
      "Loss: 10.790, Residuals: -0.038\n",
      "Loss: 10.788, Residuals: -0.038\n",
      "Loss: 10.785, Residuals: -0.038\n",
      "Loss: 10.782, Residuals: -0.036\n",
      "Loss: 10.754, Residuals: -0.032\n",
      "Loss: 10.754, Residuals: -0.033\n",
      "Loss: 10.753, Residuals: -0.033\n",
      "Loss: 10.751, Residuals: -0.032\n",
      "Loss: 10.749, Residuals: -0.032\n",
      "Loss: 10.748, Residuals: -0.031\n",
      "Loss: 10.743, Residuals: -0.030\n",
      "Loss: 10.743, Residuals: -0.029\n",
      "Loss: 10.742, Residuals: -0.029\n",
      "Loss: 10.742, Residuals: -0.029\n",
      "Loss: 10.742, Residuals: -0.028\n",
      "Loss: 10.741, Residuals: -0.028\n",
      "Loss: 10.740, Residuals: -0.027\n",
      "Loss: 10.740, Residuals: -0.027\n",
      "Loss: 10.740, Residuals: -0.027\n",
      "Loss: 10.740, Residuals: -0.027\n",
      "Loss: 10.740, Residuals: -0.027\n",
      "Loss: 10.740, Residuals: -0.027\n",
      "Loss: 10.740, Residuals: -0.026\n",
      "Loss: 10.739, Residuals: -0.026\n",
      "Loss: 10.739, Residuals: -0.026\n",
      "Loss: 10.739, Residuals: -0.026\n",
      "Loss: 10.739, Residuals: -0.026\n",
      "Loss: 10.739, Residuals: -0.026\n",
      "Loss: 10.739, Residuals: -0.026\n",
      "Loss: 10.739, Residuals: -0.026\n",
      "Evidence 100.019\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.07e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 41.291, Residuals: -0.030\n",
      "Loss: 41.044, Residuals: -0.027\n",
      "Loss: 40.680, Residuals: -0.022\n",
      "Loss: 40.591, Residuals: -0.020\n",
      "Loss: 40.499, Residuals: -0.016\n",
      "Loss: 40.497, Residuals: -0.017\n",
      "Loss: 40.481, Residuals: -0.017\n",
      "Loss: 40.455, Residuals: -0.017\n",
      "Loss: 40.272, Residuals: -0.012\n",
      "Loss: 40.255, Residuals: -0.006\n",
      "Loss: 40.232, Residuals: -0.009\n",
      "Loss: 40.195, Residuals: -0.008\n",
      "Loss: 40.178, Residuals: -0.007\n",
      "Loss: 40.155, Residuals: -0.006\n",
      "Loss: 40.152, Residuals: -0.005\n",
      "Loss: 40.148, Residuals: -0.005\n",
      "Loss: 40.141, Residuals: -0.004\n",
      "Loss: 40.140, Residuals: -0.005\n",
      "Loss: 40.139, Residuals: -0.004\n",
      "Loss: 40.138, Residuals: -0.004\n",
      "Loss: 40.137, Residuals: -0.004\n",
      "Loss: 40.137, Residuals: -0.004\n",
      "Loss: 40.137, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Loss: 40.136, Residuals: -0.004\n",
      "Evidence 312.657\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.37e-01\n",
      "Loss: 93.423, Residuals: -0.005\n",
      "Loss: 92.913, Residuals: -0.010\n",
      "Loss: 92.591, Residuals: -0.006\n",
      "Loss: 92.454, Residuals: -0.001\n",
      "Loss: 92.301, Residuals: -0.004\n",
      "Loss: 92.287, Residuals: -0.007\n",
      "Loss: 92.164, Residuals: -0.006\n",
      "Loss: 91.991, Residuals: -0.003\n",
      "Loss: 91.970, Residuals: -0.004\n",
      "Loss: 91.938, Residuals: -0.003\n",
      "Loss: 91.929, Residuals: -0.002\n",
      "Loss: 91.916, Residuals: -0.002\n",
      "Loss: 91.914, Residuals: -0.002\n",
      "Loss: 91.911, Residuals: -0.002\n",
      "Loss: 91.906, Residuals: -0.002\n",
      "Loss: 91.905, Residuals: -0.002\n",
      "Loss: 91.903, Residuals: -0.002\n",
      "Loss: 91.903, Residuals: -0.002\n",
      "Loss: 91.902, Residuals: -0.002\n",
      "Loss: 91.901, Residuals: -0.001\n",
      "Loss: 91.901, Residuals: -0.001\n",
      "Loss: 91.901, Residuals: -0.001\n",
      "Loss: 91.901, Residuals: -0.001\n",
      "Loss: 91.901, Residuals: -0.001\n",
      "Loss: 91.901, Residuals: -0.001\n",
      "Evidence 418.286\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.46e-01\n",
      "Loss: 132.822, Residuals: -0.013\n",
      "Loss: 132.390, Residuals: -0.005\n",
      "Loss: 132.296, Residuals: -0.003\n",
      "Loss: 132.128, Residuals: -0.004\n",
      "Loss: 131.890, Residuals: -0.004\n",
      "Loss: 131.882, Residuals: -0.006\n",
      "Loss: 131.871, Residuals: -0.006\n",
      "Loss: 131.849, Residuals: -0.005\n",
      "Loss: 131.812, Residuals: -0.004\n",
      "Loss: 131.804, Residuals: -0.005\n",
      "Loss: 131.790, Residuals: -0.005\n",
      "Loss: 131.776, Residuals: -0.004\n",
      "Loss: 131.774, Residuals: -0.004\n",
      "Loss: 131.771, Residuals: -0.005\n",
      "Loss: 131.767, Residuals: -0.004\n",
      "Loss: 131.765, Residuals: -0.004\n",
      "Loss: 131.763, Residuals: -0.004\n",
      "Loss: 131.761, Residuals: -0.004\n",
      "Loss: 131.759, Residuals: -0.004\n",
      "Loss: 131.759, Residuals: -0.004\n",
      "Loss: 131.757, Residuals: -0.004\n",
      "Loss: 131.757, Residuals: -0.004\n",
      "Loss: 131.756, Residuals: -0.004\n",
      "Loss: 131.755, Residuals: -0.004\n",
      "Loss: 131.755, Residuals: -0.004\n",
      "Loss: 131.754, Residuals: -0.004\n",
      "Loss: 131.754, Residuals: -0.004\n",
      "Loss: 131.753, Residuals: -0.004\n",
      "Loss: 131.753, Residuals: -0.004\n",
      "Loss: 131.752, Residuals: -0.004\n",
      "Loss: 131.752, Residuals: -0.004\n",
      "Loss: 131.752, Residuals: -0.004\n",
      "Loss: 131.752, Residuals: -0.004\n",
      "Loss: 131.752, Residuals: -0.004\n",
      "Loss: 131.751, Residuals: -0.004\n",
      "Loss: 131.751, Residuals: -0.004\n",
      "Loss: 131.751, Residuals: -0.004\n",
      "Loss: 131.751, Residuals: -0.004\n",
      "Loss: 131.750, Residuals: -0.004\n",
      "Loss: 131.750, Residuals: -0.004\n",
      "Loss: 131.750, Residuals: -0.004\n",
      "Loss: 131.750, Residuals: -0.004\n",
      "Loss: 131.750, Residuals: -0.004\n",
      "Loss: 131.749, Residuals: -0.004\n",
      "Loss: 131.749, Residuals: -0.004\n",
      "Loss: 131.749, Residuals: -0.004\n",
      "Loss: 131.749, Residuals: -0.004\n",
      "Loss: 131.749, Residuals: -0.004\n",
      "Loss: 131.748, Residuals: -0.004\n",
      "Loss: 131.748, Residuals: -0.004\n",
      "Loss: 131.748, Residuals: -0.004\n",
      "Loss: 131.748, Residuals: -0.004\n",
      "Loss: 131.748, Residuals: -0.004\n",
      "Loss: 131.747, Residuals: -0.004\n",
      "Loss: 131.747, Residuals: -0.004\n",
      "Loss: 131.747, Residuals: -0.004\n",
      "Loss: 131.747, Residuals: -0.004\n",
      "Loss: 131.746, Residuals: -0.004\n",
      "Loss: 131.746, Residuals: -0.004\n",
      "Loss: 131.746, Residuals: -0.004\n",
      "Loss: 131.746, Residuals: -0.004\n",
      "Loss: 131.745, Residuals: -0.004\n",
      "Loss: 131.745, Residuals: -0.004\n",
      "Loss: 131.745, Residuals: -0.004\n",
      "Loss: 131.745, Residuals: -0.004\n",
      "Loss: 131.744, Residuals: -0.004\n",
      "Loss: 131.744, Residuals: -0.004\n",
      "Loss: 131.743, Residuals: -0.004\n",
      "Loss: 131.743, Residuals: -0.004\n",
      "Loss: 131.742, Residuals: -0.004\n",
      "Loss: 131.742, Residuals: -0.004\n",
      "Loss: 131.742, Residuals: -0.004\n",
      "Loss: 131.741, Residuals: -0.004\n",
      "Loss: 131.740, Residuals: -0.004\n",
      "Loss: 131.740, Residuals: -0.003\n",
      "Loss: 131.739, Residuals: -0.004\n",
      "Loss: 131.738, Residuals: -0.004\n",
      "Loss: 131.738, Residuals: -0.004\n",
      "Loss: 131.737, Residuals: -0.004\n",
      "Loss: 131.736, Residuals: -0.003\n",
      "Loss: 131.735, Residuals: -0.003\n",
      "Loss: 131.734, Residuals: -0.004\n",
      "Loss: 131.734, Residuals: -0.003\n",
      "Loss: 131.732, Residuals: -0.003\n",
      "Loss: 131.731, Residuals: -0.003\n",
      "Loss: 131.730, Residuals: -0.003\n",
      "Loss: 131.729, Residuals: -0.003\n",
      "Loss: 131.728, Residuals: -0.003\n",
      "Loss: 131.728, Residuals: -0.003\n",
      "Loss: 131.726, Residuals: -0.003\n",
      "Loss: 131.725, Residuals: -0.003\n",
      "Loss: 131.724, Residuals: -0.003\n",
      "Loss: 131.723, Residuals: -0.003\n",
      "Loss: 131.722, Residuals: -0.003\n",
      "Loss: 131.721, Residuals: -0.003\n",
      "Loss: 131.720, Residuals: -0.003\n",
      "Loss: 131.719, Residuals: -0.003\n",
      "Loss: 131.718, Residuals: -0.003\n",
      "Loss: 131.717, Residuals: -0.003\n",
      "Loss: 131.717, Residuals: -0.003\n",
      "Loss: 131.716, Residuals: -0.003\n",
      "Loss: 131.716, Residuals: -0.003\n",
      "Loss: 131.715, Residuals: -0.003\n",
      "Loss: 131.715, Residuals: -0.003\n",
      "Loss: 131.715, Residuals: -0.003\n",
      "Loss: 131.714, Residuals: -0.003\n",
      "Loss: 131.714, Residuals: -0.003\n",
      "Loss: 131.714, Residuals: -0.003\n",
      "Loss: 131.713, Residuals: -0.003\n",
      "Loss: 131.713, Residuals: -0.003\n",
      "Loss: 131.713, Residuals: -0.003\n",
      "Loss: 131.713, Residuals: -0.003\n",
      "Loss: 131.712, Residuals: -0.003\n",
      "Loss: 131.712, Residuals: -0.003\n",
      "Loss: 131.712, Residuals: -0.003\n",
      "Loss: 131.712, Residuals: -0.003\n",
      "Loss: 131.712, Residuals: -0.003\n",
      "Loss: 131.712, Residuals: -0.003\n",
      "Loss: 131.712, Residuals: -0.003\n",
      "Loss: 131.712, Residuals: -0.003\n",
      "Loss: 131.712, Residuals: -0.003\n",
      "Loss: 131.712, Residuals: -0.003\n",
      "Evidence 448.441\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.73e-01\n",
      "Loss: 149.088, Residuals: -0.004\n",
      "Loss: 148.768, Residuals: 0.000\n",
      "Loss: 148.665, Residuals: -0.001\n",
      "Loss: 148.509, Residuals: 0.000\n",
      "Loss: 148.504, Residuals: 0.000\n",
      "Loss: 148.465, Residuals: 0.000\n",
      "Loss: 148.424, Residuals: 0.000\n",
      "Loss: 148.422, Residuals: -0.000\n",
      "Loss: 148.418, Residuals: 0.000\n",
      "Loss: 148.413, Residuals: 0.000\n",
      "Loss: 148.412, Residuals: 0.001\n",
      "Loss: 148.411, Residuals: 0.001\n",
      "Loss: 148.410, Residuals: 0.000\n",
      "Loss: 148.409, Residuals: 0.000\n",
      "Evidence 457.475\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.89e-01\n",
      "Loss: 155.150, Residuals: 0.002\n",
      "Loss: 154.989, Residuals: 0.003\n",
      "Loss: 154.953, Residuals: 0.003\n",
      "Loss: 154.949, Residuals: 0.002\n",
      "Loss: 154.942, Residuals: 0.002\n",
      "Loss: 154.930, Residuals: 0.002\n",
      "Loss: 154.925, Residuals: 0.002\n",
      "Loss: 154.917, Residuals: 0.002\n",
      "Loss: 154.905, Residuals: 0.002\n",
      "Loss: 154.905, Residuals: 0.003\n",
      "Loss: 154.905, Residuals: 0.003\n",
      "Loss: 154.904, Residuals: 0.003\n",
      "Loss: 154.902, Residuals: 0.003\n",
      "Loss: 154.901, Residuals: 0.003\n",
      "Loss: 154.901, Residuals: 0.003\n",
      "Loss: 154.897, Residuals: 0.003\n",
      "Loss: 154.897, Residuals: 0.003\n",
      "Loss: 154.894, Residuals: 0.003\n",
      "Loss: 154.894, Residuals: 0.003\n",
      "Loss: 154.894, Residuals: 0.003\n",
      "Loss: 154.892, Residuals: 0.003\n",
      "Loss: 154.892, Residuals: 0.003\n",
      "Loss: 154.892, Residuals: 0.003\n",
      "Loss: 154.892, Residuals: 0.003\n",
      "Evidence 459.932\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.49e-01\n",
      "Loss: 157.253, Residuals: 0.003\n",
      "Loss: 157.187, Residuals: 0.004\n",
      "Loss: 157.181, Residuals: 0.004\n",
      "Loss: 157.171, Residuals: 0.004\n",
      "Loss: 157.154, Residuals: 0.004\n",
      "Loss: 157.154, Residuals: 0.004\n",
      "Loss: 157.149, Residuals: 0.004\n",
      "Loss: 157.140, Residuals: 0.004\n",
      "Loss: 157.139, Residuals: 0.004\n",
      "Loss: 157.136, Residuals: 0.004\n",
      "Loss: 157.132, Residuals: 0.004\n",
      "Loss: 157.132, Residuals: 0.004\n",
      "Loss: 157.130, Residuals: 0.004\n",
      "Loss: 157.126, Residuals: 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 157.126, Residuals: 0.004\n",
      "Loss: 157.124, Residuals: 0.004\n",
      "Loss: 157.124, Residuals: 0.004\n",
      "Evidence 461.024\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.03e-01\n",
      "Loss: 158.087, Residuals: 0.005\n",
      "Loss: 158.043, Residuals: 0.005\n",
      "Loss: 158.039, Residuals: 0.005\n",
      "Loss: 158.034, Residuals: 0.005\n",
      "Loss: 158.025, Residuals: 0.005\n",
      "Loss: 158.019, Residuals: 0.005\n",
      "Loss: 158.010, Residuals: 0.005\n",
      "Loss: 158.009, Residuals: 0.005\n",
      "Loss: 158.004, Residuals: 0.005\n",
      "Loss: 157.999, Residuals: 0.005\n",
      "Loss: 157.999, Residuals: 0.005\n",
      "Loss: 157.998, Residuals: 0.005\n",
      "Loss: 157.992, Residuals: 0.005\n",
      "Loss: 157.992, Residuals: 0.005\n",
      "Loss: 157.987, Residuals: 0.005\n",
      "Loss: 157.986, Residuals: 0.005\n",
      "Loss: 157.985, Residuals: 0.005\n",
      "Loss: 157.982, Residuals: 0.005\n",
      "Loss: 157.982, Residuals: 0.005\n",
      "Loss: 157.979, Residuals: 0.005\n",
      "Loss: 157.979, Residuals: 0.005\n",
      "Loss: 157.977, Residuals: 0.005\n",
      "Loss: 157.977, Residuals: 0.005\n",
      "Loss: 157.977, Residuals: 0.005\n",
      "Evidence 461.808\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.20e-01\n",
      "Loss: 158.472, Residuals: 0.005\n",
      "Loss: 158.428, Residuals: 0.006\n",
      "Loss: 158.428, Residuals: 0.005\n",
      "Loss: 158.422, Residuals: 0.005\n",
      "Loss: 158.417, Residuals: 0.006\n",
      "Loss: 158.416, Residuals: 0.006\n",
      "Loss: 158.406, Residuals: 0.006\n",
      "Loss: 158.406, Residuals: 0.006\n",
      "Loss: 158.396, Residuals: 0.006\n",
      "Loss: 158.393, Residuals: 0.006\n",
      "Loss: 158.392, Residuals: 0.005\n",
      "Loss: 158.392, Residuals: 0.006\n",
      "Loss: 158.389, Residuals: 0.006\n",
      "Loss: 158.389, Residuals: 0.006\n",
      "Loss: 158.384, Residuals: 0.006\n",
      "Loss: 158.384, Residuals: 0.006\n",
      "Loss: 158.381, Residuals: 0.006\n",
      "Loss: 158.381, Residuals: 0.006\n",
      "Loss: 158.380, Residuals: 0.006\n",
      "Loss: 158.378, Residuals: 0.006\n",
      "Loss: 158.378, Residuals: 0.006\n",
      "Loss: 158.377, Residuals: 0.006\n",
      "Loss: 158.376, Residuals: 0.006\n",
      "Loss: 158.376, Residuals: 0.006\n",
      "Loss: 158.376, Residuals: 0.006\n",
      "Evidence 462.500\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.48e-01\n",
      "Loss: 158.686, Residuals: 0.006\n",
      "Loss: 158.661, Residuals: 0.006\n",
      "Loss: 158.655, Residuals: 0.007\n",
      "Loss: 158.646, Residuals: 0.006\n",
      "Loss: 158.631, Residuals: 0.006\n",
      "Loss: 158.630, Residuals: 0.006\n",
      "Loss: 158.625, Residuals: 0.006\n",
      "Loss: 158.617, Residuals: 0.006\n",
      "Loss: 158.617, Residuals: 0.006\n",
      "Loss: 158.609, Residuals: 0.006\n",
      "Loss: 158.609, Residuals: 0.006\n",
      "Loss: 158.607, Residuals: 0.006\n",
      "Loss: 158.603, Residuals: 0.006\n",
      "Loss: 158.602, Residuals: 0.006\n",
      "Loss: 158.598, Residuals: 0.006\n",
      "Loss: 158.598, Residuals: 0.006\n",
      "Loss: 158.593, Residuals: 0.006\n",
      "Loss: 158.593, Residuals: 0.006\n",
      "Loss: 158.592, Residuals: 0.006\n",
      "Loss: 158.592, Residuals: 0.006\n",
      "Loss: 158.592, Residuals: 0.006\n",
      "Loss: 158.591, Residuals: 0.006\n",
      "Loss: 158.591, Residuals: 0.006\n",
      "Evidence 463.082\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.85e-01\n",
      "Loss: 158.801, Residuals: 0.006\n",
      "Loss: 158.788, Residuals: 0.007\n",
      "Loss: 158.767, Residuals: 0.007\n",
      "Loss: 158.764, Residuals: 0.006\n",
      "Loss: 158.757, Residuals: 0.006\n",
      "Loss: 158.757, Residuals: 0.007\n",
      "Loss: 158.745, Residuals: 0.006\n",
      "Loss: 158.737, Residuals: 0.006\n",
      "Loss: 158.736, Residuals: 0.007\n",
      "Loss: 158.735, Residuals: 0.006\n",
      "Loss: 158.729, Residuals: 0.006\n",
      "Loss: 158.728, Residuals: 0.006\n",
      "Loss: 158.720, Residuals: 0.006\n",
      "Loss: 158.719, Residuals: 0.007\n",
      "Loss: 158.718, Residuals: 0.006\n",
      "Loss: 158.717, Residuals: 0.006\n",
      "Loss: 158.716, Residuals: 0.006\n",
      "Loss: 158.715, Residuals: 0.006\n",
      "Loss: 158.714, Residuals: 0.006\n",
      "Loss: 158.714, Residuals: 0.006\n",
      "Loss: 158.713, Residuals: 0.006\n",
      "Loss: 158.711, Residuals: 0.006\n",
      "Loss: 158.711, Residuals: 0.006\n",
      "Loss: 158.710, Residuals: 0.006\n",
      "Loss: 158.710, Residuals: 0.006\n",
      "Loss: 158.710, Residuals: 0.006\n",
      "Loss: 158.709, Residuals: 0.006\n",
      "Loss: 158.708, Residuals: 0.006\n",
      "Evidence 463.541\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 11.859, Residuals: -0.094\n",
      "Loss: 7.091, Residuals: -0.025\n",
      "Loss: 5.111, Residuals: -0.041\n",
      "Loss: 4.409, Residuals: -0.070\n",
      "Loss: 4.038, Residuals: -0.051\n",
      "Loss: 3.745, Residuals: -0.015\n",
      "Loss: 3.654, Residuals: 0.014\n",
      "Loss: 3.525, Residuals: 0.018\n",
      "Loss: 3.295, Residuals: 0.008\n",
      "Loss: 3.050, Residuals: 0.021\n",
      "Loss: 3.031, Residuals: 0.006\n",
      "Loss: 3.003, Residuals: 0.008\n",
      "Loss: 2.954, Residuals: 0.002\n",
      "Loss: 2.872, Residuals: -0.007\n",
      "Loss: 2.862, Residuals: 0.015\n",
      "Loss: 2.777, Residuals: 0.003\n",
      "Loss: 2.733, Residuals: 0.009\n",
      "Loss: 2.686, Residuals: 0.008\n",
      "Loss: 2.676, Residuals: -0.001\n",
      "Loss: 2.656, Residuals: -0.006\n",
      "Loss: 2.620, Residuals: -0.015\n",
      "Loss: 2.610, Residuals: -0.008\n",
      "Loss: 2.591, Residuals: -0.013\n",
      "Loss: 2.558, Residuals: -0.021\n",
      "Loss: 2.555, Residuals: -0.017\n",
      "Loss: 2.536, Residuals: -0.023\n",
      "Loss: 2.506, Residuals: -0.040\n",
      "Loss: 2.505, Residuals: -0.039\n",
      "Loss: 2.496, Residuals: -0.043\n",
      "Loss: 2.488, Residuals: -0.044\n",
      "Loss: 2.486, Residuals: -0.047\n",
      "Loss: 2.471, Residuals: -0.052\n",
      "Loss: 2.461, Residuals: -0.059\n",
      "Loss: 2.460, Residuals: -0.057\n",
      "Loss: 2.459, Residuals: -0.056\n",
      "Loss: 2.457, Residuals: -0.056\n",
      "Loss: 2.455, Residuals: -0.057\n",
      "Loss: 2.455, Residuals: -0.058\n",
      "Loss: 2.447, Residuals: -0.060\n",
      "Loss: 2.435, Residuals: -0.066\n",
      "Loss: 2.434, Residuals: -0.065\n",
      "Loss: 2.434, Residuals: -0.066\n",
      "Loss: 2.434, Residuals: -0.066\n",
      "Loss: 2.430, Residuals: -0.069\n",
      "Loss: 2.429, Residuals: -0.070\n",
      "Loss: 2.425, Residuals: -0.072\n",
      "Loss: 2.425, Residuals: -0.072\n",
      "Loss: 2.422, Residuals: -0.073\n",
      "Loss: 2.420, Residuals: -0.076\n",
      "Loss: 2.420, Residuals: -0.076\n",
      "Loss: 2.419, Residuals: -0.076\n",
      "Loss: 2.415, Residuals: -0.077\n",
      "Loss: 2.415, Residuals: -0.078\n",
      "Loss: 2.412, Residuals: -0.079\n",
      "Loss: 2.408, Residuals: -0.083\n",
      "Loss: 2.408, Residuals: -0.083\n",
      "Loss: 2.408, Residuals: -0.083\n",
      "Loss: 2.408, Residuals: -0.083\n",
      "Loss: 2.408, Residuals: -0.085\n",
      "Loss: 2.408, Residuals: -0.083\n",
      "Loss: 2.404, Residuals: -0.085\n",
      "Loss: 2.404, Residuals: -0.085\n",
      "Evidence -382.581\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.97e-03\n",
      "Loss: 10.526, Residuals: -0.056\n",
      "Loss: 10.500, Residuals: -0.063\n",
      "Loss: 10.455, Residuals: -0.060\n",
      "Loss: 10.402, Residuals: -0.058\n",
      "Loss: 10.317, Residuals: -0.056\n",
      "Loss: 10.301, Residuals: -0.061\n",
      "Loss: 10.270, Residuals: -0.059\n",
      "Loss: 10.216, Residuals: -0.053\n",
      "Loss: 10.216, Residuals: -0.054\n",
      "Loss: 10.201, Residuals: -0.052\n",
      "Loss: 10.197, Residuals: -0.046\n",
      "Loss: 10.162, Residuals: -0.042\n",
      "Loss: 10.161, Residuals: -0.043\n",
      "Loss: 10.160, Residuals: -0.043\n",
      "Loss: 10.151, Residuals: -0.040\n",
      "Loss: 10.149, Residuals: -0.038\n",
      "Loss: 10.139, Residuals: -0.035\n",
      "Loss: 10.139, Residuals: -0.036\n",
      "Loss: 10.139, Residuals: -0.036\n",
      "Loss: 10.138, Residuals: -0.036\n",
      "Loss: 10.136, Residuals: -0.035\n",
      "Loss: 10.133, Residuals: -0.034\n",
      "Loss: 10.109, Residuals: -0.030\n",
      "Loss: 10.107, Residuals: -0.030\n",
      "Loss: 10.106, Residuals: -0.030\n",
      "Loss: 10.105, Residuals: -0.030\n",
      "Loss: 10.105, Residuals: -0.030\n",
      "Loss: 10.103, Residuals: -0.029\n",
      "Loss: 10.103, Residuals: -0.029\n",
      "Loss: 10.097, Residuals: -0.028\n",
      "Loss: 10.097, Residuals: -0.028\n",
      "Loss: 10.093, Residuals: -0.027\n",
      "Loss: 10.093, Residuals: -0.027\n",
      "Loss: 10.092, Residuals: -0.027\n",
      "Loss: 10.092, Residuals: -0.027\n",
      "Loss: 10.091, Residuals: -0.026\n",
      "Loss: 10.091, Residuals: -0.026\n",
      "Loss: 10.090, Residuals: -0.026\n",
      "Loss: 10.088, Residuals: -0.025\n",
      "Loss: 10.088, Residuals: -0.025\n",
      "Loss: 10.088, Residuals: -0.025\n",
      "Loss: 10.087, Residuals: -0.025\n",
      "Loss: 10.087, Residuals: -0.024\n",
      "Loss: 10.087, Residuals: -0.024\n",
      "Loss: 10.087, Residuals: -0.024\n",
      "Loss: 10.086, Residuals: -0.024\n",
      "Loss: 10.086, Residuals: -0.023\n",
      "Loss: 10.086, Residuals: -0.023\n",
      "Loss: 10.086, Residuals: -0.023\n",
      "Loss: 10.086, Residuals: -0.023\n",
      "Loss: 10.086, Residuals: -0.023\n",
      "Loss: 10.085, Residuals: -0.023\n",
      "Loss: 10.085, Residuals: -0.023\n",
      "Loss: 10.085, Residuals: -0.023\n",
      "Loss: 10.085, Residuals: -0.023\n",
      "Loss: 10.085, Residuals: -0.023\n",
      "Loss: 10.085, Residuals: -0.023\n",
      "Loss: 10.085, Residuals: -0.022\n",
      "Loss: 10.085, Residuals: -0.022\n",
      "Loss: 10.085, Residuals: -0.022\n",
      "Loss: 10.085, Residuals: -0.022\n",
      "Loss: 10.085, Residuals: -0.022\n",
      "Loss: 10.085, Residuals: -0.022\n",
      "Loss: 10.085, Residuals: -0.022\n",
      "Loss: 10.085, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Loss: 10.084, Residuals: -0.022\n",
      "Evidence 85.385\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.94e-02\n",
      "Loss: 38.033, Residuals: -0.019\n",
      "Loss: 37.980, Residuals: -0.021\n",
      "Loss: 37.882, Residuals: -0.020\n",
      "Loss: 37.727, Residuals: -0.016\n",
      "Loss: 37.715, Residuals: -0.019\n",
      "Loss: 37.610, Residuals: -0.016\n",
      "Loss: 37.438, Residuals: -0.012\n",
      "Loss: 37.413, Residuals: -0.010\n",
      "Loss: 37.370, Residuals: -0.009\n",
      "Loss: 37.300, Residuals: -0.007\n",
      "Loss: 37.277, Residuals: -0.007\n",
      "Loss: 37.239, Residuals: -0.007\n",
      "Loss: 37.233, Residuals: -0.006\n",
      "Loss: 37.188, Residuals: -0.005\n",
      "Loss: 37.178, Residuals: -0.004\n",
      "Loss: 37.159, Residuals: -0.004\n",
      "Loss: 37.144, Residuals: -0.004\n",
      "Loss: 37.118, Residuals: -0.004\n",
      "Loss: 37.112, Residuals: -0.004\n",
      "Loss: 37.102, Residuals: -0.004\n",
      "Loss: 37.082, Residuals: -0.003\n",
      "Loss: 37.075, Residuals: -0.004\n",
      "Loss: 37.066, Residuals: -0.004\n",
      "Loss: 37.049, Residuals: -0.003\n",
      "Loss: 37.047, Residuals: -0.003\n",
      "Loss: 37.031, Residuals: -0.002\n",
      "Loss: 37.029, Residuals: -0.002\n",
      "Loss: 37.026, Residuals: -0.003\n",
      "Loss: 37.020, Residuals: -0.002\n",
      "Loss: 37.011, Residuals: -0.002\n",
      "Loss: 37.010, Residuals: -0.001\n",
      "Loss: 37.004, Residuals: -0.001\n",
      "Loss: 37.003, Residuals: -0.001\n",
      "Loss: 37.002, Residuals: -0.001\n",
      "Loss: 37.001, Residuals: -0.001\n",
      "Loss: 37.001, Residuals: -0.001\n",
      "Loss: 36.999, Residuals: -0.001\n",
      "Loss: 36.996, Residuals: -0.001\n",
      "Loss: 36.995, Residuals: -0.001\n",
      "Loss: 36.995, Residuals: -0.001\n",
      "Loss: 36.995, Residuals: -0.001\n",
      "Loss: 36.995, Residuals: -0.001\n",
      "Loss: 36.995, Residuals: -0.001\n",
      "Loss: 36.995, Residuals: -0.001\n",
      "Loss: 36.995, Residuals: -0.001\n",
      "Loss: 36.995, Residuals: -0.001\n",
      "Loss: 36.994, Residuals: -0.001\n",
      "Loss: 36.994, Residuals: -0.001\n",
      "Loss: 36.994, Residuals: -0.001\n",
      "Loss: 36.994, Residuals: -0.001\n",
      "Loss: 36.994, Residuals: -0.001\n",
      "Loss: 36.994, Residuals: -0.001\n",
      "Loss: 36.994, Residuals: -0.001\n",
      "Evidence 284.200\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.30e-01\n",
      "Loss: 86.382, Residuals: -0.007\n",
      "Loss: 85.898, Residuals: 0.002\n",
      "Loss: 85.815, Residuals: 0.001\n",
      "Loss: 85.665, Residuals: 0.002\n",
      "Loss: 85.477, Residuals: 0.004\n",
      "Loss: 85.430, Residuals: 0.002\n",
      "Loss: 85.416, Residuals: 0.002\n",
      "Loss: 85.394, Residuals: 0.003\n",
      "Loss: 85.356, Residuals: 0.004\n",
      "Loss: 85.349, Residuals: 0.003\n",
      "Loss: 85.337, Residuals: 0.004\n",
      "Loss: 85.316, Residuals: 0.004\n",
      "Loss: 85.287, Residuals: 0.006\n",
      "Loss: 85.283, Residuals: 0.005\n",
      "Loss: 85.281, Residuals: 0.005\n",
      "Loss: 85.280, Residuals: 0.006\n",
      "Loss: 85.278, Residuals: 0.005\n",
      "Loss: 85.274, Residuals: 0.006\n",
      "Loss: 85.268, Residuals: 0.006\n",
      "Loss: 85.266, Residuals: 0.005\n",
      "Loss: 85.263, Residuals: 0.006\n",
      "Loss: 85.263, Residuals: 0.006\n",
      "Loss: 85.261, Residuals: 0.006\n",
      "Loss: 85.261, Residuals: 0.006\n",
      "Loss: 85.260, Residuals: 0.006\n",
      "Loss: 85.258, Residuals: 0.006\n",
      "Loss: 85.258, Residuals: 0.006\n",
      "Loss: 85.258, Residuals: 0.006\n",
      "Loss: 85.258, Residuals: 0.006\n",
      "Evidence 389.730\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 9.13e-01\n",
      "Loss: 124.880, Residuals: -0.003\n",
      "Loss: 124.577, Residuals: -0.002\n",
      "Loss: 124.367, Residuals: 0.000\n",
      "Loss: 124.031, Residuals: 0.002\n",
      "Loss: 123.981, Residuals: 0.002\n",
      "Loss: 123.890, Residuals: 0.002\n",
      "Loss: 123.759, Residuals: 0.004\n",
      "Loss: 123.745, Residuals: 0.002\n",
      "Loss: 123.720, Residuals: 0.003\n",
      "Loss: 123.683, Residuals: 0.004\n",
      "Loss: 123.682, Residuals: 0.004\n",
      "Loss: 123.680, Residuals: 0.004\n",
      "Loss: 123.662, Residuals: 0.004\n",
      "Loss: 123.659, Residuals: 0.004\n",
      "Loss: 123.653, Residuals: 0.004\n",
      "Loss: 123.643, Residuals: 0.004\n",
      "Loss: 123.642, Residuals: 0.004\n",
      "Loss: 123.639, Residuals: 0.004\n",
      "Loss: 123.633, Residuals: 0.004\n",
      "Loss: 123.633, Residuals: 0.004\n",
      "Loss: 123.632, Residuals: 0.004\n",
      "Loss: 123.630, Residuals: 0.004\n",
      "Loss: 123.629, Residuals: 0.004\n",
      "Loss: 123.629, Residuals: 0.004\n",
      "Loss: 123.629, Residuals: 0.004\n",
      "Loss: 123.629, Residuals: 0.004\n",
      "Loss: 123.629, Residuals: 0.004\n",
      "Loss: 123.628, Residuals: 0.004\n",
      "Loss: 123.628, Residuals: 0.004\n",
      "Loss: 123.628, Residuals: 0.004\n",
      "Loss: 123.628, Residuals: 0.004\n",
      "Evidence 422.037\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.35e+00\n",
      "Loss: 141.640, Residuals: 0.001\n",
      "Loss: 141.504, Residuals: 0.004\n",
      "Loss: 141.284, Residuals: 0.004\n",
      "Loss: 141.106, Residuals: 0.006\n",
      "Loss: 141.068, Residuals: 0.003\n",
      "Loss: 141.049, Residuals: 0.004\n",
      "Loss: 141.021, Residuals: 0.005\n",
      "Loss: 141.012, Residuals: 0.005\n",
      "Loss: 140.998, Residuals: 0.005\n",
      "Loss: 140.996, Residuals: 0.004\n",
      "Loss: 140.978, Residuals: 0.005\n",
      "Loss: 140.975, Residuals: 0.004\n",
      "Loss: 140.968, Residuals: 0.005\n",
      "Loss: 140.965, Residuals: 0.004\n",
      "Loss: 140.960, Residuals: 0.005\n",
      "Loss: 140.960, Residuals: 0.005\n",
      "Loss: 140.958, Residuals: 0.005\n",
      "Loss: 140.956, Residuals: 0.005\n",
      "Loss: 140.955, Residuals: 0.005\n",
      "Loss: 140.954, Residuals: 0.005\n",
      "Loss: 140.953, Residuals: 0.005\n",
      "Loss: 140.953, Residuals: 0.005\n",
      "Loss: 140.953, Residuals: 0.005\n",
      "Loss: 140.953, Residuals: 0.005\n",
      "Loss: 140.952, Residuals: 0.005\n",
      "Loss: 140.952, Residuals: 0.005\n",
      "Loss: 140.952, Residuals: 0.005\n",
      "Loss: 140.952, Residuals: 0.005\n",
      "Loss: 140.952, Residuals: 0.005\n",
      "Loss: 140.952, Residuals: 0.005\n",
      "Loss: 140.951, Residuals: 0.005\n",
      "Loss: 140.951, Residuals: 0.005\n",
      "Loss: 140.951, Residuals: 0.005\n",
      "Loss: 140.951, Residuals: 0.005\n",
      "Evidence 430.722\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.66e+00\n",
      "Loss: 147.870, Residuals: 0.006\n",
      "Loss: 147.747, Residuals: 0.006\n",
      "Loss: 147.597, Residuals: 0.008\n",
      "Loss: 147.575, Residuals: 0.008\n",
      "Loss: 147.545, Residuals: 0.008\n",
      "Loss: 147.542, Residuals: 0.007\n",
      "Loss: 147.538, Residuals: 0.007\n",
      "Loss: 147.532, Residuals: 0.008\n",
      "Loss: 147.532, Residuals: 0.008\n",
      "Loss: 147.528, Residuals: 0.008\n",
      "Loss: 147.527, Residuals: 0.008\n",
      "Loss: 147.525, Residuals: 0.008\n",
      "Loss: 147.525, Residuals: 0.008\n",
      "Loss: 147.525, Residuals: 0.008\n",
      "Loss: 147.524, Residuals: 0.008\n",
      "Loss: 147.524, Residuals: 0.008\n",
      "Loss: 147.523, Residuals: 0.008\n",
      "Loss: 147.523, Residuals: 0.008\n",
      "Loss: 147.523, Residuals: 0.008\n",
      "Loss: 147.523, Residuals: 0.008\n",
      "Loss: 147.523, Residuals: 0.008\n",
      "Loss: 147.523, Residuals: 0.008\n",
      "Loss: 147.523, Residuals: 0.008\n",
      "Evidence 433.621\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.82e+00\n",
      "Loss: 150.182, Residuals: 0.010\n",
      "Loss: 150.105, Residuals: 0.009\n",
      "Loss: 150.081, Residuals: 0.011\n",
      "Loss: 150.042, Residuals: 0.011\n",
      "Loss: 150.018, Residuals: 0.011\n",
      "Loss: 150.016, Residuals: 0.011\n",
      "Loss: 150.014, Residuals: 0.011\n",
      "Loss: 150.013, Residuals: 0.011\n",
      "Loss: 150.013, Residuals: 0.011\n",
      "Loss: 150.013, Residuals: 0.011\n",
      "Loss: 150.013, Residuals: 0.011\n",
      "Loss: 150.013, Residuals: 0.011\n",
      "Evidence 434.965\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.90e+00\n",
      "Loss: 151.094, Residuals: 0.014\n",
      "Loss: 151.034, Residuals: 0.013\n",
      "Loss: 150.993, Residuals: 0.014\n",
      "Loss: 150.988, Residuals: 0.014\n",
      "Loss: 150.985, Residuals: 0.014\n",
      "Loss: 150.982, Residuals: 0.014\n",
      "Loss: 150.982, Residuals: 0.014\n",
      "Loss: 150.981, Residuals: 0.014\n",
      "Loss: 150.981, Residuals: 0.014\n",
      "Loss: 150.981, Residuals: 0.014\n",
      "Loss: 150.981, Residuals: 0.014\n",
      "Evidence 435.857\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.94e+00\n",
      "Loss: 151.536, Residuals: 0.017\n",
      "Loss: 151.493, Residuals: 0.017\n",
      "Loss: 151.484, Residuals: 0.016\n",
      "Loss: 151.469, Residuals: 0.017\n",
      "Loss: 151.454, Residuals: 0.017\n",
      "Loss: 151.452, Residuals: 0.017\n",
      "Loss: 151.451, Residuals: 0.017\n",
      "Loss: 151.450, Residuals: 0.017\n",
      "Loss: 151.450, Residuals: 0.017\n",
      "Loss: 151.450, Residuals: 0.017\n",
      "Loss: 151.450, Residuals: 0.017\n",
      "Loss: 151.450, Residuals: 0.017\n",
      "Loss: 151.450, Residuals: 0.017\n",
      "Loss: 151.450, Residuals: 0.017\n",
      "Evidence 436.526\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.96e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 151.815, Residuals: 0.018\n",
      "Loss: 151.803, Residuals: 0.019\n",
      "Loss: 151.785, Residuals: 0.019\n",
      "Loss: 151.769, Residuals: 0.019\n",
      "Loss: 151.765, Residuals: 0.019\n",
      "Loss: 151.762, Residuals: 0.019\n",
      "Loss: 151.762, Residuals: 0.019\n",
      "Loss: 151.761, Residuals: 0.019\n",
      "Loss: 151.761, Residuals: 0.019\n",
      "Loss: 151.761, Residuals: 0.019\n",
      "Loss: 151.761, Residuals: 0.019\n",
      "Loss: 151.761, Residuals: 0.019\n",
      "Evidence 436.999\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.98e+00\n",
      "Loss: 152.045, Residuals: 0.020\n",
      "Loss: 152.037, Residuals: 0.021\n",
      "Loss: 152.025, Residuals: 0.021\n",
      "Loss: 152.014, Residuals: 0.021\n",
      "Loss: 152.011, Residuals: 0.021\n",
      "Loss: 152.009, Residuals: 0.021\n",
      "Loss: 152.008, Residuals: 0.021\n",
      "Loss: 152.008, Residuals: 0.021\n",
      "Loss: 152.008, Residuals: 0.021\n",
      "Loss: 152.008, Residuals: 0.021\n",
      "Loss: 152.008, Residuals: 0.021\n",
      "Loss: 152.008, Residuals: 0.021\n",
      "Evidence 437.306\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 11.783, Residuals: -0.159\n",
      "Loss: 6.911, Residuals: -0.056\n",
      "Loss: 5.211, Residuals: -0.053\n",
      "Loss: 4.503, Residuals: -0.068\n",
      "Loss: 3.997, Residuals: -0.077\n",
      "Loss: 3.814, Residuals: -0.034\n",
      "Loss: 3.588, Residuals: -0.021\n",
      "Loss: 3.458, Residuals: -0.000\n",
      "Loss: 3.382, Residuals: 0.044\n",
      "Loss: 3.242, Residuals: 0.033\n",
      "Loss: 3.050, Residuals: 0.026\n",
      "Loss: 3.026, Residuals: 0.043\n",
      "Loss: 2.982, Residuals: 0.036\n",
      "Loss: 2.908, Residuals: 0.024\n",
      "Loss: 2.870, Residuals: 0.016\n",
      "Loss: 2.854, Residuals: 0.020\n",
      "Loss: 2.842, Residuals: 0.009\n",
      "Loss: 2.820, Residuals: 0.006\n",
      "Loss: 2.782, Residuals: 0.002\n",
      "Loss: 2.717, Residuals: -0.010\n",
      "Loss: 2.687, Residuals: 0.002\n",
      "Loss: 2.635, Residuals: -0.008\n",
      "Loss: 2.631, Residuals: -0.002\n",
      "Loss: 2.600, Residuals: -0.011\n",
      "Loss: 2.547, Residuals: -0.026\n",
      "Loss: 2.538, Residuals: -0.023\n",
      "Loss: 2.473, Residuals: -0.044\n",
      "Loss: 2.469, Residuals: -0.043\n",
      "Loss: 2.440, Residuals: -0.051\n",
      "Loss: 2.432, Residuals: -0.043\n",
      "Loss: 2.432, Residuals: -0.044\n",
      "Loss: 2.431, Residuals: -0.044\n",
      "Loss: 2.422, Residuals: -0.046\n",
      "Loss: 2.407, Residuals: -0.051\n",
      "Loss: 2.406, Residuals: -0.050\n",
      "Loss: 2.404, Residuals: -0.052\n",
      "Loss: 2.400, Residuals: -0.053\n",
      "Loss: 2.394, Residuals: -0.059\n",
      "Loss: 2.394, Residuals: -0.058\n",
      "Loss: 2.388, Residuals: -0.061\n",
      "Loss: 2.388, Residuals: -0.061\n",
      "Loss: 2.384, Residuals: -0.062\n",
      "Loss: 2.383, Residuals: -0.062\n",
      "Loss: 2.378, Residuals: -0.067\n",
      "Loss: 2.378, Residuals: -0.066\n",
      "Loss: 2.374, Residuals: -0.069\n",
      "Loss: 2.374, Residuals: -0.070\n",
      "Loss: 2.372, Residuals: -0.072\n",
      "Loss: 2.372, Residuals: -0.072\n",
      "Loss: 2.369, Residuals: -0.074\n",
      "Loss: 2.369, Residuals: -0.074\n",
      "Evidence -382.131\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.21e-03\n",
      "Loss: 10.550, Residuals: -0.047\n",
      "Loss: 10.533, Residuals: -0.052\n",
      "Loss: 10.501, Residuals: -0.052\n",
      "Loss: 10.446, Residuals: -0.054\n",
      "Loss: 10.376, Residuals: -0.057\n",
      "Loss: 10.259, Residuals: -0.053\n",
      "Loss: 10.233, Residuals: -0.046\n",
      "Loss: 10.189, Residuals: -0.045\n",
      "Loss: 10.152, Residuals: -0.041\n",
      "Loss: 10.143, Residuals: -0.038\n",
      "Loss: 10.138, Residuals: -0.040\n",
      "Loss: 10.130, Residuals: -0.039\n",
      "Loss: 10.116, Residuals: -0.037\n",
      "Loss: 10.091, Residuals: -0.034\n",
      "Loss: 10.090, Residuals: -0.034\n",
      "Loss: 10.056, Residuals: -0.027\n",
      "Loss: 10.054, Residuals: -0.032\n",
      "Loss: 10.050, Residuals: -0.030\n",
      "Loss: 10.045, Residuals: -0.029\n",
      "Loss: 10.040, Residuals: -0.026\n",
      "Loss: 10.040, Residuals: -0.027\n",
      "Loss: 10.039, Residuals: -0.027\n",
      "Loss: 10.039, Residuals: -0.027\n",
      "Loss: 10.038, Residuals: -0.026\n",
      "Loss: 10.038, Residuals: -0.026\n",
      "Loss: 10.037, Residuals: -0.026\n",
      "Loss: 10.036, Residuals: -0.026\n",
      "Loss: 10.036, Residuals: -0.025\n",
      "Loss: 10.036, Residuals: -0.025\n",
      "Loss: 10.036, Residuals: -0.025\n",
      "Loss: 10.036, Residuals: -0.025\n",
      "Loss: 10.036, Residuals: -0.025\n",
      "Loss: 10.036, Residuals: -0.025\n",
      "Loss: 10.035, Residuals: -0.025\n",
      "Loss: 10.035, Residuals: -0.024\n",
      "Loss: 10.035, Residuals: -0.024\n",
      "Loss: 10.035, Residuals: -0.024\n",
      "Loss: 10.035, Residuals: -0.024\n",
      "Loss: 10.035, Residuals: -0.024\n",
      "Loss: 10.035, Residuals: -0.024\n",
      "Loss: 10.035, Residuals: -0.024\n",
      "Loss: 10.035, Residuals: -0.024\n",
      "Loss: 10.035, Residuals: -0.024\n",
      "Evidence 100.536\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.80e-02\n",
      "Loss: 39.290, Residuals: -0.033\n",
      "Loss: 38.980, Residuals: -0.029\n",
      "Loss: 38.807, Residuals: -0.020\n",
      "Loss: 38.752, Residuals: -0.021\n",
      "Loss: 38.716, Residuals: -0.019\n",
      "Loss: 38.486, Residuals: -0.011\n",
      "Loss: 38.457, Residuals: -0.008\n",
      "Loss: 38.449, Residuals: -0.012\n",
      "Loss: 38.433, Residuals: -0.012\n",
      "Loss: 38.406, Residuals: -0.011\n",
      "Loss: 38.360, Residuals: -0.009\n",
      "Loss: 38.347, Residuals: -0.008\n",
      "Loss: 38.327, Residuals: -0.007\n",
      "Loss: 38.325, Residuals: -0.006\n",
      "Loss: 38.311, Residuals: -0.005\n",
      "Loss: 38.292, Residuals: -0.004\n",
      "Loss: 38.291, Residuals: -0.004\n",
      "Loss: 38.290, Residuals: -0.004\n",
      "Loss: 38.290, Residuals: -0.004\n",
      "Loss: 38.289, Residuals: -0.004\n",
      "Loss: 38.287, Residuals: -0.003\n",
      "Loss: 38.286, Residuals: -0.003\n",
      "Loss: 38.286, Residuals: -0.003\n",
      "Loss: 38.286, Residuals: -0.003\n",
      "Loss: 38.285, Residuals: -0.003\n",
      "Loss: 38.285, Residuals: -0.003\n",
      "Loss: 38.285, Residuals: -0.003\n",
      "Loss: 38.285, Residuals: -0.003\n",
      "Loss: 38.285, Residuals: -0.003\n",
      "Loss: 38.285, Residuals: -0.003\n",
      "Loss: 38.285, Residuals: -0.003\n",
      "Loss: 38.285, Residuals: -0.003\n",
      "Loss: 38.285, Residuals: -0.003\n",
      "Loss: 38.285, Residuals: -0.003\n",
      "Evidence 317.212\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.20e-01\n",
      "Loss: 90.447, Residuals: -0.013\n",
      "Loss: 90.006, Residuals: -0.015\n",
      "Loss: 89.568, Residuals: -0.006\n",
      "Loss: 89.491, Residuals: -0.002\n",
      "Loss: 89.352, Residuals: -0.002\n",
      "Loss: 89.333, Residuals: -0.007\n",
      "Loss: 89.180, Residuals: -0.005\n",
      "Loss: 89.040, Residuals: -0.001\n",
      "Loss: 89.031, Residuals: -0.002\n",
      "Loss: 89.020, Residuals: -0.003\n",
      "Loss: 89.014, Residuals: -0.003\n",
      "Loss: 89.013, Residuals: -0.003\n",
      "Loss: 89.011, Residuals: -0.003\n",
      "Loss: 89.008, Residuals: -0.003\n",
      "Loss: 89.004, Residuals: -0.003\n",
      "Loss: 89.004, Residuals: -0.002\n",
      "Loss: 89.003, Residuals: -0.002\n",
      "Loss: 89.003, Residuals: -0.002\n",
      "Loss: 89.003, Residuals: -0.002\n",
      "Loss: 89.003, Residuals: -0.002\n",
      "Loss: 89.003, Residuals: -0.002\n",
      "Loss: 89.003, Residuals: -0.002\n",
      "Loss: 89.003, Residuals: -0.002\n",
      "Evidence 427.746\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.06e-01\n",
      "Loss: 131.113, Residuals: -0.012\n",
      "Loss: 130.603, Residuals: -0.006\n",
      "Loss: 130.494, Residuals: -0.005\n",
      "Loss: 130.309, Residuals: -0.005\n",
      "Loss: 130.114, Residuals: -0.004\n",
      "Loss: 130.078, Residuals: -0.006\n",
      "Loss: 130.021, Residuals: -0.005\n",
      "Loss: 130.003, Residuals: -0.005\n",
      "Loss: 130.000, Residuals: -0.005\n",
      "Loss: 129.969, Residuals: -0.005\n",
      "Loss: 129.920, Residuals: -0.005\n",
      "Loss: 129.912, Residuals: -0.005\n",
      "Loss: 129.901, Residuals: -0.004\n",
      "Loss: 129.889, Residuals: -0.004\n",
      "Loss: 129.869, Residuals: -0.004\n",
      "Loss: 129.860, Residuals: -0.004\n",
      "Loss: 129.857, Residuals: -0.004\n",
      "Loss: 129.837, Residuals: -0.004\n",
      "Loss: 129.831, Residuals: -0.004\n",
      "Loss: 129.826, Residuals: -0.004\n",
      "Loss: 129.816, Residuals: -0.004\n",
      "Loss: 129.800, Residuals: -0.004\n",
      "Loss: 129.796, Residuals: -0.004\n",
      "Loss: 129.793, Residuals: -0.003\n",
      "Loss: 129.789, Residuals: -0.003\n",
      "Loss: 129.787, Residuals: -0.003\n",
      "Loss: 129.786, Residuals: -0.003\n",
      "Loss: 129.780, Residuals: -0.003\n",
      "Loss: 129.779, Residuals: -0.003\n",
      "Loss: 129.779, Residuals: -0.003\n",
      "Loss: 129.778, Residuals: -0.003\n",
      "Loss: 129.775, Residuals: -0.003\n",
      "Loss: 129.775, Residuals: -0.003\n",
      "Loss: 129.775, Residuals: -0.003\n",
      "Loss: 129.775, Residuals: -0.003\n",
      "Loss: 129.774, Residuals: -0.003\n",
      "Loss: 129.773, Residuals: -0.003\n",
      "Loss: 129.773, Residuals: -0.003\n",
      "Loss: 129.773, Residuals: -0.003\n",
      "Loss: 129.773, Residuals: -0.003\n",
      "Loss: 129.773, Residuals: -0.003\n",
      "Loss: 129.773, Residuals: -0.003\n",
      "Loss: 129.773, Residuals: -0.003\n",
      "Evidence 460.529\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.52e-01\n",
      "Loss: 148.353, Residuals: -0.003\n",
      "Loss: 148.310, Residuals: -0.003\n",
      "Loss: 148.229, Residuals: -0.003\n",
      "Loss: 148.090, Residuals: -0.003\n",
      "Loss: 147.929, Residuals: -0.003\n",
      "Loss: 147.925, Residuals: -0.003\n",
      "Loss: 147.916, Residuals: -0.002\n",
      "Loss: 147.852, Residuals: -0.002\n",
      "Loss: 147.843, Residuals: -0.001\n",
      "Loss: 147.841, Residuals: -0.001\n",
      "Loss: 147.835, Residuals: -0.001\n",
      "Loss: 147.825, Residuals: -0.001\n",
      "Loss: 147.824, Residuals: -0.002\n",
      "Loss: 147.816, Residuals: -0.002\n",
      "Loss: 147.802, Residuals: -0.002\n",
      "Loss: 147.795, Residuals: -0.002\n",
      "Loss: 147.795, Residuals: -0.002\n",
      "Loss: 147.792, Residuals: -0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 147.791, Residuals: -0.002\n",
      "Loss: 147.785, Residuals: -0.002\n",
      "Loss: 147.785, Residuals: -0.002\n",
      "Loss: 147.783, Residuals: -0.002\n",
      "Loss: 147.780, Residuals: -0.002\n",
      "Loss: 147.779, Residuals: -0.002\n",
      "Loss: 147.779, Residuals: -0.002\n",
      "Loss: 147.777, Residuals: -0.002\n",
      "Loss: 147.777, Residuals: -0.002\n",
      "Loss: 147.777, Residuals: -0.002\n",
      "Loss: 147.776, Residuals: -0.002\n",
      "Loss: 147.776, Residuals: -0.002\n",
      "Evidence 469.879\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.79e-01\n",
      "Loss: 155.070, Residuals: -0.000\n",
      "Loss: 155.037, Residuals: -0.001\n",
      "Loss: 154.979, Residuals: -0.001\n",
      "Loss: 154.901, Residuals: -0.000\n",
      "Loss: 154.891, Residuals: -0.001\n",
      "Loss: 154.873, Residuals: -0.001\n",
      "Loss: 154.843, Residuals: -0.001\n",
      "Loss: 154.843, Residuals: -0.001\n",
      "Loss: 154.836, Residuals: -0.001\n",
      "Loss: 154.827, Residuals: -0.001\n",
      "Loss: 154.826, Residuals: -0.001\n",
      "Loss: 154.820, Residuals: -0.001\n",
      "Loss: 154.819, Residuals: -0.001\n",
      "Loss: 154.819, Residuals: -0.001\n",
      "Loss: 154.818, Residuals: -0.001\n",
      "Loss: 154.813, Residuals: -0.001\n",
      "Loss: 154.804, Residuals: -0.001\n",
      "Loss: 154.804, Residuals: -0.001\n",
      "Loss: 154.803, Residuals: -0.001\n",
      "Loss: 154.802, Residuals: -0.001\n",
      "Loss: 154.802, Residuals: -0.001\n",
      "Loss: 154.801, Residuals: -0.001\n",
      "Loss: 154.801, Residuals: -0.001\n",
      "Loss: 154.800, Residuals: -0.001\n",
      "Evidence 472.230\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.05e-01\n",
      "Loss: 157.345, Residuals: 0.002\n",
      "Loss: 157.324, Residuals: 0.001\n",
      "Loss: 157.290, Residuals: 0.000\n",
      "Loss: 157.251, Residuals: 0.000\n",
      "Loss: 157.247, Residuals: -0.000\n",
      "Loss: 157.242, Residuals: 0.000\n",
      "Loss: 157.234, Residuals: 0.000\n",
      "Loss: 157.221, Residuals: 0.000\n",
      "Loss: 157.220, Residuals: 0.000\n",
      "Loss: 157.214, Residuals: 0.000\n",
      "Loss: 157.212, Residuals: -0.000\n",
      "Loss: 157.212, Residuals: -0.000\n",
      "Loss: 157.212, Residuals: -0.000\n",
      "Loss: 157.212, Residuals: -0.000\n",
      "Loss: 157.208, Residuals: -0.000\n",
      "Loss: 157.208, Residuals: -0.000\n",
      "Evidence 473.030\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.61e-01\n",
      "Loss: 158.139, Residuals: 0.001\n",
      "Loss: 158.124, Residuals: 0.001\n",
      "Loss: 158.103, Residuals: 0.000\n",
      "Loss: 158.075, Residuals: 0.000\n",
      "Loss: 158.074, Residuals: 0.000\n",
      "Loss: 158.069, Residuals: 0.000\n",
      "Loss: 158.068, Residuals: 0.000\n",
      "Loss: 158.066, Residuals: 0.000\n",
      "Loss: 158.062, Residuals: 0.000\n",
      "Loss: 158.062, Residuals: 0.001\n",
      "Loss: 158.059, Residuals: 0.000\n",
      "Loss: 158.055, Residuals: 0.000\n",
      "Loss: 158.054, Residuals: 0.001\n",
      "Loss: 158.054, Residuals: 0.000\n",
      "Loss: 158.054, Residuals: 0.000\n",
      "Loss: 158.053, Residuals: 0.000\n",
      "Loss: 158.053, Residuals: 0.000\n",
      "Evidence 473.333\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 11.941, Residuals: -0.169\n",
      "Loss: 6.856, Residuals: -0.067\n",
      "Loss: 5.254, Residuals: -0.065\n",
      "Loss: 4.539, Residuals: -0.075\n",
      "Loss: 3.980, Residuals: -0.084\n",
      "Loss: 3.788, Residuals: -0.060\n",
      "Loss: 3.526, Residuals: -0.046\n",
      "Loss: 3.356, Residuals: -0.034\n",
      "Loss: 3.275, Residuals: -0.036\n",
      "Loss: 3.235, Residuals: -0.026\n",
      "Loss: 3.216, Residuals: -0.011\n",
      "Loss: 3.181, Residuals: -0.016\n",
      "Loss: 3.117, Residuals: -0.024\n",
      "Loss: 2.968, Residuals: 0.026\n",
      "Loss: 2.913, Residuals: 0.045\n",
      "Loss: 2.826, Residuals: 0.040\n",
      "Loss: 2.803, Residuals: 0.008\n",
      "Loss: 2.763, Residuals: 0.005\n",
      "Loss: 2.703, Residuals: 0.003\n",
      "Loss: 2.700, Residuals: 0.007\n",
      "Loss: 2.673, Residuals: 0.003\n",
      "Loss: 2.627, Residuals: -0.009\n",
      "Loss: 2.597, Residuals: -0.022\n",
      "Loss: 2.589, Residuals: -0.002\n",
      "Loss: 2.576, Residuals: -0.006\n",
      "Loss: 2.553, Residuals: -0.014\n",
      "Loss: 2.548, Residuals: -0.022\n",
      "Loss: 2.540, Residuals: -0.024\n",
      "Loss: 2.524, Residuals: -0.030\n",
      "Loss: 2.497, Residuals: -0.042\n",
      "Loss: 2.492, Residuals: -0.042\n",
      "Loss: 2.452, Residuals: -0.058\n",
      "Loss: 2.449, Residuals: -0.058\n",
      "Loss: 2.444, Residuals: -0.060\n",
      "Loss: 2.401, Residuals: -0.075\n",
      "Loss: 2.396, Residuals: -0.072\n",
      "Loss: 2.392, Residuals: -0.072\n",
      "Loss: 2.386, Residuals: -0.074\n",
      "Loss: 2.373, Residuals: -0.074\n",
      "Loss: 2.373, Residuals: -0.074\n",
      "Loss: 2.366, Residuals: -0.075\n",
      "Loss: 2.365, Residuals: -0.073\n",
      "Loss: 2.351, Residuals: -0.078\n",
      "Loss: 2.351, Residuals: -0.078\n",
      "Loss: 2.350, Residuals: -0.078\n",
      "Loss: 2.347, Residuals: -0.079\n",
      "Loss: 2.346, Residuals: -0.082\n",
      "Loss: 2.345, Residuals: -0.079\n",
      "Loss: 2.342, Residuals: -0.081\n",
      "Loss: 2.336, Residuals: -0.083\n",
      "Loss: 2.336, Residuals: -0.085\n",
      "Loss: 2.333, Residuals: -0.085\n",
      "Loss: 2.332, Residuals: -0.086\n",
      "Loss: 2.329, Residuals: -0.087\n",
      "Loss: 2.329, Residuals: -0.086\n",
      "Loss: 2.326, Residuals: -0.087\n",
      "Loss: 2.322, Residuals: -0.090\n",
      "Loss: 2.321, Residuals: -0.090\n",
      "Loss: 2.321, Residuals: -0.090\n",
      "Loss: 2.319, Residuals: -0.092\n",
      "Loss: 2.319, Residuals: -0.091\n",
      "Loss: 2.315, Residuals: -0.092\n",
      "Loss: 2.315, Residuals: -0.091\n",
      "Loss: 2.315, Residuals: -0.092\n",
      "Loss: 2.311, Residuals: -0.093\n",
      "Loss: 2.311, Residuals: -0.093\n",
      "Loss: 2.311, Residuals: -0.093\n",
      "Loss: 2.310, Residuals: -0.093\n",
      "Loss: 2.309, Residuals: -0.093\n",
      "Loss: 2.305, Residuals: -0.096\n",
      "Loss: 2.304, Residuals: -0.098\n",
      "Loss: 2.303, Residuals: -0.098\n",
      "Loss: 2.301, Residuals: -0.099\n",
      "Loss: 2.301, Residuals: -0.099\n",
      "Loss: 2.296, Residuals: -0.098\n",
      "Loss: 2.296, Residuals: -0.097\n",
      "Loss: 2.296, Residuals: -0.097\n",
      "Loss: 2.295, Residuals: -0.097\n",
      "Loss: 2.295, Residuals: -0.097\n",
      "Loss: 2.295, Residuals: -0.096\n",
      "Loss: 2.292, Residuals: -0.098\n",
      "Loss: 2.287, Residuals: -0.100\n",
      "Loss: 2.287, Residuals: -0.100\n",
      "Loss: 2.286, Residuals: -0.099\n",
      "Loss: 2.286, Residuals: -0.099\n",
      "Loss: 2.286, Residuals: -0.099\n",
      "Loss: 2.283, Residuals: -0.100\n",
      "Loss: 2.283, Residuals: -0.100\n",
      "Loss: 2.283, Residuals: -0.100\n",
      "Loss: 2.282, Residuals: -0.100\n",
      "Loss: 2.282, Residuals: -0.100\n",
      "Loss: 2.281, Residuals: -0.101\n",
      "Loss: 2.280, Residuals: -0.100\n",
      "Loss: 2.274, Residuals: -0.103\n",
      "Loss: 2.274, Residuals: -0.102\n",
      "Loss: 2.273, Residuals: -0.102\n",
      "Loss: 2.273, Residuals: -0.102\n",
      "Loss: 2.273, Residuals: -0.102\n",
      "Loss: 2.272, Residuals: -0.103\n",
      "Loss: 2.268, Residuals: -0.104\n",
      "Loss: 2.268, Residuals: -0.104\n",
      "Loss: 2.268, Residuals: -0.104\n",
      "Loss: 2.268, Residuals: -0.104\n",
      "Loss: 2.268, Residuals: -0.103\n",
      "Loss: 2.268, Residuals: -0.103\n",
      "Loss: 2.267, Residuals: -0.104\n",
      "Loss: 2.267, Residuals: -0.104\n",
      "Evidence -384.204\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.58e-03\n",
      "Loss: 10.593, Residuals: -0.095\n",
      "Loss: 10.530, Residuals: -0.081\n",
      "Loss: 10.433, Residuals: -0.076\n",
      "Loss: 10.429, Residuals: -0.076\n",
      "Loss: 10.394, Residuals: -0.075\n",
      "Loss: 10.332, Residuals: -0.071\n",
      "Loss: 10.331, Residuals: -0.072\n",
      "Loss: 10.308, Residuals: -0.070\n",
      "Loss: 10.267, Residuals: -0.065\n",
      "Loss: 10.267, Residuals: -0.066\n",
      "Loss: 10.262, Residuals: -0.065\n",
      "Loss: 10.219, Residuals: -0.059\n",
      "Loss: 10.212, Residuals: -0.058\n",
      "Loss: 10.201, Residuals: -0.057\n",
      "Loss: 10.181, Residuals: -0.054\n",
      "Loss: 10.147, Residuals: -0.050\n",
      "Loss: 10.147, Residuals: -0.051\n",
      "Loss: 10.142, Residuals: -0.050\n",
      "Loss: 10.134, Residuals: -0.049\n",
      "Loss: 10.119, Residuals: -0.047\n",
      "Loss: 10.116, Residuals: -0.047\n",
      "Loss: 10.110, Residuals: -0.046\n",
      "Loss: 10.098, Residuals: -0.044\n",
      "Loss: 10.098, Residuals: -0.045\n",
      "Loss: 10.079, Residuals: -0.043\n",
      "Loss: 10.079, Residuals: -0.044\n",
      "Loss: 10.076, Residuals: -0.043\n",
      "Loss: 10.058, Residuals: -0.037\n",
      "Loss: 10.058, Residuals: -0.039\n",
      "Loss: 10.056, Residuals: -0.038\n",
      "Loss: 10.054, Residuals: -0.038\n",
      "Loss: 10.051, Residuals: -0.037\n",
      "Loss: 10.045, Residuals: -0.036\n",
      "Loss: 10.045, Residuals: -0.036\n",
      "Loss: 10.040, Residuals: -0.035\n",
      "Loss: 10.040, Residuals: -0.036\n",
      "Loss: 10.039, Residuals: -0.035\n",
      "Loss: 10.036, Residuals: -0.035\n",
      "Loss: 10.036, Residuals: -0.035\n",
      "Loss: 10.032, Residuals: -0.034\n",
      "Loss: 10.032, Residuals: -0.034\n",
      "Loss: 10.032, Residuals: -0.034\n",
      "Loss: 10.031, Residuals: -0.034\n",
      "Loss: 10.029, Residuals: -0.034\n",
      "Loss: 10.025, Residuals: -0.033\n",
      "Loss: 10.024, Residuals: -0.033\n",
      "Loss: 10.024, Residuals: -0.033\n",
      "Loss: 10.024, Residuals: -0.034\n",
      "Loss: 10.013, Residuals: -0.032\n",
      "Loss: 10.013, Residuals: -0.032\n",
      "Loss: 10.012, Residuals: -0.032\n",
      "Loss: 10.012, Residuals: -0.031\n",
      "Loss: 10.011, Residuals: -0.031\n",
      "Loss: 10.010, Residuals: -0.031\n",
      "Loss: 10.009, Residuals: -0.031\n",
      "Loss: 10.009, Residuals: -0.030\n",
      "Loss: 10.009, Residuals: -0.030\n",
      "Loss: 10.007, Residuals: -0.030\n",
      "Loss: 10.004, Residuals: -0.030\n",
      "Loss: 10.004, Residuals: -0.030\n",
      "Loss: 10.004, Residuals: -0.030\n",
      "Loss: 10.003, Residuals: -0.030\n",
      "Loss: 10.003, Residuals: -0.030\n",
      "Loss: 9.999, Residuals: -0.030\n",
      "Loss: 9.999, Residuals: -0.029\n",
      "Loss: 9.998, Residuals: -0.029\n",
      "Loss: 9.998, Residuals: -0.030\n",
      "Loss: 9.994, Residuals: -0.029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.994, Residuals: -0.029\n",
      "Loss: 9.994, Residuals: -0.029\n",
      "Loss: 9.994, Residuals: -0.029\n",
      "Loss: 9.994, Residuals: -0.028\n",
      "Loss: 9.993, Residuals: -0.028\n",
      "Loss: 9.993, Residuals: -0.028\n",
      "Loss: 9.992, Residuals: -0.028\n",
      "Loss: 9.992, Residuals: -0.028\n",
      "Loss: 9.991, Residuals: -0.028\n",
      "Loss: 9.991, Residuals: -0.028\n",
      "Loss: 9.991, Residuals: -0.028\n",
      "Loss: 9.991, Residuals: -0.028\n",
      "Loss: 9.991, Residuals: -0.028\n",
      "Loss: 9.990, Residuals: -0.028\n",
      "Loss: 9.990, Residuals: -0.028\n",
      "Loss: 9.990, Residuals: -0.028\n",
      "Loss: 9.990, Residuals: -0.028\n",
      "Loss: 9.990, Residuals: -0.027\n",
      "Loss: 9.990, Residuals: -0.027\n",
      "Loss: 9.990, Residuals: -0.027\n",
      "Loss: 9.989, Residuals: -0.027\n",
      "Loss: 9.989, Residuals: -0.027\n",
      "Loss: 9.989, Residuals: -0.027\n",
      "Evidence 99.873\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.93e-02\n",
      "Loss: 39.561, Residuals: -0.033\n",
      "Loss: 39.318, Residuals: -0.031\n",
      "Loss: 38.945, Residuals: -0.027\n",
      "Loss: 38.804, Residuals: -0.019\n",
      "Loss: 38.770, Residuals: -0.021\n",
      "Loss: 38.748, Residuals: -0.020\n",
      "Loss: 38.564, Residuals: -0.016\n",
      "Loss: 38.520, Residuals: -0.011\n",
      "Loss: 38.483, Residuals: -0.013\n",
      "Loss: 38.475, Residuals: -0.015\n",
      "Loss: 38.459, Residuals: -0.014\n",
      "Loss: 38.432, Residuals: -0.013\n",
      "Loss: 38.400, Residuals: -0.009\n",
      "Loss: 38.389, Residuals: -0.007\n",
      "Loss: 38.372, Residuals: -0.007\n",
      "Loss: 38.369, Residuals: -0.007\n",
      "Loss: 38.364, Residuals: -0.007\n",
      "Loss: 38.364, Residuals: -0.007\n",
      "Loss: 38.363, Residuals: -0.007\n",
      "Loss: 38.362, Residuals: -0.007\n",
      "Loss: 38.362, Residuals: -0.007\n",
      "Loss: 38.361, Residuals: -0.007\n",
      "Loss: 38.361, Residuals: -0.007\n",
      "Loss: 38.361, Residuals: -0.007\n",
      "Loss: 38.361, Residuals: -0.007\n",
      "Loss: 38.360, Residuals: -0.007\n",
      "Loss: 38.360, Residuals: -0.007\n",
      "Loss: 38.360, Residuals: -0.007\n",
      "Loss: 38.360, Residuals: -0.007\n",
      "Loss: 38.360, Residuals: -0.007\n",
      "Evidence 316.288\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.74e-01\n",
      "Loss: 90.689, Residuals: -0.022\n",
      "Loss: 90.537, Residuals: -0.014\n",
      "Loss: 90.257, Residuals: -0.013\n",
      "Loss: 89.836, Residuals: -0.010\n",
      "Loss: 89.718, Residuals: -0.011\n",
      "Loss: 89.687, Residuals: -0.010\n",
      "Loss: 89.648, Residuals: -0.011\n",
      "Loss: 89.579, Residuals: -0.010\n",
      "Loss: 89.481, Residuals: -0.008\n",
      "Loss: 89.466, Residuals: -0.009\n",
      "Loss: 89.460, Residuals: -0.008\n",
      "Loss: 89.450, Residuals: -0.008\n",
      "Loss: 89.441, Residuals: -0.008\n",
      "Loss: 89.427, Residuals: -0.007\n",
      "Loss: 89.427, Residuals: -0.007\n",
      "Loss: 89.422, Residuals: -0.007\n",
      "Loss: 89.418, Residuals: -0.007\n",
      "Loss: 89.418, Residuals: -0.007\n",
      "Loss: 89.417, Residuals: -0.007\n",
      "Loss: 89.417, Residuals: -0.007\n",
      "Loss: 89.417, Residuals: -0.007\n",
      "Loss: 89.417, Residuals: -0.007\n",
      "Loss: 89.417, Residuals: -0.007\n",
      "Loss: 89.417, Residuals: -0.007\n",
      "Evidence 425.847\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.62e-01\n",
      "Loss: 131.320, Residuals: -0.018\n",
      "Loss: 130.849, Residuals: -0.010\n",
      "Loss: 130.732, Residuals: -0.011\n",
      "Loss: 130.675, Residuals: -0.014\n",
      "Loss: 130.570, Residuals: -0.013\n",
      "Loss: 130.397, Residuals: -0.012\n",
      "Loss: 130.376, Residuals: -0.013\n",
      "Loss: 130.335, Residuals: -0.012\n",
      "Loss: 130.272, Residuals: -0.012\n",
      "Loss: 130.268, Residuals: -0.012\n",
      "Loss: 130.237, Residuals: -0.011\n",
      "Loss: 130.234, Residuals: -0.011\n",
      "Loss: 130.229, Residuals: -0.011\n",
      "Loss: 130.222, Residuals: -0.011\n",
      "Loss: 130.219, Residuals: -0.011\n",
      "Loss: 130.215, Residuals: -0.011\n",
      "Loss: 130.213, Residuals: -0.011\n",
      "Loss: 130.210, Residuals: -0.011\n",
      "Loss: 130.209, Residuals: -0.011\n",
      "Loss: 130.208, Residuals: -0.011\n",
      "Loss: 130.206, Residuals: -0.011\n",
      "Loss: 130.203, Residuals: -0.011\n",
      "Loss: 130.203, Residuals: -0.011\n",
      "Loss: 130.202, Residuals: -0.011\n",
      "Loss: 130.202, Residuals: -0.011\n",
      "Loss: 130.201, Residuals: -0.011\n",
      "Loss: 130.201, Residuals: -0.011\n",
      "Loss: 130.199, Residuals: -0.011\n",
      "Loss: 130.198, Residuals: -0.011\n",
      "Loss: 130.198, Residuals: -0.011\n",
      "Loss: 130.197, Residuals: -0.011\n",
      "Loss: 130.197, Residuals: -0.011\n",
      "Loss: 130.197, Residuals: -0.011\n",
      "Loss: 130.197, Residuals: -0.011\n",
      "Loss: 130.196, Residuals: -0.011\n",
      "Loss: 130.196, Residuals: -0.010\n",
      "Loss: 130.196, Residuals: -0.010\n",
      "Evidence 458.657\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.42e-01\n",
      "Loss: 148.582, Residuals: -0.015\n",
      "Loss: 148.077, Residuals: -0.007\n",
      "Loss: 147.965, Residuals: -0.009\n",
      "Loss: 147.788, Residuals: -0.009\n",
      "Loss: 147.743, Residuals: -0.010\n",
      "Loss: 147.666, Residuals: -0.010\n",
      "Loss: 147.573, Residuals: -0.009\n",
      "Loss: 147.563, Residuals: -0.009\n",
      "Loss: 147.553, Residuals: -0.009\n",
      "Loss: 147.538, Residuals: -0.009\n",
      "Loss: 147.536, Residuals: -0.009\n",
      "Loss: 147.531, Residuals: -0.009\n",
      "Loss: 147.526, Residuals: -0.009\n",
      "Loss: 147.526, Residuals: -0.009\n",
      "Loss: 147.525, Residuals: -0.009\n",
      "Loss: 147.525, Residuals: -0.009\n",
      "Loss: 147.525, Residuals: -0.009\n",
      "Loss: 147.524, Residuals: -0.009\n",
      "Loss: 147.524, Residuals: -0.009\n",
      "Loss: 147.523, Residuals: -0.009\n",
      "Loss: 147.523, Residuals: -0.009\n",
      "Loss: 147.523, Residuals: -0.009\n",
      "Loss: 147.523, Residuals: -0.009\n",
      "Loss: 147.523, Residuals: -0.009\n",
      "Loss: 147.523, Residuals: -0.009\n",
      "Evidence 467.017\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.57e-01\n",
      "Loss: 154.525, Residuals: -0.008\n",
      "Loss: 154.272, Residuals: -0.005\n",
      "Loss: 154.218, Residuals: -0.007\n",
      "Loss: 154.216, Residuals: -0.007\n",
      "Loss: 154.203, Residuals: -0.007\n",
      "Loss: 154.179, Residuals: -0.007\n",
      "Loss: 154.159, Residuals: -0.006\n",
      "Loss: 154.155, Residuals: -0.006\n",
      "Loss: 154.147, Residuals: -0.006\n",
      "Loss: 154.135, Residuals: -0.006\n",
      "Loss: 154.134, Residuals: -0.006\n",
      "Loss: 154.129, Residuals: -0.006\n",
      "Loss: 154.128, Residuals: -0.006\n",
      "Loss: 154.125, Residuals: -0.006\n",
      "Loss: 154.124, Residuals: -0.006\n",
      "Loss: 154.122, Residuals: -0.006\n",
      "Loss: 154.122, Residuals: -0.006\n",
      "Loss: 154.122, Residuals: -0.006\n",
      "Loss: 154.120, Residuals: -0.006\n",
      "Loss: 154.120, Residuals: -0.006\n",
      "Loss: 154.120, Residuals: -0.006\n",
      "Loss: 154.119, Residuals: -0.006\n",
      "Loss: 154.119, Residuals: -0.006\n",
      "Loss: 154.119, Residuals: -0.006\n",
      "Loss: 154.119, Residuals: -0.006\n",
      "Loss: 154.119, Residuals: -0.006\n",
      "Loss: 154.119, Residuals: -0.006\n",
      "Loss: 154.118, Residuals: -0.006\n",
      "Loss: 154.118, Residuals: -0.006\n",
      "Evidence 470.488\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.45e-01\n",
      "Loss: 156.882, Residuals: -0.004\n",
      "Loss: 156.750, Residuals: -0.004\n",
      "Loss: 156.724, Residuals: -0.004\n",
      "Loss: 156.705, Residuals: -0.006\n",
      "Loss: 156.701, Residuals: -0.005\n",
      "Loss: 156.694, Residuals: -0.005\n",
      "Loss: 156.682, Residuals: -0.005\n",
      "Loss: 156.672, Residuals: -0.005\n",
      "Loss: 156.669, Residuals: -0.004\n",
      "Loss: 156.669, Residuals: -0.005\n",
      "Loss: 156.664, Residuals: -0.005\n",
      "Loss: 156.657, Residuals: -0.005\n",
      "Loss: 156.656, Residuals: -0.005\n",
      "Loss: 156.654, Residuals: -0.005\n",
      "Loss: 156.652, Residuals: -0.005\n",
      "Loss: 156.651, Residuals: -0.004\n",
      "Loss: 156.650, Residuals: -0.004\n",
      "Loss: 156.650, Residuals: -0.005\n",
      "Loss: 156.649, Residuals: -0.005\n",
      "Loss: 156.649, Residuals: -0.005\n",
      "Loss: 156.648, Residuals: -0.005\n",
      "Loss: 156.647, Residuals: -0.005\n",
      "Loss: 156.647, Residuals: -0.004\n",
      "Loss: 156.646, Residuals: -0.005\n",
      "Loss: 156.645, Residuals: -0.005\n",
      "Loss: 156.645, Residuals: -0.005\n",
      "Loss: 156.644, Residuals: -0.005\n",
      "Loss: 156.644, Residuals: -0.005\n",
      "Evidence 471.917\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.09e-01\n",
      "Loss: 157.765, Residuals: -0.003\n",
      "Loss: 157.676, Residuals: -0.005\n",
      "Loss: 157.661, Residuals: -0.003\n",
      "Loss: 157.637, Residuals: -0.004\n",
      "Loss: 157.631, Residuals: -0.004\n",
      "Loss: 157.619, Residuals: -0.004\n",
      "Loss: 157.613, Residuals: -0.004\n",
      "Loss: 157.604, Residuals: -0.004\n",
      "Loss: 157.603, Residuals: -0.003\n",
      "Loss: 157.601, Residuals: -0.004\n",
      "Loss: 157.598, Residuals: -0.004\n",
      "Loss: 157.598, Residuals: -0.004\n",
      "Loss: 157.594, Residuals: -0.004\n",
      "Loss: 157.589, Residuals: -0.004\n",
      "Loss: 157.589, Residuals: -0.004\n",
      "Loss: 157.589, Residuals: -0.004\n",
      "Loss: 157.588, Residuals: -0.004\n",
      "Loss: 157.587, Residuals: -0.004\n",
      "Loss: 157.587, Residuals: -0.004\n",
      "Loss: 157.585, Residuals: -0.004\n",
      "Loss: 157.585, Residuals: -0.004\n",
      "Evidence 472.643\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.68e-01\n",
      "Loss: 158.101, Residuals: -0.003\n",
      "Loss: 158.041, Residuals: -0.003\n",
      "Loss: 158.029, Residuals: -0.003\n",
      "Loss: 158.009, Residuals: -0.003\n",
      "Loss: 157.985, Residuals: -0.003\n",
      "Loss: 157.984, Residuals: -0.003\n",
      "Loss: 157.982, Residuals: -0.003\n",
      "Loss: 157.978, Residuals: -0.003\n",
      "Loss: 157.976, Residuals: -0.003\n",
      "Loss: 157.971, Residuals: -0.003\n",
      "Loss: 157.970, Residuals: -0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 157.968, Residuals: -0.003\n",
      "Loss: 157.963, Residuals: -0.003\n",
      "Loss: 157.963, Residuals: -0.003\n",
      "Loss: 157.956, Residuals: -0.003\n",
      "Loss: 157.956, Residuals: -0.003\n",
      "Loss: 157.955, Residuals: -0.003\n",
      "Loss: 157.954, Residuals: -0.003\n",
      "Loss: 157.954, Residuals: -0.003\n",
      "Loss: 157.952, Residuals: -0.003\n",
      "Loss: 157.952, Residuals: -0.003\n",
      "Loss: 157.951, Residuals: -0.003\n",
      "Loss: 157.951, Residuals: -0.003\n",
      "Loss: 157.950, Residuals: -0.003\n",
      "Loss: 157.950, Residuals: -0.003\n",
      "Loss: 157.949, Residuals: -0.003\n",
      "Loss: 157.948, Residuals: -0.003\n",
      "Evidence 473.237\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.22e-01\n",
      "Loss: 158.259, Residuals: -0.002\n",
      "Loss: 158.228, Residuals: -0.002\n",
      "Loss: 158.220, Residuals: -0.002\n",
      "Loss: 158.206, Residuals: -0.002\n",
      "Loss: 158.187, Residuals: -0.002\n",
      "Loss: 158.186, Residuals: -0.002\n",
      "Loss: 158.184, Residuals: -0.002\n",
      "Loss: 158.180, Residuals: -0.002\n",
      "Loss: 158.174, Residuals: -0.002\n",
      "Loss: 158.171, Residuals: -0.002\n",
      "Loss: 158.170, Residuals: -0.002\n",
      "Loss: 158.167, Residuals: -0.002\n",
      "Loss: 158.166, Residuals: -0.002\n",
      "Loss: 158.164, Residuals: -0.002\n",
      "Loss: 158.159, Residuals: -0.002\n",
      "Loss: 158.159, Residuals: -0.002\n",
      "Loss: 158.158, Residuals: -0.002\n",
      "Loss: 158.157, Residuals: -0.002\n",
      "Loss: 158.157, Residuals: -0.002\n",
      "Loss: 158.157, Residuals: -0.002\n",
      "Loss: 158.157, Residuals: -0.002\n",
      "Loss: 158.156, Residuals: -0.002\n",
      "Evidence 473.788\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.84e-01\n",
      "Loss: 158.398, Residuals: -0.001\n",
      "Loss: 158.376, Residuals: -0.001\n",
      "Loss: 158.371, Residuals: -0.001\n",
      "Loss: 158.361, Residuals: -0.001\n",
      "Loss: 158.353, Residuals: -0.001\n",
      "Loss: 158.352, Residuals: -0.001\n",
      "Loss: 158.339, Residuals: -0.001\n",
      "Loss: 158.339, Residuals: -0.001\n",
      "Loss: 158.339, Residuals: -0.001\n",
      "Loss: 158.335, Residuals: -0.001\n",
      "Loss: 158.331, Residuals: -0.001\n",
      "Loss: 158.331, Residuals: -0.001\n",
      "Loss: 158.331, Residuals: -0.001\n",
      "Loss: 158.330, Residuals: -0.001\n",
      "Loss: 158.329, Residuals: -0.001\n",
      "Loss: 158.329, Residuals: -0.001\n",
      "Loss: 158.329, Residuals: -0.001\n",
      "Loss: 158.327, Residuals: -0.001\n",
      "Loss: 158.327, Residuals: -0.001\n",
      "Loss: 158.326, Residuals: -0.001\n",
      "Loss: 158.326, Residuals: -0.001\n",
      "Loss: 158.326, Residuals: -0.001\n",
      "Evidence 474.177\n",
      "Pass count  1\n",
      "Total samples: 39, Updated regularization: 1.00e-05\n",
      "Loss: 11.651, Residuals: -0.117\n",
      "Loss: 6.999, Residuals: -0.036\n",
      "Loss: 4.994, Residuals: -0.049\n",
      "Loss: 4.234, Residuals: -0.055\n",
      "Loss: 3.862, Residuals: -0.056\n",
      "Loss: 3.749, Residuals: -0.026\n",
      "Loss: 3.553, Residuals: -0.033\n",
      "Loss: 3.473, Residuals: 0.018\n",
      "Loss: 3.108, Residuals: 0.031\n",
      "Loss: 3.061, Residuals: -0.007\n",
      "Loss: 3.002, Residuals: 0.019\n",
      "Loss: 2.913, Residuals: 0.017\n",
      "Loss: 2.866, Residuals: 0.018\n",
      "Loss: 2.786, Residuals: 0.007\n",
      "Loss: 2.772, Residuals: 0.018\n",
      "Loss: 2.744, Residuals: 0.013\n",
      "Loss: 2.693, Residuals: 0.003\n",
      "Loss: 2.646, Residuals: 0.003\n",
      "Loss: 2.637, Residuals: 0.002\n",
      "Loss: 2.621, Residuals: -0.000\n",
      "Loss: 2.592, Residuals: -0.008\n",
      "Loss: 2.545, Residuals: -0.022\n",
      "Loss: 2.542, Residuals: -0.019\n",
      "Loss: 2.521, Residuals: -0.026\n",
      "Loss: 2.493, Residuals: -0.038\n",
      "Loss: 2.487, Residuals: -0.037\n",
      "Loss: 2.486, Residuals: -0.036\n",
      "Loss: 2.476, Residuals: -0.038\n",
      "Loss: 2.460, Residuals: -0.045\n",
      "Loss: 2.446, Residuals: -0.060\n",
      "Loss: 2.445, Residuals: -0.057\n",
      "Loss: 2.443, Residuals: -0.056\n",
      "Loss: 2.438, Residuals: -0.054\n",
      "Loss: 2.436, Residuals: -0.053\n",
      "Loss: 2.431, Residuals: -0.055\n",
      "Loss: 2.431, Residuals: -0.053\n",
      "Loss: 2.428, Residuals: -0.054\n",
      "Loss: 2.423, Residuals: -0.056\n",
      "Loss: 2.423, Residuals: -0.057\n",
      "Loss: 2.420, Residuals: -0.057\n",
      "Loss: 2.420, Residuals: -0.057\n",
      "Loss: 2.418, Residuals: -0.057\n",
      "Loss: 2.418, Residuals: -0.058\n",
      "Loss: 2.414, Residuals: -0.060\n",
      "Loss: 2.414, Residuals: -0.060\n",
      "Loss: 2.414, Residuals: -0.060\n",
      "Loss: 2.414, Residuals: -0.061\n",
      "Loss: 2.412, Residuals: -0.061\n",
      "Loss: 2.411, Residuals: -0.063\n",
      "Loss: 2.411, Residuals: -0.062\n",
      "Loss: 2.409, Residuals: -0.063\n",
      "Loss: 2.409, Residuals: -0.063\n",
      "Loss: 2.408, Residuals: -0.063\n",
      "Loss: 2.408, Residuals: -0.063\n",
      "Loss: 2.407, Residuals: -0.064\n",
      "Loss: 2.400, Residuals: -0.068\n",
      "Loss: 2.400, Residuals: -0.066\n",
      "Loss: 2.399, Residuals: -0.066\n",
      "Loss: 2.397, Residuals: -0.064\n",
      "Loss: 2.396, Residuals: -0.062\n",
      "Loss: 2.393, Residuals: -0.063\n",
      "Loss: 2.393, Residuals: -0.062\n",
      "Loss: 2.391, Residuals: -0.062\n",
      "Loss: 2.389, Residuals: -0.063\n",
      "Loss: 2.389, Residuals: -0.063\n",
      "Loss: 2.389, Residuals: -0.063\n",
      "Loss: 2.387, Residuals: -0.063\n",
      "Loss: 2.387, Residuals: -0.063\n",
      "Loss: 2.386, Residuals: -0.063\n",
      "Loss: 2.384, Residuals: -0.064\n",
      "Loss: 2.384, Residuals: -0.063\n",
      "Loss: 2.383, Residuals: -0.064\n",
      "Loss: 2.382, Residuals: -0.065\n",
      "Loss: 2.382, Residuals: -0.064\n",
      "Loss: 2.379, Residuals: -0.065\n",
      "Loss: 2.379, Residuals: -0.064\n",
      "Loss: 2.379, Residuals: -0.064\n",
      "Loss: 2.371, Residuals: -0.071\n",
      "Loss: 2.371, Residuals: -0.071\n",
      "Loss: 2.371, Residuals: -0.071\n",
      "Loss: 2.370, Residuals: -0.070\n",
      "Loss: 2.370, Residuals: -0.070\n",
      "Loss: 2.368, Residuals: -0.068\n",
      "Loss: 2.367, Residuals: -0.068\n",
      "Loss: 2.367, Residuals: -0.066\n",
      "Loss: 2.366, Residuals: -0.066\n",
      "Loss: 2.361, Residuals: -0.070\n",
      "Loss: 2.361, Residuals: -0.069\n",
      "Loss: 2.360, Residuals: -0.069\n",
      "Loss: 2.360, Residuals: -0.069\n",
      "Loss: 2.359, Residuals: -0.068\n",
      "Loss: 2.359, Residuals: -0.067\n",
      "Loss: 2.351, Residuals: -0.072\n",
      "Loss: 2.351, Residuals: -0.071\n",
      "Loss: 2.350, Residuals: -0.070\n",
      "Loss: 2.349, Residuals: -0.070\n",
      "Loss: 2.348, Residuals: -0.068\n",
      "Loss: 2.348, Residuals: -0.068\n",
      "Loss: 2.345, Residuals: -0.071\n",
      "Loss: 2.345, Residuals: -0.071\n",
      "Loss: 2.342, Residuals: -0.072\n",
      "Loss: 2.342, Residuals: -0.072\n",
      "Loss: 2.341, Residuals: -0.073\n",
      "Loss: 2.339, Residuals: -0.076\n",
      "Loss: 2.339, Residuals: -0.076\n",
      "Loss: 2.339, Residuals: -0.076\n",
      "Loss: 2.337, Residuals: -0.078\n",
      "Loss: 2.337, Residuals: -0.077\n",
      "Loss: 2.336, Residuals: -0.079\n",
      "Loss: 2.336, Residuals: -0.079\n",
      "Loss: 2.335, Residuals: -0.080\n",
      "Loss: 2.335, Residuals: -0.080\n",
      "Loss: 2.334, Residuals: -0.081\n",
      "Loss: 2.334, Residuals: -0.082\n",
      "Loss: 2.334, Residuals: -0.082\n",
      "Evidence -366.274\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 2.14e-03\n",
      "Loss: 10.423, Residuals: -0.075\n",
      "Loss: 10.391, Residuals: -0.073\n",
      "Loss: 10.329, Residuals: -0.070\n",
      "Loss: 10.223, Residuals: -0.064\n",
      "Loss: 10.223, Residuals: -0.065\n",
      "Loss: 10.136, Residuals: -0.059\n",
      "Loss: 10.127, Residuals: -0.060\n",
      "Loss: 10.041, Residuals: -0.054\n",
      "Loss: 10.041, Residuals: -0.054\n",
      "Loss: 9.955, Residuals: -0.045\n",
      "Loss: 9.942, Residuals: -0.046\n",
      "Loss: 9.923, Residuals: -0.045\n",
      "Loss: 9.923, Residuals: -0.046\n",
      "Loss: 9.877, Residuals: -0.042\n",
      "Loss: 9.868, Residuals: -0.039\n",
      "Loss: 9.852, Residuals: -0.039\n",
      "Loss: 9.851, Residuals: -0.040\n",
      "Loss: 9.832, Residuals: -0.039\n",
      "Loss: 9.806, Residuals: -0.038\n",
      "Loss: 9.805, Residuals: -0.039\n",
      "Loss: 9.801, Residuals: -0.038\n",
      "Loss: 9.793, Residuals: -0.038\n",
      "Loss: 9.790, Residuals: -0.039\n",
      "Loss: 9.789, Residuals: -0.039\n",
      "Loss: 9.755, Residuals: -0.037\n",
      "Loss: 9.755, Residuals: -0.037\n",
      "Loss: 9.749, Residuals: -0.037\n",
      "Loss: 9.738, Residuals: -0.036\n",
      "Loss: 9.737, Residuals: -0.037\n",
      "Loss: 9.700, Residuals: -0.033\n",
      "Loss: 9.700, Residuals: -0.033\n",
      "Loss: 9.698, Residuals: -0.034\n",
      "Loss: 9.696, Residuals: -0.033\n",
      "Loss: 9.691, Residuals: -0.033\n",
      "Loss: 9.691, Residuals: -0.034\n",
      "Loss: 9.672, Residuals: -0.032\n",
      "Loss: 9.672, Residuals: -0.032\n",
      "Loss: 9.672, Residuals: -0.032\n",
      "Loss: 9.671, Residuals: -0.032\n",
      "Loss: 9.671, Residuals: -0.032\n",
      "Loss: 9.664, Residuals: -0.031\n",
      "Loss: 9.664, Residuals: -0.032\n",
      "Loss: 9.660, Residuals: -0.032\n",
      "Loss: 9.659, Residuals: -0.032\n",
      "Loss: 9.659, Residuals: -0.032\n",
      "Loss: 9.654, Residuals: -0.031\n",
      "Loss: 9.654, Residuals: -0.030\n",
      "Loss: 9.649, Residuals: -0.030\n",
      "Loss: 9.649, Residuals: -0.031\n",
      "Loss: 9.641, Residuals: -0.028\n",
      "Loss: 9.640, Residuals: -0.029\n",
      "Loss: 9.639, Residuals: -0.030\n",
      "Loss: 9.636, Residuals: -0.029\n",
      "Loss: 9.636, Residuals: -0.029\n",
      "Loss: 9.633, Residuals: -0.028\n",
      "Loss: 9.632, Residuals: -0.028\n",
      "Loss: 9.623, Residuals: -0.026\n",
      "Loss: 9.620, Residuals: -0.028\n",
      "Loss: 9.617, Residuals: -0.028\n",
      "Loss: 9.616, Residuals: -0.027\n",
      "Loss: 9.616, Residuals: -0.027\n",
      "Loss: 9.615, Residuals: -0.027\n",
      "Loss: 9.613, Residuals: -0.027\n",
      "Loss: 9.612, Residuals: -0.027\n",
      "Loss: 9.612, Residuals: -0.026\n",
      "Loss: 9.610, Residuals: -0.026\n",
      "Loss: 9.610, Residuals: -0.026\n",
      "Loss: 9.609, Residuals: -0.026\n",
      "Loss: 9.609, Residuals: -0.026\n",
      "Loss: 9.609, Residuals: -0.026\n",
      "Loss: 9.607, Residuals: -0.025\n",
      "Loss: 9.607, Residuals: -0.025\n",
      "Loss: 9.607, Residuals: -0.025\n",
      "Loss: 9.607, Residuals: -0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.607, Residuals: -0.026\n",
      "Loss: 9.606, Residuals: -0.025\n",
      "Loss: 9.606, Residuals: -0.024\n",
      "Loss: 9.605, Residuals: -0.024\n",
      "Evidence 73.857\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 4.15e-02\n",
      "Loss: 37.829, Residuals: -0.016\n",
      "Loss: 37.727, Residuals: -0.021\n",
      "Loss: 37.547, Residuals: -0.019\n",
      "Loss: 37.541, Residuals: -0.016\n",
      "Loss: 37.482, Residuals: -0.015\n",
      "Loss: 37.377, Residuals: -0.013\n",
      "Loss: 37.225, Residuals: -0.009\n",
      "Loss: 37.224, Residuals: -0.009\n",
      "Loss: 37.221, Residuals: -0.009\n",
      "Loss: 37.217, Residuals: -0.009\n",
      "Loss: 37.210, Residuals: -0.009\n",
      "Loss: 37.143, Residuals: -0.008\n",
      "Loss: 37.036, Residuals: -0.005\n",
      "Loss: 37.024, Residuals: -0.003\n",
      "Loss: 37.003, Residuals: -0.002\n",
      "Loss: 36.964, Residuals: -0.001\n",
      "Loss: 36.908, Residuals: 0.002\n",
      "Loss: 36.899, Residuals: 0.002\n",
      "Loss: 36.881, Residuals: 0.002\n",
      "Loss: 36.849, Residuals: 0.003\n",
      "Loss: 36.794, Residuals: 0.005\n",
      "Loss: 36.793, Residuals: 0.005\n",
      "Loss: 36.791, Residuals: 0.005\n",
      "Loss: 36.788, Residuals: 0.004\n",
      "Loss: 36.783, Residuals: 0.004\n",
      "Loss: 36.736, Residuals: 0.005\n",
      "Loss: 36.722, Residuals: 0.006\n",
      "Loss: 36.704, Residuals: 0.006\n",
      "Loss: 36.702, Residuals: 0.006\n",
      "Loss: 36.701, Residuals: 0.006\n",
      "Loss: 36.686, Residuals: 0.007\n",
      "Loss: 36.660, Residuals: 0.008\n",
      "Loss: 36.659, Residuals: 0.007\n",
      "Loss: 36.659, Residuals: 0.007\n",
      "Loss: 36.646, Residuals: 0.008\n",
      "Loss: 36.646, Residuals: 0.008\n",
      "Loss: 36.643, Residuals: 0.008\n",
      "Loss: 36.639, Residuals: 0.008\n",
      "Loss: 36.635, Residuals: 0.008\n",
      "Loss: 36.634, Residuals: 0.008\n",
      "Loss: 36.634, Residuals: 0.008\n",
      "Loss: 36.631, Residuals: 0.008\n",
      "Loss: 36.631, Residuals: 0.009\n",
      "Loss: 36.628, Residuals: 0.009\n",
      "Loss: 36.628, Residuals: 0.009\n",
      "Loss: 36.626, Residuals: 0.009\n",
      "Loss: 36.624, Residuals: 0.009\n",
      "Loss: 36.624, Residuals: 0.009\n",
      "Loss: 36.624, Residuals: 0.009\n",
      "Loss: 36.624, Residuals: 0.009\n",
      "Loss: 36.623, Residuals: 0.009\n",
      "Loss: 36.623, Residuals: 0.009\n",
      "Loss: 36.622, Residuals: 0.009\n",
      "Loss: 36.622, Residuals: 0.009\n",
      "Evidence 290.169\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 2.17e-01\n",
      "Loss: 86.158, Residuals: 0.010\n",
      "Loss: 86.038, Residuals: 0.006\n",
      "Loss: 85.816, Residuals: 0.008\n",
      "Loss: 85.551, Residuals: 0.010\n",
      "Loss: 85.541, Residuals: 0.011\n",
      "Loss: 85.523, Residuals: 0.011\n",
      "Loss: 85.499, Residuals: 0.013\n",
      "Loss: 85.452, Residuals: 0.013\n",
      "Loss: 85.369, Residuals: 0.014\n",
      "Loss: 85.320, Residuals: 0.014\n",
      "Loss: 85.307, Residuals: 0.013\n",
      "Loss: 85.281, Residuals: 0.013\n",
      "Loss: 85.269, Residuals: 0.015\n",
      "Loss: 85.261, Residuals: 0.014\n",
      "Loss: 85.192, Residuals: 0.015\n",
      "Loss: 85.185, Residuals: 0.015\n",
      "Loss: 85.135, Residuals: 0.016\n",
      "Loss: 85.134, Residuals: 0.016\n",
      "Loss: 85.133, Residuals: 0.016\n",
      "Loss: 85.126, Residuals: 0.016\n",
      "Loss: 85.126, Residuals: 0.016\n",
      "Evidence 398.206\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 3.68e-01\n",
      "Loss: 124.752, Residuals: 0.013\n",
      "Loss: 124.750, Residuals: 0.013\n",
      "Evidence 433.623\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 4.10e-01\n",
      "Loss: 142.735, Residuals: 0.010\n",
      "Loss: 142.726, Residuals: 0.009\n",
      "Loss: 142.654, Residuals: 0.010\n",
      "Loss: 142.526, Residuals: 0.010\n",
      "Loss: 142.523, Residuals: 0.010\n",
      "Loss: 142.412, Residuals: 0.011\n",
      "Loss: 142.218, Residuals: 0.012\n",
      "Loss: 142.210, Residuals: 0.010\n",
      "Loss: 142.135, Residuals: 0.011\n",
      "Loss: 142.019, Residuals: 0.012\n",
      "Loss: 142.019, Residuals: 0.012\n",
      "Evidence 441.540\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 4.49e-01\n",
      "Loss: 149.043, Residuals: 0.013\n",
      "Loss: 148.879, Residuals: 0.012\n",
      "Loss: 148.878, Residuals: 0.012\n",
      "Evidence 443.882\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 4.58e-01\n",
      "Loss: 151.516, Residuals: 0.011\n",
      "Loss: 151.368, Residuals: 0.012\n",
      "Loss: 151.368, Residuals: 0.012\n",
      "Evidence 444.888\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 4.65e-01\n",
      "Loss: 152.533, Residuals: 0.009\n",
      "Loss: 152.342, Residuals: 0.010\n",
      "Loss: 152.341, Residuals: 0.010\n",
      "Evidence 445.208\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 11.823, Residuals: -0.159\n",
      "Loss: 6.971, Residuals: -0.048\n",
      "Loss: 5.204, Residuals: -0.044\n",
      "Loss: 4.613, Residuals: -0.056\n",
      "Loss: 4.108, Residuals: -0.021\n",
      "Loss: 3.961, Residuals: -0.029\n",
      "Loss: 3.716, Residuals: -0.038\n",
      "Loss: 3.414, Residuals: -0.029\n",
      "Loss: 3.363, Residuals: -0.019\n",
      "Loss: 3.273, Residuals: -0.025\n",
      "Loss: 3.129, Residuals: -0.035\n",
      "Loss: 3.091, Residuals: -0.003\n",
      "Loss: 2.938, Residuals: 0.019\n",
      "Loss: 2.887, Residuals: 0.033\n",
      "Loss: 2.854, Residuals: 0.025\n",
      "Loss: 2.798, Residuals: 0.019\n",
      "Loss: 2.720, Residuals: 0.006\n",
      "Loss: 2.709, Residuals: -0.015\n",
      "Loss: 2.700, Residuals: 0.005\n",
      "Loss: 2.684, Residuals: 0.002\n",
      "Loss: 2.658, Residuals: -0.008\n",
      "Loss: 2.621, Residuals: -0.016\n",
      "Loss: 2.618, Residuals: -0.018\n",
      "Loss: 2.611, Residuals: -0.020\n",
      "Loss: 2.599, Residuals: -0.024\n",
      "Loss: 2.590, Residuals: -0.026\n",
      "Loss: 2.576, Residuals: -0.030\n",
      "Loss: 2.575, Residuals: -0.026\n",
      "Loss: 2.567, Residuals: -0.028\n",
      "Loss: 2.555, Residuals: -0.039\n",
      "Loss: 2.554, Residuals: -0.037\n",
      "Loss: 2.548, Residuals: -0.039\n",
      "Loss: 2.538, Residuals: -0.047\n",
      "Loss: 2.537, Residuals: -0.047\n",
      "Loss: 2.533, Residuals: -0.050\n",
      "Loss: 2.529, Residuals: -0.055\n",
      "Loss: 2.529, Residuals: -0.055\n",
      "Loss: 2.527, Residuals: -0.056\n",
      "Loss: 2.522, Residuals: -0.058\n",
      "Loss: 2.518, Residuals: -0.062\n",
      "Loss: 2.517, Residuals: -0.063\n",
      "Loss: 2.516, Residuals: -0.064\n",
      "Loss: 2.511, Residuals: -0.065\n",
      "Loss: 2.503, Residuals: -0.067\n",
      "Loss: 2.502, Residuals: -0.065\n",
      "Loss: 2.498, Residuals: -0.066\n",
      "Loss: 2.490, Residuals: -0.065\n",
      "Loss: 2.490, Residuals: -0.062\n",
      "Loss: 2.490, Residuals: -0.063\n",
      "Loss: 2.479, Residuals: -0.067\n",
      "Loss: 2.478, Residuals: -0.066\n",
      "Loss: 2.478, Residuals: -0.067\n",
      "Loss: 2.470, Residuals: -0.067\n",
      "Loss: 2.469, Residuals: -0.065\n",
      "Loss: 2.468, Residuals: -0.065\n",
      "Loss: 2.467, Residuals: -0.066\n",
      "Loss: 2.466, Residuals: -0.066\n",
      "Loss: 2.460, Residuals: -0.068\n",
      "Loss: 2.459, Residuals: -0.068\n",
      "Loss: 2.455, Residuals: -0.069\n",
      "Loss: 2.455, Residuals: -0.069\n",
      "Loss: 2.453, Residuals: -0.069\n",
      "Loss: 2.453, Residuals: -0.069\n",
      "Loss: 2.448, Residuals: -0.071\n",
      "Loss: 2.448, Residuals: -0.071\n",
      "Loss: 2.448, Residuals: -0.070\n",
      "Loss: 2.444, Residuals: -0.072\n",
      "Loss: 2.444, Residuals: -0.073\n",
      "Loss: 2.443, Residuals: -0.073\n",
      "Loss: 2.441, Residuals: -0.073\n",
      "Loss: 2.441, Residuals: -0.073\n",
      "Loss: 2.439, Residuals: -0.074\n",
      "Loss: 2.439, Residuals: -0.075\n",
      "Loss: 2.439, Residuals: -0.075\n",
      "Loss: 2.436, Residuals: -0.075\n",
      "Loss: 2.436, Residuals: -0.073\n",
      "Loss: 2.434, Residuals: -0.075\n",
      "Loss: 2.433, Residuals: -0.076\n",
      "Loss: 2.433, Residuals: -0.075\n",
      "Loss: 2.432, Residuals: -0.075\n",
      "Loss: 2.431, Residuals: -0.076\n",
      "Loss: 2.431, Residuals: -0.076\n",
      "Loss: 2.426, Residuals: -0.079\n",
      "Loss: 2.426, Residuals: -0.079\n",
      "Loss: 2.426, Residuals: -0.079\n",
      "Loss: 2.423, Residuals: -0.081\n",
      "Loss: 2.423, Residuals: -0.080\n",
      "Loss: 2.423, Residuals: -0.080\n",
      "Loss: 2.423, Residuals: -0.081\n",
      "Loss: 2.422, Residuals: -0.081\n",
      "Loss: 2.422, Residuals: -0.080\n",
      "Loss: 2.421, Residuals: -0.081\n",
      "Loss: 2.420, Residuals: -0.082\n",
      "Loss: 2.420, Residuals: -0.082\n",
      "Loss: 2.420, Residuals: -0.082\n",
      "Loss: 2.418, Residuals: -0.083\n",
      "Loss: 2.418, Residuals: -0.083\n",
      "Loss: 2.416, Residuals: -0.084\n",
      "Loss: 2.416, Residuals: -0.084\n",
      "Loss: 2.416, Residuals: -0.084\n",
      "Loss: 2.413, Residuals: -0.085\n",
      "Loss: 2.412, Residuals: -0.086\n",
      "Loss: 2.412, Residuals: -0.086\n",
      "Loss: 2.411, Residuals: -0.086\n",
      "Loss: 2.410, Residuals: -0.086\n",
      "Loss: 2.404, Residuals: -0.088\n",
      "Loss: 2.404, Residuals: -0.088\n",
      "Loss: 2.404, Residuals: -0.088\n",
      "Loss: 2.402, Residuals: -0.089\n",
      "Loss: 2.402, Residuals: -0.089\n",
      "Loss: 2.397, Residuals: -0.090\n",
      "Loss: 2.397, Residuals: -0.091\n",
      "Loss: 2.397, Residuals: -0.090\n",
      "Loss: 2.396, Residuals: -0.090\n",
      "Loss: 2.390, Residuals: -0.091\n",
      "Loss: 2.389, Residuals: -0.090\n",
      "Loss: 2.389, Residuals: -0.090\n",
      "Loss: 2.389, Residuals: -0.090\n",
      "Loss: 2.384, Residuals: -0.091\n",
      "Loss: 2.384, Residuals: -0.091\n",
      "Loss: 2.382, Residuals: -0.092\n",
      "Loss: 2.382, Residuals: -0.092\n",
      "Loss: 2.382, Residuals: -0.092\n",
      "Loss: 2.378, Residuals: -0.095\n",
      "Loss: 2.377, Residuals: -0.095\n",
      "Loss: 2.377, Residuals: -0.095\n",
      "Loss: 2.377, Residuals: -0.095\n",
      "Loss: 2.377, Residuals: -0.096\n",
      "Loss: 2.377, Residuals: -0.095\n",
      "Loss: 2.372, Residuals: -0.096\n",
      "Loss: 2.372, Residuals: -0.096\n",
      "Loss: 2.372, Residuals: -0.095\n",
      "Loss: 2.369, Residuals: -0.096\n",
      "Loss: 2.365, Residuals: -0.099\n",
      "Loss: 2.364, Residuals: -0.099\n",
      "Loss: 2.364, Residuals: -0.099\n",
      "Loss: 2.364, Residuals: -0.098\n",
      "Loss: 2.364, Residuals: -0.098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.362, Residuals: -0.099\n",
      "Loss: 2.361, Residuals: -0.100\n",
      "Loss: 2.356, Residuals: -0.102\n",
      "Loss: 2.356, Residuals: -0.103\n",
      "Loss: 2.356, Residuals: -0.102\n",
      "Loss: 2.355, Residuals: -0.101\n",
      "Loss: 2.354, Residuals: -0.101\n",
      "Loss: 2.353, Residuals: -0.101\n",
      "Loss: 2.353, Residuals: -0.101\n",
      "Loss: 2.348, Residuals: -0.103\n",
      "Loss: 2.348, Residuals: -0.102\n",
      "Loss: 2.348, Residuals: -0.102\n",
      "Loss: 2.347, Residuals: -0.103\n",
      "Loss: 2.346, Residuals: -0.101\n",
      "Loss: 2.345, Residuals: -0.102\n",
      "Loss: 2.345, Residuals: -0.102\n",
      "Loss: 2.345, Residuals: -0.103\n",
      "Loss: 2.344, Residuals: -0.103\n",
      "Loss: 2.342, Residuals: -0.104\n",
      "Loss: 2.342, Residuals: -0.104\n",
      "Loss: 2.342, Residuals: -0.105\n",
      "Loss: 2.342, Residuals: -0.105\n",
      "Loss: 2.339, Residuals: -0.106\n",
      "Loss: 2.339, Residuals: -0.106\n",
      "Loss: 2.339, Residuals: -0.105\n",
      "Loss: 2.336, Residuals: -0.107\n",
      "Loss: 2.336, Residuals: -0.107\n",
      "Loss: 2.336, Residuals: -0.107\n",
      "Loss: 2.336, Residuals: -0.107\n",
      "Loss: 2.335, Residuals: -0.107\n",
      "Loss: 2.335, Residuals: -0.108\n",
      "Loss: 2.335, Residuals: -0.108\n",
      "Loss: 2.334, Residuals: -0.107\n",
      "Loss: 2.334, Residuals: -0.106\n",
      "Loss: 2.331, Residuals: -0.107\n",
      "Loss: 2.331, Residuals: -0.108\n",
      "Loss: 2.331, Residuals: -0.107\n",
      "Loss: 2.330, Residuals: -0.106\n",
      "Loss: 2.330, Residuals: -0.106\n",
      "Loss: 2.329, Residuals: -0.106\n",
      "Loss: 2.329, Residuals: -0.106\n",
      "Loss: 2.328, Residuals: -0.106\n",
      "Loss: 2.327, Residuals: -0.106\n",
      "Loss: 2.327, Residuals: -0.106\n",
      "Evidence -372.479\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.11e-03\n",
      "Loss: 11.385, Residuals: -0.106\n",
      "Loss: 11.225, Residuals: -0.097\n",
      "Loss: 11.023, Residuals: -0.076\n",
      "Loss: 11.016, Residuals: -0.073\n",
      "Loss: 11.006, Residuals: -0.070\n",
      "Loss: 10.927, Residuals: -0.069\n",
      "Loss: 10.924, Residuals: -0.069\n",
      "Loss: 10.900, Residuals: -0.068\n",
      "Loss: 10.863, Residuals: -0.065\n",
      "Loss: 10.860, Residuals: -0.063\n",
      "Loss: 10.835, Residuals: -0.062\n",
      "Loss: 10.826, Residuals: -0.065\n",
      "Loss: 10.825, Residuals: -0.064\n",
      "Loss: 10.673, Residuals: -0.058\n",
      "Loss: 10.672, Residuals: -0.059\n",
      "Loss: 10.670, Residuals: -0.059\n",
      "Loss: 10.669, Residuals: -0.059\n",
      "Loss: 10.657, Residuals: -0.058\n",
      "Loss: 10.641, Residuals: -0.056\n",
      "Loss: 10.640, Residuals: -0.056\n",
      "Loss: 10.593, Residuals: -0.053\n",
      "Loss: 10.593, Residuals: -0.053\n",
      "Loss: 10.593, Residuals: -0.053\n",
      "Loss: 10.584, Residuals: -0.052\n",
      "Loss: 10.583, Residuals: -0.053\n",
      "Loss: 10.582, Residuals: -0.053\n",
      "Loss: 10.582, Residuals: -0.052\n",
      "Loss: 10.535, Residuals: -0.049\n",
      "Loss: 10.534, Residuals: -0.052\n",
      "Loss: 10.534, Residuals: -0.051\n",
      "Loss: 10.529, Residuals: -0.052\n",
      "Loss: 10.529, Residuals: -0.051\n",
      "Loss: 10.492, Residuals: -0.047\n",
      "Loss: 10.491, Residuals: -0.049\n",
      "Loss: 10.484, Residuals: -0.049\n",
      "Loss: 10.484, Residuals: -0.049\n",
      "Loss: 10.480, Residuals: -0.049\n",
      "Loss: 10.440, Residuals: -0.045\n",
      "Loss: 10.437, Residuals: -0.049\n",
      "Loss: 10.413, Residuals: -0.050\n",
      "Loss: 10.412, Residuals: -0.049\n",
      "Loss: 10.385, Residuals: -0.051\n",
      "Loss: 10.380, Residuals: -0.055\n",
      "Loss: 10.377, Residuals: -0.050\n",
      "Loss: 10.374, Residuals: -0.053\n",
      "Loss: 10.369, Residuals: -0.053\n",
      "Loss: 10.366, Residuals: -0.054\n",
      "Loss: 10.335, Residuals: -0.051\n",
      "Loss: 10.334, Residuals: -0.053\n",
      "Loss: 10.324, Residuals: -0.051\n",
      "Loss: 10.323, Residuals: -0.051\n",
      "Loss: 10.312, Residuals: -0.050\n",
      "Loss: 10.312, Residuals: -0.050\n",
      "Loss: 10.311, Residuals: -0.051\n",
      "Loss: 10.304, Residuals: -0.049\n",
      "Loss: 10.302, Residuals: -0.049\n",
      "Loss: 10.301, Residuals: -0.050\n",
      "Loss: 10.300, Residuals: -0.051\n",
      "Loss: 10.287, Residuals: -0.050\n",
      "Loss: 10.286, Residuals: -0.050\n",
      "Loss: 10.256, Residuals: -0.047\n",
      "Loss: 10.253, Residuals: -0.045\n",
      "Loss: 10.248, Residuals: -0.044\n",
      "Loss: 10.247, Residuals: -0.045\n",
      "Loss: 10.245, Residuals: -0.045\n",
      "Loss: 10.243, Residuals: -0.045\n",
      "Loss: 10.241, Residuals: -0.045\n",
      "Loss: 10.241, Residuals: -0.045\n",
      "Loss: 10.236, Residuals: -0.044\n",
      "Loss: 10.235, Residuals: -0.044\n",
      "Loss: 10.235, Residuals: -0.044\n",
      "Loss: 10.230, Residuals: -0.044\n",
      "Loss: 10.229, Residuals: -0.043\n",
      "Loss: 10.224, Residuals: -0.043\n",
      "Loss: 10.224, Residuals: -0.043\n",
      "Loss: 10.217, Residuals: -0.042\n",
      "Loss: 10.213, Residuals: -0.040\n",
      "Loss: 10.213, Residuals: -0.041\n",
      "Loss: 10.160, Residuals: -0.038\n",
      "Loss: 10.156, Residuals: -0.041\n",
      "Loss: 10.149, Residuals: -0.039\n",
      "Loss: 10.139, Residuals: -0.038\n",
      "Loss: 10.121, Residuals: -0.036\n",
      "Loss: 10.119, Residuals: -0.037\n",
      "Loss: 10.062, Residuals: -0.034\n",
      "Loss: 10.049, Residuals: -0.035\n",
      "Loss: 10.040, Residuals: -0.036\n",
      "Loss: 10.025, Residuals: -0.037\n",
      "Loss: 10.005, Residuals: -0.039\n",
      "Loss: 10.002, Residuals: -0.040\n",
      "Loss: 9.975, Residuals: -0.040\n",
      "Loss: 9.944, Residuals: -0.039\n",
      "Loss: 9.939, Residuals: -0.040\n",
      "Loss: 9.933, Residuals: -0.040\n",
      "Loss: 9.922, Residuals: -0.040\n",
      "Loss: 9.902, Residuals: -0.039\n",
      "Loss: 9.901, Residuals: -0.039\n",
      "Loss: 9.888, Residuals: -0.038\n",
      "Loss: 9.886, Residuals: -0.038\n",
      "Loss: 9.883, Residuals: -0.038\n",
      "Loss: 9.878, Residuals: -0.037\n",
      "Loss: 9.876, Residuals: -0.036\n",
      "Loss: 9.875, Residuals: -0.037\n",
      "Loss: 9.872, Residuals: -0.037\n",
      "Loss: 9.867, Residuals: -0.036\n",
      "Loss: 9.866, Residuals: -0.036\n",
      "Loss: 9.866, Residuals: -0.036\n",
      "Loss: 9.865, Residuals: -0.036\n",
      "Loss: 9.864, Residuals: -0.036\n",
      "Loss: 9.863, Residuals: -0.036\n",
      "Loss: 9.863, Residuals: -0.036\n",
      "Loss: 9.862, Residuals: -0.036\n",
      "Loss: 9.861, Residuals: -0.036\n",
      "Loss: 9.861, Residuals: -0.036\n",
      "Loss: 9.860, Residuals: -0.036\n",
      "Loss: 9.860, Residuals: -0.036\n",
      "Loss: 9.859, Residuals: -0.036\n",
      "Loss: 9.859, Residuals: -0.036\n",
      "Loss: 9.859, Residuals: -0.036\n",
      "Loss: 9.858, Residuals: -0.035\n",
      "Loss: 9.858, Residuals: -0.036\n",
      "Loss: 9.857, Residuals: -0.035\n",
      "Loss: 9.857, Residuals: -0.035\n",
      "Loss: 9.856, Residuals: -0.035\n",
      "Loss: 9.856, Residuals: -0.035\n",
      "Loss: 9.856, Residuals: -0.035\n",
      "Loss: 9.856, Residuals: -0.035\n",
      "Loss: 9.856, Residuals: -0.035\n",
      "Loss: 9.855, Residuals: -0.035\n",
      "Loss: 9.855, Residuals: -0.035\n",
      "Loss: 9.855, Residuals: -0.035\n",
      "Loss: 9.855, Residuals: -0.035\n",
      "Loss: 9.854, Residuals: -0.035\n",
      "Loss: 9.854, Residuals: -0.035\n",
      "Loss: 9.854, Residuals: -0.035\n",
      "Loss: 9.854, Residuals: -0.035\n",
      "Loss: 9.854, Residuals: -0.035\n",
      "Loss: 9.854, Residuals: -0.035\n",
      "Loss: 9.854, Residuals: -0.035\n",
      "Loss: 9.854, Residuals: -0.035\n",
      "Loss: 9.854, Residuals: -0.035\n",
      "Loss: 9.853, Residuals: -0.035\n",
      "Loss: 9.853, Residuals: -0.035\n",
      "Loss: 9.853, Residuals: -0.035\n",
      "Loss: 9.853, Residuals: -0.035\n",
      "Loss: 9.853, Residuals: -0.034\n",
      "Loss: 9.853, Residuals: -0.035\n",
      "Loss: 9.853, Residuals: -0.034\n",
      "Loss: 9.853, Residuals: -0.034\n",
      "Loss: 9.853, Residuals: -0.034\n",
      "Loss: 9.853, Residuals: -0.034\n",
      "Loss: 9.853, Residuals: -0.034\n",
      "Loss: 9.853, Residuals: -0.034\n",
      "Loss: 9.853, Residuals: -0.034\n",
      "Evidence 84.093\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.78e-02\n",
      "Loss: 39.301, Residuals: -0.037\n",
      "Loss: 39.148, Residuals: -0.028\n",
      "Loss: 38.871, Residuals: -0.025\n",
      "Loss: 38.533, Residuals: -0.013\n",
      "Loss: 38.476, Residuals: -0.008\n",
      "Loss: 38.460, Residuals: -0.016\n",
      "Loss: 38.434, Residuals: -0.015\n",
      "Loss: 38.392, Residuals: -0.012\n",
      "Loss: 38.374, Residuals: -0.010\n",
      "Loss: 38.370, Residuals: -0.011\n",
      "Loss: 38.366, Residuals: -0.011\n",
      "Loss: 38.360, Residuals: -0.011\n",
      "Loss: 38.351, Residuals: -0.009\n",
      "Loss: 38.350, Residuals: -0.009\n",
      "Loss: 38.348, Residuals: -0.009\n",
      "Loss: 38.346, Residuals: -0.009\n",
      "Loss: 38.345, Residuals: -0.008\n",
      "Loss: 38.345, Residuals: -0.009\n",
      "Loss: 38.345, Residuals: -0.009\n",
      "Loss: 38.345, Residuals: -0.009\n",
      "Loss: 38.345, Residuals: -0.009\n",
      "Loss: 38.344, Residuals: -0.008\n",
      "Loss: 38.344, Residuals: -0.008\n",
      "Loss: 38.344, Residuals: -0.008\n",
      "Loss: 38.343, Residuals: -0.008\n",
      "Loss: 38.343, Residuals: -0.008\n",
      "Loss: 38.342, Residuals: -0.008\n",
      "Loss: 38.342, Residuals: -0.008\n",
      "Loss: 38.342, Residuals: -0.008\n",
      "Loss: 38.342, Residuals: -0.008\n",
      "Loss: 38.342, Residuals: -0.008\n",
      "Loss: 38.342, Residuals: -0.008\n",
      "Loss: 38.342, Residuals: -0.008\n",
      "Loss: 38.342, Residuals: -0.008\n",
      "Evidence 315.431\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.81e-01\n",
      "Loss: 91.456, Residuals: -0.018\n",
      "Loss: 90.738, Residuals: -0.015\n",
      "Loss: 90.350, Residuals: -0.004\n",
      "Loss: 90.238, Residuals: -0.010\n",
      "Loss: 90.211, Residuals: -0.014\n",
      "Loss: 90.001, Residuals: -0.009\n",
      "Loss: 89.972, Residuals: -0.006\n",
      "Loss: 89.927, Residuals: -0.006\n",
      "Loss: 89.892, Residuals: -0.004\n",
      "Loss: 89.886, Residuals: -0.004\n",
      "Loss: 89.885, Residuals: -0.005\n",
      "Loss: 89.883, Residuals: -0.005\n",
      "Loss: 89.879, Residuals: -0.005\n",
      "Loss: 89.874, Residuals: -0.004\n",
      "Loss: 89.873, Residuals: -0.004\n",
      "Loss: 89.872, Residuals: -0.004\n",
      "Loss: 89.866, Residuals: -0.005\n",
      "Loss: 89.866, Residuals: -0.005\n",
      "Loss: 89.864, Residuals: -0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 89.864, Residuals: -0.004\n",
      "Loss: 89.862, Residuals: -0.004\n",
      "Loss: 89.861, Residuals: -0.004\n",
      "Loss: 89.861, Residuals: -0.004\n",
      "Loss: 89.861, Residuals: -0.004\n",
      "Loss: 89.861, Residuals: -0.004\n",
      "Evidence 423.718\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.47e-01\n",
      "Loss: 132.198, Residuals: -0.012\n",
      "Loss: 131.609, Residuals: -0.003\n",
      "Loss: 131.404, Residuals: -0.005\n",
      "Loss: 131.063, Residuals: -0.006\n",
      "Loss: 130.629, Residuals: -0.002\n",
      "Loss: 130.493, Residuals: -0.001\n",
      "Loss: 130.432, Residuals: -0.002\n",
      "Loss: 130.414, Residuals: -0.004\n",
      "Loss: 130.381, Residuals: -0.003\n",
      "Loss: 130.325, Residuals: -0.003\n",
      "Loss: 130.264, Residuals: -0.003\n",
      "Loss: 130.260, Residuals: -0.002\n",
      "Loss: 130.257, Residuals: -0.002\n",
      "Loss: 130.251, Residuals: -0.002\n",
      "Loss: 130.244, Residuals: -0.002\n",
      "Loss: 130.244, Residuals: -0.002\n",
      "Loss: 130.244, Residuals: -0.002\n",
      "Loss: 130.244, Residuals: -0.002\n",
      "Loss: 130.242, Residuals: -0.002\n",
      "Loss: 130.242, Residuals: -0.002\n",
      "Loss: 130.242, Residuals: -0.002\n",
      "Loss: 130.241, Residuals: -0.002\n",
      "Loss: 130.240, Residuals: -0.002\n",
      "Loss: 130.240, Residuals: -0.002\n",
      "Loss: 130.240, Residuals: -0.002\n",
      "Evidence 455.651\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.48e-01\n",
      "Loss: 149.172, Residuals: -0.000\n",
      "Loss: 149.167, Residuals: 0.000\n",
      "Loss: 149.130, Residuals: 0.000\n",
      "Loss: 149.059, Residuals: 0.000\n",
      "Loss: 148.942, Residuals: 0.001\n",
      "Loss: 148.838, Residuals: 0.001\n",
      "Loss: 148.829, Residuals: 0.001\n",
      "Loss: 148.814, Residuals: 0.001\n",
      "Loss: 148.796, Residuals: 0.001\n",
      "Loss: 148.796, Residuals: 0.001\n",
      "Evidence 463.859\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.73e-01\n",
      "Loss: 155.362, Residuals: 0.004\n",
      "Loss: 155.330, Residuals: 0.002\n",
      "Loss: 155.281, Residuals: 0.003\n",
      "Loss: 155.241, Residuals: 0.003\n",
      "Loss: 155.239, Residuals: 0.003\n",
      "Loss: 155.234, Residuals: 0.003\n",
      "Loss: 155.225, Residuals: 0.003\n",
      "Loss: 155.224, Residuals: 0.004\n",
      "Loss: 155.221, Residuals: 0.004\n",
      "Loss: 155.221, Residuals: 0.004\n",
      "Loss: 155.220, Residuals: 0.004\n",
      "Loss: 155.218, Residuals: 0.004\n",
      "Loss: 155.218, Residuals: 0.004\n",
      "Loss: 155.218, Residuals: 0.004\n",
      "Loss: 155.218, Residuals: 0.004\n",
      "Loss: 155.217, Residuals: 0.004\n",
      "Loss: 155.217, Residuals: 0.004\n",
      "Loss: 155.216, Residuals: 0.004\n",
      "Evidence 465.856\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.48e-01\n",
      "Loss: 157.353, Residuals: 0.005\n",
      "Loss: 157.335, Residuals: 0.005\n",
      "Loss: 157.309, Residuals: 0.005\n",
      "Loss: 157.288, Residuals: 0.005\n",
      "Loss: 157.286, Residuals: 0.005\n",
      "Loss: 157.285, Residuals: 0.005\n",
      "Loss: 157.283, Residuals: 0.005\n",
      "Loss: 157.282, Residuals: 0.005\n",
      "Loss: 157.282, Residuals: 0.005\n",
      "Loss: 157.281, Residuals: 0.005\n",
      "Loss: 157.280, Residuals: 0.005\n",
      "Loss: 157.280, Residuals: 0.005\n",
      "Loss: 157.279, Residuals: 0.005\n",
      "Loss: 157.279, Residuals: 0.005\n",
      "Loss: 157.279, Residuals: 0.005\n",
      "Evidence 466.744\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.23e-01\n",
      "Loss: 158.098, Residuals: 0.007\n",
      "Loss: 158.091, Residuals: 0.007\n",
      "Loss: 158.078, Residuals: 0.006\n",
      "Loss: 158.064, Residuals: 0.006\n",
      "Loss: 158.064, Residuals: 0.006\n",
      "Loss: 158.062, Residuals: 0.006\n",
      "Loss: 158.060, Residuals: 0.006\n",
      "Loss: 158.060, Residuals: 0.006\n",
      "Loss: 158.059, Residuals: 0.006\n",
      "Loss: 158.059, Residuals: 0.006\n",
      "Loss: 158.059, Residuals: 0.006\n",
      "Loss: 158.058, Residuals: 0.006\n",
      "Loss: 158.057, Residuals: 0.006\n",
      "Loss: 158.057, Residuals: 0.006\n",
      "Evidence 467.283\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.06e-01\n",
      "Loss: 158.447, Residuals: 0.007\n",
      "Loss: 158.442, Residuals: 0.008\n",
      "Loss: 158.434, Residuals: 0.007\n",
      "Loss: 158.424, Residuals: 0.007\n",
      "Loss: 158.424, Residuals: 0.007\n",
      "Evidence 467.583\n",
      "Pass count  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 13.642, Residuals: -0.038\n",
      "Loss: 8.023, Residuals: -0.015\n",
      "Loss: 6.727, Residuals: -0.014\n",
      "Loss: 5.914, Residuals: 0.021\n",
      "Loss: 5.246, Residuals: -0.005\n",
      "Loss: 4.741, Residuals: 0.002\n",
      "Loss: 4.452, Residuals: -0.021\n",
      "Loss: 4.420, Residuals: -0.030\n",
      "Loss: 4.153, Residuals: -0.025\n",
      "Loss: 4.088, Residuals: 0.042\n",
      "Loss: 3.972, Residuals: 0.028\n",
      "Loss: 3.781, Residuals: 0.004\n",
      "Loss: 3.752, Residuals: 0.019\n",
      "Loss: 3.706, Residuals: 0.003\n",
      "Loss: 3.625, Residuals: -0.006\n",
      "Loss: 3.620, Residuals: 0.004\n",
      "Loss: 3.567, Residuals: -0.004\n",
      "Loss: 3.477, Residuals: -0.014\n",
      "Loss: 3.474, Residuals: -0.012\n",
      "Loss: 3.451, Residuals: -0.020\n",
      "Loss: 3.413, Residuals: -0.030\n",
      "Loss: 3.412, Residuals: -0.025\n",
      "Loss: 3.409, Residuals: -0.025\n",
      "Loss: 3.383, Residuals: -0.033\n",
      "Loss: 3.378, Residuals: -0.028\n",
      "Loss: 3.370, Residuals: -0.030\n",
      "Loss: 3.370, Residuals: -0.032\n",
      "Loss: 3.359, Residuals: -0.035\n",
      "Loss: 3.359, Residuals: -0.035\n",
      "Loss: 3.345, Residuals: -0.040\n",
      "Loss: 3.322, Residuals: -0.048\n",
      "Loss: 3.322, Residuals: -0.048\n",
      "Evidence -412.826\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.85e-02\n",
      "Loss: 14.557, Residuals: -0.049\n",
      "Loss: 14.389, Residuals: -0.046\n",
      "Loss: 14.111, Residuals: -0.036\n",
      "Loss: 13.923, Residuals: -0.003\n",
      "Loss: 13.912, Residuals: -0.005\n",
      "Loss: 13.895, Residuals: -0.001\n",
      "Loss: 13.866, Residuals: 0.001\n",
      "Loss: 13.856, Residuals: 0.011\n",
      "Loss: 13.838, Residuals: 0.010\n",
      "Loss: 13.835, Residuals: 0.005\n",
      "Loss: 13.802, Residuals: 0.007\n",
      "Loss: 13.745, Residuals: 0.011\n",
      "Loss: 13.744, Residuals: 0.011\n",
      "Loss: 13.740, Residuals: 0.011\n",
      "Loss: 13.705, Residuals: 0.015\n",
      "Loss: 13.700, Residuals: 0.014\n",
      "Loss: 13.694, Residuals: 0.016\n",
      "Loss: 13.683, Residuals: 0.017\n",
      "Loss: 13.664, Residuals: 0.019\n",
      "Loss: 13.663, Residuals: 0.021\n",
      "Loss: 13.655, Residuals: 0.023\n",
      "Loss: 13.653, Residuals: 0.023\n",
      "Loss: 13.653, Residuals: 0.023\n",
      "Loss: 13.650, Residuals: 0.023\n",
      "Loss: 13.644, Residuals: 0.024\n",
      "Loss: 13.644, Residuals: 0.024\n",
      "Loss: 13.640, Residuals: 0.024\n",
      "Loss: 13.637, Residuals: 0.025\n",
      "Loss: 13.636, Residuals: 0.025\n",
      "Loss: 13.636, Residuals: 0.025\n",
      "Loss: 13.635, Residuals: 0.025\n",
      "Loss: 13.634, Residuals: 0.025\n",
      "Loss: 13.633, Residuals: 0.025\n",
      "Loss: 13.633, Residuals: 0.025\n",
      "Loss: 13.632, Residuals: 0.025\n",
      "Loss: 13.632, Residuals: 0.025\n",
      "Loss: 13.632, Residuals: 0.025\n",
      "Loss: 13.631, Residuals: 0.025\n",
      "Loss: 13.630, Residuals: 0.025\n",
      "Loss: 13.630, Residuals: 0.025\n",
      "Loss: 13.630, Residuals: 0.025\n",
      "Loss: 13.630, Residuals: 0.025\n",
      "Loss: 13.629, Residuals: 0.025\n",
      "Loss: 13.629, Residuals: 0.025\n",
      "Loss: 13.629, Residuals: 0.025\n",
      "Loss: 13.629, Residuals: 0.025\n",
      "Loss: 13.629, Residuals: 0.025\n",
      "Loss: 13.629, Residuals: 0.024\n",
      "Loss: 13.629, Residuals: 0.025\n",
      "Loss: 13.629, Residuals: 0.025\n",
      "Loss: 13.629, Residuals: 0.025\n",
      "Loss: 13.629, Residuals: 0.025\n",
      "Loss: 13.628, Residuals: 0.024\n",
      "Loss: 13.628, Residuals: 0.024\n",
      "Loss: 13.628, Residuals: 0.024\n",
      "Evidence 96.105\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.94e-01\n",
      "Loss: 42.248, Residuals: 0.024\n",
      "Loss: 42.064, Residuals: 0.024\n",
      "Loss: 41.931, Residuals: 0.027\n",
      "Loss: 41.929, Residuals: 0.027\n",
      "Loss: 41.872, Residuals: 0.028\n",
      "Loss: 41.776, Residuals: 0.030\n",
      "Loss: 41.626, Residuals: 0.034\n",
      "Loss: 41.617, Residuals: 0.033\n",
      "Loss: 41.606, Residuals: 0.034\n",
      "Loss: 41.522, Residuals: 0.037\n",
      "Loss: 41.519, Residuals: 0.038\n",
      "Loss: 41.514, Residuals: 0.038\n",
      "Loss: 41.511, Residuals: 0.037\n",
      "Loss: 41.492, Residuals: 0.037\n",
      "Loss: 41.477, Residuals: 0.038\n",
      "Loss: 41.476, Residuals: 0.037\n",
      "Loss: 41.474, Residuals: 0.037\n",
      "Loss: 41.457, Residuals: 0.038\n",
      "Loss: 41.456, Residuals: 0.037\n",
      "Loss: 41.447, Residuals: 0.038\n",
      "Loss: 41.446, Residuals: 0.038\n",
      "Loss: 41.436, Residuals: 0.039\n",
      "Loss: 41.435, Residuals: 0.039\n",
      "Loss: 41.432, Residuals: 0.039\n",
      "Loss: 41.427, Residuals: 0.039\n",
      "Loss: 41.427, Residuals: 0.039\n",
      "Loss: 41.423, Residuals: 0.039\n",
      "Loss: 41.423, Residuals: 0.040\n",
      "Loss: 41.421, Residuals: 0.040\n",
      "Loss: 41.421, Residuals: 0.039\n",
      "Loss: 41.420, Residuals: 0.039\n",
      "Loss: 41.419, Residuals: 0.040\n",
      "Loss: 41.419, Residuals: 0.040\n",
      "Loss: 41.418, Residuals: 0.040\n",
      "Loss: 41.417, Residuals: 0.040\n",
      "Loss: 41.417, Residuals: 0.040\n",
      "Loss: 41.416, Residuals: 0.040\n",
      "Loss: 41.416, Residuals: 0.040\n",
      "Loss: 41.415, Residuals: 0.041\n",
      "Loss: 41.415, Residuals: 0.041\n",
      "Loss: 41.415, Residuals: 0.041\n",
      "Loss: 41.415, Residuals: 0.041\n",
      "Loss: 41.415, Residuals: 0.041\n",
      "Evidence 284.862\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.04e-01\n",
      "Loss: 83.958, Residuals: 0.038\n",
      "Loss: 83.713, Residuals: 0.033\n",
      "Loss: 83.655, Residuals: 0.036\n",
      "Loss: 83.544, Residuals: 0.037\n",
      "Loss: 83.347, Residuals: 0.037\n",
      "Loss: 83.330, Residuals: 0.036\n",
      "Loss: 83.184, Residuals: 0.037\n",
      "Loss: 83.024, Residuals: 0.038\n",
      "Loss: 83.020, Residuals: 0.039\n",
      "Loss: 83.015, Residuals: 0.038\n",
      "Loss: 83.009, Residuals: 0.038\n",
      "Loss: 83.001, Residuals: 0.038\n",
      "Loss: 83.001, Residuals: 0.038\n",
      "Loss: 83.001, Residuals: 0.038\n",
      "Loss: 83.000, Residuals: 0.038\n",
      "Loss: 83.000, Residuals: 0.038\n",
      "Loss: 82.999, Residuals: 0.038\n",
      "Loss: 82.999, Residuals: 0.038\n",
      "Loss: 82.999, Residuals: 0.038\n",
      "Loss: 82.998, Residuals: 0.038\n",
      "Loss: 82.998, Residuals: 0.038\n",
      "Loss: 82.998, Residuals: 0.038\n",
      "Loss: 82.998, Residuals: 0.038\n",
      "Loss: 82.998, Residuals: 0.038\n",
      "Loss: 82.998, Residuals: 0.038\n",
      "Loss: 82.998, Residuals: 0.038\n",
      "Evidence 393.297\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.46e+00\n",
      "Loss: 121.511, Residuals: 0.046\n",
      "Loss: 121.086, Residuals: 0.042\n",
      "Loss: 120.896, Residuals: 0.031\n",
      "Loss: 120.638, Residuals: 0.032\n",
      "Loss: 120.631, Residuals: 0.034\n",
      "Loss: 120.571, Residuals: 0.034\n",
      "Loss: 120.495, Residuals: 0.032\n",
      "Loss: 120.490, Residuals: 0.033\n",
      "Loss: 120.487, Residuals: 0.032\n",
      "Loss: 120.481, Residuals: 0.032\n",
      "Loss: 120.480, Residuals: 0.032\n",
      "Loss: 120.478, Residuals: 0.032\n",
      "Loss: 120.476, Residuals: 0.031\n",
      "Loss: 120.476, Residuals: 0.031\n",
      "Loss: 120.475, Residuals: 0.031\n",
      "Loss: 120.475, Residuals: 0.031\n",
      "Loss: 120.475, Residuals: 0.031\n",
      "Loss: 120.475, Residuals: 0.031\n",
      "Loss: 120.475, Residuals: 0.031\n",
      "Loss: 120.475, Residuals: 0.031\n",
      "Evidence 433.564\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.70e+00\n",
      "Loss: 140.742, Residuals: 0.032\n",
      "Loss: 140.568, Residuals: 0.033\n",
      "Loss: 140.303, Residuals: 0.034\n",
      "Loss: 140.118, Residuals: 0.033\n",
      "Loss: 139.882, Residuals: 0.032\n",
      "Loss: 139.877, Residuals: 0.032\n",
      "Loss: 139.834, Residuals: 0.031\n",
      "Loss: 139.767, Residuals: 0.029\n",
      "Loss: 139.758, Residuals: 0.028\n",
      "Loss: 139.743, Residuals: 0.028\n",
      "Loss: 139.732, Residuals: 0.027\n",
      "Loss: 139.731, Residuals: 0.028\n",
      "Loss: 139.731, Residuals: 0.028\n",
      "Loss: 139.730, Residuals: 0.028\n",
      "Loss: 139.729, Residuals: 0.028\n",
      "Loss: 139.729, Residuals: 0.027\n",
      "Loss: 139.729, Residuals: 0.027\n",
      "Loss: 139.728, Residuals: 0.027\n",
      "Loss: 139.728, Residuals: 0.027\n",
      "Evidence 444.508\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.70e+00\n",
      "Loss: 147.032, Residuals: 0.032\n",
      "Loss: 146.825, Residuals: 0.032\n",
      "Loss: 146.619, Residuals: 0.029\n",
      "Loss: 146.484, Residuals: 0.026\n",
      "Loss: 146.476, Residuals: 0.027\n",
      "Loss: 146.405, Residuals: 0.027\n",
      "Loss: 146.326, Residuals: 0.025\n",
      "Loss: 146.324, Residuals: 0.025\n",
      "Loss: 146.320, Residuals: 0.025\n",
      "Loss: 146.313, Residuals: 0.025\n",
      "Loss: 146.311, Residuals: 0.025\n",
      "Loss: 146.309, Residuals: 0.025\n",
      "Loss: 146.305, Residuals: 0.025\n",
      "Evidence 449.002\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.63e+00\n",
      "Loss: 149.038, Residuals: 0.026\n",
      "Loss: 148.966, Residuals: 0.026\n",
      "Loss: 148.838, Residuals: 0.027\n",
      "Loss: 148.662, Residuals: 0.027\n",
      "Loss: 148.578, Residuals: 0.024\n",
      "Loss: 148.493, Residuals: 0.023\n",
      "Loss: 148.491, Residuals: 0.023\n",
      "Loss: 148.478, Residuals: 0.023\n",
      "Loss: 148.458, Residuals: 0.023\n",
      "Loss: 148.442, Residuals: 0.023\n",
      "Loss: 148.442, Residuals: 0.023\n",
      "Evidence 451.893\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.54e+00\n",
      "Loss: 149.715, Residuals: 0.024\n",
      "Loss: 149.675, Residuals: 0.024\n",
      "Loss: 149.604, Residuals: 0.025\n",
      "Loss: 149.504, Residuals: 0.025\n",
      "Loss: 149.450, Residuals: 0.023\n",
      "Loss: 149.418, Residuals: 0.022\n",
      "Loss: 149.416, Residuals: 0.022\n",
      "Loss: 149.413, Residuals: 0.022\n",
      "Loss: 149.408, Residuals: 0.022\n",
      "Loss: 149.407, Residuals: 0.023\n",
      "Loss: 149.401, Residuals: 0.023\n",
      "Loss: 149.393, Residuals: 0.022\n",
      "Loss: 149.393, Residuals: 0.022\n",
      "Evidence 453.786\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.47e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 150.204, Residuals: 0.022\n",
      "Loss: 150.186, Residuals: 0.023\n",
      "Loss: 150.153, Residuals: 0.023\n",
      "Loss: 150.106, Residuals: 0.023\n",
      "Loss: 150.074, Residuals: 0.021\n",
      "Loss: 150.056, Residuals: 0.021\n",
      "Loss: 150.054, Residuals: 0.021\n",
      "Loss: 150.052, Residuals: 0.021\n",
      "Loss: 150.049, Residuals: 0.021\n",
      "Loss: 150.045, Residuals: 0.021\n",
      "Loss: 150.045, Residuals: 0.021\n",
      "Evidence 454.923\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.43e+00\n",
      "Loss: 150.555, Residuals: 0.023\n",
      "Loss: 150.523, Residuals: 0.022\n",
      "Loss: 150.503, Residuals: 0.022\n",
      "Loss: 150.495, Residuals: 0.021\n",
      "Loss: 150.495, Residuals: 0.021\n",
      "Loss: 150.494, Residuals: 0.021\n",
      "Loss: 150.493, Residuals: 0.021\n",
      "Loss: 150.493, Residuals: 0.021\n",
      "Loss: 150.493, Residuals: 0.021\n",
      "Loss: 150.493, Residuals: 0.021\n",
      "Loss: 150.493, Residuals: 0.021\n",
      "Evidence 455.665\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.41e+00\n",
      "Loss: 150.819, Residuals: 0.022\n",
      "Loss: 150.810, Residuals: 0.021\n",
      "Loss: 150.800, Residuals: 0.021\n",
      "Loss: 150.796, Residuals: 0.021\n",
      "Loss: 150.796, Residuals: 0.021\n",
      "Loss: 150.796, Residuals: 0.021\n",
      "Loss: 150.795, Residuals: 0.021\n",
      "Loss: 150.795, Residuals: 0.021\n",
      "Loss: 150.795, Residuals: 0.021\n",
      "Loss: 150.795, Residuals: 0.021\n",
      "Loss: 150.795, Residuals: 0.021\n",
      "Loss: 150.795, Residuals: 0.021\n",
      "Loss: 150.795, Residuals: 0.021\n",
      "Loss: 150.795, Residuals: 0.021\n",
      "Evidence 456.173\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.40e+00\n",
      "Loss: 151.006, Residuals: 0.021\n",
      "Loss: 151.000, Residuals: 0.021\n",
      "Loss: 150.999, Residuals: 0.021\n",
      "Loss: 150.997, Residuals: 0.021\n",
      "Loss: 150.997, Residuals: 0.021\n",
      "Loss: 150.997, Residuals: 0.021\n",
      "Loss: 150.997, Residuals: 0.021\n",
      "Loss: 150.997, Residuals: 0.021\n",
      "Evidence 456.553\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.953, Residuals: -0.045\n",
      "Loss: 7.500, Residuals: -0.048\n",
      "Loss: 6.446, Residuals: -0.036\n",
      "Loss: 5.528, Residuals: -0.023\n",
      "Loss: 5.026, Residuals: -0.028\n",
      "Loss: 4.630, Residuals: -0.008\n",
      "Loss: 4.284, Residuals: -0.014\n",
      "Loss: 4.234, Residuals: 0.009\n",
      "Loss: 4.154, Residuals: 0.006\n",
      "Loss: 4.014, Residuals: -0.001\n",
      "Loss: 3.984, Residuals: 0.012\n",
      "Loss: 3.743, Residuals: -0.007\n",
      "Loss: 3.591, Residuals: -0.016\n",
      "Loss: 3.588, Residuals: -0.019\n",
      "Loss: 3.566, Residuals: -0.013\n",
      "Loss: 3.531, Residuals: -0.004\n",
      "Loss: 3.468, Residuals: -0.010\n",
      "Loss: 3.459, Residuals: 0.013\n",
      "Loss: 3.374, Residuals: 0.001\n",
      "Loss: 3.371, Residuals: 0.004\n",
      "Loss: 3.340, Residuals: -0.001\n",
      "Loss: 3.285, Residuals: -0.011\n",
      "Loss: 3.263, Residuals: -0.012\n",
      "Loss: 3.260, Residuals: -0.003\n",
      "Loss: 3.236, Residuals: -0.008\n",
      "Loss: 3.194, Residuals: -0.018\n",
      "Loss: 3.174, Residuals: -0.023\n",
      "Loss: 3.173, Residuals: -0.024\n",
      "Loss: 3.172, Residuals: -0.023\n",
      "Loss: 3.162, Residuals: -0.024\n",
      "Loss: 3.160, Residuals: -0.015\n",
      "Loss: 3.137, Residuals: -0.020\n",
      "Loss: 3.105, Residuals: -0.029\n",
      "Loss: 3.101, Residuals: -0.031\n",
      "Loss: 3.100, Residuals: -0.030\n",
      "Loss: 3.097, Residuals: -0.028\n",
      "Loss: 3.067, Residuals: -0.034\n",
      "Loss: 3.064, Residuals: -0.020\n",
      "Loss: 3.037, Residuals: -0.026\n",
      "Loss: 2.989, Residuals: -0.038\n",
      "Loss: 2.989, Residuals: -0.038\n",
      "Evidence -409.338\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.89e-02\n",
      "Loss: 13.731, Residuals: -0.055\n",
      "Loss: 13.696, Residuals: -0.040\n",
      "Loss: 13.394, Residuals: -0.035\n",
      "Loss: 13.393, Residuals: -0.035\n",
      "Evidence 94.703\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.08e-01\n",
      "Loss: 42.068, Residuals: -0.036\n",
      "Loss: 41.703, Residuals: -0.034\n",
      "Loss: 41.064, Residuals: -0.029\n",
      "Loss: 41.059, Residuals: -0.028\n",
      "Loss: 40.872, Residuals: -0.025\n",
      "Loss: 40.539, Residuals: -0.020\n",
      "Loss: 40.504, Residuals: -0.014\n",
      "Loss: 40.213, Residuals: -0.010\n",
      "Loss: 40.211, Residuals: -0.010\n",
      "Loss: 39.947, Residuals: -0.004\n",
      "Loss: 39.946, Residuals: -0.004\n",
      "Evidence 282.626\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.62e-01\n",
      "Loss: 84.591, Residuals: -0.005\n",
      "Loss: 84.498, Residuals: -0.006\n",
      "Loss: 84.333, Residuals: -0.009\n",
      "Loss: 84.036, Residuals: -0.008\n",
      "Loss: 83.529, Residuals: -0.007\n",
      "Loss: 82.593, Residuals: -0.005\n",
      "Loss: 81.913, Residuals: -0.002\n",
      "Loss: 81.753, Residuals: -0.003\n",
      "Loss: 81.555, Residuals: -0.001\n",
      "Loss: 81.243, Residuals: 0.002\n",
      "Loss: 81.211, Residuals: 0.000\n",
      "Loss: 80.961, Residuals: 0.003\n",
      "Loss: 80.938, Residuals: 0.002\n",
      "Loss: 80.748, Residuals: 0.005\n",
      "Loss: 80.739, Residuals: 0.002\n",
      "Loss: 80.727, Residuals: 0.004\n",
      "Loss: 80.328, Residuals: 0.009\n",
      "Loss: 80.295, Residuals: 0.009\n",
      "Loss: 80.252, Residuals: 0.007\n",
      "Loss: 80.170, Residuals: 0.008\n",
      "Loss: 80.114, Residuals: 0.010\n",
      "Loss: 80.108, Residuals: 0.011\n",
      "Loss: 80.100, Residuals: 0.011\n",
      "Loss: 80.028, Residuals: 0.012\n",
      "Loss: 80.025, Residuals: 0.012\n",
      "Loss: 79.919, Residuals: 0.014\n",
      "Loss: 79.912, Residuals: 0.013\n",
      "Loss: 79.849, Residuals: 0.015\n",
      "Loss: 79.843, Residuals: 0.015\n",
      "Loss: 79.836, Residuals: 0.015\n",
      "Loss: 79.823, Residuals: 0.016\n",
      "Loss: 79.821, Residuals: 0.015\n",
      "Loss: 79.809, Residuals: 0.016\n",
      "Loss: 79.809, Residuals: 0.016\n",
      "Loss: 79.807, Residuals: 0.016\n",
      "Loss: 79.804, Residuals: 0.016\n",
      "Loss: 79.803, Residuals: 0.016\n",
      "Loss: 79.803, Residuals: 0.016\n",
      "Loss: 79.803, Residuals: 0.016\n",
      "Loss: 79.802, Residuals: 0.016\n",
      "Loss: 79.801, Residuals: 0.017\n",
      "Loss: 79.801, Residuals: 0.017\n",
      "Loss: 79.800, Residuals: 0.017\n",
      "Loss: 79.799, Residuals: 0.017\n",
      "Loss: 79.799, Residuals: 0.017\n",
      "Loss: 79.799, Residuals: 0.017\n",
      "Loss: 79.799, Residuals: 0.017\n",
      "Evidence 390.042\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.24e+00\n",
      "Loss: 118.790, Residuals: 0.025\n",
      "Loss: 118.484, Residuals: 0.027\n",
      "Loss: 118.397, Residuals: 0.022\n",
      "Loss: 118.234, Residuals: 0.022\n",
      "Loss: 117.962, Residuals: 0.022\n",
      "Loss: 117.684, Residuals: 0.023\n",
      "Loss: 117.675, Residuals: 0.023\n",
      "Loss: 117.659, Residuals: 0.023\n",
      "Loss: 117.634, Residuals: 0.022\n",
      "Loss: 117.629, Residuals: 0.021\n",
      "Loss: 117.620, Residuals: 0.021\n",
      "Loss: 117.605, Residuals: 0.021\n",
      "Loss: 117.588, Residuals: 0.021\n",
      "Loss: 117.588, Residuals: 0.021\n",
      "Loss: 117.587, Residuals: 0.021\n",
      "Loss: 117.586, Residuals: 0.021\n",
      "Loss: 117.586, Residuals: 0.021\n",
      "Loss: 117.586, Residuals: 0.021\n",
      "Loss: 117.586, Residuals: 0.021\n",
      "Evidence 437.269\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.69e+00\n",
      "Loss: 139.218, Residuals: 0.025\n",
      "Loss: 139.002, Residuals: 0.024\n",
      "Loss: 138.792, Residuals: 0.022\n",
      "Loss: 138.684, Residuals: 0.019\n",
      "Loss: 138.653, Residuals: 0.021\n",
      "Loss: 138.600, Residuals: 0.021\n",
      "Loss: 138.526, Residuals: 0.020\n",
      "Loss: 138.524, Residuals: 0.020\n",
      "Loss: 138.508, Residuals: 0.020\n",
      "Loss: 138.490, Residuals: 0.019\n",
      "Loss: 138.489, Residuals: 0.019\n",
      "Loss: 138.489, Residuals: 0.019\n",
      "Loss: 138.489, Residuals: 0.018\n",
      "Loss: 138.489, Residuals: 0.018\n",
      "Loss: 138.488, Residuals: 0.018\n",
      "Loss: 138.488, Residuals: 0.018\n",
      "Loss: 138.488, Residuals: 0.018\n",
      "Loss: 138.488, Residuals: 0.018\n",
      "Evidence 449.404\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.79e+00\n",
      "Loss: 146.393, Residuals: 0.025\n",
      "Loss: 146.167, Residuals: 0.021\n",
      "Loss: 146.066, Residuals: 0.017\n",
      "Loss: 145.946, Residuals: 0.017\n",
      "Loss: 145.941, Residuals: 0.018\n",
      "Loss: 145.903, Residuals: 0.017\n",
      "Loss: 145.872, Residuals: 0.016\n",
      "Loss: 145.871, Residuals: 0.017\n",
      "Loss: 145.870, Residuals: 0.017\n",
      "Loss: 145.870, Residuals: 0.017\n",
      "Loss: 145.869, Residuals: 0.016\n",
      "Loss: 145.868, Residuals: 0.016\n",
      "Loss: 145.867, Residuals: 0.016\n",
      "Loss: 145.866, Residuals: 0.016\n",
      "Loss: 145.866, Residuals: 0.016\n",
      "Evidence 454.057\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.76e+00\n",
      "Loss: 148.651, Residuals: 0.022\n",
      "Loss: 148.474, Residuals: 0.018\n",
      "Loss: 148.379, Residuals: 0.015\n",
      "Loss: 148.280, Residuals: 0.014\n",
      "Loss: 148.276, Residuals: 0.015\n",
      "Loss: 148.245, Residuals: 0.014\n",
      "Loss: 148.216, Residuals: 0.014\n",
      "Loss: 148.216, Residuals: 0.014\n",
      "Loss: 148.215, Residuals: 0.014\n",
      "Loss: 148.213, Residuals: 0.014\n",
      "Loss: 148.211, Residuals: 0.014\n",
      "Loss: 148.211, Residuals: 0.014\n",
      "Loss: 148.210, Residuals: 0.014\n",
      "Loss: 148.210, Residuals: 0.014\n",
      "Loss: 148.210, Residuals: 0.014\n",
      "Evidence 457.079\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.67e+00\n",
      "Loss: 149.326, Residuals: 0.017\n",
      "Loss: 149.248, Residuals: 0.014\n",
      "Loss: 149.227, Residuals: 0.015\n",
      "Loss: 149.191, Residuals: 0.014\n",
      "Loss: 149.144, Residuals: 0.013\n",
      "Loss: 149.139, Residuals: 0.013\n",
      "Loss: 149.130, Residuals: 0.013\n",
      "Loss: 149.115, Residuals: 0.013\n",
      "Loss: 149.110, Residuals: 0.012\n",
      "Loss: 149.110, Residuals: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 149.109, Residuals: 0.012\n",
      "Loss: 149.106, Residuals: 0.012\n",
      "Loss: 149.103, Residuals: 0.012\n",
      "Evidence 459.247\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.59e+00\n",
      "Loss: 149.762, Residuals: 0.012\n",
      "Loss: 149.745, Residuals: 0.012\n",
      "Loss: 149.718, Residuals: 0.012\n",
      "Loss: 149.684, Residuals: 0.012\n",
      "Loss: 149.665, Residuals: 0.012\n",
      "Loss: 149.663, Residuals: 0.011\n",
      "Loss: 149.659, Residuals: 0.011\n",
      "Loss: 149.653, Residuals: 0.011\n",
      "Loss: 149.653, Residuals: 0.012\n",
      "Loss: 149.652, Residuals: 0.012\n",
      "Loss: 149.651, Residuals: 0.012\n",
      "Loss: 149.651, Residuals: 0.012\n",
      "Loss: 149.651, Residuals: 0.012\n",
      "Loss: 149.651, Residuals: 0.011\n",
      "Loss: 149.651, Residuals: 0.011\n",
      "Loss: 149.650, Residuals: 0.011\n",
      "Loss: 149.650, Residuals: 0.011\n",
      "Evidence 460.709\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.54e+00\n",
      "Loss: 150.135, Residuals: 0.011\n",
      "Loss: 150.104, Residuals: 0.012\n",
      "Loss: 150.090, Residuals: 0.011\n",
      "Loss: 150.089, Residuals: 0.011\n",
      "Loss: 150.087, Residuals: 0.011\n",
      "Loss: 150.085, Residuals: 0.011\n",
      "Loss: 150.083, Residuals: 0.011\n",
      "Evidence 461.670\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.50e+00\n",
      "Loss: 150.437, Residuals: 0.011\n",
      "Loss: 150.420, Residuals: 0.011\n",
      "Loss: 150.413, Residuals: 0.011\n",
      "Loss: 150.412, Residuals: 0.011\n",
      "Loss: 150.412, Residuals: 0.011\n",
      "Loss: 150.412, Residuals: 0.011\n",
      "Loss: 150.411, Residuals: 0.011\n",
      "Loss: 150.411, Residuals: 0.011\n",
      "Loss: 150.411, Residuals: 0.011\n",
      "Loss: 150.411, Residuals: 0.011\n",
      "Loss: 150.410, Residuals: 0.011\n",
      "Loss: 150.410, Residuals: 0.011\n",
      "Loss: 150.410, Residuals: 0.011\n",
      "Evidence 462.327\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.48e+00\n",
      "Loss: 150.658, Residuals: 0.011\n",
      "Loss: 150.649, Residuals: 0.011\n",
      "Loss: 150.646, Residuals: 0.011\n",
      "Loss: 150.645, Residuals: 0.011\n",
      "Loss: 150.645, Residuals: 0.011\n",
      "Loss: 150.645, Residuals: 0.011\n",
      "Loss: 150.645, Residuals: 0.011\n",
      "Evidence 462.793\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.48e+00\n",
      "Loss: 150.823, Residuals: 0.011\n",
      "Loss: 150.820, Residuals: 0.011\n",
      "Loss: 150.819, Residuals: 0.011\n",
      "Loss: 150.818, Residuals: 0.011\n",
      "Loss: 150.817, Residuals: 0.011\n",
      "Loss: 150.817, Residuals: 0.011\n",
      "Loss: 150.817, Residuals: 0.011\n",
      "Evidence 463.135\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.599, Residuals: -0.032\n",
      "Loss: 7.839, Residuals: -0.053\n",
      "Loss: 5.473, Residuals: -0.029\n",
      "Loss: 4.781, Residuals: -0.014\n",
      "Loss: 4.210, Residuals: -0.012\n",
      "Loss: 4.013, Residuals: -0.002\n",
      "Loss: 3.966, Residuals: -0.022\n",
      "Loss: 3.875, Residuals: -0.022\n",
      "Loss: 3.708, Residuals: -0.025\n",
      "Loss: 3.472, Residuals: -0.029\n",
      "Loss: 3.468, Residuals: -0.032\n",
      "Loss: 3.439, Residuals: -0.023\n",
      "Loss: 3.385, Residuals: -0.028\n",
      "Loss: 3.285, Residuals: -0.033\n",
      "Loss: 3.146, Residuals: -0.041\n",
      "Loss: 3.141, Residuals: -0.040\n",
      "Loss: 3.132, Residuals: -0.037\n",
      "Loss: 3.119, Residuals: -0.032\n",
      "Loss: 3.102, Residuals: -0.025\n",
      "Loss: 3.071, Residuals: -0.032\n",
      "Loss: 3.020, Residuals: -0.042\n",
      "Loss: 3.015, Residuals: -0.042\n",
      "Loss: 3.013, Residuals: -0.036\n",
      "Loss: 2.989, Residuals: -0.041\n",
      "Loss: 2.974, Residuals: -0.032\n",
      "Loss: 2.973, Residuals: -0.034\n",
      "Loss: 2.970, Residuals: -0.034\n",
      "Loss: 2.970, Residuals: -0.032\n",
      "Loss: 2.949, Residuals: -0.037\n",
      "Loss: 2.949, Residuals: -0.037\n",
      "Loss: 2.928, Residuals: -0.043\n",
      "Loss: 2.928, Residuals: -0.040\n",
      "Loss: 2.895, Residuals: -0.049\n",
      "Loss: 2.894, Residuals: -0.049\n",
      "Loss: 2.892, Residuals: -0.048\n",
      "Loss: 2.874, Residuals: -0.053\n",
      "Loss: 2.872, Residuals: -0.055\n",
      "Loss: 2.872, Residuals: -0.053\n",
      "Loss: 2.869, Residuals: -0.053\n",
      "Loss: 2.867, Residuals: -0.051\n",
      "Loss: 2.851, Residuals: -0.056\n",
      "Loss: 2.851, Residuals: -0.056\n",
      "Evidence -402.323\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.64e-03\n",
      "Loss: 12.995, Residuals: -0.043\n",
      "Loss: 12.993, Residuals: -0.043\n",
      "Loss: 12.978, Residuals: -0.040\n",
      "Loss: 12.861, Residuals: -0.024\n",
      "Loss: 12.860, Residuals: -0.025\n",
      "Evidence 114.755\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.32e-02\n",
      "Loss: 41.975, Residuals: -0.019\n",
      "Loss: 41.814, Residuals: -0.017\n",
      "Loss: 41.546, Residuals: -0.013\n",
      "Loss: 41.530, Residuals: -0.011\n",
      "Loss: 40.976, Residuals: 0.000\n",
      "Loss: 40.975, Residuals: 0.000\n",
      "Evidence 315.409\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.13e-01\n",
      "Loss: 88.541, Residuals: -0.000\n",
      "Loss: 88.269, Residuals: -0.002\n",
      "Loss: 87.865, Residuals: -0.007\n",
      "Loss: 87.199, Residuals: -0.002\n",
      "Loss: 86.045, Residuals: 0.002\n",
      "Loss: 86.036, Residuals: 0.002\n",
      "Evidence 427.807\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.98e-01\n",
      "Loss: 128.139, Residuals: 0.001\n",
      "Loss: 127.296, Residuals: 0.002\n",
      "Loss: 126.275, Residuals: 0.002\n",
      "Loss: 126.263, Residuals: 0.002\n",
      "Loss: 124.508, Residuals: 0.004\n",
      "Loss: 124.499, Residuals: 0.005\n",
      "Evidence 468.039\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.79e-01\n",
      "Loss: 145.740, Residuals: 0.003\n",
      "Loss: 142.211, Residuals: 0.007\n",
      "Loss: 142.172, Residuals: 0.008\n",
      "Loss: 142.149, Residuals: 0.007\n",
      "Loss: 141.277, Residuals: 0.006\n",
      "Loss: 140.983, Residuals: 0.008\n",
      "Loss: 140.455, Residuals: 0.008\n",
      "Loss: 139.697, Residuals: 0.009\n",
      "Loss: 139.684, Residuals: 0.011\n",
      "Loss: 139.242, Residuals: 0.009\n",
      "Loss: 139.222, Residuals: 0.007\n",
      "Loss: 139.027, Residuals: 0.007\n",
      "Loss: 139.025, Residuals: 0.008\n",
      "Loss: 138.651, Residuals: 0.009\n",
      "Loss: 138.648, Residuals: 0.009\n",
      "Loss: 138.138, Residuals: 0.012\n",
      "Loss: 138.122, Residuals: 0.011\n",
      "Loss: 138.108, Residuals: 0.012\n",
      "Loss: 138.087, Residuals: 0.011\n",
      "Loss: 137.543, Residuals: 0.022\n",
      "Loss: 137.291, Residuals: 0.026\n",
      "Loss: 137.151, Residuals: 0.023\n",
      "Loss: 137.016, Residuals: 0.020\n",
      "Loss: 137.004, Residuals: 0.020\n",
      "Loss: 136.542, Residuals: 0.019\n",
      "Loss: 136.447, Residuals: 0.017\n",
      "Loss: 136.427, Residuals: 0.020\n",
      "Loss: 136.238, Residuals: 0.020\n",
      "Loss: 135.944, Residuals: 0.019\n",
      "Loss: 135.914, Residuals: 0.018\n",
      "Loss: 135.859, Residuals: 0.018\n",
      "Loss: 135.856, Residuals: 0.019\n",
      "Loss: 135.823, Residuals: 0.019\n",
      "Loss: 135.771, Residuals: 0.018\n",
      "Loss: 135.726, Residuals: 0.017\n",
      "Loss: 135.723, Residuals: 0.017\n",
      "Loss: 135.722, Residuals: 0.017\n",
      "Loss: 135.722, Residuals: 0.017\n",
      "Loss: 135.721, Residuals: 0.017\n",
      "Loss: 135.719, Residuals: 0.017\n",
      "Loss: 135.719, Residuals: 0.017\n",
      "Loss: 135.719, Residuals: 0.017\n",
      "Loss: 135.718, Residuals: 0.017\n",
      "Evidence 488.805\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.06e+00\n",
      "Loss: 147.853, Residuals: 0.027\n",
      "Loss: 147.487, Residuals: 0.024\n",
      "Loss: 147.228, Residuals: 0.022\n",
      "Loss: 147.181, Residuals: 0.024\n",
      "Loss: 147.102, Residuals: 0.023\n",
      "Loss: 147.009, Residuals: 0.022\n",
      "Loss: 147.007, Residuals: 0.021\n",
      "Loss: 147.004, Residuals: 0.021\n",
      "Loss: 146.998, Residuals: 0.021\n",
      "Loss: 146.996, Residuals: 0.021\n",
      "Loss: 146.992, Residuals: 0.021\n",
      "Loss: 146.992, Residuals: 0.021\n",
      "Loss: 146.990, Residuals: 0.021\n",
      "Loss: 146.990, Residuals: 0.021\n",
      "Loss: 146.989, Residuals: 0.021\n",
      "Loss: 146.988, Residuals: 0.021\n",
      "Loss: 146.988, Residuals: 0.021\n",
      "Loss: 146.988, Residuals: 0.021\n",
      "Evidence 501.075\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.02e+00\n",
      "Loss: 152.565, Residuals: 0.024\n",
      "Loss: 152.516, Residuals: 0.025\n",
      "Loss: 152.443, Residuals: 0.023\n",
      "Loss: 152.357, Residuals: 0.022\n",
      "Loss: 152.354, Residuals: 0.023\n",
      "Loss: 152.326, Residuals: 0.023\n",
      "Loss: 152.299, Residuals: 0.022\n",
      "Loss: 152.298, Residuals: 0.022\n",
      "Loss: 152.297, Residuals: 0.022\n",
      "Loss: 152.296, Residuals: 0.022\n",
      "Loss: 152.295, Residuals: 0.022\n",
      "Loss: 152.295, Residuals: 0.022\n",
      "Loss: 152.295, Residuals: 0.022\n",
      "Loss: 152.295, Residuals: 0.022\n",
      "Loss: 152.295, Residuals: 0.022\n",
      "Evidence 505.027\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.47e-01\n",
      "Loss: 154.427, Residuals: 0.023\n",
      "Loss: 154.417, Residuals: 0.024\n",
      "Loss: 154.398, Residuals: 0.024\n",
      "Loss: 154.366, Residuals: 0.023\n",
      "Loss: 154.327, Residuals: 0.022\n",
      "Loss: 154.324, Residuals: 0.023\n",
      "Loss: 154.306, Residuals: 0.022\n",
      "Loss: 154.305, Residuals: 0.022\n",
      "Loss: 154.303, Residuals: 0.022\n",
      "Loss: 154.298, Residuals: 0.022\n",
      "Loss: 154.297, Residuals: 0.022\n",
      "Loss: 154.295, Residuals: 0.022\n",
      "Loss: 154.293, Residuals: 0.022\n",
      "Loss: 154.293, Residuals: 0.022\n",
      "Evidence 507.113\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.96e-01\n",
      "Loss: 155.233, Residuals: 0.022\n",
      "Loss: 155.219, Residuals: 0.021\n",
      "Loss: 155.199, Residuals: 0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 155.184, Residuals: 0.021\n",
      "Loss: 155.183, Residuals: 0.021\n",
      "Loss: 155.177, Residuals: 0.021\n",
      "Loss: 155.175, Residuals: 0.021\n",
      "Loss: 155.174, Residuals: 0.021\n",
      "Loss: 155.173, Residuals: 0.021\n",
      "Loss: 155.173, Residuals: 0.021\n",
      "Loss: 155.172, Residuals: 0.021\n",
      "Loss: 155.172, Residuals: 0.021\n",
      "Loss: 155.171, Residuals: 0.021\n",
      "Evidence 508.307\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.59e-01\n",
      "Loss: 155.694, Residuals: 0.020\n",
      "Loss: 155.683, Residuals: 0.021\n",
      "Loss: 155.675, Residuals: 0.021\n",
      "Loss: 155.675, Residuals: 0.020\n",
      "Loss: 155.674, Residuals: 0.021\n",
      "Loss: 155.672, Residuals: 0.021\n",
      "Loss: 155.671, Residuals: 0.020\n",
      "Loss: 155.671, Residuals: 0.020\n",
      "Loss: 155.671, Residuals: 0.020\n",
      "Loss: 155.671, Residuals: 0.020\n",
      "Loss: 155.670, Residuals: 0.020\n",
      "Loss: 155.670, Residuals: 0.020\n",
      "Loss: 155.670, Residuals: 0.020\n",
      "Evidence 508.973\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.43e-01\n",
      "Loss: 156.006, Residuals: 0.020\n",
      "Loss: 156.000, Residuals: 0.020\n",
      "Loss: 155.997, Residuals: 0.020\n",
      "Loss: 155.997, Residuals: 0.020\n",
      "Loss: 155.996, Residuals: 0.020\n",
      "Loss: 155.996, Residuals: 0.020\n",
      "Loss: 155.995, Residuals: 0.020\n",
      "Loss: 155.995, Residuals: 0.020\n",
      "Loss: 155.995, Residuals: 0.020\n",
      "Loss: 155.995, Residuals: 0.020\n",
      "Loss: 155.995, Residuals: 0.020\n",
      "Loss: 155.995, Residuals: 0.020\n",
      "Evidence 509.367\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.972, Residuals: -0.084\n",
      "Loss: 6.924, Residuals: -0.083\n",
      "Loss: 5.374, Residuals: -0.069\n",
      "Loss: 4.806, Residuals: -0.014\n",
      "Loss: 4.077, Residuals: -0.040\n",
      "Loss: 3.874, Residuals: 0.025\n",
      "Loss: 3.832, Residuals: 0.014\n",
      "Loss: 3.485, Residuals: -0.007\n",
      "Loss: 3.312, Residuals: -0.024\n",
      "Loss: 3.280, Residuals: 0.010\n",
      "Loss: 3.220, Residuals: 0.004\n",
      "Loss: 3.112, Residuals: -0.000\n",
      "Loss: 3.091, Residuals: 0.024\n",
      "Loss: 3.050, Residuals: 0.018\n",
      "Loss: 2.976, Residuals: 0.007\n",
      "Loss: 2.954, Residuals: 0.011\n",
      "Loss: 2.914, Residuals: 0.005\n",
      "Loss: 2.846, Residuals: -0.007\n",
      "Loss: 2.844, Residuals: -0.006\n",
      "Loss: 2.831, Residuals: -0.003\n",
      "Loss: 2.805, Residuals: -0.008\n",
      "Loss: 2.761, Residuals: -0.017\n",
      "Loss: 2.760, Residuals: -0.018\n",
      "Loss: 2.758, Residuals: -0.016\n",
      "Loss: 2.746, Residuals: -0.015\n",
      "Loss: 2.743, Residuals: -0.006\n",
      "Loss: 2.718, Residuals: -0.013\n",
      "Loss: 2.701, Residuals: -0.013\n",
      "Loss: 2.694, Residuals: -0.015\n",
      "Loss: 2.693, Residuals: -0.015\n",
      "Loss: 2.692, Residuals: -0.013\n",
      "Loss: 2.691, Residuals: -0.011\n",
      "Loss: 2.689, Residuals: -0.006\n",
      "Loss: 2.669, Residuals: -0.011\n",
      "Loss: 2.669, Residuals: -0.011\n",
      "Evidence -416.386\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.05e-02\n",
      "Loss: 13.748, Residuals: -0.012\n",
      "Loss: 13.552, Residuals: -0.007\n",
      "Loss: 13.269, Residuals: 0.008\n",
      "Loss: 13.227, Residuals: 0.021\n",
      "Loss: 13.207, Residuals: 0.014\n",
      "Loss: 13.169, Residuals: 0.016\n",
      "Loss: 13.105, Residuals: 0.023\n",
      "Loss: 13.097, Residuals: 0.032\n",
      "Loss: 13.030, Residuals: 0.035\n",
      "Loss: 12.942, Residuals: 0.043\n",
      "Loss: 12.942, Residuals: 0.043\n",
      "Evidence 115.722\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.32e-01\n",
      "Loss: 41.486, Residuals: 0.042\n",
      "Loss: 41.444, Residuals: 0.042\n",
      "Loss: 41.378, Residuals: 0.041\n",
      "Loss: 41.281, Residuals: 0.039\n",
      "Loss: 41.223, Residuals: 0.037\n",
      "Loss: 41.124, Residuals: 0.039\n",
      "Loss: 40.996, Residuals: 0.043\n",
      "Loss: 40.991, Residuals: 0.045\n",
      "Loss: 40.983, Residuals: 0.045\n",
      "Loss: 40.967, Residuals: 0.045\n",
      "Loss: 40.938, Residuals: 0.044\n",
      "Loss: 40.938, Residuals: 0.044\n",
      "Evidence 315.623\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.49e-01\n",
      "Loss: 87.284, Residuals: 0.044\n",
      "Loss: 87.168, Residuals: 0.044\n",
      "Loss: 86.964, Residuals: 0.044\n",
      "Loss: 86.658, Residuals: 0.040\n",
      "Loss: 86.397, Residuals: 0.040\n",
      "Loss: 86.347, Residuals: 0.035\n",
      "Loss: 86.261, Residuals: 0.035\n",
      "Loss: 86.252, Residuals: 0.037\n",
      "Loss: 86.166, Residuals: 0.037\n",
      "Loss: 86.019, Residuals: 0.037\n",
      "Loss: 86.017, Residuals: 0.037\n",
      "Loss: 85.944, Residuals: 0.036\n",
      "Loss: 85.944, Residuals: 0.036\n",
      "Loss: 85.898, Residuals: 0.036\n",
      "Loss: 85.898, Residuals: 0.036\n",
      "Evidence 430.099\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.31e-01\n",
      "Loss: 127.155, Residuals: 0.036\n",
      "Loss: 126.950, Residuals: 0.038\n",
      "Loss: 126.665, Residuals: 0.038\n",
      "Loss: 126.282, Residuals: 0.035\n",
      "Loss: 125.925, Residuals: 0.033\n",
      "Loss: 125.923, Residuals: 0.033\n",
      "Evidence 470.550\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.04e+00\n",
      "Loss: 145.946, Residuals: 0.032\n",
      "Loss: 145.543, Residuals: 0.033\n",
      "Loss: 145.281, Residuals: 0.031\n",
      "Loss: 145.264, Residuals: 0.033\n",
      "Loss: 145.098, Residuals: 0.033\n",
      "Loss: 144.814, Residuals: 0.033\n",
      "Loss: 144.811, Residuals: 0.033\n",
      "Loss: 144.790, Residuals: 0.032\n",
      "Loss: 144.599, Residuals: 0.032\n",
      "Loss: 144.596, Residuals: 0.032\n",
      "Loss: 144.593, Residuals: 0.032\n",
      "Loss: 144.468, Residuals: 0.032\n",
      "Loss: 144.467, Residuals: 0.032\n",
      "Loss: 144.347, Residuals: 0.032\n",
      "Loss: 144.342, Residuals: 0.033\n",
      "Loss: 144.151, Residuals: 0.033\n",
      "Loss: 144.144, Residuals: 0.033\n",
      "Loss: 144.134, Residuals: 0.032\n",
      "Loss: 144.051, Residuals: 0.034\n",
      "Loss: 144.049, Residuals: 0.033\n",
      "Loss: 144.046, Residuals: 0.033\n",
      "Loss: 143.936, Residuals: 0.034\n",
      "Loss: 143.934, Residuals: 0.034\n",
      "Loss: 143.930, Residuals: 0.034\n",
      "Loss: 143.923, Residuals: 0.034\n",
      "Loss: 143.909, Residuals: 0.034\n",
      "Loss: 143.885, Residuals: 0.034\n",
      "Loss: 143.885, Residuals: 0.034\n",
      "Loss: 143.881, Residuals: 0.034\n",
      "Loss: 143.874, Residuals: 0.034\n",
      "Loss: 143.867, Residuals: 0.035\n",
      "Loss: 143.867, Residuals: 0.035\n",
      "Loss: 143.859, Residuals: 0.035\n",
      "Loss: 143.859, Residuals: 0.035\n",
      "Evidence 483.251\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.08e+00\n",
      "Loss: 151.410, Residuals: 0.038\n",
      "Loss: 151.172, Residuals: 0.034\n",
      "Loss: 151.137, Residuals: 0.035\n",
      "Loss: 151.074, Residuals: 0.036\n",
      "Loss: 150.973, Residuals: 0.036\n",
      "Loss: 150.853, Residuals: 0.036\n",
      "Loss: 150.849, Residuals: 0.036\n",
      "Loss: 150.843, Residuals: 0.037\n",
      "Loss: 150.834, Residuals: 0.037\n",
      "Loss: 150.823, Residuals: 0.036\n",
      "Loss: 150.823, Residuals: 0.036\n",
      "Loss: 150.822, Residuals: 0.036\n",
      "Loss: 150.822, Residuals: 0.036\n",
      "Loss: 150.821, Residuals: 0.036\n",
      "Loss: 150.821, Residuals: 0.036\n",
      "Loss: 150.821, Residuals: 0.036\n",
      "Loss: 150.821, Residuals: 0.036\n",
      "Evidence 488.990\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.10e+00\n",
      "Loss: 153.742, Residuals: 0.037\n",
      "Loss: 153.601, Residuals: 0.035\n",
      "Loss: 153.580, Residuals: 0.035\n",
      "Loss: 153.545, Residuals: 0.035\n",
      "Loss: 153.498, Residuals: 0.036\n",
      "Loss: 153.492, Residuals: 0.036\n",
      "Loss: 153.483, Residuals: 0.036\n",
      "Loss: 153.476, Residuals: 0.036\n",
      "Loss: 153.476, Residuals: 0.036\n",
      "Loss: 153.475, Residuals: 0.036\n",
      "Loss: 153.475, Residuals: 0.036\n",
      "Loss: 153.475, Residuals: 0.036\n",
      "Loss: 153.475, Residuals: 0.036\n",
      "Evidence 491.767\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.12e+00\n",
      "Loss: 154.827, Residuals: 0.037\n",
      "Loss: 154.780, Residuals: 0.036\n",
      "Loss: 154.732, Residuals: 0.035\n",
      "Loss: 154.731, Residuals: 0.035\n",
      "Loss: 154.715, Residuals: 0.035\n",
      "Loss: 154.696, Residuals: 0.035\n",
      "Loss: 154.695, Residuals: 0.035\n",
      "Loss: 154.694, Residuals: 0.035\n",
      "Loss: 154.691, Residuals: 0.035\n",
      "Loss: 154.691, Residuals: 0.035\n",
      "Evidence 493.409\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.14e+00\n",
      "Loss: 155.522, Residuals: 0.035\n",
      "Loss: 155.485, Residuals: 0.035\n",
      "Loss: 155.428, Residuals: 0.035\n",
      "Loss: 155.395, Residuals: 0.034\n",
      "Loss: 155.392, Residuals: 0.034\n",
      "Loss: 155.386, Residuals: 0.034\n",
      "Loss: 155.376, Residuals: 0.034\n",
      "Loss: 155.362, Residuals: 0.034\n",
      "Loss: 155.362, Residuals: 0.034\n",
      "Loss: 155.361, Residuals: 0.034\n",
      "Loss: 155.361, Residuals: 0.034\n",
      "Loss: 155.356, Residuals: 0.034\n",
      "Loss: 155.355, Residuals: 0.034\n",
      "Evidence 494.489\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.16e+00\n",
      "Loss: 155.836, Residuals: 0.034\n",
      "Loss: 155.812, Residuals: 0.034\n",
      "Loss: 155.775, Residuals: 0.034\n",
      "Loss: 155.755, Residuals: 0.033\n",
      "Loss: 155.743, Residuals: 0.033\n",
      "Loss: 155.742, Residuals: 0.033\n",
      "Loss: 155.740, Residuals: 0.033\n",
      "Loss: 155.737, Residuals: 0.033\n",
      "Loss: 155.737, Residuals: 0.033\n",
      "Evidence 495.223\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.17e+00\n",
      "Loss: 156.065, Residuals: 0.033\n",
      "Loss: 156.051, Residuals: 0.033\n",
      "Loss: 156.029, Residuals: 0.033\n",
      "Loss: 156.019, Residuals: 0.032\n",
      "Loss: 156.003, Residuals: 0.032\n",
      "Loss: 156.003, Residuals: 0.032\n",
      "Loss: 156.001, Residuals: 0.032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 155.996, Residuals: 0.032\n",
      "Evidence 495.759\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.19e+00\n",
      "Loss: 156.210, Residuals: 0.032\n",
      "Loss: 156.200, Residuals: 0.032\n",
      "Loss: 156.187, Residuals: 0.032\n",
      "Loss: 156.181, Residuals: 0.031\n",
      "Loss: 156.171, Residuals: 0.031\n",
      "Loss: 156.170, Residuals: 0.031\n",
      "Loss: 156.164, Residuals: 0.031\n",
      "Loss: 156.164, Residuals: 0.031\n",
      "Loss: 156.157, Residuals: 0.031\n",
      "Loss: 156.157, Residuals: 0.031\n",
      "Evidence 496.188\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.714, Residuals: -0.066\n",
      "Loss: 7.826, Residuals: -0.054\n",
      "Loss: 5.687, Residuals: -0.050\n",
      "Loss: 5.113, Residuals: -0.034\n",
      "Loss: 4.519, Residuals: -0.040\n",
      "Loss: 4.387, Residuals: -0.036\n",
      "Loss: 4.177, Residuals: 0.000\n",
      "Loss: 3.924, Residuals: -0.025\n",
      "Loss: 3.913, Residuals: -0.031\n",
      "Loss: 3.893, Residuals: -0.017\n",
      "Loss: 3.734, Residuals: -0.026\n",
      "Loss: 3.702, Residuals: 0.026\n",
      "Loss: 3.643, Residuals: 0.018\n",
      "Loss: 3.590, Residuals: -0.008\n",
      "Loss: 3.501, Residuals: -0.011\n",
      "Loss: 3.492, Residuals: 0.008\n",
      "Loss: 3.415, Residuals: -0.003\n",
      "Loss: 3.410, Residuals: 0.002\n",
      "Loss: 3.363, Residuals: -0.009\n",
      "Loss: 3.348, Residuals: -0.010\n",
      "Loss: 3.344, Residuals: 0.004\n",
      "Loss: 3.338, Residuals: -0.005\n",
      "Loss: 3.328, Residuals: -0.008\n",
      "Loss: 3.311, Residuals: -0.014\n",
      "Loss: 3.311, Residuals: -0.014\n",
      "Loss: 3.302, Residuals: -0.017\n",
      "Loss: 3.286, Residuals: -0.023\n",
      "Loss: 3.285, Residuals: -0.024\n",
      "Loss: 3.270, Residuals: -0.029\n",
      "Loss: 3.270, Residuals: -0.025\n",
      "Loss: 3.254, Residuals: -0.031\n",
      "Loss: 3.249, Residuals: -0.033\n",
      "Loss: 3.249, Residuals: -0.033\n",
      "Loss: 3.249, Residuals: -0.032\n",
      "Loss: 3.242, Residuals: -0.032\n",
      "Loss: 3.241, Residuals: -0.033\n",
      "Loss: 3.241, Residuals: -0.033\n",
      "Loss: 3.240, Residuals: -0.033\n",
      "Loss: 3.235, Residuals: -0.033\n",
      "Loss: 3.235, Residuals: -0.034\n",
      "Loss: 3.235, Residuals: -0.030\n",
      "Loss: 3.225, Residuals: -0.033\n",
      "Loss: 3.225, Residuals: -0.033\n",
      "Evidence -402.287\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.75e-02\n",
      "Loss: 13.857, Residuals: -0.033\n",
      "Loss: 13.764, Residuals: -0.030\n",
      "Loss: 13.710, Residuals: -0.019\n",
      "Loss: 13.614, Residuals: -0.018\n",
      "Loss: 13.476, Residuals: -0.015\n",
      "Loss: 13.476, Residuals: -0.015\n",
      "Loss: 13.451, Residuals: -0.013\n",
      "Loss: 13.406, Residuals: -0.010\n",
      "Loss: 13.332, Residuals: -0.005\n",
      "Loss: 13.332, Residuals: -0.006\n",
      "Loss: 13.327, Residuals: -0.005\n",
      "Loss: 13.293, Residuals: 0.001\n",
      "Loss: 13.293, Residuals: 0.001\n",
      "Evidence 105.475\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.10e-01\n",
      "Loss: 42.226, Residuals: 0.000\n",
      "Loss: 42.202, Residuals: -0.001\n",
      "Loss: 42.159, Residuals: -0.001\n",
      "Loss: 42.078, Residuals: -0.001\n",
      "Loss: 41.934, Residuals: 0.001\n",
      "Loss: 41.696, Residuals: 0.006\n",
      "Loss: 41.633, Residuals: 0.007\n",
      "Loss: 41.628, Residuals: 0.006\n",
      "Evidence 305.129\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.63e-01\n",
      "Loss: 85.935, Residuals: 0.006\n",
      "Loss: 85.687, Residuals: 0.006\n",
      "Loss: 85.336, Residuals: 0.006\n",
      "Loss: 84.782, Residuals: 0.007\n",
      "Loss: 84.755, Residuals: 0.007\n",
      "Loss: 84.512, Residuals: 0.009\n",
      "Loss: 84.089, Residuals: 0.010\n",
      "Loss: 84.067, Residuals: 0.011\n",
      "Loss: 83.872, Residuals: 0.012\n",
      "Loss: 83.871, Residuals: 0.011\n",
      "Loss: 83.691, Residuals: 0.012\n",
      "Loss: 83.690, Residuals: 0.012\n",
      "Evidence 421.275\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.52e-01\n",
      "Loss: 124.765, Residuals: 0.013\n",
      "Loss: 124.631, Residuals: 0.014\n",
      "Loss: 124.393, Residuals: 0.015\n",
      "Loss: 124.041, Residuals: 0.016\n",
      "Loss: 123.983, Residuals: 0.013\n",
      "Loss: 123.508, Residuals: 0.014\n",
      "Loss: 123.373, Residuals: 0.008\n",
      "Loss: 123.119, Residuals: 0.010\n",
      "Loss: 123.116, Residuals: 0.009\n",
      "Loss: 122.172, Residuals: 0.017\n",
      "Loss: 122.051, Residuals: 0.015\n",
      "Loss: 121.992, Residuals: 0.016\n",
      "Loss: 121.939, Residuals: 0.013\n",
      "Loss: 121.505, Residuals: 0.016\n",
      "Loss: 121.486, Residuals: 0.017\n",
      "Loss: 121.331, Residuals: 0.017\n",
      "Loss: 121.310, Residuals: 0.017\n",
      "Loss: 121.274, Residuals: 0.017\n",
      "Loss: 121.220, Residuals: 0.018\n",
      "Loss: 121.218, Residuals: 0.018\n",
      "Loss: 121.204, Residuals: 0.017\n",
      "Loss: 121.202, Residuals: 0.016\n",
      "Loss: 121.198, Residuals: 0.016\n",
      "Loss: 121.198, Residuals: 0.016\n",
      "Loss: 121.196, Residuals: 0.016\n",
      "Loss: 121.196, Residuals: 0.016\n",
      "Loss: 121.195, Residuals: 0.016\n",
      "Loss: 121.194, Residuals: 0.016\n",
      "Loss: 121.194, Residuals: 0.016\n",
      "Evidence 468.586\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.18e+00\n",
      "Loss: 143.464, Residuals: 0.022\n",
      "Loss: 143.303, Residuals: 0.019\n",
      "Loss: 143.102, Residuals: 0.020\n",
      "Loss: 142.974, Residuals: 0.019\n",
      "Loss: 142.959, Residuals: 0.018\n",
      "Loss: 142.950, Residuals: 0.017\n",
      "Loss: 142.948, Residuals: 0.017\n",
      "Loss: 142.946, Residuals: 0.017\n",
      "Loss: 142.943, Residuals: 0.017\n",
      "Loss: 142.939, Residuals: 0.017\n",
      "Loss: 142.939, Residuals: 0.017\n",
      "Loss: 142.939, Residuals: 0.017\n",
      "Loss: 142.938, Residuals: 0.017\n",
      "Loss: 142.937, Residuals: 0.017\n",
      "Loss: 142.937, Residuals: 0.017\n",
      "Evidence 482.195\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.30e+00\n",
      "Loss: 151.577, Residuals: 0.020\n",
      "Loss: 151.509, Residuals: 0.018\n",
      "Loss: 151.427, Residuals: 0.018\n",
      "Loss: 151.421, Residuals: 0.018\n",
      "Loss: 151.409, Residuals: 0.018\n",
      "Loss: 151.389, Residuals: 0.018\n",
      "Loss: 151.365, Residuals: 0.017\n",
      "Loss: 151.364, Residuals: 0.017\n",
      "Loss: 151.361, Residuals: 0.017\n",
      "Loss: 151.356, Residuals: 0.017\n",
      "Loss: 151.356, Residuals: 0.017\n",
      "Loss: 151.355, Residuals: 0.017\n",
      "Loss: 151.355, Residuals: 0.017\n",
      "Loss: 151.355, Residuals: 0.017\n",
      "Loss: 151.355, Residuals: 0.017\n",
      "Loss: 151.354, Residuals: 0.017\n",
      "Loss: 151.354, Residuals: 0.017\n",
      "Evidence 485.459\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.32e+00\n",
      "Loss: 154.243, Residuals: 0.018\n",
      "Loss: 154.222, Residuals: 0.018\n",
      "Loss: 154.188, Residuals: 0.018\n",
      "Loss: 154.140, Residuals: 0.018\n",
      "Loss: 154.137, Residuals: 0.017\n",
      "Loss: 154.129, Residuals: 0.017\n",
      "Loss: 154.117, Residuals: 0.017\n",
      "Loss: 154.116, Residuals: 0.017\n",
      "Loss: 154.111, Residuals: 0.017\n",
      "Loss: 154.103, Residuals: 0.017\n",
      "Loss: 154.096, Residuals: 0.017\n",
      "Loss: 154.096, Residuals: 0.017\n",
      "Loss: 154.095, Residuals: 0.017\n",
      "Loss: 154.095, Residuals: 0.017\n",
      "Evidence 486.748\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.30e+00\n",
      "Loss: 155.202, Residuals: 0.021\n",
      "Loss: 155.165, Residuals: 0.018\n",
      "Loss: 155.141, Residuals: 0.018\n",
      "Loss: 155.135, Residuals: 0.018\n",
      "Loss: 155.127, Residuals: 0.018\n",
      "Loss: 155.126, Residuals: 0.017\n",
      "Loss: 155.124, Residuals: 0.017\n",
      "Loss: 155.120, Residuals: 0.017\n",
      "Loss: 155.120, Residuals: 0.017\n",
      "Loss: 155.119, Residuals: 0.017\n",
      "Loss: 155.117, Residuals: 0.017\n",
      "Loss: 155.117, Residuals: 0.017\n",
      "Loss: 155.116, Residuals: 0.018\n",
      "Loss: 155.116, Residuals: 0.018\n",
      "Loss: 155.116, Residuals: 0.018\n",
      "Loss: 155.116, Residuals: 0.018\n",
      "Loss: 155.116, Residuals: 0.018\n",
      "Loss: 155.115, Residuals: 0.018\n",
      "Loss: 155.115, Residuals: 0.018\n",
      "Loss: 155.115, Residuals: 0.018\n",
      "Evidence 487.528\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.28e+00\n",
      "Loss: 155.731, Residuals: 0.020\n",
      "Loss: 155.712, Residuals: 0.018\n",
      "Loss: 155.702, Residuals: 0.018\n",
      "Loss: 155.699, Residuals: 0.018\n",
      "Loss: 155.696, Residuals: 0.018\n",
      "Loss: 155.696, Residuals: 0.018\n",
      "Loss: 155.695, Residuals: 0.018\n",
      "Loss: 155.694, Residuals: 0.018\n",
      "Loss: 155.694, Residuals: 0.018\n",
      "Evidence 488.051\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.27e+00\n",
      "Loss: 156.100, Residuals: 0.020\n",
      "Loss: 156.089, Residuals: 0.019\n",
      "Loss: 156.082, Residuals: 0.018\n",
      "Loss: 156.081, Residuals: 0.018\n",
      "Loss: 156.079, Residuals: 0.018\n",
      "Loss: 156.079, Residuals: 0.018\n",
      "Loss: 156.079, Residuals: 0.018\n",
      "Loss: 156.078, Residuals: 0.018\n",
      "Loss: 156.078, Residuals: 0.018\n",
      "Loss: 156.078, Residuals: 0.018\n",
      "Evidence 488.400\n",
      "Pass count  1\n",
      "Total samples: 37, Updated regularization: 1.00e-05\n",
      "Loss: 13.625, Residuals: -0.032\n",
      "Loss: 7.405, Residuals: -0.018\n",
      "Loss: 5.147, Residuals: -0.023\n",
      "Loss: 4.402, Residuals: -0.014\n",
      "Loss: 4.292, Residuals: -0.031\n",
      "Loss: 4.098, Residuals: -0.029\n",
      "Loss: 3.773, Residuals: -0.036\n",
      "Loss: 3.692, Residuals: 0.002\n",
      "Loss: 3.678, Residuals: 0.024\n",
      "Loss: 3.558, Residuals: 0.010\n",
      "Loss: 3.464, Residuals: -0.001\n",
      "Loss: 3.463, Residuals: 0.001\n",
      "Loss: 3.421, Residuals: -0.007\n",
      "Loss: 3.355, Residuals: -0.022\n",
      "Loss: 3.354, Residuals: -0.024\n",
      "Loss: 3.318, Residuals: -0.032\n",
      "Loss: 3.317, Residuals: -0.034\n",
      "Loss: 3.315, Residuals: -0.032\n",
      "Loss: 3.299, Residuals: -0.035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.296, Residuals: -0.036\n",
      "Loss: 3.267, Residuals: -0.042\n",
      "Loss: 3.267, Residuals: -0.042\n",
      "Loss: 3.266, Residuals: -0.042\n",
      "Loss: 3.258, Residuals: -0.043\n",
      "Loss: 3.258, Residuals: -0.044\n",
      "Evidence -396.059\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.05e-02\n",
      "Loss: 13.250, Residuals: -0.044\n",
      "Loss: 13.033, Residuals: -0.039\n",
      "Loss: 12.771, Residuals: -0.027\n",
      "Loss: 12.749, Residuals: -0.019\n",
      "Loss: 12.746, Residuals: -0.013\n",
      "Loss: 12.741, Residuals: -0.013\n",
      "Loss: 12.732, Residuals: -0.012\n",
      "Loss: 12.665, Residuals: -0.003\n",
      "Loss: 12.660, Residuals: -0.002\n",
      "Loss: 12.651, Residuals: -0.000\n",
      "Loss: 12.634, Residuals: 0.002\n",
      "Loss: 12.605, Residuals: 0.005\n",
      "Loss: 12.604, Residuals: 0.003\n",
      "Loss: 12.602, Residuals: 0.004\n",
      "Loss: 12.585, Residuals: 0.006\n",
      "Loss: 12.585, Residuals: 0.006\n",
      "Evidence 85.511\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.29e-01\n",
      "Loss: 37.490, Residuals: 0.006\n",
      "Loss: 37.435, Residuals: 0.006\n",
      "Loss: 37.337, Residuals: 0.008\n",
      "Loss: 37.192, Residuals: 0.014\n",
      "Loss: 37.192, Residuals: 0.014\n",
      "Evidence 268.593\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 4.88e-01\n",
      "Loss: 76.869, Residuals: 0.013\n",
      "Loss: 76.748, Residuals: 0.014\n",
      "Loss: 76.539, Residuals: 0.014\n",
      "Loss: 76.218, Residuals: 0.012\n",
      "Loss: 75.722, Residuals: 0.015\n",
      "Loss: 75.712, Residuals: 0.017\n",
      "Loss: 75.640, Residuals: 0.014\n",
      "Loss: 75.629, Residuals: 0.015\n",
      "Loss: 75.210, Residuals: 0.017\n",
      "Loss: 75.203, Residuals: 0.017\n",
      "Loss: 74.928, Residuals: 0.018\n",
      "Loss: 74.916, Residuals: 0.018\n",
      "Loss: 74.447, Residuals: 0.022\n",
      "Loss: 74.426, Residuals: 0.021\n",
      "Loss: 74.391, Residuals: 0.021\n",
      "Loss: 73.755, Residuals: 0.034\n",
      "Loss: 73.693, Residuals: 0.032\n",
      "Loss: 73.619, Residuals: 0.031\n",
      "Loss: 73.498, Residuals: 0.033\n",
      "Loss: 73.406, Residuals: 0.035\n",
      "Loss: 73.387, Residuals: 0.034\n",
      "Loss: 73.383, Residuals: 0.035\n",
      "Loss: 73.383, Residuals: 0.034\n",
      "Loss: 73.378, Residuals: 0.034\n",
      "Loss: 73.371, Residuals: 0.034\n",
      "Loss: 73.370, Residuals: 0.034\n",
      "Loss: 73.370, Residuals: 0.034\n",
      "Loss: 73.369, Residuals: 0.034\n",
      "Loss: 73.369, Residuals: 0.034\n",
      "Loss: 73.369, Residuals: 0.034\n",
      "Loss: 73.369, Residuals: 0.034\n",
      "Loss: 73.368, Residuals: 0.034\n",
      "Loss: 73.368, Residuals: 0.034\n",
      "Loss: 73.368, Residuals: 0.034\n",
      "Evidence 380.077\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.37e+00\n",
      "Loss: 110.567, Residuals: 0.042\n",
      "Loss: 110.069, Residuals: 0.038\n",
      "Loss: 109.721, Residuals: 0.040\n",
      "Loss: 109.653, Residuals: 0.037\n",
      "Loss: 109.616, Residuals: 0.038\n",
      "Loss: 109.595, Residuals: 0.039\n",
      "Loss: 109.561, Residuals: 0.039\n",
      "Loss: 109.556, Residuals: 0.038\n",
      "Loss: 109.546, Residuals: 0.038\n",
      "Loss: 109.528, Residuals: 0.038\n",
      "Loss: 109.507, Residuals: 0.039\n",
      "Loss: 109.506, Residuals: 0.039\n",
      "Loss: 109.506, Residuals: 0.038\n",
      "Loss: 109.503, Residuals: 0.039\n",
      "Loss: 109.502, Residuals: 0.039\n",
      "Loss: 109.502, Residuals: 0.039\n",
      "Loss: 109.502, Residuals: 0.039\n",
      "Loss: 109.502, Residuals: 0.039\n",
      "Loss: 109.501, Residuals: 0.039\n",
      "Loss: 109.501, Residuals: 0.039\n",
      "Loss: 109.501, Residuals: 0.039\n",
      "Evidence 432.018\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.82e+00\n",
      "Loss: 131.964, Residuals: 0.047\n",
      "Loss: 131.697, Residuals: 0.040\n",
      "Loss: 131.616, Residuals: 0.040\n",
      "Loss: 131.524, Residuals: 0.039\n",
      "Loss: 131.518, Residuals: 0.039\n",
      "Loss: 131.508, Residuals: 0.038\n",
      "Loss: 131.494, Residuals: 0.038\n",
      "Loss: 131.487, Residuals: 0.038\n",
      "Loss: 131.486, Residuals: 0.038\n",
      "Loss: 131.485, Residuals: 0.038\n",
      "Loss: 131.485, Residuals: 0.038\n",
      "Loss: 131.485, Residuals: 0.038\n",
      "Loss: 131.485, Residuals: 0.038\n",
      "Loss: 131.485, Residuals: 0.038\n",
      "Loss: 131.484, Residuals: 0.038\n",
      "Loss: 131.484, Residuals: 0.038\n",
      "Loss: 131.484, Residuals: 0.038\n",
      "Evidence 447.866\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.88e+00\n",
      "Loss: 140.793, Residuals: 0.044\n",
      "Loss: 140.615, Residuals: 0.038\n",
      "Loss: 140.576, Residuals: 0.037\n",
      "Loss: 140.566, Residuals: 0.036\n",
      "Loss: 140.550, Residuals: 0.037\n",
      "Loss: 140.534, Residuals: 0.037\n",
      "Loss: 140.532, Residuals: 0.037\n",
      "Loss: 140.530, Residuals: 0.037\n",
      "Loss: 140.530, Residuals: 0.037\n",
      "Loss: 140.530, Residuals: 0.037\n",
      "Loss: 140.529, Residuals: 0.037\n",
      "Loss: 140.529, Residuals: 0.037\n",
      "Loss: 140.529, Residuals: 0.037\n",
      "Loss: 140.529, Residuals: 0.037\n",
      "Evidence 453.126\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.83e+00\n",
      "Loss: 143.915, Residuals: 0.041\n",
      "Loss: 143.802, Residuals: 0.036\n",
      "Loss: 143.792, Residuals: 0.036\n",
      "Loss: 143.777, Residuals: 0.036\n",
      "Loss: 143.772, Residuals: 0.036\n",
      "Loss: 143.766, Residuals: 0.036\n",
      "Loss: 143.765, Residuals: 0.036\n",
      "Loss: 143.765, Residuals: 0.036\n",
      "Loss: 143.764, Residuals: 0.036\n",
      "Loss: 143.764, Residuals: 0.036\n",
      "Loss: 143.764, Residuals: 0.036\n",
      "Loss: 143.764, Residuals: 0.036\n",
      "Loss: 143.763, Residuals: 0.036\n",
      "Evidence 455.595\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.77e+00\n",
      "Loss: 145.062, Residuals: 0.039\n",
      "Loss: 145.001, Residuals: 0.035\n",
      "Loss: 144.992, Residuals: 0.035\n",
      "Loss: 144.983, Residuals: 0.035\n",
      "Loss: 144.982, Residuals: 0.035\n",
      "Loss: 144.981, Residuals: 0.035\n",
      "Loss: 144.981, Residuals: 0.035\n",
      "Loss: 144.980, Residuals: 0.035\n",
      "Loss: 144.979, Residuals: 0.035\n",
      "Loss: 144.978, Residuals: 0.035\n",
      "Loss: 144.978, Residuals: 0.035\n",
      "Evidence 457.013\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.73e+00\n",
      "Loss: 145.569, Residuals: 0.037\n",
      "Loss: 145.541, Residuals: 0.035\n",
      "Loss: 145.535, Residuals: 0.035\n",
      "Loss: 145.533, Residuals: 0.035\n",
      "Loss: 145.529, Residuals: 0.035\n",
      "Loss: 145.524, Residuals: 0.035\n",
      "Loss: 145.524, Residuals: 0.035\n",
      "Loss: 145.523, Residuals: 0.035\n",
      "Loss: 145.523, Residuals: 0.035\n",
      "Loss: 145.522, Residuals: 0.035\n",
      "Loss: 145.522, Residuals: 0.035\n",
      "Loss: 145.522, Residuals: 0.035\n",
      "Evidence 457.901\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.71e+00\n",
      "Loss: 145.847, Residuals: 0.036\n",
      "Loss: 145.840, Residuals: 0.035\n",
      "Loss: 145.830, Residuals: 0.035\n",
      "Loss: 145.825, Residuals: 0.035\n",
      "Loss: 145.824, Residuals: 0.035\n",
      "Loss: 145.824, Residuals: 0.035\n",
      "Loss: 145.823, Residuals: 0.035\n",
      "Loss: 145.823, Residuals: 0.035\n",
      "Evidence 458.458\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.69e+00\n",
      "Loss: 146.037, Residuals: 0.036\n",
      "Loss: 146.027, Residuals: 0.035\n",
      "Loss: 146.027, Residuals: 0.035\n",
      "Loss: 146.026, Residuals: 0.035\n",
      "Loss: 146.025, Residuals: 0.035\n",
      "Loss: 146.025, Residuals: 0.035\n",
      "Loss: 146.025, Residuals: 0.035\n",
      "Loss: 146.025, Residuals: 0.035\n",
      "Loss: 146.024, Residuals: 0.035\n",
      "Loss: 146.024, Residuals: 0.035\n",
      "Loss: 146.024, Residuals: 0.035\n",
      "Loss: 146.024, Residuals: 0.035\n",
      "Loss: 146.024, Residuals: 0.035\n",
      "Loss: 146.024, Residuals: 0.035\n",
      "Evidence 458.834\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.903, Residuals: -0.058\n",
      "Loss: 8.052, Residuals: -0.051\n",
      "Loss: 5.578, Residuals: -0.031\n",
      "Loss: 4.898, Residuals: -0.026\n",
      "Loss: 4.738, Residuals: -0.056\n",
      "Loss: 4.539, Residuals: -0.001\n",
      "Loss: 4.225, Residuals: -0.015\n",
      "Loss: 4.026, Residuals: -0.033\n",
      "Loss: 4.022, Residuals: -0.035\n",
      "Loss: 3.891, Residuals: -0.037\n",
      "Loss: 3.858, Residuals: 0.007\n",
      "Loss: 3.799, Residuals: -0.001\n",
      "Loss: 3.741, Residuals: -0.026\n",
      "Loss: 3.713, Residuals: -0.004\n",
      "Loss: 3.664, Residuals: -0.012\n",
      "Loss: 3.586, Residuals: -0.021\n",
      "Loss: 3.577, Residuals: -0.011\n",
      "Loss: 3.560, Residuals: -0.015\n",
      "Loss: 3.528, Residuals: -0.020\n",
      "Loss: 3.527, Residuals: -0.019\n",
      "Loss: 3.490, Residuals: -0.028\n",
      "Loss: 3.490, Residuals: -0.028\n",
      "Loss: 3.485, Residuals: -0.028\n",
      "Loss: 3.478, Residuals: -0.028\n",
      "Loss: 3.475, Residuals: -0.026\n",
      "Loss: 3.449, Residuals: -0.034\n",
      "Loss: 3.447, Residuals: -0.031\n",
      "Loss: 3.429, Residuals: -0.037\n",
      "Loss: 3.423, Residuals: -0.036\n",
      "Loss: 3.414, Residuals: -0.040\n",
      "Loss: 3.413, Residuals: -0.039\n",
      "Loss: 3.400, Residuals: -0.043\n",
      "Loss: 3.395, Residuals: -0.043\n",
      "Loss: 3.394, Residuals: -0.043\n",
      "Loss: 3.394, Residuals: -0.043\n",
      "Loss: 3.393, Residuals: -0.041\n",
      "Loss: 3.387, Residuals: -0.043\n",
      "Loss: 3.375, Residuals: -0.047\n",
      "Loss: 3.375, Residuals: -0.047\n",
      "Evidence -410.452\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.66e-02\n",
      "Loss: 14.846, Residuals: -0.048\n",
      "Loss: 14.452, Residuals: -0.040\n",
      "Loss: 14.245, Residuals: -0.003\n",
      "Loss: 14.237, Residuals: -0.004\n",
      "Loss: 14.224, Residuals: -0.000\n",
      "Loss: 14.202, Residuals: 0.001\n",
      "Loss: 14.166, Residuals: 0.001\n",
      "Loss: 14.101, Residuals: 0.004\n",
      "Loss: 14.101, Residuals: 0.004\n",
      "Evidence 110.122\n",
      "Updating hyper-parameters...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 40, Updated regularization: 1.70e-01\n",
      "Loss: 44.768, Residuals: 0.003\n",
      "Loss: 44.650, Residuals: 0.001\n",
      "Loss: 44.429, Residuals: 0.003\n",
      "Loss: 44.069, Residuals: 0.009\n",
      "Loss: 44.068, Residuals: 0.009\n",
      "Evidence 305.423\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.63e-01\n",
      "Loss: 92.044, Residuals: 0.009\n",
      "Loss: 91.772, Residuals: 0.009\n",
      "Loss: 91.289, Residuals: 0.009\n",
      "Loss: 90.587, Residuals: 0.007\n",
      "Loss: 89.601, Residuals: 0.012\n",
      "Loss: 89.550, Residuals: 0.013\n",
      "Loss: 89.140, Residuals: 0.014\n",
      "Loss: 89.092, Residuals: 0.010\n",
      "Loss: 88.660, Residuals: 0.013\n",
      "Loss: 88.400, Residuals: 0.023\n",
      "Loss: 88.378, Residuals: 0.022\n",
      "Loss: 88.343, Residuals: 0.022\n",
      "Loss: 88.047, Residuals: 0.023\n",
      "Loss: 88.040, Residuals: 0.024\n",
      "Loss: 87.788, Residuals: 0.026\n",
      "Loss: 87.779, Residuals: 0.026\n",
      "Loss: 87.771, Residuals: 0.025\n",
      "Loss: 87.697, Residuals: 0.025\n",
      "Loss: 87.693, Residuals: 0.025\n",
      "Loss: 87.538, Residuals: 0.027\n",
      "Loss: 87.517, Residuals: 0.027\n",
      "Loss: 87.505, Residuals: 0.026\n",
      "Loss: 87.502, Residuals: 0.026\n",
      "Loss: 87.394, Residuals: 0.028\n",
      "Loss: 87.374, Residuals: 0.026\n",
      "Loss: 87.370, Residuals: 0.026\n",
      "Loss: 87.332, Residuals: 0.027\n",
      "Loss: 87.264, Residuals: 0.028\n",
      "Loss: 87.260, Residuals: 0.028\n",
      "Loss: 87.222, Residuals: 0.029\n",
      "Loss: 87.220, Residuals: 0.028\n",
      "Loss: 87.214, Residuals: 0.029\n",
      "Loss: 87.204, Residuals: 0.029\n",
      "Loss: 87.191, Residuals: 0.029\n",
      "Loss: 87.191, Residuals: 0.030\n",
      "Loss: 87.190, Residuals: 0.029\n",
      "Loss: 87.190, Residuals: 0.029\n",
      "Loss: 87.189, Residuals: 0.029\n",
      "Loss: 87.188, Residuals: 0.030\n",
      "Loss: 87.188, Residuals: 0.030\n",
      "Loss: 87.188, Residuals: 0.029\n",
      "Loss: 87.188, Residuals: 0.030\n",
      "Loss: 87.188, Residuals: 0.029\n",
      "Evidence 414.168\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.46e+00\n",
      "Loss: 126.430, Residuals: 0.030\n",
      "Loss: 126.041, Residuals: 0.035\n",
      "Loss: 125.615, Residuals: 0.032\n",
      "Loss: 125.566, Residuals: 0.034\n",
      "Loss: 125.478, Residuals: 0.033\n",
      "Loss: 125.469, Residuals: 0.031\n",
      "Loss: 125.389, Residuals: 0.031\n",
      "Loss: 125.276, Residuals: 0.031\n",
      "Loss: 125.270, Residuals: 0.030\n",
      "Loss: 125.258, Residuals: 0.030\n",
      "Loss: 125.242, Residuals: 0.030\n",
      "Loss: 125.241, Residuals: 0.030\n",
      "Loss: 125.239, Residuals: 0.030\n",
      "Loss: 125.236, Residuals: 0.030\n",
      "Loss: 125.236, Residuals: 0.030\n",
      "Loss: 125.235, Residuals: 0.030\n",
      "Loss: 125.235, Residuals: 0.030\n",
      "Loss: 125.235, Residuals: 0.030\n",
      "Loss: 125.234, Residuals: 0.030\n",
      "Loss: 125.234, Residuals: 0.030\n",
      "Loss: 125.234, Residuals: 0.030\n",
      "Evidence 456.751\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.96e+00\n",
      "Loss: 145.212, Residuals: 0.033\n",
      "Loss: 144.913, Residuals: 0.030\n",
      "Loss: 144.735, Residuals: 0.031\n",
      "Loss: 144.696, Residuals: 0.029\n",
      "Loss: 144.629, Residuals: 0.029\n",
      "Loss: 144.535, Residuals: 0.029\n",
      "Loss: 144.533, Residuals: 0.029\n",
      "Loss: 144.515, Residuals: 0.029\n",
      "Loss: 144.494, Residuals: 0.028\n",
      "Loss: 144.493, Residuals: 0.029\n",
      "Loss: 144.491, Residuals: 0.028\n",
      "Loss: 144.490, Residuals: 0.028\n",
      "Loss: 144.489, Residuals: 0.028\n",
      "Loss: 144.486, Residuals: 0.028\n",
      "Loss: 144.486, Residuals: 0.028\n",
      "Loss: 144.486, Residuals: 0.028\n",
      "Loss: 144.486, Residuals: 0.028\n",
      "Loss: 144.486, Residuals: 0.028\n",
      "Loss: 144.486, Residuals: 0.028\n",
      "Loss: 144.485, Residuals: 0.028\n",
      "Evidence 468.427\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.23e+00\n",
      "Loss: 151.422, Residuals: 0.034\n",
      "Loss: 151.218, Residuals: 0.029\n",
      "Loss: 151.101, Residuals: 0.028\n",
      "Loss: 151.077, Residuals: 0.027\n",
      "Loss: 151.035, Residuals: 0.027\n",
      "Loss: 150.984, Residuals: 0.027\n",
      "Loss: 150.982, Residuals: 0.027\n",
      "Loss: 150.960, Residuals: 0.027\n",
      "Loss: 150.947, Residuals: 0.027\n",
      "Loss: 150.946, Residuals: 0.027\n",
      "Loss: 150.945, Residuals: 0.027\n",
      "Loss: 150.942, Residuals: 0.027\n",
      "Loss: 150.942, Residuals: 0.027\n",
      "Loss: 150.942, Residuals: 0.027\n",
      "Loss: 150.941, Residuals: 0.027\n",
      "Loss: 150.941, Residuals: 0.027\n",
      "Loss: 150.941, Residuals: 0.027\n",
      "Loss: 150.941, Residuals: 0.027\n",
      "Evidence 473.456\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.41e+00\n",
      "Loss: 153.462, Residuals: 0.033\n",
      "Loss: 153.333, Residuals: 0.028\n",
      "Loss: 153.303, Residuals: 0.029\n",
      "Loss: 153.254, Residuals: 0.028\n",
      "Loss: 153.193, Residuals: 0.027\n",
      "Loss: 153.186, Residuals: 0.026\n",
      "Loss: 153.174, Residuals: 0.026\n",
      "Loss: 153.154, Residuals: 0.026\n",
      "Loss: 153.153, Residuals: 0.026\n",
      "Loss: 153.147, Residuals: 0.026\n",
      "Loss: 153.139, Residuals: 0.026\n",
      "Loss: 153.139, Residuals: 0.026\n",
      "Loss: 153.139, Residuals: 0.026\n",
      "Loss: 153.139, Residuals: 0.026\n",
      "Loss: 153.139, Residuals: 0.026\n",
      "Loss: 153.138, Residuals: 0.026\n",
      "Loss: 153.138, Residuals: 0.026\n",
      "Loss: 153.138, Residuals: 0.026\n",
      "Loss: 153.138, Residuals: 0.026\n",
      "Loss: 153.138, Residuals: 0.026\n",
      "Evidence 476.558\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.54e+00\n",
      "Loss: 154.351, Residuals: 0.030\n",
      "Loss: 154.277, Residuals: 0.027\n",
      "Loss: 154.227, Residuals: 0.025\n",
      "Loss: 154.217, Residuals: 0.026\n",
      "Loss: 154.199, Residuals: 0.025\n",
      "Loss: 154.175, Residuals: 0.025\n",
      "Loss: 154.172, Residuals: 0.025\n",
      "Loss: 154.168, Residuals: 0.025\n",
      "Loss: 154.160, Residuals: 0.025\n",
      "Loss: 154.160, Residuals: 0.025\n",
      "Loss: 154.160, Residuals: 0.025\n",
      "Loss: 154.159, Residuals: 0.025\n",
      "Loss: 154.159, Residuals: 0.025\n",
      "Loss: 154.159, Residuals: 0.025\n",
      "Loss: 154.158, Residuals: 0.025\n",
      "Evidence 478.599\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.60e+00\n",
      "Loss: 154.893, Residuals: 0.025\n",
      "Loss: 154.873, Residuals: 0.025\n",
      "Loss: 154.845, Residuals: 0.024\n",
      "Loss: 154.831, Residuals: 0.024\n",
      "Loss: 154.830, Residuals: 0.024\n",
      "Loss: 154.828, Residuals: 0.024\n",
      "Loss: 154.826, Residuals: 0.024\n",
      "Loss: 154.824, Residuals: 0.024\n",
      "Loss: 154.824, Residuals: 0.024\n",
      "Loss: 154.824, Residuals: 0.024\n",
      "Loss: 154.824, Residuals: 0.024\n",
      "Evidence 479.940\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.63e+00\n",
      "Loss: 155.319, Residuals: 0.024\n",
      "Loss: 155.307, Residuals: 0.023\n",
      "Loss: 155.303, Residuals: 0.024\n",
      "Loss: 155.296, Residuals: 0.023\n",
      "Loss: 155.289, Residuals: 0.023\n",
      "Loss: 155.289, Residuals: 0.023\n",
      "Loss: 155.288, Residuals: 0.023\n",
      "Loss: 155.287, Residuals: 0.023\n",
      "Loss: 155.287, Residuals: 0.023\n",
      "Loss: 155.287, Residuals: 0.023\n",
      "Evidence 480.845\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.65e+00\n",
      "Loss: 155.622, Residuals: 0.023\n",
      "Loss: 155.614, Residuals: 0.023\n",
      "Loss: 155.612, Residuals: 0.023\n",
      "Loss: 155.607, Residuals: 0.023\n",
      "Loss: 155.604, Residuals: 0.022\n",
      "Loss: 155.604, Residuals: 0.022\n",
      "Loss: 155.604, Residuals: 0.022\n",
      "Loss: 155.604, Residuals: 0.022\n",
      "Loss: 155.604, Residuals: 0.022\n",
      "Loss: 155.604, Residuals: 0.022\n",
      "Loss: 155.604, Residuals: 0.022\n",
      "Loss: 155.604, Residuals: 0.022\n",
      "Evidence 481.496\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.66e+00\n",
      "Loss: 155.825, Residuals: 0.023\n",
      "Loss: 155.820, Residuals: 0.022\n",
      "Loss: 155.815, Residuals: 0.022\n",
      "Loss: 155.814, Residuals: 0.022\n",
      "Loss: 155.814, Residuals: 0.022\n",
      "Loss: 155.814, Residuals: 0.022\n",
      "Loss: 155.814, Residuals: 0.022\n",
      "Loss: 155.814, Residuals: 0.022\n",
      "Loss: 155.814, Residuals: 0.022\n",
      "Evidence 481.983\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.67e+00\n",
      "Loss: 155.970, Residuals: 0.022\n",
      "Loss: 155.964, Residuals: 0.022\n",
      "Loss: 155.961, Residuals: 0.021\n",
      "Loss: 155.961, Residuals: 0.021\n",
      "Loss: 155.961, Residuals: 0.021\n",
      "Loss: 155.961, Residuals: 0.021\n",
      "Loss: 155.960, Residuals: 0.021\n",
      "Loss: 155.960, Residuals: 0.021\n",
      "Loss: 155.960, Residuals: 0.021\n",
      "Evidence 482.363\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 13.329, Residuals: -0.063\n",
      "Loss: 7.258, Residuals: -0.067\n",
      "Loss: 5.101, Residuals: -0.046\n",
      "Loss: 4.414, Residuals: -0.048\n",
      "Loss: 4.284, Residuals: -0.050\n",
      "Loss: 4.045, Residuals: -0.036\n",
      "Loss: 3.687, Residuals: -0.010\n",
      "Loss: 3.515, Residuals: -0.027\n",
      "Loss: 3.510, Residuals: -0.031\n",
      "Loss: 3.464, Residuals: -0.032\n",
      "Loss: 3.379, Residuals: -0.035\n",
      "Loss: 3.337, Residuals: 0.001\n",
      "Loss: 3.260, Residuals: -0.007\n",
      "Loss: 3.123, Residuals: -0.021\n",
      "Loss: 3.096, Residuals: 0.001\n",
      "Loss: 3.050, Residuals: -0.007\n",
      "Loss: 2.975, Residuals: -0.016\n",
      "Loss: 2.972, Residuals: -0.012\n",
      "Loss: 2.940, Residuals: -0.017\n",
      "Loss: 2.913, Residuals: -0.019\n",
      "Loss: 2.912, Residuals: -0.020\n",
      "Loss: 2.909, Residuals: -0.018\n",
      "Loss: 2.904, Residuals: -0.016\n",
      "Loss: 2.866, Residuals: -0.026\n",
      "Loss: 2.865, Residuals: -0.026\n",
      "Loss: 2.864, Residuals: -0.025\n",
      "Loss: 2.858, Residuals: -0.027\n",
      "Loss: 2.845, Residuals: -0.031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.845, Residuals: -0.032\n",
      "Loss: 2.828, Residuals: -0.037\n",
      "Loss: 2.828, Residuals: -0.037\n",
      "Loss: 2.827, Residuals: -0.037\n",
      "Loss: 2.827, Residuals: -0.037\n",
      "Loss: 2.826, Residuals: -0.037\n",
      "Loss: 2.817, Residuals: -0.041\n",
      "Loss: 2.817, Residuals: -0.041\n",
      "Loss: 2.816, Residuals: -0.041\n",
      "Loss: 2.808, Residuals: -0.046\n",
      "Loss: 2.807, Residuals: -0.045\n",
      "Loss: 2.807, Residuals: -0.044\n",
      "Loss: 2.806, Residuals: -0.044\n",
      "Loss: 2.805, Residuals: -0.044\n",
      "Loss: 2.794, Residuals: -0.052\n",
      "Loss: 2.793, Residuals: -0.052\n",
      "Loss: 2.793, Residuals: -0.052\n",
      "Evidence -416.096\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.87e-02\n",
      "Loss: 13.434, Residuals: -0.052\n",
      "Loss: 12.986, Residuals: -0.037\n",
      "Loss: 12.722, Residuals: -0.002\n",
      "Loss: 12.699, Residuals: 0.015\n",
      "Loss: 12.659, Residuals: 0.012\n",
      "Loss: 12.602, Residuals: 0.010\n",
      "Loss: 12.508, Residuals: 0.015\n",
      "Loss: 12.503, Residuals: 0.013\n",
      "Loss: 12.451, Residuals: 0.018\n",
      "Loss: 12.389, Residuals: 0.029\n",
      "Loss: 12.387, Residuals: 0.027\n",
      "Loss: 12.385, Residuals: 0.030\n",
      "Loss: 12.383, Residuals: 0.030\n",
      "Loss: 12.363, Residuals: 0.032\n",
      "Loss: 12.363, Residuals: 0.032\n",
      "Loss: 12.362, Residuals: 0.033\n",
      "Loss: 12.354, Residuals: 0.034\n",
      "Loss: 12.354, Residuals: 0.035\n",
      "Loss: 12.352, Residuals: 0.035\n",
      "Loss: 12.352, Residuals: 0.035\n",
      "Loss: 12.350, Residuals: 0.036\n",
      "Loss: 12.348, Residuals: 0.037\n",
      "Loss: 12.348, Residuals: 0.037\n",
      "Loss: 12.348, Residuals: 0.037\n",
      "Loss: 12.348, Residuals: 0.037\n",
      "Loss: 12.348, Residuals: 0.037\n",
      "Loss: 12.347, Residuals: 0.037\n",
      "Loss: 12.347, Residuals: 0.037\n",
      "Loss: 12.347, Residuals: 0.037\n",
      "Loss: 12.347, Residuals: 0.037\n",
      "Loss: 12.347, Residuals: 0.037\n",
      "Loss: 12.347, Residuals: 0.037\n",
      "Loss: 12.347, Residuals: 0.037\n",
      "Loss: 12.347, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Loss: 12.346, Residuals: 0.037\n",
      "Evidence 97.517\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.93e-01\n",
      "Loss: 39.972, Residuals: 0.036\n",
      "Loss: 39.931, Residuals: 0.036\n",
      "Loss: 39.861, Residuals: 0.036\n",
      "Loss: 39.748, Residuals: 0.037\n",
      "Loss: 39.661, Residuals: 0.044\n",
      "Loss: 39.647, Residuals: 0.044\n",
      "Loss: 39.545, Residuals: 0.046\n",
      "Loss: 39.427, Residuals: 0.051\n",
      "Loss: 39.421, Residuals: 0.048\n",
      "Loss: 39.415, Residuals: 0.050\n",
      "Loss: 39.403, Residuals: 0.049\n",
      "Loss: 39.381, Residuals: 0.050\n",
      "Loss: 39.343, Residuals: 0.051\n",
      "Loss: 39.338, Residuals: 0.050\n",
      "Loss: 39.330, Residuals: 0.050\n",
      "Loss: 39.316, Residuals: 0.051\n",
      "Loss: 39.316, Residuals: 0.050\n",
      "Loss: 39.297, Residuals: 0.051\n",
      "Loss: 39.296, Residuals: 0.051\n",
      "Loss: 39.286, Residuals: 0.052\n",
      "Loss: 39.286, Residuals: 0.052\n",
      "Loss: 39.285, Residuals: 0.052\n",
      "Loss: 39.283, Residuals: 0.052\n",
      "Loss: 39.280, Residuals: 0.052\n",
      "Loss: 39.280, Residuals: 0.052\n",
      "Loss: 39.279, Residuals: 0.052\n",
      "Loss: 39.277, Residuals: 0.053\n",
      "Loss: 39.277, Residuals: 0.053\n",
      "Loss: 39.276, Residuals: 0.053\n",
      "Loss: 39.275, Residuals: 0.053\n",
      "Loss: 39.275, Residuals: 0.053\n",
      "Evidence 288.134\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.95e-01\n",
      "Loss: 82.055, Residuals: 0.065\n",
      "Loss: 81.738, Residuals: 0.050\n",
      "Loss: 81.456, Residuals: 0.044\n",
      "Loss: 81.416, Residuals: 0.046\n",
      "Loss: 81.347, Residuals: 0.046\n",
      "Loss: 81.253, Residuals: 0.045\n",
      "Loss: 81.119, Residuals: 0.047\n",
      "Loss: 81.115, Residuals: 0.047\n",
      "Loss: 81.111, Residuals: 0.046\n",
      "Loss: 81.079, Residuals: 0.047\n",
      "Loss: 81.079, Residuals: 0.046\n",
      "Loss: 81.073, Residuals: 0.047\n",
      "Loss: 81.061, Residuals: 0.047\n",
      "Loss: 81.061, Residuals: 0.046\n",
      "Loss: 81.055, Residuals: 0.047\n",
      "Loss: 81.047, Residuals: 0.047\n",
      "Loss: 81.047, Residuals: 0.047\n",
      "Loss: 81.047, Residuals: 0.047\n",
      "Loss: 81.046, Residuals: 0.047\n",
      "Loss: 81.046, Residuals: 0.047\n",
      "Loss: 81.045, Residuals: 0.047\n",
      "Loss: 81.044, Residuals: 0.047\n",
      "Loss: 81.044, Residuals: 0.047\n",
      "Loss: 81.043, Residuals: 0.047\n",
      "Loss: 81.043, Residuals: 0.047\n",
      "Evidence 397.684\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.41e+00\n",
      "Loss: 119.537, Residuals: 0.054\n",
      "Loss: 119.129, Residuals: 0.046\n",
      "Loss: 118.804, Residuals: 0.041\n",
      "Loss: 118.573, Residuals: 0.041\n",
      "Loss: 118.563, Residuals: 0.042\n",
      "Loss: 118.544, Residuals: 0.042\n",
      "Loss: 118.396, Residuals: 0.041\n",
      "Loss: 118.395, Residuals: 0.041\n",
      "Loss: 118.356, Residuals: 0.041\n",
      "Loss: 118.293, Residuals: 0.040\n",
      "Loss: 118.291, Residuals: 0.040\n",
      "Loss: 118.287, Residuals: 0.040\n",
      "Loss: 118.261, Residuals: 0.040\n",
      "Loss: 118.261, Residuals: 0.041\n",
      "Loss: 118.254, Residuals: 0.040\n",
      "Loss: 118.253, Residuals: 0.040\n",
      "Loss: 118.250, Residuals: 0.040\n",
      "Loss: 118.250, Residuals: 0.040\n",
      "Loss: 118.247, Residuals: 0.040\n",
      "Loss: 118.241, Residuals: 0.040\n",
      "Loss: 118.241, Residuals: 0.041\n",
      "Loss: 118.241, Residuals: 0.040\n",
      "Loss: 118.239, Residuals: 0.040\n",
      "Loss: 118.239, Residuals: 0.040\n",
      "Loss: 118.239, Residuals: 0.040\n",
      "Loss: 118.239, Residuals: 0.040\n",
      "Loss: 118.239, Residuals: 0.040\n",
      "Loss: 118.238, Residuals: 0.040\n",
      "Loss: 118.238, Residuals: 0.040\n",
      "Evidence 440.025\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.65e+00\n",
      "Loss: 138.953, Residuals: 0.041\n",
      "Loss: 138.716, Residuals: 0.042\n",
      "Loss: 138.346, Residuals: 0.042\n",
      "Loss: 138.096, Residuals: 0.039\n",
      "Loss: 137.915, Residuals: 0.037\n",
      "Loss: 137.912, Residuals: 0.036\n",
      "Loss: 137.883, Residuals: 0.037\n",
      "Loss: 137.827, Residuals: 0.037\n",
      "Loss: 137.729, Residuals: 0.037\n",
      "Loss: 137.714, Residuals: 0.037\n",
      "Loss: 137.686, Residuals: 0.037\n",
      "Loss: 137.635, Residuals: 0.037\n",
      "Loss: 137.633, Residuals: 0.037\n",
      "Loss: 137.618, Residuals: 0.037\n",
      "Loss: 137.592, Residuals: 0.037\n",
      "Loss: 137.557, Residuals: 0.037\n",
      "Loss: 137.555, Residuals: 0.037\n",
      "Loss: 137.554, Residuals: 0.037\n",
      "Loss: 137.554, Residuals: 0.037\n",
      "Loss: 137.551, Residuals: 0.037\n",
      "Loss: 137.548, Residuals: 0.037\n",
      "Loss: 137.548, Residuals: 0.037\n",
      "Loss: 137.548, Residuals: 0.037\n",
      "Loss: 137.548, Residuals: 0.037\n",
      "Loss: 137.548, Residuals: 0.037\n",
      "Loss: 137.548, Residuals: 0.037\n",
      "Loss: 137.547, Residuals: 0.037\n",
      "Loss: 137.547, Residuals: 0.037\n",
      "Evidence 452.850\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.63e+00\n",
      "Loss: 145.465, Residuals: 0.037\n",
      "Loss: 145.285, Residuals: 0.038\n",
      "Loss: 144.990, Residuals: 0.038\n",
      "Loss: 144.726, Residuals: 0.037\n",
      "Loss: 144.573, Residuals: 0.035\n",
      "Loss: 144.571, Residuals: 0.035\n",
      "Loss: 144.556, Residuals: 0.035\n",
      "Loss: 144.437, Residuals: 0.035\n",
      "Loss: 144.432, Residuals: 0.035\n",
      "Loss: 144.388, Residuals: 0.035\n",
      "Loss: 144.336, Residuals: 0.035\n",
      "Loss: 144.335, Residuals: 0.035\n",
      "Loss: 144.334, Residuals: 0.035\n",
      "Loss: 144.331, Residuals: 0.035\n",
      "Loss: 144.329, Residuals: 0.035\n",
      "Loss: 144.326, Residuals: 0.035\n",
      "Loss: 144.323, Residuals: 0.035\n",
      "Evidence 458.525\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.50e+00\n",
      "Loss: 147.389, Residuals: 0.035\n",
      "Loss: 147.249, Residuals: 0.035\n",
      "Loss: 147.026, Residuals: 0.036\n",
      "Loss: 146.858, Residuals: 0.034\n",
      "Loss: 146.783, Residuals: 0.034\n",
      "Loss: 146.778, Residuals: 0.035\n",
      "Loss: 146.771, Residuals: 0.035\n",
      "Loss: 146.756, Residuals: 0.035\n",
      "Loss: 146.731, Residuals: 0.034\n",
      "Loss: 146.699, Residuals: 0.034\n",
      "Loss: 146.697, Residuals: 0.034\n",
      "Loss: 146.686, Residuals: 0.033\n",
      "Loss: 146.686, Residuals: 0.033\n",
      "Evidence 462.057\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.45e+00\n",
      "Loss: 148.204, Residuals: 0.034\n",
      "Loss: 148.124, Residuals: 0.034\n",
      "Loss: 147.995, Residuals: 0.034\n",
      "Loss: 147.896, Residuals: 0.032\n",
      "Loss: 147.850, Residuals: 0.032\n",
      "Loss: 147.847, Residuals: 0.033\n",
      "Loss: 147.842, Residuals: 0.033\n",
      "Loss: 147.832, Residuals: 0.033\n",
      "Loss: 147.821, Residuals: 0.032\n",
      "Loss: 147.820, Residuals: 0.032\n",
      "Loss: 147.816, Residuals: 0.032\n",
      "Evidence 464.232\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.43e+00\n",
      "Loss: 148.763, Residuals: 0.033\n",
      "Loss: 148.720, Residuals: 0.032\n",
      "Loss: 148.647, Residuals: 0.032\n",
      "Loss: 148.566, Residuals: 0.032\n",
      "Loss: 148.538, Residuals: 0.032\n",
      "Loss: 148.523, Residuals: 0.031\n",
      "Loss: 148.521, Residuals: 0.032\n",
      "Loss: 148.518, Residuals: 0.032\n",
      "Loss: 148.518, Residuals: 0.031\n",
      "Loss: 148.517, Residuals: 0.031\n",
      "Loss: 148.516, Residuals: 0.031\n",
      "Loss: 148.516, Residuals: 0.031\n",
      "Loss: 148.516, Residuals: 0.031\n",
      "Loss: 148.516, Residuals: 0.031\n",
      "Evidence 465.656\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.41e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 149.128, Residuals: 0.032\n",
      "Evidence 466.252\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.42e+00\n",
      "Loss: 149.663, Residuals: 0.031\n",
      "Loss: 149.623, Residuals: 0.032\n",
      "Loss: 149.609, Residuals: 0.031\n",
      "Loss: 149.606, Residuals: 0.031\n",
      "Loss: 149.601, Residuals: 0.031\n",
      "Loss: 149.601, Residuals: 0.031\n",
      "Loss: 149.601, Residuals: 0.031\n",
      "Loss: 149.601, Residuals: 0.031\n",
      "Loss: 149.601, Residuals: 0.031\n",
      "Evidence 466.932\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.42e+00\n",
      "Loss: 149.585, Residuals: 0.031\n",
      "Loss: 149.566, Residuals: 0.030\n",
      "Loss: 149.559, Residuals: 0.030\n",
      "Loss: 149.557, Residuals: 0.030\n",
      "Loss: 149.557, Residuals: 0.031\n",
      "Loss: 149.556, Residuals: 0.030\n",
      "Loss: 149.556, Residuals: 0.030\n",
      "Loss: 149.556, Residuals: 0.030\n",
      "Evidence 467.482\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.43e+00\n",
      "Loss: 149.744, Residuals: 0.031\n",
      "Loss: 149.735, Residuals: 0.030\n",
      "Loss: 149.731, Residuals: 0.030\n",
      "Loss: 149.728, Residuals: 0.030\n",
      "Loss: 149.728, Residuals: 0.030\n",
      "Loss: 149.728, Residuals: 0.030\n",
      "Loss: 149.728, Residuals: 0.030\n",
      "Loss: 149.728, Residuals: 0.030\n",
      "Evidence 467.845\n",
      "Pass count  1\n",
      "Total samples: 37, Updated regularization: 1.00e-05\n",
      "Loss: 12.736, Residuals: -0.034\n",
      "Loss: 7.256, Residuals: -0.024\n",
      "Loss: 5.932, Residuals: -0.037\n",
      "Loss: 5.267, Residuals: -0.039\n",
      "Loss: 4.596, Residuals: -0.022\n",
      "Loss: 4.448, Residuals: -0.030\n",
      "Loss: 4.177, Residuals: -0.033\n",
      "Loss: 3.736, Residuals: -0.022\n",
      "Loss: 3.551, Residuals: 0.034\n",
      "Loss: 3.288, Residuals: 0.018\n",
      "Loss: 3.263, Residuals: 0.065\n",
      "Loss: 3.216, Residuals: 0.051\n",
      "Loss: 3.139, Residuals: 0.027\n",
      "Loss: 3.111, Residuals: 0.015\n",
      "Loss: 3.064, Residuals: -0.003\n",
      "Loss: 3.048, Residuals: -0.008\n",
      "Loss: 3.046, Residuals: -0.006\n",
      "Loss: 3.024, Residuals: -0.014\n",
      "Loss: 2.994, Residuals: -0.031\n",
      "Loss: 2.993, Residuals: -0.030\n",
      "Loss: 2.991, Residuals: -0.030\n",
      "Loss: 2.988, Residuals: -0.031\n",
      "Loss: 2.982, Residuals: -0.033\n",
      "Loss: 2.981, Residuals: -0.032\n",
      "Loss: 2.972, Residuals: -0.036\n",
      "Loss: 2.969, Residuals: -0.033\n",
      "Loss: 2.963, Residuals: -0.036\n",
      "Loss: 2.962, Residuals: -0.035\n",
      "Loss: 2.958, Residuals: -0.037\n",
      "Loss: 2.949, Residuals: -0.041\n",
      "Loss: 2.945, Residuals: -0.038\n",
      "Loss: 2.944, Residuals: -0.034\n",
      "Loss: 2.940, Residuals: -0.037\n",
      "Loss: 2.931, Residuals: -0.041\n",
      "Loss: 2.927, Residuals: -0.040\n",
      "Loss: 2.926, Residuals: -0.037\n",
      "Loss: 2.920, Residuals: -0.041\n",
      "Loss: 2.915, Residuals: -0.043\n",
      "Loss: 2.915, Residuals: -0.043\n",
      "Loss: 2.915, Residuals: -0.042\n",
      "Loss: 2.914, Residuals: -0.042\n",
      "Loss: 2.910, Residuals: -0.044\n",
      "Loss: 2.910, Residuals: -0.044\n",
      "Loss: 2.908, Residuals: -0.045\n",
      "Loss: 2.904, Residuals: -0.048\n",
      "Loss: 2.904, Residuals: -0.048\n",
      "Loss: 2.902, Residuals: -0.049\n",
      "Loss: 2.901, Residuals: -0.047\n",
      "Loss: 2.899, Residuals: -0.048\n",
      "Loss: 2.889, Residuals: -0.057\n",
      "Loss: 2.887, Residuals: -0.057\n",
      "Loss: 2.884, Residuals: -0.054\n",
      "Loss: 2.878, Residuals: -0.051\n",
      "Loss: 2.872, Residuals: -0.046\n",
      "Loss: 2.872, Residuals: -0.046\n",
      "Loss: 2.869, Residuals: -0.041\n",
      "Loss: 2.864, Residuals: -0.041\n",
      "Loss: 2.864, Residuals: -0.041\n",
      "Evidence -382.283\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 3.77e-03\n",
      "Loss: 11.462, Residuals: -0.040\n",
      "Loss: 11.455, Residuals: -0.040\n",
      "Loss: 11.396, Residuals: -0.037\n",
      "Loss: 11.347, Residuals: -0.024\n",
      "Loss: 11.332, Residuals: -0.023\n",
      "Loss: 11.303, Residuals: -0.021\n",
      "Loss: 11.286, Residuals: -0.018\n",
      "Loss: 11.278, Residuals: -0.021\n",
      "Loss: 11.278, Residuals: -0.021\n",
      "Evidence 77.661\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 3.00e-02\n",
      "Loss: 35.594, Residuals: -0.007\n",
      "Loss: 35.565, Residuals: -0.007\n",
      "Loss: 35.510, Residuals: -0.007\n",
      "Loss: 35.047, Residuals: 0.004\n",
      "Loss: 35.039, Residuals: 0.002\n",
      "Loss: 34.969, Residuals: 0.002\n",
      "Loss: 34.838, Residuals: 0.005\n",
      "Loss: 34.757, Residuals: 0.006\n",
      "Loss: 34.744, Residuals: 0.008\n",
      "Loss: 34.631, Residuals: 0.009\n",
      "Loss: 34.440, Residuals: 0.013\n",
      "Loss: 34.412, Residuals: 0.013\n",
      "Loss: 34.363, Residuals: 0.014\n",
      "Loss: 34.361, Residuals: 0.014\n",
      "Loss: 34.264, Residuals: 0.016\n",
      "Loss: 34.258, Residuals: 0.016\n",
      "Loss: 34.210, Residuals: 0.018\n",
      "Loss: 34.179, Residuals: 0.019\n",
      "Loss: 34.177, Residuals: 0.019\n",
      "Loss: 34.159, Residuals: 0.019\n",
      "Loss: 34.158, Residuals: 0.019\n",
      "Loss: 34.116, Residuals: 0.020\n",
      "Loss: 34.111, Residuals: 0.020\n",
      "Loss: 34.103, Residuals: 0.020\n",
      "Loss: 34.100, Residuals: 0.021\n",
      "Loss: 34.075, Residuals: 0.022\n",
      "Loss: 34.075, Residuals: 0.023\n",
      "Loss: 34.067, Residuals: 0.023\n",
      "Loss: 34.055, Residuals: 0.024\n",
      "Loss: 34.053, Residuals: 0.023\n",
      "Loss: 34.051, Residuals: 0.023\n",
      "Loss: 34.047, Residuals: 0.023\n",
      "Loss: 34.041, Residuals: 0.024\n",
      "Loss: 34.041, Residuals: 0.023\n",
      "Loss: 34.040, Residuals: 0.023\n",
      "Loss: 34.039, Residuals: 0.023\n",
      "Loss: 34.036, Residuals: 0.023\n",
      "Loss: 34.036, Residuals: 0.023\n",
      "Loss: 34.034, Residuals: 0.023\n",
      "Loss: 34.034, Residuals: 0.023\n",
      "Loss: 34.033, Residuals: 0.023\n",
      "Loss: 34.031, Residuals: 0.024\n",
      "Loss: 34.030, Residuals: 0.023\n",
      "Loss: 34.029, Residuals: 0.023\n",
      "Loss: 34.029, Residuals: 0.023\n",
      "Loss: 34.029, Residuals: 0.023\n",
      "Loss: 34.028, Residuals: 0.023\n",
      "Loss: 34.027, Residuals: 0.023\n",
      "Loss: 34.027, Residuals: 0.023\n",
      "Loss: 34.026, Residuals: 0.023\n",
      "Loss: 34.026, Residuals: 0.024\n",
      "Loss: 34.026, Residuals: 0.023\n",
      "Loss: 34.026, Residuals: 0.023\n",
      "Loss: 34.025, Residuals: 0.023\n",
      "Loss: 34.025, Residuals: 0.023\n",
      "Loss: 34.025, Residuals: 0.023\n",
      "Loss: 34.024, Residuals: 0.023\n",
      "Loss: 34.024, Residuals: 0.023\n",
      "Loss: 34.024, Residuals: 0.023\n",
      "Loss: 34.024, Residuals: 0.023\n",
      "Evidence 251.982\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 3.91e-01\n",
      "Loss: 72.835, Residuals: 0.024\n",
      "Loss: 72.284, Residuals: 0.027\n",
      "Loss: 72.268, Residuals: 0.027\n",
      "Loss: 72.238, Residuals: 0.026\n",
      "Loss: 72.187, Residuals: 0.025\n",
      "Loss: 72.091, Residuals: 0.025\n",
      "Loss: 72.005, Residuals: 0.023\n",
      "Loss: 71.886, Residuals: 0.025\n",
      "Loss: 71.873, Residuals: 0.027\n",
      "Loss: 71.778, Residuals: 0.029\n",
      "Loss: 71.771, Residuals: 0.030\n",
      "Loss: 71.718, Residuals: 0.031\n",
      "Loss: 71.717, Residuals: 0.030\n",
      "Loss: 71.709, Residuals: 0.030\n",
      "Loss: 71.696, Residuals: 0.031\n",
      "Loss: 71.684, Residuals: 0.031\n",
      "Loss: 71.683, Residuals: 0.031\n",
      "Loss: 71.680, Residuals: 0.031\n",
      "Loss: 71.679, Residuals: 0.031\n",
      "Loss: 71.677, Residuals: 0.031\n",
      "Loss: 71.677, Residuals: 0.031\n",
      "Loss: 71.676, Residuals: 0.031\n",
      "Loss: 71.674, Residuals: 0.031\n",
      "Loss: 71.672, Residuals: 0.031\n",
      "Loss: 71.672, Residuals: 0.031\n",
      "Loss: 71.672, Residuals: 0.031\n",
      "Loss: 71.672, Residuals: 0.031\n",
      "Loss: 71.671, Residuals: 0.031\n",
      "Loss: 71.671, Residuals: 0.031\n",
      "Loss: 71.671, Residuals: 0.031\n",
      "Loss: 71.671, Residuals: 0.031\n",
      "Loss: 71.671, Residuals: 0.031\n",
      "Evidence 371.488\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.01e+00\n",
      "Loss: 110.946, Residuals: 0.029\n",
      "Loss: 110.393, Residuals: 0.023\n",
      "Loss: 110.072, Residuals: 0.030\n",
      "Loss: 110.002, Residuals: 0.027\n",
      "Loss: 109.920, Residuals: 0.028\n",
      "Loss: 109.801, Residuals: 0.028\n",
      "Loss: 109.801, Residuals: 0.028\n",
      "Evidence 418.171\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.38e+00\n",
      "Loss: 132.182, Residuals: 0.032\n",
      "Loss: 131.869, Residuals: 0.030\n",
      "Loss: 131.602, Residuals: 0.026\n",
      "Loss: 131.237, Residuals: 0.024\n",
      "Loss: 131.220, Residuals: 0.025\n",
      "Loss: 131.188, Residuals: 0.024\n",
      "Loss: 131.135, Residuals: 0.024\n",
      "Loss: 131.135, Residuals: 0.024\n",
      "Loss: 131.108, Residuals: 0.024\n",
      "Loss: 131.102, Residuals: 0.023\n",
      "Loss: 131.092, Residuals: 0.023\n",
      "Loss: 131.078, Residuals: 0.023\n",
      "Loss: 131.078, Residuals: 0.023\n",
      "Loss: 131.078, Residuals: 0.023\n",
      "Loss: 131.075, Residuals: 0.023\n",
      "Loss: 131.075, Residuals: 0.023\n",
      "Loss: 131.074, Residuals: 0.023\n",
      "Loss: 131.073, Residuals: 0.023\n",
      "Loss: 131.073, Residuals: 0.023\n",
      "Loss: 131.073, Residuals: 0.023\n",
      "Loss: 131.073, Residuals: 0.023\n",
      "Loss: 131.072, Residuals: 0.023\n",
      "Loss: 131.072, Residuals: 0.023\n",
      "Loss: 131.072, Residuals: 0.023\n",
      "Loss: 131.072, Residuals: 0.023\n",
      "Loss: 131.072, Residuals: 0.023\n",
      "Loss: 131.072, Residuals: 0.023\n",
      "Evidence 431.637\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.37e+00\n",
      "Loss: 140.017, Residuals: 0.023\n",
      "Loss: 139.913, Residuals: 0.023\n",
      "Loss: 139.745, Residuals: 0.024\n",
      "Loss: 139.591, Residuals: 0.022\n",
      "Loss: 139.521, Residuals: 0.021\n",
      "Loss: 139.496, Residuals: 0.020\n",
      "Loss: 139.482, Residuals: 0.021\n",
      "Loss: 139.457, Residuals: 0.020\n",
      "Loss: 139.419, Residuals: 0.021\n",
      "Loss: 139.419, Residuals: 0.021\n",
      "Evidence 436.191\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.36e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 142.895, Residuals: 0.021\n",
      "Loss: 142.853, Residuals: 0.021\n",
      "Loss: 142.781, Residuals: 0.021\n",
      "Loss: 142.688, Residuals: 0.021\n",
      "Loss: 142.637, Residuals: 0.020\n",
      "Loss: 142.625, Residuals: 0.020\n",
      "Loss: 142.604, Residuals: 0.019\n",
      "Loss: 142.603, Residuals: 0.020\n",
      "Loss: 142.586, Residuals: 0.020\n",
      "Loss: 142.562, Residuals: 0.019\n",
      "Loss: 142.562, Residuals: 0.019\n",
      "Evidence 438.258\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.30e+00\n",
      "Loss: 144.025, Residuals: 0.019\n",
      "Loss: 143.963, Residuals: 0.019\n",
      "Loss: 143.908, Residuals: 0.020\n",
      "Loss: 143.886, Residuals: 0.018\n",
      "Loss: 143.870, Residuals: 0.018\n",
      "Loss: 143.870, Residuals: 0.018\n",
      "Evidence 439.415\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.30e+00\n",
      "Loss: 144.522, Residuals: 0.019\n",
      "Loss: 144.508, Residuals: 0.018\n",
      "Loss: 144.493, Residuals: 0.018\n",
      "Loss: 144.484, Residuals: 0.018\n",
      "Loss: 144.483, Residuals: 0.018\n",
      "Loss: 144.475, Residuals: 0.018\n",
      "Loss: 144.475, Residuals: 0.018\n",
      "Loss: 144.472, Residuals: 0.018\n",
      "Loss: 144.471, Residuals: 0.018\n",
      "Loss: 144.471, Residuals: 0.018\n",
      "Loss: 144.469, Residuals: 0.018\n",
      "Evidence 440.068\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.27e+00\n",
      "Loss: 144.911, Residuals: 0.018\n",
      "Evidence 440.347\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.255, Residuals: -0.071\n",
      "Loss: 7.787, Residuals: -0.064\n",
      "Loss: 5.565, Residuals: -0.051\n",
      "Loss: 5.049, Residuals: 0.071\n",
      "Loss: 4.999, Residuals: 0.082\n",
      "Loss: 4.582, Residuals: 0.039\n",
      "Loss: 4.542, Residuals: 0.033\n",
      "Loss: 4.229, Residuals: 0.001\n",
      "Loss: 4.216, Residuals: 0.012\n",
      "Loss: 4.091, Residuals: 0.004\n",
      "Loss: 3.900, Residuals: -0.014\n",
      "Loss: 3.714, Residuals: -0.042\n",
      "Loss: 3.689, Residuals: -0.038\n",
      "Loss: 3.658, Residuals: -0.031\n",
      "Loss: 3.604, Residuals: -0.029\n",
      "Loss: 3.600, Residuals: -0.020\n",
      "Loss: 3.486, Residuals: -0.016\n",
      "Loss: 3.476, Residuals: -0.022\n",
      "Loss: 3.471, Residuals: -0.018\n",
      "Loss: 3.463, Residuals: -0.022\n",
      "Loss: 3.448, Residuals: -0.025\n",
      "Loss: 3.422, Residuals: -0.032\n",
      "Loss: 3.421, Residuals: -0.030\n",
      "Loss: 3.420, Residuals: -0.031\n",
      "Loss: 3.403, Residuals: -0.035\n",
      "Loss: 3.399, Residuals: -0.038\n",
      "Loss: 3.391, Residuals: -0.039\n",
      "Loss: 3.390, Residuals: -0.039\n",
      "Loss: 3.361, Residuals: -0.047\n",
      "Loss: 3.361, Residuals: -0.047\n",
      "Loss: 3.360, Residuals: -0.045\n",
      "Loss: 3.354, Residuals: -0.046\n",
      "Loss: 3.353, Residuals: -0.047\n",
      "Loss: 3.349, Residuals: -0.047\n",
      "Loss: 3.349, Residuals: -0.047\n",
      "Evidence -400.383\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.91e-02\n",
      "Loss: 14.386, Residuals: -0.048\n",
      "Loss: 14.208, Residuals: -0.042\n",
      "Loss: 13.934, Residuals: -0.026\n",
      "Loss: 13.816, Residuals: 0.005\n",
      "Loss: 13.808, Residuals: 0.004\n",
      "Loss: 13.805, Residuals: 0.002\n",
      "Loss: 13.801, Residuals: 0.003\n",
      "Loss: 13.764, Residuals: 0.003\n",
      "Loss: 13.701, Residuals: 0.006\n",
      "Loss: 13.701, Residuals: 0.005\n",
      "Loss: 13.631, Residuals: 0.014\n",
      "Loss: 13.630, Residuals: 0.014\n",
      "Loss: 13.628, Residuals: 0.012\n",
      "Loss: 13.627, Residuals: 0.013\n",
      "Loss: 13.610, Residuals: 0.014\n",
      "Loss: 13.581, Residuals: 0.016\n",
      "Loss: 13.581, Residuals: 0.016\n",
      "Loss: 13.580, Residuals: 0.016\n",
      "Loss: 13.577, Residuals: 0.017\n",
      "Loss: 13.554, Residuals: 0.016\n",
      "Loss: 13.549, Residuals: 0.019\n",
      "Loss: 13.548, Residuals: 0.018\n",
      "Loss: 13.548, Residuals: 0.019\n",
      "Loss: 13.529, Residuals: 0.018\n",
      "Loss: 13.529, Residuals: 0.017\n",
      "Evidence 108.024\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.25e-01\n",
      "Loss: 42.521, Residuals: 0.017\n",
      "Loss: 42.474, Residuals: 0.017\n",
      "Loss: 42.394, Residuals: 0.017\n",
      "Loss: 42.287, Residuals: 0.019\n",
      "Loss: 42.158, Residuals: 0.024\n",
      "Loss: 42.134, Residuals: 0.022\n",
      "Loss: 42.126, Residuals: 0.021\n",
      "Loss: 42.066, Residuals: 0.023\n",
      "Loss: 42.066, Residuals: 0.023\n",
      "Loss: 42.066, Residuals: 0.023\n",
      "Loss: 42.065, Residuals: 0.023\n",
      "Loss: 42.059, Residuals: 0.023\n",
      "Loss: 42.057, Residuals: 0.024\n",
      "Loss: 41.997, Residuals: 0.024\n",
      "Loss: 41.997, Residuals: 0.024\n",
      "Evidence 306.862\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.06e-01\n",
      "Loss: 87.962, Residuals: 0.024\n",
      "Loss: 87.842, Residuals: 0.023\n",
      "Loss: 87.643, Residuals: 0.021\n",
      "Loss: 87.442, Residuals: 0.018\n",
      "Loss: 87.146, Residuals: 0.020\n",
      "Loss: 87.119, Residuals: 0.020\n",
      "Loss: 86.871, Residuals: 0.022\n",
      "Loss: 86.867, Residuals: 0.021\n",
      "Loss: 86.411, Residuals: 0.029\n",
      "Loss: 86.270, Residuals: 0.027\n",
      "Loss: 86.211, Residuals: 0.025\n",
      "Loss: 86.103, Residuals: 0.026\n",
      "Loss: 86.082, Residuals: 0.026\n",
      "Loss: 85.906, Residuals: 0.030\n",
      "Loss: 85.903, Residuals: 0.030\n",
      "Loss: 85.873, Residuals: 0.031\n",
      "Loss: 85.820, Residuals: 0.031\n",
      "Loss: 85.813, Residuals: 0.031\n",
      "Loss: 85.799, Residuals: 0.032\n",
      "Loss: 85.776, Residuals: 0.032\n",
      "Loss: 85.776, Residuals: 0.032\n",
      "Loss: 85.769, Residuals: 0.032\n",
      "Loss: 85.761, Residuals: 0.033\n",
      "Loss: 85.761, Residuals: 0.033\n",
      "Loss: 85.761, Residuals: 0.033\n",
      "Loss: 85.760, Residuals: 0.033\n",
      "Loss: 85.760, Residuals: 0.033\n",
      "Loss: 85.760, Residuals: 0.033\n",
      "Loss: 85.759, Residuals: 0.033\n",
      "Loss: 85.759, Residuals: 0.033\n",
      "Loss: 85.759, Residuals: 0.033\n",
      "Loss: 85.759, Residuals: 0.033\n",
      "Loss: 85.758, Residuals: 0.033\n",
      "Loss: 85.758, Residuals: 0.033\n",
      "Evidence 420.877\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.65e-01\n",
      "Loss: 126.370, Residuals: 0.043\n",
      "Loss: 126.003, Residuals: 0.040\n",
      "Loss: 125.755, Residuals: 0.033\n",
      "Loss: 125.500, Residuals: 0.034\n",
      "Loss: 125.450, Residuals: 0.033\n",
      "Loss: 125.449, Residuals: 0.033\n",
      "Loss: 125.389, Residuals: 0.033\n",
      "Loss: 125.285, Residuals: 0.033\n",
      "Loss: 125.155, Residuals: 0.034\n",
      "Loss: 125.153, Residuals: 0.034\n",
      "Loss: 125.149, Residuals: 0.034\n",
      "Loss: 125.142, Residuals: 0.034\n",
      "Loss: 125.131, Residuals: 0.034\n",
      "Loss: 125.131, Residuals: 0.034\n",
      "Loss: 125.124, Residuals: 0.034\n",
      "Loss: 125.115, Residuals: 0.034\n",
      "Loss: 125.115, Residuals: 0.034\n",
      "Loss: 125.114, Residuals: 0.034\n",
      "Loss: 125.114, Residuals: 0.033\n",
      "Loss: 125.113, Residuals: 0.033\n",
      "Loss: 125.113, Residuals: 0.033\n",
      "Loss: 125.113, Residuals: 0.033\n",
      "Loss: 125.112, Residuals: 0.033\n",
      "Loss: 125.111, Residuals: 0.033\n",
      "Loss: 125.111, Residuals: 0.033\n",
      "Evidence 463.467\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.03e-01\n",
      "Loss: 145.552, Residuals: 0.041\n",
      "Loss: 145.369, Residuals: 0.034\n",
      "Loss: 145.233, Residuals: 0.034\n",
      "Loss: 145.098, Residuals: 0.032\n",
      "Loss: 145.070, Residuals: 0.032\n",
      "Loss: 145.060, Residuals: 0.031\n",
      "Loss: 145.041, Residuals: 0.031\n",
      "Loss: 145.013, Residuals: 0.031\n",
      "Loss: 145.012, Residuals: 0.031\n",
      "Loss: 145.003, Residuals: 0.031\n",
      "Loss: 145.003, Residuals: 0.031\n",
      "Loss: 145.001, Residuals: 0.031\n",
      "Loss: 144.998, Residuals: 0.031\n",
      "Loss: 144.998, Residuals: 0.031\n",
      "Evidence 474.383\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.35e-01\n",
      "Loss: 152.086, Residuals: 0.033\n",
      "Loss: 151.972, Residuals: 0.029\n",
      "Loss: 151.870, Residuals: 0.029\n",
      "Loss: 151.847, Residuals: 0.030\n",
      "Loss: 151.828, Residuals: 0.029\n",
      "Loss: 151.820, Residuals: 0.029\n",
      "Loss: 151.817, Residuals: 0.029\n",
      "Loss: 151.815, Residuals: 0.029\n",
      "Loss: 151.811, Residuals: 0.029\n",
      "Loss: 151.804, Residuals: 0.029\n",
      "Loss: 151.804, Residuals: 0.029\n",
      "Loss: 151.802, Residuals: 0.029\n",
      "Loss: 151.800, Residuals: 0.029\n",
      "Loss: 151.800, Residuals: 0.029\n",
      "Loss: 151.799, Residuals: 0.029\n",
      "Loss: 151.799, Residuals: 0.029\n",
      "Loss: 151.799, Residuals: 0.029\n",
      "Loss: 151.799, Residuals: 0.029\n",
      "Loss: 151.799, Residuals: 0.029\n",
      "Loss: 151.798, Residuals: 0.029\n",
      "Evidence 478.386\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.40e-01\n",
      "Loss: 154.209, Residuals: 0.031\n",
      "Loss: 154.136, Residuals: 0.028\n",
      "Loss: 154.078, Residuals: 0.028\n",
      "Loss: 154.067, Residuals: 0.027\n",
      "Loss: 154.064, Residuals: 0.028\n",
      "Loss: 154.059, Residuals: 0.028\n",
      "Loss: 154.050, Residuals: 0.028\n",
      "Loss: 154.050, Residuals: 0.027\n",
      "Loss: 154.047, Residuals: 0.027\n",
      "Loss: 154.044, Residuals: 0.027\n",
      "Loss: 154.044, Residuals: 0.027\n",
      "Loss: 154.044, Residuals: 0.027\n",
      "Loss: 154.044, Residuals: 0.027\n",
      "Loss: 154.044, Residuals: 0.027\n",
      "Loss: 154.043, Residuals: 0.027\n",
      "Loss: 154.043, Residuals: 0.027\n",
      "Loss: 154.043, Residuals: 0.027\n",
      "Evidence 480.675\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.40e-01\n",
      "Loss: 155.027, Residuals: 0.027\n",
      "Loss: 155.000, Residuals: 0.026\n",
      "Loss: 154.991, Residuals: 0.027\n",
      "Loss: 154.975, Residuals: 0.027\n",
      "Loss: 154.955, Residuals: 0.027\n",
      "Loss: 154.952, Residuals: 0.026\n",
      "Loss: 154.948, Residuals: 0.026\n",
      "Loss: 154.948, Residuals: 0.026\n",
      "Loss: 154.946, Residuals: 0.026\n",
      "Loss: 154.944, Residuals: 0.026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 154.942, Residuals: 0.026\n",
      "Loss: 154.942, Residuals: 0.026\n",
      "Evidence 482.235\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.39e-01\n",
      "Loss: 155.440, Residuals: 0.026\n",
      "Loss: 155.421, Residuals: 0.025\n",
      "Loss: 155.396, Residuals: 0.025\n",
      "Loss: 155.394, Residuals: 0.025\n",
      "Loss: 155.391, Residuals: 0.025\n",
      "Loss: 155.385, Residuals: 0.025\n",
      "Loss: 155.380, Residuals: 0.025\n",
      "Loss: 155.380, Residuals: 0.025\n",
      "Loss: 155.379, Residuals: 0.025\n",
      "Loss: 155.379, Residuals: 0.025\n",
      "Loss: 155.379, Residuals: 0.025\n",
      "Loss: 155.379, Residuals: 0.025\n",
      "Loss: 155.379, Residuals: 0.025\n",
      "Loss: 155.379, Residuals: 0.025\n",
      "Loss: 155.379, Residuals: 0.025\n",
      "Loss: 155.379, Residuals: 0.025\n",
      "Evidence 483.397\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.37e-01\n",
      "Loss: 155.675, Residuals: 0.025\n",
      "Loss: 155.661, Residuals: 0.025\n",
      "Loss: 155.643, Residuals: 0.024\n",
      "Loss: 155.641, Residuals: 0.024\n",
      "Loss: 155.638, Residuals: 0.024\n",
      "Loss: 155.633, Residuals: 0.024\n",
      "Loss: 155.633, Residuals: 0.024\n",
      "Loss: 155.631, Residuals: 0.024\n",
      "Loss: 155.630, Residuals: 0.024\n",
      "Loss: 155.630, Residuals: 0.024\n",
      "Loss: 155.630, Residuals: 0.024\n",
      "Loss: 155.630, Residuals: 0.024\n",
      "Evidence 484.312\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.32e-01\n",
      "Loss: 155.820, Residuals: 0.025\n",
      "Loss: 155.810, Residuals: 0.024\n",
      "Loss: 155.797, Residuals: 0.023\n",
      "Loss: 155.795, Residuals: 0.024\n",
      "Loss: 155.793, Residuals: 0.024\n",
      "Loss: 155.790, Residuals: 0.023\n",
      "Loss: 155.790, Residuals: 0.023\n",
      "Loss: 155.788, Residuals: 0.023\n",
      "Loss: 155.788, Residuals: 0.023\n",
      "Loss: 155.788, Residuals: 0.023\n",
      "Loss: 155.788, Residuals: 0.023\n",
      "Loss: 155.788, Residuals: 0.023\n",
      "Evidence 485.031\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.25e-01\n",
      "Loss: 155.933, Residuals: 0.024\n",
      "Loss: 155.926, Residuals: 0.023\n",
      "Loss: 155.916, Residuals: 0.023\n",
      "Loss: 155.915, Residuals: 0.023\n",
      "Loss: 155.914, Residuals: 0.023\n",
      "Loss: 155.911, Residuals: 0.023\n",
      "Loss: 155.911, Residuals: 0.023\n",
      "Loss: 155.911, Residuals: 0.023\n",
      "Loss: 155.910, Residuals: 0.023\n",
      "Evidence 485.605\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.21e-01\n",
      "Loss: 156.033, Residuals: 0.024\n",
      "Loss: 156.027, Residuals: 0.022\n",
      "Loss: 156.025, Residuals: 0.023\n",
      "Loss: 156.021, Residuals: 0.023\n",
      "Loss: 156.017, Residuals: 0.022\n",
      "Loss: 156.017, Residuals: 0.022\n",
      "Loss: 156.016, Residuals: 0.022\n",
      "Loss: 156.015, Residuals: 0.022\n",
      "Loss: 156.015, Residuals: 0.022\n",
      "Evidence 486.051\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.901, Residuals: -0.028\n",
      "Loss: 7.425, Residuals: -0.053\n",
      "Loss: 6.264, Residuals: -0.047\n",
      "Loss: 5.227, Residuals: -0.053\n",
      "Loss: 4.771, Residuals: 0.070\n",
      "Loss: 4.672, Residuals: 0.041\n",
      "Loss: 4.487, Residuals: 0.024\n",
      "Loss: 4.179, Residuals: 0.005\n",
      "Loss: 4.162, Residuals: 0.033\n",
      "Loss: 4.011, Residuals: 0.019\n",
      "Loss: 3.902, Residuals: 0.004\n",
      "Loss: 3.720, Residuals: -0.008\n",
      "Loss: 3.621, Residuals: 0.015\n",
      "Loss: 3.599, Residuals: 0.016\n",
      "Loss: 3.556, Residuals: 0.012\n",
      "Loss: 3.480, Residuals: 0.006\n",
      "Loss: 3.475, Residuals: 0.016\n",
      "Loss: 3.430, Residuals: 0.010\n",
      "Loss: 3.347, Residuals: 0.006\n",
      "Loss: 3.338, Residuals: 0.015\n",
      "Loss: 3.253, Residuals: 0.005\n",
      "Loss: 3.232, Residuals: 0.010\n",
      "Loss: 3.066, Residuals: -0.017\n",
      "Loss: 3.061, Residuals: -0.014\n",
      "Loss: 3.029, Residuals: -0.006\n",
      "Loss: 3.025, Residuals: -0.007\n",
      "Loss: 2.987, Residuals: -0.014\n",
      "Loss: 2.920, Residuals: -0.024\n",
      "Loss: 2.917, Residuals: -0.019\n",
      "Loss: 2.885, Residuals: -0.025\n",
      "Loss: 2.880, Residuals: -0.025\n",
      "Loss: 2.834, Residuals: -0.038\n",
      "Loss: 2.833, Residuals: -0.039\n",
      "Loss: 2.832, Residuals: -0.039\n",
      "Loss: 2.820, Residuals: -0.037\n",
      "Loss: 2.818, Residuals: -0.038\n",
      "Loss: 2.801, Residuals: -0.044\n",
      "Loss: 2.801, Residuals: -0.044\n",
      "Loss: 2.788, Residuals: -0.048\n",
      "Loss: 2.788, Residuals: -0.044\n",
      "Loss: 2.774, Residuals: -0.049\n",
      "Loss: 2.774, Residuals: -0.049\n",
      "Loss: 2.752, Residuals: -0.057\n",
      "Loss: 2.752, Residuals: -0.058\n",
      "Loss: 2.751, Residuals: -0.057\n",
      "Loss: 2.751, Residuals: -0.055\n",
      "Loss: 2.742, Residuals: -0.058\n",
      "Loss: 2.736, Residuals: -0.057\n",
      "Loss: 2.736, Residuals: -0.058\n",
      "Loss: 2.735, Residuals: -0.057\n",
      "Loss: 2.734, Residuals: -0.056\n",
      "Loss: 2.734, Residuals: -0.057\n",
      "Evidence -396.655\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.48e-03\n",
      "Loss: 12.619, Residuals: -0.044\n",
      "Loss: 12.583, Residuals: -0.044\n",
      "Loss: 12.517, Residuals: -0.038\n",
      "Loss: 12.410, Residuals: -0.029\n",
      "Loss: 12.288, Residuals: -0.016\n",
      "Loss: 12.285, Residuals: -0.017\n",
      "Loss: 12.251, Residuals: -0.015\n",
      "Loss: 12.192, Residuals: -0.010\n",
      "Loss: 12.110, Residuals: 0.000\n",
      "Loss: 12.108, Residuals: -0.001\n",
      "Loss: 12.087, Residuals: -0.000\n",
      "Loss: 12.050, Residuals: 0.002\n",
      "Loss: 12.045, Residuals: 0.003\n",
      "Loss: 12.004, Residuals: 0.005\n",
      "Loss: 12.004, Residuals: 0.004\n",
      "Loss: 12.004, Residuals: 0.004\n",
      "Loss: 11.986, Residuals: 0.004\n",
      "Loss: 11.978, Residuals: 0.007\n",
      "Loss: 11.962, Residuals: 0.007\n",
      "Loss: 11.961, Residuals: 0.006\n",
      "Loss: 11.951, Residuals: 0.006\n",
      "Loss: 11.934, Residuals: 0.006\n",
      "Loss: 11.933, Residuals: 0.007\n",
      "Loss: 11.908, Residuals: 0.006\n",
      "Loss: 11.907, Residuals: 0.007\n",
      "Loss: 11.905, Residuals: 0.007\n",
      "Loss: 11.901, Residuals: 0.006\n",
      "Loss: 11.897, Residuals: 0.006\n",
      "Loss: 11.897, Residuals: 0.007\n",
      "Loss: 11.887, Residuals: 0.006\n",
      "Loss: 11.887, Residuals: 0.006\n",
      "Loss: 11.884, Residuals: 0.006\n",
      "Loss: 11.881, Residuals: 0.006\n",
      "Loss: 11.880, Residuals: 0.006\n",
      "Loss: 11.869, Residuals: 0.005\n",
      "Loss: 11.868, Residuals: 0.004\n",
      "Loss: 11.868, Residuals: 0.006\n",
      "Loss: 11.866, Residuals: 0.005\n",
      "Loss: 11.857, Residuals: 0.004\n",
      "Loss: 11.856, Residuals: 0.005\n",
      "Loss: 11.855, Residuals: 0.005\n",
      "Loss: 11.853, Residuals: 0.004\n",
      "Loss: 11.851, Residuals: 0.004\n",
      "Loss: 11.851, Residuals: 0.004\n",
      "Loss: 11.837, Residuals: 0.004\n",
      "Loss: 11.836, Residuals: 0.003\n",
      "Loss: 11.835, Residuals: 0.003\n",
      "Loss: 11.833, Residuals: 0.003\n",
      "Loss: 11.815, Residuals: 0.003\n",
      "Loss: 11.814, Residuals: 0.004\n",
      "Loss: 11.814, Residuals: 0.003\n",
      "Loss: 11.813, Residuals: 0.003\n",
      "Loss: 11.807, Residuals: 0.003\n",
      "Loss: 11.805, Residuals: 0.004\n",
      "Loss: 11.804, Residuals: 0.004\n",
      "Loss: 11.798, Residuals: 0.004\n",
      "Loss: 11.798, Residuals: 0.004\n",
      "Loss: 11.786, Residuals: 0.004\n",
      "Loss: 11.785, Residuals: 0.004\n",
      "Loss: 11.785, Residuals: 0.004\n",
      "Loss: 11.780, Residuals: 0.004\n",
      "Loss: 11.779, Residuals: 0.004\n",
      "Loss: 11.765, Residuals: 0.005\n",
      "Loss: 11.765, Residuals: 0.005\n",
      "Loss: 11.762, Residuals: 0.005\n",
      "Loss: 11.757, Residuals: 0.005\n",
      "Loss: 11.749, Residuals: 0.005\n",
      "Loss: 11.748, Residuals: 0.006\n",
      "Loss: 11.735, Residuals: 0.007\n",
      "Loss: 11.734, Residuals: 0.006\n",
      "Loss: 11.724, Residuals: 0.008\n",
      "Loss: 11.720, Residuals: 0.008\n",
      "Loss: 11.720, Residuals: 0.008\n",
      "Loss: 11.714, Residuals: 0.009\n",
      "Loss: 11.705, Residuals: 0.011\n",
      "Loss: 11.705, Residuals: 0.011\n",
      "Loss: 11.704, Residuals: 0.011\n",
      "Loss: 11.703, Residuals: 0.011\n",
      "Loss: 11.703, Residuals: 0.011\n",
      "Loss: 11.701, Residuals: 0.011\n",
      "Loss: 11.697, Residuals: 0.012\n",
      "Loss: 11.697, Residuals: 0.013\n",
      "Loss: 11.696, Residuals: 0.013\n",
      "Loss: 11.694, Residuals: 0.014\n",
      "Loss: 11.693, Residuals: 0.014\n",
      "Loss: 11.693, Residuals: 0.014\n",
      "Loss: 11.692, Residuals: 0.014\n",
      "Loss: 11.692, Residuals: 0.014\n",
      "Loss: 11.692, Residuals: 0.014\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.691, Residuals: 0.015\n",
      "Loss: 11.690, Residuals: 0.015\n",
      "Loss: 11.690, Residuals: 0.015\n",
      "Loss: 11.690, Residuals: 0.015\n",
      "Loss: 11.690, Residuals: 0.015\n",
      "Loss: 11.690, Residuals: 0.015\n",
      "Evidence 105.536\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 5.93e-02\n",
      "Loss: 39.476, Residuals: 0.021\n",
      "Loss: 39.277, Residuals: 0.021\n",
      "Loss: 39.175, Residuals: 0.024\n",
      "Loss: 39.136, Residuals: 0.021\n",
      "Loss: 39.065, Residuals: 0.023\n",
      "Loss: 38.949, Residuals: 0.025\n",
      "Loss: 38.825, Residuals: 0.031\n",
      "Loss: 38.818, Residuals: 0.036\n",
      "Loss: 38.809, Residuals: 0.033\n",
      "Loss: 38.795, Residuals: 0.034\n",
      "Loss: 38.776, Residuals: 0.035\n",
      "Loss: 38.775, Residuals: 0.034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 38.774, Residuals: 0.034\n",
      "Loss: 38.774, Residuals: 0.034\n",
      "Loss: 38.772, Residuals: 0.034\n",
      "Loss: 38.768, Residuals: 0.035\n",
      "Loss: 38.768, Residuals: 0.035\n",
      "Loss: 38.766, Residuals: 0.035\n",
      "Loss: 38.763, Residuals: 0.035\n",
      "Loss: 38.760, Residuals: 0.035\n",
      "Loss: 38.760, Residuals: 0.035\n",
      "Loss: 38.760, Residuals: 0.035\n",
      "Loss: 38.758, Residuals: 0.035\n",
      "Loss: 38.758, Residuals: 0.035\n",
      "Loss: 38.757, Residuals: 0.034\n",
      "Loss: 38.756, Residuals: 0.035\n",
      "Loss: 38.756, Residuals: 0.035\n",
      "Loss: 38.756, Residuals: 0.035\n",
      "Loss: 38.755, Residuals: 0.035\n",
      "Loss: 38.755, Residuals: 0.035\n",
      "Loss: 38.755, Residuals: 0.035\n",
      "Loss: 38.755, Residuals: 0.035\n",
      "Loss: 38.754, Residuals: 0.035\n",
      "Loss: 38.754, Residuals: 0.035\n",
      "Loss: 38.754, Residuals: 0.035\n",
      "Loss: 38.754, Residuals: 0.035\n",
      "Loss: 38.754, Residuals: 0.035\n",
      "Loss: 38.754, Residuals: 0.034\n",
      "Loss: 38.754, Residuals: 0.034\n",
      "Evidence 307.878\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.27e-01\n",
      "Loss: 84.914, Residuals: 0.032\n",
      "Loss: 84.758, Residuals: 0.031\n",
      "Loss: 84.544, Residuals: 0.027\n",
      "Loss: 84.282, Residuals: 0.029\n",
      "Loss: 84.253, Residuals: 0.030\n",
      "Loss: 84.204, Residuals: 0.030\n",
      "Loss: 84.127, Residuals: 0.032\n",
      "Loss: 84.125, Residuals: 0.031\n",
      "Loss: 84.100, Residuals: 0.032\n",
      "Loss: 84.061, Residuals: 0.032\n",
      "Loss: 84.057, Residuals: 0.033\n",
      "Loss: 84.033, Residuals: 0.032\n",
      "Loss: 84.030, Residuals: 0.033\n",
      "Loss: 84.027, Residuals: 0.033\n",
      "Loss: 84.005, Residuals: 0.033\n",
      "Loss: 84.004, Residuals: 0.032\n",
      "Loss: 83.996, Residuals: 0.032\n",
      "Loss: 83.981, Residuals: 0.032\n",
      "Loss: 83.980, Residuals: 0.033\n",
      "Loss: 83.979, Residuals: 0.033\n",
      "Loss: 83.976, Residuals: 0.032\n",
      "Loss: 83.976, Residuals: 0.032\n",
      "Loss: 83.966, Residuals: 0.032\n",
      "Loss: 83.966, Residuals: 0.032\n",
      "Loss: 83.964, Residuals: 0.032\n",
      "Loss: 83.964, Residuals: 0.032\n",
      "Loss: 83.961, Residuals: 0.032\n",
      "Loss: 83.961, Residuals: 0.032\n",
      "Loss: 83.958, Residuals: 0.032\n",
      "Loss: 83.954, Residuals: 0.032\n",
      "Loss: 83.953, Residuals: 0.032\n",
      "Loss: 83.953, Residuals: 0.032\n",
      "Loss: 83.949, Residuals: 0.032\n",
      "Loss: 83.949, Residuals: 0.033\n",
      "Loss: 83.949, Residuals: 0.032\n",
      "Loss: 83.948, Residuals: 0.032\n",
      "Loss: 83.948, Residuals: 0.032\n",
      "Loss: 83.945, Residuals: 0.032\n",
      "Loss: 83.945, Residuals: 0.032\n",
      "Loss: 83.945, Residuals: 0.032\n",
      "Loss: 83.944, Residuals: 0.032\n",
      "Loss: 83.944, Residuals: 0.032\n",
      "Loss: 83.943, Residuals: 0.032\n",
      "Loss: 83.943, Residuals: 0.032\n",
      "Loss: 83.942, Residuals: 0.032\n",
      "Loss: 83.942, Residuals: 0.032\n",
      "Loss: 83.942, Residuals: 0.032\n",
      "Evidence 414.193\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.95e-01\n",
      "Loss: 122.782, Residuals: 0.030\n",
      "Loss: 122.475, Residuals: 0.024\n",
      "Loss: 122.396, Residuals: 0.025\n",
      "Loss: 122.341, Residuals: 0.027\n",
      "Loss: 122.247, Residuals: 0.027\n",
      "Loss: 122.124, Residuals: 0.026\n",
      "Loss: 122.111, Residuals: 0.026\n",
      "Loss: 122.087, Residuals: 0.026\n",
      "Loss: 122.041, Residuals: 0.026\n",
      "Loss: 121.960, Residuals: 0.026\n",
      "Loss: 121.932, Residuals: 0.026\n",
      "Loss: 121.927, Residuals: 0.026\n",
      "Loss: 121.925, Residuals: 0.026\n",
      "Loss: 121.923, Residuals: 0.026\n",
      "Loss: 121.842, Residuals: 0.026\n",
      "Loss: 121.839, Residuals: 0.026\n",
      "Loss: 121.812, Residuals: 0.026\n",
      "Loss: 121.800, Residuals: 0.026\n",
      "Loss: 121.799, Residuals: 0.026\n",
      "Loss: 121.769, Residuals: 0.026\n",
      "Loss: 121.768, Residuals: 0.026\n",
      "Loss: 121.730, Residuals: 0.026\n",
      "Loss: 121.729, Residuals: 0.025\n",
      "Loss: 120.711, Residuals: 0.030\n",
      "Loss: 120.211, Residuals: 0.027\n",
      "Loss: 120.101, Residuals: 0.031\n",
      "Loss: 119.909, Residuals: 0.030\n",
      "Loss: 119.667, Residuals: 0.029\n",
      "Loss: 119.651, Residuals: 0.029\n",
      "Loss: 119.623, Residuals: 0.029\n",
      "Loss: 119.583, Residuals: 0.029\n",
      "Loss: 119.581, Residuals: 0.029\n",
      "Loss: 119.565, Residuals: 0.029\n",
      "Loss: 119.534, Residuals: 0.029\n",
      "Loss: 119.498, Residuals: 0.030\n",
      "Loss: 119.496, Residuals: 0.029\n",
      "Loss: 119.494, Residuals: 0.029\n",
      "Loss: 119.470, Residuals: 0.029\n",
      "Loss: 119.465, Residuals: 0.029\n",
      "Loss: 119.465, Residuals: 0.029\n",
      "Loss: 119.445, Residuals: 0.029\n",
      "Loss: 119.444, Residuals: 0.029\n",
      "Loss: 119.431, Residuals: 0.029\n",
      "Loss: 119.428, Residuals: 0.029\n",
      "Loss: 119.427, Residuals: 0.029\n",
      "Loss: 119.427, Residuals: 0.029\n",
      "Loss: 119.417, Residuals: 0.030\n",
      "Loss: 119.414, Residuals: 0.029\n",
      "Loss: 119.414, Residuals: 0.029\n",
      "Loss: 119.408, Residuals: 0.029\n",
      "Loss: 119.407, Residuals: 0.029\n",
      "Loss: 119.407, Residuals: 0.029\n",
      "Loss: 119.399, Residuals: 0.030\n",
      "Loss: 119.398, Residuals: 0.030\n",
      "Loss: 119.398, Residuals: 0.029\n",
      "Loss: 119.398, Residuals: 0.030\n",
      "Loss: 119.393, Residuals: 0.030\n",
      "Loss: 119.392, Residuals: 0.029\n",
      "Loss: 119.392, Residuals: 0.030\n",
      "Loss: 119.392, Residuals: 0.030\n",
      "Loss: 119.388, Residuals: 0.030\n",
      "Loss: 119.383, Residuals: 0.030\n",
      "Loss: 119.381, Residuals: 0.030\n",
      "Loss: 119.381, Residuals: 0.030\n",
      "Loss: 119.381, Residuals: 0.030\n",
      "Loss: 119.379, Residuals: 0.030\n",
      "Loss: 119.378, Residuals: 0.030\n",
      "Loss: 119.378, Residuals: 0.030\n",
      "Loss: 119.376, Residuals: 0.030\n",
      "Loss: 119.375, Residuals: 0.030\n",
      "Loss: 119.375, Residuals: 0.030\n",
      "Loss: 119.374, Residuals: 0.030\n",
      "Loss: 119.373, Residuals: 0.030\n",
      "Loss: 119.373, Residuals: 0.030\n",
      "Loss: 119.372, Residuals: 0.030\n",
      "Loss: 119.372, Residuals: 0.030\n",
      "Loss: 119.372, Residuals: 0.030\n",
      "Loss: 119.372, Residuals: 0.030\n",
      "Loss: 119.371, Residuals: 0.030\n",
      "Loss: 119.371, Residuals: 0.030\n",
      "Loss: 119.371, Residuals: 0.030\n",
      "Loss: 119.371, Residuals: 0.030\n",
      "Loss: 119.370, Residuals: 0.030\n",
      "Loss: 119.370, Residuals: 0.030\n",
      "Loss: 119.370, Residuals: 0.030\n",
      "Loss: 119.370, Residuals: 0.030\n",
      "Loss: 119.369, Residuals: 0.030\n",
      "Evidence 452.614\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.84e-01\n",
      "Loss: 139.064, Residuals: 0.033\n",
      "Loss: 138.986, Residuals: 0.031\n",
      "Loss: 138.855, Residuals: 0.030\n",
      "Loss: 138.807, Residuals: 0.030\n",
      "Loss: 138.714, Residuals: 0.030\n",
      "Loss: 138.547, Residuals: 0.030\n",
      "Loss: 138.303, Residuals: 0.029\n",
      "Loss: 138.291, Residuals: 0.029\n",
      "Loss: 138.290, Residuals: 0.029\n",
      "Loss: 138.247, Residuals: 0.029\n",
      "Loss: 138.172, Residuals: 0.029\n",
      "Loss: 138.165, Residuals: 0.029\n",
      "Loss: 138.158, Residuals: 0.029\n",
      "Loss: 138.101, Residuals: 0.029\n",
      "Loss: 138.100, Residuals: 0.029\n",
      "Loss: 138.092, Residuals: 0.029\n",
      "Loss: 138.077, Residuals: 0.029\n",
      "Loss: 138.075, Residuals: 0.029\n",
      "Loss: 138.064, Residuals: 0.029\n",
      "Loss: 138.063, Residuals: 0.029\n",
      "Loss: 138.062, Residuals: 0.029\n",
      "Loss: 138.050, Residuals: 0.029\n",
      "Loss: 138.050, Residuals: 0.029\n",
      "Loss: 138.043, Residuals: 0.029\n",
      "Loss: 138.043, Residuals: 0.029\n",
      "Loss: 138.032, Residuals: 0.029\n",
      "Loss: 138.032, Residuals: 0.029\n",
      "Loss: 138.020, Residuals: 0.029\n",
      "Loss: 138.020, Residuals: 0.029\n",
      "Evidence 465.041\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.52e-01\n",
      "Loss: 145.743, Residuals: 0.032\n",
      "Loss: 145.635, Residuals: 0.030\n",
      "Loss: 145.538, Residuals: 0.030\n",
      "Loss: 145.523, Residuals: 0.030\n",
      "Loss: 145.504, Residuals: 0.030\n",
      "Loss: 145.469, Residuals: 0.030\n",
      "Loss: 145.409, Residuals: 0.030\n",
      "Loss: 145.408, Residuals: 0.030\n",
      "Loss: 145.360, Residuals: 0.030\n",
      "Loss: 145.352, Residuals: 0.030\n",
      "Loss: 145.286, Residuals: 0.030\n",
      "Loss: 145.286, Residuals: 0.030\n",
      "Evidence 468.836\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.22e-01\n",
      "Loss: 148.476, Residuals: 0.032\n",
      "Loss: 148.424, Residuals: 0.031\n",
      "Loss: 148.361, Residuals: 0.030\n",
      "Loss: 148.308, Residuals: 0.030\n",
      "Loss: 148.299, Residuals: 0.030\n",
      "Loss: 148.296, Residuals: 0.030\n",
      "Loss: 148.295, Residuals: 0.030\n",
      "Loss: 148.242, Residuals: 0.030\n",
      "Loss: 148.241, Residuals: 0.030\n",
      "Loss: 148.218, Residuals: 0.030\n",
      "Loss: 148.218, Residuals: 0.030\n",
      "Loss: 148.180, Residuals: 0.030\n",
      "Loss: 148.179, Residuals: 0.030\n",
      "Evidence 469.910\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.83e-01\n",
      "Loss: 149.699, Residuals: 0.031\n",
      "Loss: 149.663, Residuals: 0.031\n",
      "Loss: 149.620, Residuals: 0.030\n",
      "Loss: 149.617, Residuals: 0.030\n",
      "Loss: 149.587, Residuals: 0.030\n",
      "Loss: 149.586, Residuals: 0.030\n",
      "Loss: 149.519, Residuals: 0.030\n",
      "Loss: 149.519, Residuals: 0.030\n",
      "Evidence 470.269\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.306, Residuals: -0.075\n",
      "Loss: 7.579, Residuals: -0.061\n",
      "Loss: 5.012, Residuals: -0.052\n",
      "Loss: 4.258, Residuals: -0.025\n",
      "Loss: 4.136, Residuals: -0.054\n",
      "Loss: 3.905, Residuals: -0.034\n",
      "Loss: 3.548, Residuals: -0.002\n",
      "Loss: 3.514, Residuals: 0.022\n",
      "Loss: 3.247, Residuals: 0.001\n",
      "Loss: 3.086, Residuals: -0.013\n",
      "Loss: 3.059, Residuals: -0.002\n",
      "Loss: 3.008, Residuals: -0.007\n",
      "Loss: 2.917, Residuals: -0.017\n",
      "Loss: 2.867, Residuals: 0.004\n",
      "Loss: 2.866, Residuals: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.828, Residuals: -0.005\n",
      "Loss: 2.765, Residuals: -0.017\n",
      "Loss: 2.756, Residuals: -0.029\n",
      "Loss: 2.752, Residuals: -0.017\n",
      "Loss: 2.722, Residuals: -0.026\n",
      "Loss: 2.720, Residuals: -0.034\n",
      "Loss: 2.700, Residuals: -0.040\n",
      "Loss: 2.671, Residuals: -0.051\n",
      "Loss: 2.671, Residuals: -0.051\n",
      "Loss: 2.669, Residuals: -0.052\n",
      "Loss: 2.667, Residuals: -0.052\n",
      "Loss: 2.662, Residuals: -0.055\n",
      "Loss: 2.658, Residuals: -0.057\n",
      "Loss: 2.658, Residuals: -0.058\n",
      "Loss: 2.640, Residuals: -0.064\n",
      "Loss: 2.639, Residuals: -0.063\n",
      "Loss: 2.639, Residuals: -0.065\n",
      "Loss: 2.631, Residuals: -0.068\n",
      "Loss: 2.631, Residuals: -0.068\n",
      "Loss: 2.610, Residuals: -0.076\n",
      "Loss: 2.605, Residuals: -0.075\n",
      "Loss: 2.605, Residuals: -0.075\n",
      "Loss: 2.603, Residuals: -0.076\n",
      "Loss: 2.600, Residuals: -0.078\n",
      "Loss: 2.580, Residuals: -0.083\n",
      "Loss: 2.579, Residuals: -0.082\n",
      "Loss: 2.577, Residuals: -0.082\n",
      "Loss: 2.574, Residuals: -0.082\n",
      "Loss: 2.571, Residuals: -0.084\n",
      "Loss: 2.571, Residuals: -0.084\n",
      "Loss: 2.535, Residuals: -0.088\n",
      "Loss: 2.532, Residuals: -0.088\n",
      "Loss: 2.532, Residuals: -0.088\n",
      "Loss: 2.532, Residuals: -0.088\n",
      "Loss: 2.528, Residuals: -0.088\n",
      "Loss: 2.528, Residuals: -0.088\n",
      "Loss: 2.527, Residuals: -0.089\n",
      "Loss: 2.527, Residuals: -0.087\n",
      "Loss: 2.497, Residuals: -0.090\n",
      "Loss: 2.495, Residuals: -0.089\n",
      "Loss: 2.495, Residuals: -0.090\n",
      "Loss: 2.488, Residuals: -0.090\n",
      "Loss: 2.487, Residuals: -0.087\n",
      "Loss: 2.470, Residuals: -0.087\n",
      "Loss: 2.470, Residuals: -0.086\n",
      "Loss: 2.464, Residuals: -0.087\n",
      "Loss: 2.427, Residuals: -0.090\n",
      "Loss: 2.418, Residuals: -0.090\n",
      "Loss: 2.417, Residuals: -0.090\n",
      "Loss: 2.417, Residuals: -0.090\n",
      "Loss: 2.416, Residuals: -0.090\n",
      "Loss: 2.416, Residuals: -0.090\n",
      "Loss: 2.416, Residuals: -0.091\n",
      "Loss: 2.415, Residuals: -0.091\n",
      "Loss: 2.414, Residuals: -0.091\n",
      "Loss: 2.406, Residuals: -0.090\n",
      "Loss: 2.406, Residuals: -0.090\n",
      "Loss: 2.406, Residuals: -0.090\n",
      "Evidence -418.222\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.24e-02\n",
      "Loss: 13.176, Residuals: -0.033\n",
      "Loss: 13.128, Residuals: -0.060\n",
      "Loss: 13.048, Residuals: -0.059\n",
      "Loss: 12.911, Residuals: -0.050\n",
      "Loss: 12.868, Residuals: -0.046\n",
      "Loss: 12.793, Residuals: -0.040\n",
      "Loss: 12.709, Residuals: -0.026\n",
      "Loss: 12.704, Residuals: -0.026\n",
      "Loss: 12.698, Residuals: -0.026\n",
      "Loss: 12.654, Residuals: -0.022\n",
      "Loss: 12.653, Residuals: -0.022\n",
      "Evidence 109.571\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.93e-02\n",
      "Loss: 43.837, Residuals: -0.020\n",
      "Loss: 43.809, Residuals: -0.018\n",
      "Loss: 43.762, Residuals: -0.018\n",
      "Loss: 43.704, Residuals: -0.018\n",
      "Loss: 43.596, Residuals: -0.016\n",
      "Loss: 43.409, Residuals: -0.011\n",
      "Loss: 43.365, Residuals: -0.009\n",
      "Loss: 43.281, Residuals: -0.008\n",
      "Loss: 43.144, Residuals: -0.005\n",
      "Loss: 43.142, Residuals: -0.005\n",
      "Loss: 43.138, Residuals: -0.005\n",
      "Loss: 43.011, Residuals: -0.003\n",
      "Loss: 43.011, Residuals: -0.003\n",
      "Evidence 308.490\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.03e-01\n",
      "Loss: 90.136, Residuals: -0.003\n",
      "Loss: 89.549, Residuals: -0.011\n",
      "Loss: 89.494, Residuals: -0.013\n",
      "Loss: 88.981, Residuals: -0.011\n",
      "Loss: 88.980, Residuals: -0.012\n",
      "Loss: 87.976, Residuals: -0.006\n",
      "Loss: 87.943, Residuals: -0.006\n",
      "Loss: 87.929, Residuals: -0.008\n",
      "Loss: 87.421, Residuals: -0.005\n",
      "Loss: 87.415, Residuals: -0.005\n",
      "Loss: 87.408, Residuals: -0.005\n",
      "Loss: 87.338, Residuals: -0.004\n",
      "Loss: 87.217, Residuals: -0.003\n",
      "Loss: 87.122, Residuals: -0.001\n",
      "Loss: 86.947, Residuals: 0.000\n",
      "Loss: 86.940, Residuals: 0.001\n",
      "Loss: 86.883, Residuals: 0.000\n",
      "Loss: 86.832, Residuals: 0.001\n",
      "Loss: 86.735, Residuals: 0.001\n",
      "Loss: 86.687, Residuals: 0.002\n",
      "Loss: 86.331, Residuals: 0.003\n",
      "Loss: 86.305, Residuals: 0.004\n",
      "Loss: 86.295, Residuals: 0.003\n",
      "Loss: 86.276, Residuals: 0.003\n",
      "Loss: 86.246, Residuals: 0.004\n",
      "Loss: 86.220, Residuals: 0.003\n",
      "Loss: 86.214, Residuals: 0.003\n",
      "Loss: 85.568, Residuals: 0.006\n",
      "Loss: 85.370, Residuals: 0.009\n",
      "Loss: 85.236, Residuals: 0.004\n",
      "Loss: 85.066, Residuals: 0.007\n",
      "Loss: 85.038, Residuals: 0.006\n",
      "Loss: 84.984, Residuals: 0.006\n",
      "Loss: 84.883, Residuals: 0.005\n",
      "Loss: 84.878, Residuals: 0.004\n",
      "Loss: 84.081, Residuals: 0.007\n",
      "Loss: 84.029, Residuals: 0.007\n",
      "Loss: 83.973, Residuals: 0.007\n",
      "Loss: 83.871, Residuals: 0.007\n",
      "Loss: 83.699, Residuals: 0.008\n",
      "Loss: 83.678, Residuals: 0.010\n",
      "Loss: 82.916, Residuals: 0.012\n",
      "Loss: 82.882, Residuals: 0.013\n",
      "Loss: 82.825, Residuals: 0.011\n",
      "Loss: 82.725, Residuals: 0.012\n",
      "Loss: 82.672, Residuals: 0.011\n",
      "Loss: 82.221, Residuals: 0.013\n",
      "Loss: 82.200, Residuals: 0.012\n",
      "Loss: 82.013, Residuals: 0.012\n",
      "Loss: 81.963, Residuals: 0.014\n",
      "Loss: 81.870, Residuals: 0.015\n",
      "Loss: 81.863, Residuals: 0.013\n",
      "Loss: 81.801, Residuals: 0.014\n",
      "Loss: 81.697, Residuals: 0.015\n",
      "Loss: 81.684, Residuals: 0.016\n",
      "Loss: 81.659, Residuals: 0.016\n",
      "Loss: 81.620, Residuals: 0.016\n",
      "Loss: 81.615, Residuals: 0.016\n",
      "Loss: 81.606, Residuals: 0.016\n",
      "Loss: 81.593, Residuals: 0.017\n",
      "Loss: 81.591, Residuals: 0.017\n",
      "Loss: 81.588, Residuals: 0.017\n",
      "Loss: 81.585, Residuals: 0.017\n",
      "Loss: 81.584, Residuals: 0.017\n",
      "Loss: 81.584, Residuals: 0.017\n",
      "Loss: 81.584, Residuals: 0.017\n",
      "Evidence 422.708\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.66e+00\n",
      "Loss: 121.427, Residuals: 0.028\n",
      "Loss: 120.547, Residuals: 0.017\n",
      "Loss: 120.488, Residuals: 0.014\n",
      "Loss: 120.019, Residuals: 0.014\n",
      "Loss: 119.692, Residuals: 0.017\n",
      "Loss: 119.675, Residuals: 0.015\n",
      "Loss: 119.645, Residuals: 0.015\n",
      "Loss: 119.610, Residuals: 0.013\n",
      "Loss: 119.563, Residuals: 0.013\n",
      "Loss: 119.547, Residuals: 0.012\n",
      "Loss: 119.543, Residuals: 0.013\n",
      "Loss: 119.542, Residuals: 0.013\n",
      "Loss: 119.541, Residuals: 0.013\n",
      "Loss: 119.539, Residuals: 0.012\n",
      "Loss: 119.539, Residuals: 0.012\n",
      "Loss: 119.539, Residuals: 0.012\n",
      "Loss: 119.539, Residuals: 0.012\n",
      "Loss: 119.539, Residuals: 0.012\n",
      "Loss: 119.539, Residuals: 0.012\n",
      "Loss: 119.539, Residuals: 0.012\n",
      "Loss: 119.539, Residuals: 0.012\n",
      "Evidence 478.514\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.94e+00\n",
      "Loss: 142.792, Residuals: 0.019\n",
      "Loss: 142.707, Residuals: 0.016\n",
      "Loss: 142.565, Residuals: 0.014\n",
      "Loss: 142.376, Residuals: 0.011\n",
      "Loss: 142.371, Residuals: 0.011\n",
      "Loss: 142.326, Residuals: 0.011\n",
      "Loss: 142.265, Residuals: 0.010\n",
      "Loss: 142.264, Residuals: 0.010\n",
      "Loss: 142.254, Residuals: 0.010\n",
      "Loss: 142.245, Residuals: 0.009\n",
      "Loss: 142.245, Residuals: 0.009\n",
      "Loss: 142.244, Residuals: 0.009\n",
      "Loss: 142.244, Residuals: 0.009\n",
      "Loss: 142.244, Residuals: 0.009\n",
      "Loss: 142.244, Residuals: 0.009\n",
      "Loss: 142.244, Residuals: 0.009\n",
      "Loss: 142.244, Residuals: 0.009\n",
      "Loss: 142.244, Residuals: 0.009\n",
      "Evidence 492.813\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.87e+00\n",
      "Loss: 151.380, Residuals: 0.015\n",
      "Loss: 151.242, Residuals: 0.013\n",
      "Loss: 151.103, Residuals: 0.008\n",
      "Loss: 151.078, Residuals: 0.007\n",
      "Loss: 151.037, Residuals: 0.007\n",
      "Loss: 151.035, Residuals: 0.007\n",
      "Loss: 151.016, Residuals: 0.007\n",
      "Loss: 151.015, Residuals: 0.007\n",
      "Loss: 151.011, Residuals: 0.007\n",
      "Loss: 151.005, Residuals: 0.007\n",
      "Loss: 150.998, Residuals: 0.007\n",
      "Loss: 150.998, Residuals: 0.007\n",
      "Loss: 150.998, Residuals: 0.007\n",
      "Loss: 150.998, Residuals: 0.007\n",
      "Loss: 150.998, Residuals: 0.007\n",
      "Loss: 150.998, Residuals: 0.007\n",
      "Loss: 150.998, Residuals: 0.007\n",
      "Loss: 150.997, Residuals: 0.007\n",
      "Evidence 497.130\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.75e+00\n",
      "Loss: 154.200, Residuals: 0.010\n",
      "Loss: 154.142, Residuals: 0.010\n",
      "Loss: 154.081, Residuals: 0.008\n",
      "Loss: 154.004, Residuals: 0.006\n",
      "Loss: 154.001, Residuals: 0.006\n",
      "Loss: 153.979, Residuals: 0.006\n",
      "Loss: 153.954, Residuals: 0.005\n",
      "Loss: 153.953, Residuals: 0.006\n",
      "Loss: 153.953, Residuals: 0.005\n",
      "Loss: 153.952, Residuals: 0.005\n",
      "Loss: 153.950, Residuals: 0.005\n",
      "Loss: 153.948, Residuals: 0.005\n",
      "Loss: 153.948, Residuals: 0.005\n",
      "Loss: 153.948, Residuals: 0.005\n",
      "Loss: 153.947, Residuals: 0.005\n",
      "Loss: 153.947, Residuals: 0.005\n",
      "Loss: 153.947, Residuals: 0.005\n",
      "Evidence 499.213\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.65e+00\n",
      "Loss: 155.155, Residuals: 0.007\n",
      "Loss: 155.101, Residuals: 0.005\n",
      "Loss: 155.060, Residuals: 0.004\n",
      "Loss: 155.055, Residuals: 0.004\n",
      "Loss: 155.046, Residuals: 0.004\n",
      "Loss: 155.032, Residuals: 0.004\n",
      "Loss: 155.032, Residuals: 0.004\n",
      "Loss: 155.027, Residuals: 0.004\n",
      "Loss: 155.021, Residuals: 0.004\n",
      "Loss: 155.021, Residuals: 0.004\n",
      "Loss: 155.021, Residuals: 0.004\n",
      "Loss: 155.021, Residuals: 0.004\n",
      "Loss: 155.020, Residuals: 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence 500.542\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.57e+00\n",
      "Loss: 155.573, Residuals: 0.005\n",
      "Loss: 155.549, Residuals: 0.002\n",
      "Loss: 155.524, Residuals: 0.002\n",
      "Loss: 155.523, Residuals: 0.002\n",
      "Loss: 155.523, Residuals: 0.002\n",
      "Loss: 155.515, Residuals: 0.002\n",
      "Loss: 155.506, Residuals: 0.002\n",
      "Loss: 155.506, Residuals: 0.002\n",
      "Evidence 501.430\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.52e+00\n",
      "Loss: 155.826, Residuals: 0.003\n",
      "Loss: 155.824, Residuals: 0.003\n",
      "Loss: 155.806, Residuals: 0.002\n",
      "Loss: 155.796, Residuals: 0.001\n",
      "Loss: 155.796, Residuals: 0.001\n",
      "Loss: 155.792, Residuals: 0.001\n",
      "Loss: 155.788, Residuals: 0.001\n",
      "Loss: 155.788, Residuals: 0.001\n",
      "Loss: 155.787, Residuals: 0.001\n",
      "Loss: 155.785, Residuals: 0.001\n",
      "Loss: 155.785, Residuals: 0.001\n",
      "Loss: 155.785, Residuals: 0.002\n",
      "Loss: 155.785, Residuals: 0.002\n",
      "Loss: 155.785, Residuals: 0.002\n",
      "Evidence 502.049\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.47e+00\n",
      "Loss: 156.006, Residuals: 0.002\n",
      "Loss: 156.002, Residuals: 0.001\n",
      "Loss: 155.996, Residuals: 0.001\n",
      "Loss: 155.991, Residuals: 0.001\n",
      "Loss: 155.991, Residuals: 0.001\n",
      "Loss: 155.990, Residuals: 0.001\n",
      "Loss: 155.988, Residuals: 0.001\n",
      "Loss: 155.986, Residuals: 0.001\n",
      "Evidence 502.471\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 13.230, Residuals: -0.018\n",
      "Loss: 7.843, Residuals: -0.060\n",
      "Loss: 5.613, Residuals: -0.059\n",
      "Loss: 5.060, Residuals: -0.029\n",
      "Loss: 4.514, Residuals: -0.049\n",
      "Loss: 4.330, Residuals: -0.032\n",
      "Loss: 4.269, Residuals: 0.007\n",
      "Loss: 4.156, Residuals: -0.002\n",
      "Loss: 4.030, Residuals: 0.013\n",
      "Loss: 4.009, Residuals: 0.014\n",
      "Loss: 3.837, Residuals: -0.006\n",
      "Loss: 3.575, Residuals: -0.038\n",
      "Loss: 3.558, Residuals: -0.013\n",
      "Loss: 3.418, Residuals: -0.022\n",
      "Loss: 3.408, Residuals: -0.005\n",
      "Loss: 3.389, Residuals: -0.009\n",
      "Loss: 3.357, Residuals: -0.011\n",
      "Loss: 3.357, Residuals: -0.012\n",
      "Loss: 3.294, Residuals: -0.025\n",
      "Loss: 3.278, Residuals: -0.018\n",
      "Loss: 3.278, Residuals: -0.019\n",
      "Loss: 3.244, Residuals: -0.026\n",
      "Loss: 3.226, Residuals: -0.037\n",
      "Loss: 3.224, Residuals: -0.040\n",
      "Loss: 3.223, Residuals: -0.035\n",
      "Loss: 3.205, Residuals: -0.038\n",
      "Loss: 3.174, Residuals: -0.044\n",
      "Loss: 3.127, Residuals: -0.061\n",
      "Loss: 3.126, Residuals: -0.061\n",
      "Loss: 3.121, Residuals: -0.060\n",
      "Loss: 3.120, Residuals: -0.058\n",
      "Loss: 3.094, Residuals: -0.062\n",
      "Loss: 3.088, Residuals: -0.064\n",
      "Loss: 3.088, Residuals: -0.065\n",
      "Evidence -388.445\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.55e-03\n",
      "Loss: 12.250, Residuals: -0.037\n",
      "Loss: 12.148, Residuals: -0.055\n",
      "Loss: 12.140, Residuals: -0.051\n",
      "Loss: 11.864, Residuals: -0.045\n",
      "Loss: 11.859, Residuals: -0.045\n",
      "Loss: 11.818, Residuals: -0.044\n",
      "Loss: 11.776, Residuals: -0.040\n",
      "Loss: 11.716, Residuals: -0.035\n",
      "Loss: 11.712, Residuals: -0.035\n",
      "Loss: 11.705, Residuals: -0.034\n",
      "Loss: 11.651, Residuals: -0.027\n",
      "Loss: 11.639, Residuals: -0.023\n",
      "Loss: 11.627, Residuals: -0.021\n",
      "Loss: 11.606, Residuals: -0.019\n",
      "Loss: 11.596, Residuals: -0.016\n",
      "Loss: 11.545, Residuals: -0.013\n",
      "Loss: 11.540, Residuals: -0.014\n",
      "Loss: 11.538, Residuals: -0.014\n",
      "Loss: 11.533, Residuals: -0.013\n",
      "Loss: 11.523, Residuals: -0.012\n",
      "Loss: 11.480, Residuals: -0.011\n",
      "Loss: 11.478, Residuals: -0.012\n",
      "Loss: 11.476, Residuals: -0.009\n",
      "Loss: 11.464, Residuals: -0.008\n",
      "Loss: 11.408, Residuals: -0.008\n",
      "Loss: 11.402, Residuals: -0.009\n",
      "Loss: 11.401, Residuals: -0.009\n",
      "Loss: 11.399, Residuals: -0.008\n",
      "Loss: 11.397, Residuals: -0.007\n",
      "Loss: 11.377, Residuals: -0.005\n",
      "Loss: 11.373, Residuals: -0.003\n",
      "Loss: 11.342, Residuals: -0.004\n",
      "Loss: 11.342, Residuals: -0.004\n",
      "Evidence 79.240\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 9.84e-02\n",
      "Loss: 38.149, Residuals: -0.005\n",
      "Loss: 37.980, Residuals: -0.004\n",
      "Loss: 37.697, Residuals: -0.004\n",
      "Loss: 37.561, Residuals: -0.003\n",
      "Loss: 37.558, Residuals: -0.002\n",
      "Loss: 37.537, Residuals: -0.001\n",
      "Loss: 37.496, Residuals: 0.000\n",
      "Loss: 37.456, Residuals: -0.000\n",
      "Loss: 37.395, Residuals: 0.003\n",
      "Loss: 37.291, Residuals: 0.005\n",
      "Loss: 37.284, Residuals: 0.008\n",
      "Loss: 37.219, Residuals: 0.009\n",
      "Loss: 37.133, Residuals: 0.013\n",
      "Loss: 37.133, Residuals: 0.013\n",
      "Evidence 284.031\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.83e-01\n",
      "Loss: 81.149, Residuals: 0.013\n",
      "Loss: 81.050, Residuals: 0.011\n",
      "Loss: 80.895, Residuals: 0.007\n",
      "Loss: 80.764, Residuals: 0.009\n",
      "Loss: 80.720, Residuals: 0.011\n",
      "Loss: 80.369, Residuals: 0.011\n",
      "Loss: 80.368, Residuals: 0.012\n",
      "Evidence 398.057\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.01e-01\n",
      "Loss: 121.555, Residuals: 0.011\n",
      "Loss: 121.506, Residuals: 0.012\n",
      "Loss: 121.420, Residuals: 0.013\n",
      "Loss: 121.283, Residuals: 0.010\n",
      "Loss: 121.064, Residuals: 0.010\n",
      "Loss: 120.662, Residuals: 0.010\n",
      "Loss: 120.367, Residuals: 0.004\n",
      "Loss: 120.222, Residuals: 0.005\n",
      "Loss: 119.953, Residuals: 0.007\n",
      "Loss: 119.943, Residuals: 0.008\n",
      "Loss: 119.578, Residuals: 0.010\n",
      "Loss: 119.573, Residuals: 0.009\n",
      "Loss: 119.170, Residuals: 0.013\n",
      "Loss: 119.115, Residuals: 0.012\n",
      "Loss: 119.077, Residuals: 0.013\n",
      "Loss: 119.043, Residuals: 0.011\n",
      "Loss: 118.741, Residuals: 0.013\n",
      "Loss: 118.729, Residuals: 0.012\n",
      "Loss: 118.708, Residuals: 0.012\n",
      "Loss: 118.068, Residuals: 0.018\n",
      "Loss: 117.948, Residuals: 0.021\n",
      "Loss: 117.879, Residuals: 0.016\n",
      "Loss: 117.843, Residuals: 0.014\n",
      "Loss: 117.777, Residuals: 0.015\n",
      "Loss: 117.670, Residuals: 0.016\n",
      "Loss: 117.653, Residuals: 0.014\n",
      "Loss: 117.623, Residuals: 0.015\n",
      "Loss: 117.621, Residuals: 0.015\n",
      "Loss: 117.608, Residuals: 0.015\n",
      "Loss: 117.586, Residuals: 0.015\n",
      "Loss: 117.584, Residuals: 0.015\n",
      "Loss: 117.579, Residuals: 0.015\n",
      "Loss: 117.571, Residuals: 0.015\n",
      "Loss: 117.571, Residuals: 0.015\n",
      "Loss: 117.568, Residuals: 0.015\n",
      "Loss: 117.568, Residuals: 0.015\n",
      "Loss: 117.567, Residuals: 0.015\n",
      "Loss: 117.567, Residuals: 0.015\n",
      "Loss: 117.567, Residuals: 0.015\n",
      "Loss: 117.566, Residuals: 0.015\n",
      "Loss: 117.566, Residuals: 0.015\n",
      "Loss: 117.566, Residuals: 0.015\n",
      "Evidence 441.852\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.09e+00\n",
      "Loss: 138.784, Residuals: 0.019\n",
      "Loss: 138.569, Residuals: 0.019\n",
      "Loss: 138.278, Residuals: 0.019\n",
      "Loss: 138.238, Residuals: 0.018\n",
      "Loss: 138.166, Residuals: 0.018\n",
      "Loss: 138.057, Residuals: 0.018\n",
      "Loss: 138.054, Residuals: 0.018\n",
      "Loss: 138.023, Residuals: 0.018\n",
      "Loss: 137.980, Residuals: 0.017\n",
      "Loss: 137.978, Residuals: 0.017\n",
      "Loss: 137.974, Residuals: 0.017\n",
      "Loss: 137.968, Residuals: 0.017\n",
      "Loss: 137.968, Residuals: 0.017\n",
      "Loss: 137.966, Residuals: 0.017\n",
      "Loss: 137.966, Residuals: 0.017\n",
      "Loss: 137.965, Residuals: 0.017\n",
      "Loss: 137.964, Residuals: 0.017\n",
      "Loss: 137.964, Residuals: 0.017\n",
      "Evidence 456.068\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.13e+00\n",
      "Loss: 146.376, Residuals: 0.023\n",
      "Loss: 146.305, Residuals: 0.018\n",
      "Loss: 146.202, Residuals: 0.018\n",
      "Loss: 146.145, Residuals: 0.017\n",
      "Loss: 146.142, Residuals: 0.018\n",
      "Loss: 146.121, Residuals: 0.017\n",
      "Loss: 146.093, Residuals: 0.017\n",
      "Loss: 146.093, Residuals: 0.018\n",
      "Loss: 146.091, Residuals: 0.017\n",
      "Loss: 146.088, Residuals: 0.017\n",
      "Loss: 146.088, Residuals: 0.017\n",
      "Loss: 146.088, Residuals: 0.017\n",
      "Loss: 146.086, Residuals: 0.017\n",
      "Loss: 146.086, Residuals: 0.017\n",
      "Loss: 146.086, Residuals: 0.017\n",
      "Loss: 146.085, Residuals: 0.017\n",
      "Loss: 146.085, Residuals: 0.017\n",
      "Loss: 146.085, Residuals: 0.017\n",
      "Loss: 146.085, Residuals: 0.017\n",
      "Loss: 146.085, Residuals: 0.017\n",
      "Evidence 460.286\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.10e+00\n",
      "Loss: 148.957, Residuals: 0.020\n",
      "Loss: 148.875, Residuals: 0.019\n",
      "Loss: 148.848, Residuals: 0.018\n",
      "Loss: 148.840, Residuals: 0.018\n",
      "Loss: 148.830, Residuals: 0.018\n",
      "Loss: 148.815, Residuals: 0.018\n",
      "Loss: 148.814, Residuals: 0.018\n",
      "Loss: 148.809, Residuals: 0.018\n",
      "Loss: 148.801, Residuals: 0.018\n",
      "Loss: 148.800, Residuals: 0.018\n",
      "Loss: 148.799, Residuals: 0.018\n",
      "Loss: 148.796, Residuals: 0.018\n",
      "Loss: 148.796, Residuals: 0.018\n",
      "Evidence 462.500\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.06e+00\n",
      "Loss: 149.932, Residuals: 0.018\n",
      "Loss: 149.911, Residuals: 0.020\n",
      "Loss: 149.883, Residuals: 0.019\n",
      "Loss: 149.877, Residuals: 0.018\n",
      "Loss: 149.874, Residuals: 0.018\n",
      "Loss: 149.869, Residuals: 0.018\n",
      "Loss: 149.868, Residuals: 0.018\n",
      "Loss: 149.859, Residuals: 0.018\n",
      "Loss: 149.854, Residuals: 0.018\n",
      "Loss: 149.854, Residuals: 0.018\n",
      "Loss: 149.854, Residuals: 0.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 149.854, Residuals: 0.018\n",
      "Loss: 149.854, Residuals: 0.018\n",
      "Loss: 149.854, Residuals: 0.018\n",
      "Evidence 464.011\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.03e+00\n",
      "Loss: 150.449, Residuals: 0.018\n",
      "Loss: 150.432, Residuals: 0.019\n",
      "Loss: 150.417, Residuals: 0.018\n",
      "Loss: 150.413, Residuals: 0.018\n",
      "Loss: 150.409, Residuals: 0.018\n",
      "Loss: 150.405, Residuals: 0.018\n",
      "Loss: 150.405, Residuals: 0.018\n",
      "Loss: 150.404, Residuals: 0.018\n",
      "Loss: 150.403, Residuals: 0.018\n",
      "Loss: 150.402, Residuals: 0.018\n",
      "Loss: 150.402, Residuals: 0.018\n",
      "Loss: 150.402, Residuals: 0.018\n",
      "Loss: 150.402, Residuals: 0.018\n",
      "Loss: 150.402, Residuals: 0.018\n",
      "Evidence 465.102\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.02e+00\n",
      "Loss: 150.774, Residuals: 0.019\n",
      "Loss: 150.761, Residuals: 0.018\n",
      "Loss: 150.752, Residuals: 0.019\n",
      "Loss: 150.750, Residuals: 0.018\n",
      "Loss: 150.748, Residuals: 0.018\n",
      "Loss: 150.747, Residuals: 0.018\n",
      "Loss: 150.746, Residuals: 0.018\n",
      "Loss: 150.745, Residuals: 0.018\n",
      "Loss: 150.744, Residuals: 0.018\n",
      "Loss: 150.743, Residuals: 0.018\n",
      "Loss: 150.743, Residuals: 0.018\n",
      "Loss: 150.743, Residuals: 0.018\n",
      "Loss: 150.743, Residuals: 0.018\n",
      "Evidence 465.932\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.01e+00\n",
      "Loss: 150.990, Residuals: 0.019\n",
      "Loss: 150.975, Residuals: 0.018\n",
      "Loss: 150.974, Residuals: 0.018\n",
      "Loss: 150.972, Residuals: 0.018\n",
      "Loss: 150.969, Residuals: 0.018\n",
      "Loss: 150.968, Residuals: 0.018\n",
      "Loss: 150.967, Residuals: 0.018\n",
      "Loss: 150.967, Residuals: 0.018\n",
      "Loss: 150.967, Residuals: 0.018\n",
      "Loss: 150.967, Residuals: 0.018\n",
      "Loss: 150.966, Residuals: 0.018\n",
      "Loss: 150.966, Residuals: 0.018\n",
      "Evidence 466.597\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.00e+00\n",
      "Loss: 151.134, Residuals: 0.019\n",
      "Loss: 151.127, Residuals: 0.018\n",
      "Loss: 151.121, Residuals: 0.018\n",
      "Loss: 151.121, Residuals: 0.018\n",
      "Loss: 151.120, Residuals: 0.018\n",
      "Loss: 151.119, Residuals: 0.018\n",
      "Loss: 151.117, Residuals: 0.018\n",
      "Loss: 151.117, Residuals: 0.018\n",
      "Loss: 151.117, Residuals: 0.018\n",
      "Loss: 151.117, Residuals: 0.018\n",
      "Loss: 151.116, Residuals: 0.018\n",
      "Loss: 151.116, Residuals: 0.018\n",
      "Loss: 151.116, Residuals: 0.018\n",
      "Loss: 151.116, Residuals: 0.018\n",
      "Evidence 467.161\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 9.98e-01\n",
      "Loss: 151.228, Residuals: 0.019\n",
      "Loss: 151.220, Residuals: 0.018\n",
      "Loss: 151.218, Residuals: 0.018\n",
      "Loss: 151.216, Residuals: 0.018\n",
      "Loss: 151.213, Residuals: 0.018\n",
      "Loss: 151.213, Residuals: 0.018\n",
      "Loss: 151.213, Residuals: 0.018\n",
      "Loss: 151.212, Residuals: 0.018\n",
      "Loss: 151.212, Residuals: 0.018\n",
      "Evidence 467.646\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 9.98e-01\n",
      "Loss: 151.303, Residuals: 0.019\n",
      "Loss: 151.296, Residuals: 0.018\n",
      "Loss: 151.295, Residuals: 0.018\n",
      "Loss: 151.293, Residuals: 0.018\n",
      "Loss: 151.290, Residuals: 0.018\n",
      "Loss: 151.290, Residuals: 0.018\n",
      "Loss: 151.290, Residuals: 0.018\n",
      "Loss: 151.290, Residuals: 0.018\n",
      "Loss: 151.290, Residuals: 0.018\n",
      "Loss: 151.290, Residuals: 0.018\n",
      "Evidence 468.064\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.608, Residuals: -0.060\n",
      "Loss: 7.864, Residuals: -0.070\n",
      "Loss: 5.579, Residuals: -0.048\n",
      "Loss: 4.901, Residuals: -0.022\n",
      "Loss: 4.623, Residuals: -0.044\n",
      "Loss: 4.211, Residuals: -0.039\n",
      "Loss: 4.196, Residuals: -0.014\n",
      "Loss: 4.057, Residuals: -0.021\n",
      "Loss: 3.845, Residuals: -0.035\n",
      "Loss: 3.798, Residuals: -0.016\n",
      "Loss: 3.718, Residuals: -0.022\n",
      "Loss: 3.597, Residuals: -0.034\n",
      "Loss: 3.572, Residuals: -0.026\n",
      "Loss: 3.530, Residuals: -0.031\n",
      "Loss: 3.454, Residuals: -0.038\n",
      "Loss: 3.422, Residuals: -0.044\n",
      "Loss: 3.396, Residuals: -0.035\n",
      "Loss: 3.354, Residuals: -0.042\n",
      "Loss: 3.327, Residuals: -0.049\n",
      "Loss: 3.325, Residuals: -0.043\n",
      "Loss: 3.320, Residuals: -0.044\n",
      "Loss: 3.287, Residuals: -0.049\n",
      "Loss: 3.286, Residuals: -0.050\n",
      "Loss: 3.261, Residuals: -0.055\n",
      "Loss: 3.260, Residuals: -0.056\n",
      "Loss: 3.258, Residuals: -0.056\n",
      "Loss: 3.242, Residuals: -0.061\n",
      "Loss: 3.242, Residuals: -0.062\n",
      "Loss: 3.235, Residuals: -0.064\n",
      "Loss: 3.229, Residuals: -0.065\n",
      "Loss: 3.228, Residuals: -0.063\n",
      "Loss: 3.222, Residuals: -0.065\n",
      "Loss: 3.214, Residuals: -0.065\n",
      "Loss: 3.214, Residuals: -0.065\n",
      "Loss: 3.214, Residuals: -0.065\n",
      "Loss: 3.213, Residuals: -0.064\n",
      "Loss: 3.208, Residuals: -0.067\n",
      "Loss: 3.207, Residuals: -0.067\n",
      "Loss: 3.199, Residuals: -0.071\n",
      "Loss: 3.198, Residuals: -0.073\n",
      "Loss: 3.188, Residuals: -0.077\n",
      "Loss: 3.188, Residuals: -0.076\n",
      "Loss: 3.186, Residuals: -0.075\n",
      "Loss: 3.175, Residuals: -0.079\n",
      "Loss: 3.174, Residuals: -0.079\n",
      "Loss: 3.173, Residuals: -0.079\n",
      "Loss: 3.172, Residuals: -0.080\n",
      "Loss: 3.171, Residuals: -0.078\n",
      "Loss: 3.161, Residuals: -0.083\n",
      "Loss: 3.161, Residuals: -0.083\n",
      "Loss: 3.161, Residuals: -0.083\n",
      "Loss: 3.160, Residuals: -0.083\n",
      "Loss: 3.157, Residuals: -0.082\n",
      "Loss: 3.157, Residuals: -0.081\n",
      "Loss: 3.150, Residuals: -0.084\n",
      "Loss: 3.150, Residuals: -0.084\n",
      "Loss: 3.149, Residuals: -0.084\n",
      "Loss: 3.148, Residuals: -0.084\n",
      "Loss: 3.147, Residuals: -0.083\n",
      "Loss: 3.147, Residuals: -0.084\n",
      "Loss: 3.144, Residuals: -0.085\n",
      "Loss: 3.144, Residuals: -0.085\n",
      "Loss: 3.137, Residuals: -0.089\n",
      "Loss: 3.137, Residuals: -0.089\n",
      "Loss: 3.137, Residuals: -0.089\n",
      "Loss: 3.136, Residuals: -0.089\n",
      "Loss: 3.136, Residuals: -0.089\n",
      "Loss: 3.135, Residuals: -0.090\n",
      "Loss: 3.134, Residuals: -0.089\n",
      "Loss: 3.126, Residuals: -0.095\n",
      "Loss: 3.126, Residuals: -0.095\n",
      "Loss: 3.126, Residuals: -0.095\n",
      "Loss: 3.125, Residuals: -0.096\n",
      "Loss: 3.124, Residuals: -0.096\n",
      "Loss: 3.124, Residuals: -0.095\n",
      "Loss: 3.121, Residuals: -0.097\n",
      "Loss: 3.121, Residuals: -0.098\n",
      "Loss: 3.121, Residuals: -0.098\n",
      "Loss: 3.117, Residuals: -0.100\n",
      "Loss: 3.117, Residuals: -0.099\n",
      "Loss: 3.117, Residuals: -0.100\n",
      "Loss: 3.117, Residuals: -0.100\n",
      "Loss: 3.116, Residuals: -0.100\n",
      "Loss: 3.116, Residuals: -0.101\n",
      "Loss: 3.116, Residuals: -0.101\n",
      "Loss: 3.113, Residuals: -0.102\n",
      "Loss: 3.113, Residuals: -0.103\n",
      "Loss: 3.113, Residuals: -0.103\n",
      "Loss: 3.112, Residuals: -0.102\n",
      "Loss: 3.112, Residuals: -0.101\n",
      "Loss: 3.108, Residuals: -0.105\n",
      "Loss: 3.107, Residuals: -0.104\n",
      "Loss: 3.107, Residuals: -0.103\n",
      "Loss: 3.105, Residuals: -0.104\n",
      "Loss: 3.105, Residuals: -0.106\n",
      "Loss: 3.101, Residuals: -0.104\n",
      "Loss: 3.100, Residuals: -0.104\n",
      "Loss: 3.098, Residuals: -0.104\n",
      "Loss: 3.095, Residuals: -0.102\n",
      "Loss: 3.093, Residuals: -0.104\n",
      "Loss: 3.084, Residuals: -0.101\n",
      "Loss: 3.083, Residuals: -0.099\n",
      "Loss: 3.082, Residuals: -0.098\n",
      "Loss: 3.080, Residuals: -0.097\n",
      "Loss: 3.079, Residuals: -0.096\n",
      "Loss: 3.076, Residuals: -0.096\n",
      "Loss: 3.076, Residuals: -0.095\n",
      "Loss: 3.066, Residuals: -0.099\n",
      "Loss: 3.064, Residuals: -0.097\n",
      "Loss: 3.064, Residuals: -0.096\n",
      "Loss: 3.063, Residuals: -0.096\n",
      "Loss: 3.058, Residuals: -0.097\n",
      "Loss: 3.057, Residuals: -0.098\n",
      "Loss: 3.057, Residuals: -0.096\n",
      "Loss: 3.054, Residuals: -0.097\n",
      "Loss: 3.053, Residuals: -0.097\n",
      "Loss: 3.043, Residuals: -0.101\n",
      "Loss: 3.042, Residuals: -0.100\n",
      "Loss: 3.042, Residuals: -0.099\n",
      "Loss: 3.041, Residuals: -0.099\n",
      "Loss: 3.038, Residuals: -0.099\n",
      "Loss: 3.038, Residuals: -0.098\n",
      "Loss: 3.029, Residuals: -0.102\n",
      "Loss: 3.029, Residuals: -0.101\n",
      "Loss: 3.029, Residuals: -0.101\n",
      "Loss: 3.029, Residuals: -0.101\n",
      "Loss: 3.024, Residuals: -0.103\n",
      "Loss: 3.024, Residuals: -0.102\n",
      "Loss: 3.023, Residuals: -0.102\n",
      "Loss: 3.023, Residuals: -0.103\n",
      "Loss: 3.023, Residuals: -0.103\n",
      "Loss: 3.022, Residuals: -0.103\n",
      "Loss: 3.022, Residuals: -0.103\n",
      "Loss: 3.022, Residuals: -0.103\n",
      "Loss: 3.007, Residuals: -0.108\n",
      "Loss: 3.006, Residuals: -0.106\n",
      "Loss: 3.005, Residuals: -0.106\n",
      "Loss: 3.005, Residuals: -0.107\n",
      "Loss: 3.004, Residuals: -0.106\n",
      "Loss: 3.003, Residuals: -0.106\n",
      "Loss: 3.001, Residuals: -0.107\n",
      "Loss: 2.998, Residuals: -0.108\n",
      "Loss: 2.998, Residuals: -0.105\n",
      "Loss: 2.997, Residuals: -0.107\n",
      "Loss: 2.997, Residuals: -0.107\n",
      "Loss: 2.997, Residuals: -0.109\n",
      "Loss: 2.995, Residuals: -0.109\n",
      "Loss: 2.995, Residuals: -0.107\n",
      "Loss: 2.995, Residuals: -0.108\n",
      "Loss: 2.994, Residuals: -0.108\n",
      "Loss: 2.988, Residuals: -0.107\n",
      "Loss: 2.988, Residuals: -0.106\n",
      "Loss: 2.988, Residuals: -0.106\n",
      "Loss: 2.988, Residuals: -0.107\n",
      "Loss: 2.988, Residuals: -0.107\n",
      "Loss: 2.988, Residuals: -0.107\n",
      "Loss: 2.986, Residuals: -0.106\n",
      "Loss: 2.986, Residuals: -0.106\n",
      "Loss: 2.986, Residuals: -0.106\n",
      "Loss: 2.986, Residuals: -0.106\n",
      "Loss: 2.983, Residuals: -0.106\n",
      "Loss: 2.983, Residuals: -0.106\n",
      "Loss: 2.983, Residuals: -0.106\n",
      "Loss: 2.983, Residuals: -0.106\n",
      "Loss: 2.980, Residuals: -0.107\n",
      "Loss: 2.980, Residuals: -0.106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.980, Residuals: -0.106\n",
      "Loss: 2.977, Residuals: -0.106\n",
      "Loss: 2.977, Residuals: -0.106\n",
      "Loss: 2.977, Residuals: -0.106\n",
      "Loss: 2.977, Residuals: -0.106\n",
      "Loss: 2.974, Residuals: -0.106\n",
      "Loss: 2.974, Residuals: -0.106\n",
      "Loss: 2.974, Residuals: -0.106\n",
      "Loss: 2.974, Residuals: -0.106\n",
      "Loss: 2.974, Residuals: -0.106\n",
      "Loss: 2.974, Residuals: -0.106\n",
      "Loss: 2.973, Residuals: -0.106\n",
      "Loss: 2.971, Residuals: -0.106\n",
      "Loss: 2.971, Residuals: -0.106\n",
      "Loss: 2.971, Residuals: -0.106\n",
      "Loss: 2.971, Residuals: -0.106\n",
      "Loss: 2.970, Residuals: -0.106\n",
      "Loss: 2.970, Residuals: -0.106\n",
      "Loss: 2.970, Residuals: -0.106\n",
      "Loss: 2.970, Residuals: -0.106\n",
      "Evidence -387.953\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.15e-04\n",
      "Loss: 13.600, Residuals: -0.110\n",
      "Loss: 13.415, Residuals: -0.097\n",
      "Loss: 13.282, Residuals: -0.072\n",
      "Loss: 13.267, Residuals: -0.064\n",
      "Loss: 13.258, Residuals: -0.067\n",
      "Loss: 13.243, Residuals: -0.071\n",
      "Loss: 13.218, Residuals: -0.073\n",
      "Loss: 13.213, Residuals: -0.070\n",
      "Loss: 13.168, Residuals: -0.069\n",
      "Loss: 13.094, Residuals: -0.066\n",
      "Loss: 13.093, Residuals: -0.065\n",
      "Loss: 13.074, Residuals: -0.064\n",
      "Loss: 13.041, Residuals: -0.062\n",
      "Loss: 13.039, Residuals: -0.066\n",
      "Loss: 12.985, Residuals: -0.063\n",
      "Loss: 12.983, Residuals: -0.063\n",
      "Loss: 12.979, Residuals: -0.062\n",
      "Loss: 12.978, Residuals: -0.062\n",
      "Loss: 12.975, Residuals: -0.061\n",
      "Loss: 12.975, Residuals: -0.061\n",
      "Loss: 12.975, Residuals: -0.061\n",
      "Loss: 12.920, Residuals: -0.060\n",
      "Loss: 12.918, Residuals: -0.058\n",
      "Loss: 12.916, Residuals: -0.059\n",
      "Loss: 12.916, Residuals: -0.059\n",
      "Loss: 12.916, Residuals: -0.059\n",
      "Loss: 12.916, Residuals: -0.059\n",
      "Loss: 12.916, Residuals: -0.059\n",
      "Loss: 12.888, Residuals: -0.057\n",
      "Loss: 12.888, Residuals: -0.057\n",
      "Loss: 12.861, Residuals: -0.055\n",
      "Loss: 12.861, Residuals: -0.054\n",
      "Loss: 12.860, Residuals: -0.054\n",
      "Loss: 12.823, Residuals: -0.051\n",
      "Loss: 12.823, Residuals: -0.051\n",
      "Loss: 12.822, Residuals: -0.051\n",
      "Loss: 12.821, Residuals: -0.051\n",
      "Loss: 12.819, Residuals: -0.050\n",
      "Loss: 12.818, Residuals: -0.051\n",
      "Loss: 12.818, Residuals: -0.051\n",
      "Loss: 12.818, Residuals: -0.051\n",
      "Loss: 12.818, Residuals: -0.051\n",
      "Evidence 105.896\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.85e-03\n",
      "Loss: 44.713, Residuals: -0.059\n",
      "Loss: 44.403, Residuals: -0.044\n",
      "Loss: 44.394, Residuals: -0.040\n",
      "Loss: 44.382, Residuals: -0.040\n",
      "Loss: 44.377, Residuals: -0.041\n",
      "Loss: 44.184, Residuals: -0.039\n",
      "Loss: 44.182, Residuals: -0.038\n",
      "Loss: 44.179, Residuals: -0.038\n",
      "Loss: 44.072, Residuals: -0.037\n",
      "Loss: 43.894, Residuals: -0.034\n",
      "Loss: 43.851, Residuals: -0.033\n",
      "Loss: 43.516, Residuals: -0.028\n",
      "Loss: 43.510, Residuals: -0.027\n",
      "Loss: 43.498, Residuals: -0.027\n",
      "Loss: 43.488, Residuals: -0.028\n",
      "Loss: 43.138, Residuals: -0.023\n",
      "Loss: 43.128, Residuals: -0.023\n",
      "Loss: 43.111, Residuals: -0.024\n",
      "Loss: 43.107, Residuals: -0.022\n",
      "Loss: 42.968, Residuals: -0.020\n",
      "Loss: 42.967, Residuals: -0.019\n",
      "Loss: 42.960, Residuals: -0.019\n",
      "Loss: 42.946, Residuals: -0.019\n",
      "Loss: 42.924, Residuals: -0.019\n",
      "Loss: 42.917, Residuals: -0.018\n",
      "Loss: 42.647, Residuals: -0.017\n",
      "Loss: 42.645, Residuals: -0.018\n",
      "Loss: 42.641, Residuals: -0.017\n",
      "Loss: 42.634, Residuals: -0.017\n",
      "Loss: 42.628, Residuals: -0.016\n",
      "Loss: 42.625, Residuals: -0.019\n",
      "Loss: 42.624, Residuals: -0.016\n",
      "Loss: 42.623, Residuals: -0.017\n",
      "Loss: 42.623, Residuals: -0.017\n",
      "Loss: 42.623, Residuals: -0.017\n",
      "Loss: 42.392, Residuals: -0.014\n",
      "Loss: 42.389, Residuals: -0.014\n",
      "Loss: 42.387, Residuals: -0.015\n",
      "Loss: 42.383, Residuals: -0.015\n",
      "Loss: 42.342, Residuals: -0.014\n",
      "Loss: 42.342, Residuals: -0.013\n",
      "Loss: 42.342, Residuals: -0.013\n",
      "Loss: 42.339, Residuals: -0.013\n",
      "Loss: 42.231, Residuals: -0.010\n",
      "Loss: 42.230, Residuals: -0.009\n",
      "Loss: 42.229, Residuals: -0.010\n",
      "Loss: 42.227, Residuals: -0.010\n",
      "Loss: 42.224, Residuals: -0.010\n",
      "Loss: 42.219, Residuals: -0.011\n",
      "Loss: 42.218, Residuals: -0.011\n",
      "Loss: 42.218, Residuals: -0.011\n",
      "Loss: 42.217, Residuals: -0.011\n",
      "Loss: 42.217, Residuals: -0.011\n",
      "Loss: 42.146, Residuals: -0.009\n",
      "Loss: 42.145, Residuals: -0.010\n",
      "Loss: 42.113, Residuals: -0.008\n",
      "Loss: 42.111, Residuals: -0.009\n",
      "Loss: 42.111, Residuals: -0.009\n",
      "Loss: 42.110, Residuals: -0.009\n",
      "Loss: 42.085, Residuals: -0.007\n",
      "Loss: 42.083, Residuals: -0.008\n",
      "Loss: 42.083, Residuals: -0.008\n",
      "Loss: 42.082, Residuals: -0.008\n",
      "Loss: 42.082, Residuals: -0.008\n",
      "Loss: 42.071, Residuals: -0.007\n",
      "Loss: 42.071, Residuals: -0.007\n",
      "Loss: 42.065, Residuals: -0.007\n",
      "Loss: 42.055, Residuals: -0.006\n",
      "Loss: 42.055, Residuals: -0.007\n",
      "Loss: 42.054, Residuals: -0.007\n",
      "Loss: 42.048, Residuals: -0.006\n",
      "Loss: 42.047, Residuals: -0.006\n",
      "Loss: 42.047, Residuals: -0.006\n",
      "Loss: 42.044, Residuals: -0.006\n",
      "Loss: 42.044, Residuals: -0.006\n",
      "Loss: 42.044, Residuals: -0.006\n",
      "Evidence 312.694\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.49e-02\n",
      "Loss: 92.022, Residuals: -0.020\n",
      "Loss: 91.778, Residuals: -0.012\n",
      "Loss: 91.749, Residuals: -0.013\n",
      "Loss: 91.708, Residuals: -0.010\n",
      "Loss: 91.649, Residuals: -0.012\n",
      "Loss: 91.608, Residuals: -0.010\n",
      "Loss: 91.271, Residuals: -0.007\n",
      "Loss: 91.266, Residuals: -0.005\n",
      "Loss: 91.087, Residuals: -0.004\n",
      "Loss: 91.059, Residuals: -0.003\n",
      "Loss: 91.054, Residuals: -0.005\n",
      "Loss: 91.012, Residuals: -0.004\n",
      "Loss: 91.010, Residuals: -0.003\n",
      "Loss: 91.010, Residuals: -0.003\n",
      "Loss: 90.938, Residuals: -0.002\n",
      "Loss: 90.937, Residuals: -0.002\n",
      "Evidence 422.315\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.73e-02\n",
      "Loss: 132.134, Residuals: -0.009\n",
      "Loss: 131.886, Residuals: -0.007\n",
      "Loss: 131.873, Residuals: -0.007\n",
      "Loss: 131.848, Residuals: -0.008\n",
      "Loss: 131.801, Residuals: -0.008\n",
      "Loss: 131.719, Residuals: -0.009\n",
      "Loss: 131.576, Residuals: -0.009\n",
      "Loss: 131.367, Residuals: -0.007\n",
      "Loss: 131.360, Residuals: -0.007\n",
      "Loss: 131.292, Residuals: -0.007\n",
      "Loss: 131.191, Residuals: -0.005\n",
      "Loss: 131.190, Residuals: -0.006\n",
      "Loss: 131.188, Residuals: -0.006\n",
      "Loss: 131.170, Residuals: -0.006\n",
      "Loss: 131.167, Residuals: -0.006\n",
      "Loss: 131.137, Residuals: -0.006\n",
      "Loss: 131.137, Residuals: -0.006\n",
      "Evidence 453.377\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.31e-02\n",
      "Loss: 150.144, Residuals: -0.010\n",
      "Loss: 150.041, Residuals: -0.007\n",
      "Loss: 150.029, Residuals: -0.009\n",
      "Loss: 149.916, Residuals: -0.009\n",
      "Loss: 149.766, Residuals: -0.009\n",
      "Loss: 149.765, Residuals: -0.009\n",
      "Evidence 459.781\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.82e-02\n",
      "Loss: 156.302, Residuals: -0.012\n",
      "Loss: 156.225, Residuals: -0.012\n",
      "Loss: 156.219, Residuals: -0.012\n",
      "Loss: 156.160, Residuals: -0.011\n",
      "Loss: 156.065, Residuals: -0.011\n",
      "Loss: 156.063, Residuals: -0.011\n",
      "Loss: 155.989, Residuals: -0.011\n",
      "Loss: 155.988, Residuals: -0.011\n",
      "Loss: 155.900, Residuals: -0.010\n",
      "Loss: 155.900, Residuals: -0.011\n",
      "Evidence 460.852\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.05e-02\n",
      "Loss: 158.138, Residuals: -0.011\n",
      "Loss: 158.131, Residuals: -0.011\n",
      "Loss: 158.067, Residuals: -0.011\n",
      "Loss: 158.064, Residuals: -0.011\n",
      "Loss: 157.971, Residuals: -0.011\n",
      "Loss: 157.970, Residuals: -0.011\n",
      "Loss: 157.925, Residuals: -0.011\n",
      "Loss: 157.925, Residuals: -0.011\n",
      "Evidence 461.463\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.11e-02\n",
      "Loss: 158.660, Residuals: -0.009\n",
      "Loss: 158.655, Residuals: -0.010\n",
      "Loss: 158.647, Residuals: -0.010\n",
      "Loss: 158.634, Residuals: -0.010\n",
      "Loss: 158.631, Residuals: -0.010\n",
      "Loss: 158.626, Residuals: -0.010\n",
      "Loss: 158.584, Residuals: -0.011\n",
      "Loss: 158.581, Residuals: -0.010\n",
      "Loss: 158.580, Residuals: -0.010\n",
      "Loss: 158.540, Residuals: -0.010\n",
      "Loss: 158.534, Residuals: -0.011\n",
      "Loss: 158.532, Residuals: -0.011\n",
      "Loss: 158.532, Residuals: -0.011\n",
      "Loss: 158.419, Residuals: -0.011\n",
      "Loss: 158.416, Residuals: -0.011\n",
      "Loss: 158.410, Residuals: -0.011\n",
      "Loss: 158.401, Residuals: -0.012\n",
      "Loss: 158.397, Residuals: -0.011\n",
      "Loss: 158.390, Residuals: -0.012\n",
      "Loss: 158.386, Residuals: -0.012\n",
      "Loss: 158.379, Residuals: -0.012\n",
      "Loss: 158.369, Residuals: -0.012\n",
      "Loss: 158.364, Residuals: -0.012\n",
      "Loss: 158.324, Residuals: -0.013\n",
      "Loss: 158.300, Residuals: -0.013\n",
      "Loss: 158.254, Residuals: -0.012\n",
      "Loss: 157.826, Residuals: -0.011\n",
      "Loss: 157.674, Residuals: -0.017\n",
      "Loss: 157.424, Residuals: -0.017\n",
      "Loss: 157.403, Residuals: -0.016\n",
      "Loss: 157.202, Residuals: -0.015\n",
      "Loss: 156.860, Residuals: -0.014\n",
      "Loss: 156.858, Residuals: -0.015\n",
      "Loss: 156.550, Residuals: -0.013\n",
      "Loss: 156.337, Residuals: -0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 156.332, Residuals: -0.011\n",
      "Loss: 156.327, Residuals: -0.011\n",
      "Loss: 156.283, Residuals: -0.011\n",
      "Loss: 156.215, Residuals: -0.010\n",
      "Loss: 156.212, Residuals: -0.010\n",
      "Loss: 156.211, Residuals: -0.010\n",
      "Loss: 156.199, Residuals: -0.010\n",
      "Loss: 156.181, Residuals: -0.009\n",
      "Loss: 156.178, Residuals: -0.009\n",
      "Loss: 156.178, Residuals: -0.009\n",
      "Loss: 155.693, Residuals: -0.009\n",
      "Loss: 155.622, Residuals: -0.008\n",
      "Loss: 155.594, Residuals: -0.010\n",
      "Loss: 155.546, Residuals: -0.010\n",
      "Loss: 155.491, Residuals: -0.010\n",
      "Loss: 155.481, Residuals: -0.010\n",
      "Loss: 155.465, Residuals: -0.010\n",
      "Loss: 155.443, Residuals: -0.010\n",
      "Loss: 155.439, Residuals: -0.010\n",
      "Loss: 154.845, Residuals: -0.010\n",
      "Loss: 154.789, Residuals: -0.009\n",
      "Loss: 154.695, Residuals: -0.010\n",
      "Loss: 154.563, Residuals: -0.011\n",
      "Loss: 154.463, Residuals: -0.009\n",
      "Loss: 154.458, Residuals: -0.009\n",
      "Loss: 154.415, Residuals: -0.009\n",
      "Loss: 152.717, Residuals: -0.008\n",
      "Loss: 152.627, Residuals: -0.005\n",
      "Loss: 152.519, Residuals: -0.002\n",
      "Loss: 152.421, Residuals: -0.006\n",
      "Loss: 152.360, Residuals: -0.004\n",
      "Loss: 152.300, Residuals: -0.004\n",
      "Loss: 152.295, Residuals: -0.004\n",
      "Loss: 152.240, Residuals: -0.004\n",
      "Loss: 152.147, Residuals: -0.004\n",
      "Loss: 152.143, Residuals: -0.003\n",
      "Loss: 152.106, Residuals: -0.003\n",
      "Loss: 152.103, Residuals: -0.003\n",
      "Loss: 152.074, Residuals: -0.003\n",
      "Loss: 152.027, Residuals: -0.003\n",
      "Loss: 152.026, Residuals: -0.002\n",
      "Loss: 152.024, Residuals: -0.003\n",
      "Loss: 151.966, Residuals: -0.002\n",
      "Loss: 151.965, Residuals: -0.002\n",
      "Loss: 151.964, Residuals: -0.002\n",
      "Loss: 151.961, Residuals: -0.002\n",
      "Loss: 151.957, Residuals: -0.002\n",
      "Loss: 151.956, Residuals: -0.002\n",
      "Loss: 151.949, Residuals: -0.002\n",
      "Loss: 151.944, Residuals: -0.001\n",
      "Loss: 151.944, Residuals: -0.001\n",
      "Loss: 151.943, Residuals: -0.001\n",
      "Loss: 151.938, Residuals: -0.001\n",
      "Loss: 151.938, Residuals: -0.001\n",
      "Loss: 151.930, Residuals: -0.001\n",
      "Loss: 151.930, Residuals: -0.001\n",
      "Evidence 468.922\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.30e-01\n",
      "Loss: 156.247, Residuals: 0.010\n",
      "Loss: 155.368, Residuals: 0.011\n",
      "Loss: 155.258, Residuals: 0.010\n",
      "Loss: 154.439, Residuals: 0.013\n",
      "Loss: 154.173, Residuals: 0.014\n",
      "Loss: 154.104, Residuals: 0.009\n",
      "Loss: 153.973, Residuals: 0.009\n",
      "Loss: 153.915, Residuals: 0.009\n",
      "Loss: 153.380, Residuals: 0.010\n",
      "Loss: 153.341, Residuals: 0.010\n",
      "Loss: 152.976, Residuals: 0.012\n",
      "Loss: 152.956, Residuals: 0.011\n",
      "Loss: 152.167, Residuals: 0.014\n",
      "Loss: 152.150, Residuals: 0.014\n",
      "Loss: 151.546, Residuals: 0.015\n",
      "Loss: 151.390, Residuals: 0.017\n",
      "Loss: 151.243, Residuals: 0.016\n",
      "Loss: 151.226, Residuals: 0.017\n",
      "Loss: 151.094, Residuals: 0.018\n",
      "Loss: 151.089, Residuals: 0.017\n",
      "Loss: 151.042, Residuals: 0.018\n",
      "Loss: 150.989, Residuals: 0.019\n",
      "Loss: 150.989, Residuals: 0.019\n",
      "Evidence 477.560\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.37e+00\n",
      "Loss: 154.730, Residuals: 0.029\n",
      "Loss: 154.539, Residuals: 0.027\n",
      "Loss: 154.345, Residuals: 0.027\n",
      "Loss: 154.333, Residuals: 0.026\n",
      "Loss: 154.311, Residuals: 0.026\n",
      "Loss: 154.273, Residuals: 0.027\n",
      "Loss: 154.232, Residuals: 0.027\n",
      "Loss: 154.231, Residuals: 0.027\n",
      "Loss: 154.229, Residuals: 0.027\n",
      "Loss: 154.225, Residuals: 0.027\n",
      "Loss: 154.220, Residuals: 0.027\n",
      "Loss: 154.215, Residuals: 0.027\n",
      "Loss: 154.215, Residuals: 0.027\n",
      "Evidence 488.305\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.49e+00\n",
      "Loss: 156.525, Residuals: 0.028\n",
      "Loss: 156.499, Residuals: 0.028\n",
      "Loss: 156.462, Residuals: 0.028\n",
      "Loss: 156.421, Residuals: 0.028\n",
      "Loss: 156.418, Residuals: 0.029\n",
      "Loss: 156.414, Residuals: 0.029\n",
      "Loss: 156.409, Residuals: 0.028\n",
      "Loss: 156.408, Residuals: 0.028\n",
      "Loss: 156.407, Residuals: 0.028\n",
      "Loss: 156.405, Residuals: 0.029\n",
      "Loss: 156.405, Residuals: 0.029\n",
      "Loss: 156.405, Residuals: 0.029\n",
      "Loss: 156.405, Residuals: 0.029\n",
      "Loss: 156.405, Residuals: 0.028\n",
      "Loss: 156.405, Residuals: 0.028\n",
      "Loss: 156.405, Residuals: 0.028\n",
      "Loss: 156.405, Residuals: 0.028\n",
      "Loss: 156.405, Residuals: 0.028\n",
      "Loss: 156.405, Residuals: 0.028\n",
      "Loss: 156.405, Residuals: 0.028\n",
      "Evidence 490.652\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.49e+00\n",
      "Loss: 157.393, Residuals: 0.028\n",
      "Loss: 157.370, Residuals: 0.029\n",
      "Loss: 157.348, Residuals: 0.028\n",
      "Loss: 157.346, Residuals: 0.028\n",
      "Loss: 157.345, Residuals: 0.028\n",
      "Loss: 157.343, Residuals: 0.028\n",
      "Loss: 157.340, Residuals: 0.028\n",
      "Loss: 157.336, Residuals: 0.028\n",
      "Loss: 157.336, Residuals: 0.028\n",
      "Loss: 157.335, Residuals: 0.028\n",
      "Loss: 157.335, Residuals: 0.028\n",
      "Loss: 157.335, Residuals: 0.028\n",
      "Loss: 157.335, Residuals: 0.028\n",
      "Loss: 157.334, Residuals: 0.028\n",
      "Loss: 157.334, Residuals: 0.028\n",
      "Loss: 157.334, Residuals: 0.028\n",
      "Evidence 491.930\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.47e+00\n",
      "Loss: 157.817, Residuals: 0.028\n",
      "Loss: 157.804, Residuals: 0.028\n",
      "Loss: 157.800, Residuals: 0.028\n",
      "Loss: 157.793, Residuals: 0.028\n",
      "Loss: 157.784, Residuals: 0.028\n",
      "Loss: 157.783, Residuals: 0.028\n",
      "Loss: 157.783, Residuals: 0.028\n",
      "Loss: 157.783, Residuals: 0.028\n",
      "Loss: 157.782, Residuals: 0.028\n",
      "Loss: 157.782, Residuals: 0.028\n",
      "Loss: 157.782, Residuals: 0.028\n",
      "Evidence 492.764\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.46e+00\n",
      "Loss: 158.062, Residuals: 0.028\n",
      "Loss: 158.053, Residuals: 0.028\n",
      "Loss: 158.050, Residuals: 0.027\n",
      "Loss: 158.046, Residuals: 0.027\n",
      "Loss: 158.040, Residuals: 0.027\n",
      "Loss: 158.040, Residuals: 0.027\n",
      "Loss: 158.040, Residuals: 0.027\n",
      "Loss: 158.039, Residuals: 0.027\n",
      "Loss: 158.039, Residuals: 0.027\n",
      "Loss: 158.039, Residuals: 0.027\n",
      "Loss: 158.039, Residuals: 0.027\n",
      "Loss: 158.038, Residuals: 0.027\n",
      "Evidence 493.344\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.44e+00\n",
      "Loss: 158.228, Residuals: 0.027\n",
      "Loss: 158.221, Residuals: 0.027\n",
      "Loss: 158.218, Residuals: 0.027\n",
      "Loss: 158.215, Residuals: 0.027\n",
      "Loss: 158.212, Residuals: 0.027\n",
      "Loss: 158.212, Residuals: 0.027\n",
      "Loss: 158.212, Residuals: 0.027\n",
      "Loss: 158.212, Residuals: 0.027\n",
      "Loss: 158.212, Residuals: 0.027\n",
      "Evidence 493.747\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.919, Residuals: -0.081\n",
      "Loss: 8.051, Residuals: -0.049\n",
      "Loss: 5.600, Residuals: -0.042\n",
      "Loss: 4.990, Residuals: -0.036\n",
      "Loss: 4.828, Residuals: -0.037\n",
      "Loss: 4.563, Residuals: -0.006\n",
      "Loss: 4.238, Residuals: -0.029\n",
      "Loss: 4.214, Residuals: -0.008\n",
      "Loss: 4.030, Residuals: -0.024\n",
      "Loss: 4.021, Residuals: -0.025\n",
      "Loss: 3.942, Residuals: -0.029\n",
      "Loss: 3.806, Residuals: -0.039\n",
      "Loss: 3.754, Residuals: -0.023\n",
      "Loss: 3.742, Residuals: -0.019\n",
      "Loss: 3.646, Residuals: -0.027\n",
      "Loss: 3.636, Residuals: -0.013\n",
      "Loss: 3.546, Residuals: -0.024\n",
      "Loss: 3.541, Residuals: -0.019\n",
      "Loss: 3.493, Residuals: -0.027\n",
      "Loss: 3.468, Residuals: -0.025\n",
      "Loss: 3.463, Residuals: -0.026\n",
      "Loss: 3.456, Residuals: -0.018\n",
      "Loss: 3.444, Residuals: -0.022\n",
      "Loss: 3.438, Residuals: -0.026\n",
      "Loss: 3.428, Residuals: -0.028\n",
      "Loss: 3.426, Residuals: -0.025\n",
      "Loss: 3.407, Residuals: -0.030\n",
      "Loss: 3.406, Residuals: -0.029\n",
      "Loss: 3.394, Residuals: -0.033\n",
      "Loss: 3.384, Residuals: -0.037\n",
      "Loss: 3.381, Residuals: -0.039\n",
      "Loss: 3.379, Residuals: -0.037\n",
      "Loss: 3.376, Residuals: -0.034\n",
      "Loss: 3.355, Residuals: -0.041\n",
      "Loss: 3.353, Residuals: -0.038\n",
      "Loss: 3.352, Residuals: -0.037\n",
      "Loss: 3.330, Residuals: -0.047\n",
      "Loss: 3.329, Residuals: -0.047\n",
      "Loss: 3.329, Residuals: -0.048\n",
      "Loss: 3.323, Residuals: -0.049\n",
      "Loss: 3.323, Residuals: -0.049\n",
      "Evidence -416.488\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.95e-02\n",
      "Loss: 15.281, Residuals: -0.050\n",
      "Loss: 14.888, Residuals: -0.036\n",
      "Loss: 14.689, Residuals: -0.011\n",
      "Loss: 14.679, Residuals: -0.012\n",
      "Loss: 14.679, Residuals: -0.012\n",
      "Evidence 115.822\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.08e-01\n",
      "Loss: 46.501, Residuals: -0.012\n",
      "Loss: 46.352, Residuals: -0.007\n",
      "Loss: 46.071, Residuals: -0.004\n",
      "Loss: 45.612, Residuals: 0.003\n",
      "Loss: 45.593, Residuals: 0.006\n",
      "Loss: 45.418, Residuals: 0.009\n",
      "Loss: 45.375, Residuals: 0.011\n",
      "Loss: 45.295, Residuals: 0.012\n",
      "Loss: 45.152, Residuals: 0.015\n",
      "Loss: 45.149, Residuals: 0.013\n",
      "Loss: 45.019, Residuals: 0.017\n",
      "Loss: 44.916, Residuals: 0.023\n",
      "Loss: 44.915, Residuals: 0.022\n",
      "Loss: 44.906, Residuals: 0.022\n",
      "Loss: 44.899, Residuals: 0.022\n",
      "Loss: 44.899, Residuals: 0.022\n",
      "Evidence 312.343\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.14e-01\n",
      "Loss: 92.352, Residuals: 0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 92.059, Residuals: 0.022\n",
      "Loss: 91.616, Residuals: 0.020\n",
      "Loss: 91.353, Residuals: 0.014\n",
      "Loss: 90.994, Residuals: 0.019\n",
      "Loss: 90.991, Residuals: 0.019\n",
      "Loss: 90.960, Residuals: 0.019\n",
      "Loss: 90.687, Residuals: 0.020\n",
      "Loss: 90.672, Residuals: 0.020\n",
      "Loss: 90.527, Residuals: 0.021\n",
      "Loss: 90.526, Residuals: 0.022\n",
      "Loss: 90.309, Residuals: 0.024\n",
      "Loss: 90.303, Residuals: 0.023\n",
      "Loss: 90.238, Residuals: 0.024\n",
      "Loss: 90.229, Residuals: 0.024\n",
      "Loss: 90.215, Residuals: 0.024\n",
      "Loss: 90.214, Residuals: 0.024\n",
      "Loss: 90.029, Residuals: 0.026\n",
      "Loss: 90.010, Residuals: 0.026\n",
      "Loss: 89.988, Residuals: 0.025\n",
      "Loss: 89.984, Residuals: 0.025\n",
      "Loss: 89.847, Residuals: 0.027\n",
      "Loss: 89.838, Residuals: 0.027\n",
      "Loss: 89.752, Residuals: 0.028\n",
      "Loss: 89.618, Residuals: 0.029\n",
      "Loss: 89.609, Residuals: 0.029\n",
      "Loss: 89.600, Residuals: 0.029\n",
      "Loss: 89.599, Residuals: 0.029\n",
      "Loss: 89.585, Residuals: 0.029\n",
      "Loss: 89.565, Residuals: 0.030\n",
      "Loss: 89.565, Residuals: 0.030\n",
      "Loss: 89.563, Residuals: 0.030\n",
      "Loss: 89.561, Residuals: 0.030\n",
      "Loss: 89.559, Residuals: 0.030\n",
      "Loss: 89.559, Residuals: 0.030\n",
      "Loss: 89.559, Residuals: 0.030\n",
      "Loss: 89.559, Residuals: 0.030\n",
      "Loss: 89.558, Residuals: 0.030\n",
      "Loss: 89.558, Residuals: 0.030\n",
      "Loss: 89.558, Residuals: 0.030\n",
      "Evidence 423.379\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.56e+00\n",
      "Loss: 129.289, Residuals: 0.029\n",
      "Loss: 128.935, Residuals: 0.034\n",
      "Loss: 128.830, Residuals: 0.027\n",
      "Loss: 128.643, Residuals: 0.028\n",
      "Loss: 128.411, Residuals: 0.030\n",
      "Loss: 128.373, Residuals: 0.028\n",
      "Loss: 128.304, Residuals: 0.028\n",
      "Loss: 128.213, Residuals: 0.028\n",
      "Loss: 128.209, Residuals: 0.028\n",
      "Loss: 128.208, Residuals: 0.028\n",
      "Loss: 128.197, Residuals: 0.028\n",
      "Loss: 128.186, Residuals: 0.028\n",
      "Loss: 128.186, Residuals: 0.028\n",
      "Loss: 128.186, Residuals: 0.027\n",
      "Loss: 128.185, Residuals: 0.027\n",
      "Loss: 128.185, Residuals: 0.027\n",
      "Evidence 463.966\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.79e+00\n",
      "Loss: 147.965, Residuals: 0.032\n",
      "Loss: 147.700, Residuals: 0.029\n",
      "Loss: 147.649, Residuals: 0.029\n",
      "Loss: 147.556, Residuals: 0.028\n",
      "Loss: 147.409, Residuals: 0.027\n",
      "Loss: 147.270, Residuals: 0.025\n",
      "Loss: 147.263, Residuals: 0.025\n",
      "Loss: 147.256, Residuals: 0.024\n",
      "Loss: 147.254, Residuals: 0.024\n",
      "Loss: 147.251, Residuals: 0.024\n",
      "Loss: 147.251, Residuals: 0.024\n",
      "Loss: 147.250, Residuals: 0.024\n",
      "Loss: 147.248, Residuals: 0.024\n",
      "Loss: 147.247, Residuals: 0.024\n",
      "Loss: 147.247, Residuals: 0.024\n",
      "Loss: 147.247, Residuals: 0.024\n",
      "Evidence 474.648\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.76e+00\n",
      "Loss: 153.987, Residuals: 0.031\n",
      "Loss: 153.871, Residuals: 0.024\n",
      "Loss: 153.749, Residuals: 0.024\n",
      "Loss: 153.700, Residuals: 0.024\n",
      "Loss: 153.627, Residuals: 0.023\n",
      "Loss: 153.618, Residuals: 0.023\n",
      "Loss: 153.603, Residuals: 0.023\n",
      "Loss: 153.579, Residuals: 0.022\n",
      "Loss: 153.564, Residuals: 0.022\n",
      "Loss: 153.563, Residuals: 0.022\n",
      "Loss: 153.562, Residuals: 0.022\n",
      "Loss: 153.561, Residuals: 0.022\n",
      "Loss: 153.561, Residuals: 0.022\n",
      "Loss: 153.560, Residuals: 0.022\n",
      "Loss: 153.560, Residuals: 0.022\n",
      "Evidence 479.045\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.66e+00\n",
      "Loss: 155.864, Residuals: 0.026\n",
      "Loss: 155.812, Residuals: 0.025\n",
      "Loss: 155.752, Residuals: 0.022\n",
      "Loss: 155.681, Residuals: 0.021\n",
      "Loss: 155.677, Residuals: 0.021\n",
      "Loss: 155.675, Residuals: 0.021\n",
      "Loss: 155.661, Residuals: 0.021\n",
      "Loss: 155.652, Residuals: 0.020\n",
      "Loss: 155.651, Residuals: 0.020\n",
      "Loss: 155.650, Residuals: 0.020\n",
      "Loss: 155.648, Residuals: 0.020\n",
      "Loss: 155.646, Residuals: 0.020\n",
      "Loss: 155.646, Residuals: 0.020\n",
      "Evidence 481.772\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.57e+00\n",
      "Loss: 156.694, Residuals: 0.022\n",
      "Loss: 156.666, Residuals: 0.022\n",
      "Loss: 156.643, Residuals: 0.021\n",
      "Loss: 156.633, Residuals: 0.020\n",
      "Loss: 156.617, Residuals: 0.020\n",
      "Loss: 156.593, Residuals: 0.019\n",
      "Loss: 156.589, Residuals: 0.018\n",
      "Loss: 156.581, Residuals: 0.018\n",
      "Loss: 156.581, Residuals: 0.019\n",
      "Loss: 156.577, Residuals: 0.019\n",
      "Loss: 156.577, Residuals: 0.019\n",
      "Loss: 156.576, Residuals: 0.019\n",
      "Loss: 156.575, Residuals: 0.019\n",
      "Loss: 156.575, Residuals: 0.019\n",
      "Evidence 483.523\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.50e+00\n",
      "Loss: 157.189, Residuals: 0.020\n",
      "Loss: 157.171, Residuals: 0.019\n",
      "Loss: 157.151, Residuals: 0.019\n",
      "Loss: 157.137, Residuals: 0.018\n",
      "Loss: 157.136, Residuals: 0.017\n",
      "Loss: 157.134, Residuals: 0.018\n",
      "Loss: 157.133, Residuals: 0.018\n",
      "Loss: 157.130, Residuals: 0.018\n",
      "Loss: 157.130, Residuals: 0.018\n",
      "Loss: 157.129, Residuals: 0.018\n",
      "Loss: 157.129, Residuals: 0.018\n",
      "Loss: 157.129, Residuals: 0.018\n",
      "Evidence 484.617\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.47e+00\n",
      "Loss: 157.539, Residuals: 0.018\n",
      "Loss: 157.531, Residuals: 0.018\n",
      "Loss: 157.521, Residuals: 0.018\n",
      "Loss: 157.518, Residuals: 0.017\n",
      "Loss: 157.516, Residuals: 0.017\n",
      "Loss: 157.515, Residuals: 0.017\n",
      "Loss: 157.515, Residuals: 0.017\n",
      "Loss: 157.514, Residuals: 0.017\n",
      "Loss: 157.513, Residuals: 0.017\n",
      "Loss: 157.513, Residuals: 0.017\n",
      "Loss: 157.513, Residuals: 0.017\n",
      "Loss: 157.512, Residuals: 0.017\n",
      "Evidence 485.300\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.45e+00\n",
      "Loss: 157.798, Residuals: 0.018\n",
      "Loss: 157.789, Residuals: 0.018\n",
      "Loss: 157.788, Residuals: 0.017\n",
      "Loss: 157.786, Residuals: 0.017\n",
      "Loss: 157.784, Residuals: 0.017\n",
      "Loss: 157.783, Residuals: 0.017\n",
      "Loss: 157.783, Residuals: 0.017\n",
      "Evidence 485.744\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 13.883, Residuals: -0.031\n",
      "Loss: 7.867, Residuals: -0.037\n",
      "Loss: 6.589, Residuals: -0.031\n",
      "Loss: 5.809, Residuals: 0.005\n",
      "Loss: 4.964, Residuals: -0.015\n",
      "Loss: 4.693, Residuals: 0.075\n",
      "Loss: 4.640, Residuals: 0.045\n",
      "Loss: 4.211, Residuals: 0.027\n",
      "Loss: 4.193, Residuals: 0.047\n",
      "Loss: 4.031, Residuals: 0.027\n",
      "Loss: 3.923, Residuals: 0.013\n",
      "Loss: 3.880, Residuals: 0.036\n",
      "Loss: 3.801, Residuals: 0.025\n",
      "Loss: 3.665, Residuals: 0.005\n",
      "Loss: 3.659, Residuals: 0.011\n",
      "Loss: 3.605, Residuals: 0.002\n",
      "Loss: 3.514, Residuals: -0.011\n",
      "Loss: 3.510, Residuals: -0.006\n",
      "Loss: 3.477, Residuals: -0.008\n",
      "Loss: 3.472, Residuals: -0.001\n",
      "Loss: 3.419, Residuals: -0.007\n",
      "Loss: 3.417, Residuals: -0.002\n",
      "Loss: 3.355, Residuals: -0.011\n",
      "Loss: 3.345, Residuals: -0.002\n",
      "Loss: 3.264, Residuals: -0.019\n",
      "Loss: 3.259, Residuals: -0.012\n",
      "Loss: 3.226, Residuals: -0.022\n",
      "Loss: 3.222, Residuals: -0.011\n",
      "Loss: 3.193, Residuals: -0.019\n",
      "Loss: 3.187, Residuals: -0.023\n",
      "Loss: 3.175, Residuals: -0.026\n",
      "Loss: 3.153, Residuals: -0.032\n",
      "Loss: 3.152, Residuals: -0.032\n",
      "Loss: 3.122, Residuals: -0.041\n",
      "Loss: 3.122, Residuals: -0.040\n",
      "Loss: 3.122, Residuals: -0.039\n",
      "Loss: 3.113, Residuals: -0.041\n",
      "Loss: 3.107, Residuals: -0.044\n",
      "Loss: 3.107, Residuals: -0.044\n",
      "Loss: 3.107, Residuals: -0.044\n",
      "Loss: 3.106, Residuals: -0.042\n",
      "Loss: 3.089, Residuals: -0.048\n",
      "Loss: 3.089, Residuals: -0.048\n",
      "Loss: 3.089, Residuals: -0.047\n",
      "Loss: 3.088, Residuals: -0.046\n",
      "Loss: 3.076, Residuals: -0.050\n",
      "Loss: 3.076, Residuals: -0.050\n",
      "Loss: 3.075, Residuals: -0.050\n",
      "Loss: 3.069, Residuals: -0.053\n",
      "Loss: 3.068, Residuals: -0.051\n",
      "Loss: 3.063, Residuals: -0.050\n",
      "Loss: 3.063, Residuals: -0.051\n",
      "Evidence -404.067\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.61e-02\n",
      "Loss: 13.216, Residuals: -0.034\n",
      "Loss: 13.203, Residuals: -0.031\n",
      "Loss: 13.179, Residuals: -0.031\n",
      "Loss: 13.140, Residuals: -0.029\n",
      "Loss: 13.082, Residuals: -0.031\n",
      "Loss: 12.979, Residuals: -0.026\n",
      "Loss: 12.857, Residuals: -0.011\n",
      "Loss: 12.855, Residuals: -0.012\n",
      "Loss: 12.853, Residuals: -0.013\n",
      "Loss: 12.849, Residuals: -0.012\n",
      "Loss: 12.842, Residuals: -0.013\n",
      "Loss: 12.784, Residuals: -0.008\n",
      "Loss: 12.781, Residuals: -0.008\n",
      "Loss: 12.762, Residuals: -0.006\n",
      "Loss: 12.729, Residuals: -0.003\n",
      "Loss: 12.729, Residuals: -0.003\n",
      "Evidence 96.865\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.02e-01\n",
      "Loss: 41.283, Residuals: -0.004\n",
      "Loss: 41.225, Residuals: -0.004\n",
      "Loss: 41.123, Residuals: -0.002\n",
      "Loss: 40.971, Residuals: 0.001\n",
      "Loss: 40.833, Residuals: 0.004\n",
      "Loss: 40.823, Residuals: 0.004\n",
      "Loss: 40.497, Residuals: 0.007\n",
      "Loss: 40.493, Residuals: 0.007\n",
      "Loss: 40.355, Residuals: 0.009\n",
      "Loss: 40.137, Residuals: 0.015\n",
      "Loss: 40.133, Residuals: 0.014\n",
      "Loss: 40.128, Residuals: 0.015\n",
      "Loss: 40.118, Residuals: 0.015\n",
      "Loss: 40.033, Residuals: 0.016\n",
      "Loss: 40.029, Residuals: 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.027, Residuals: 0.016\n",
      "Loss: 39.958, Residuals: 0.018\n",
      "Loss: 39.958, Residuals: 0.018\n",
      "Evidence 287.199\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.01e-01\n",
      "Loss: 86.299, Residuals: 0.017\n",
      "Loss: 86.079, Residuals: 0.018\n",
      "Loss: 85.791, Residuals: 0.017\n",
      "Loss: 85.393, Residuals: 0.015\n",
      "Loss: 85.383, Residuals: 0.015\n",
      "Loss: 85.367, Residuals: 0.015\n",
      "Loss: 85.336, Residuals: 0.015\n",
      "Loss: 85.064, Residuals: 0.017\n",
      "Loss: 85.012, Residuals: 0.017\n",
      "Loss: 84.913, Residuals: 0.018\n",
      "Loss: 84.734, Residuals: 0.019\n",
      "Loss: 84.454, Residuals: 0.020\n",
      "Loss: 84.440, Residuals: 0.021\n",
      "Loss: 84.428, Residuals: 0.020\n",
      "Loss: 84.324, Residuals: 0.021\n",
      "Loss: 84.321, Residuals: 0.021\n",
      "Loss: 84.222, Residuals: 0.022\n",
      "Loss: 84.214, Residuals: 0.021\n",
      "Loss: 84.211, Residuals: 0.021\n",
      "Loss: 84.089, Residuals: 0.023\n",
      "Loss: 84.078, Residuals: 0.022\n",
      "Loss: 84.076, Residuals: 0.023\n",
      "Loss: 84.008, Residuals: 0.024\n",
      "Loss: 83.999, Residuals: 0.023\n",
      "Loss: 83.994, Residuals: 0.023\n",
      "Loss: 83.951, Residuals: 0.024\n",
      "Loss: 83.948, Residuals: 0.024\n",
      "Loss: 83.835, Residuals: 0.026\n",
      "Loss: 83.801, Residuals: 0.026\n",
      "Loss: 83.796, Residuals: 0.026\n",
      "Loss: 83.787, Residuals: 0.025\n",
      "Loss: 83.771, Residuals: 0.026\n",
      "Loss: 83.768, Residuals: 0.025\n",
      "Loss: 83.739, Residuals: 0.025\n",
      "Loss: 83.738, Residuals: 0.026\n",
      "Loss: 83.727, Residuals: 0.026\n",
      "Loss: 83.709, Residuals: 0.026\n",
      "Loss: 83.708, Residuals: 0.026\n",
      "Loss: 83.705, Residuals: 0.026\n",
      "Loss: 83.700, Residuals: 0.026\n",
      "Loss: 83.699, Residuals: 0.026\n",
      "Loss: 83.696, Residuals: 0.026\n",
      "Loss: 83.696, Residuals: 0.026\n",
      "Loss: 83.695, Residuals: 0.026\n",
      "Loss: 83.695, Residuals: 0.026\n",
      "Loss: 83.694, Residuals: 0.026\n",
      "Loss: 83.694, Residuals: 0.026\n",
      "Loss: 83.694, Residuals: 0.026\n",
      "Loss: 83.694, Residuals: 0.026\n",
      "Loss: 83.694, Residuals: 0.026\n",
      "Loss: 83.694, Residuals: 0.026\n",
      "Evidence 395.799\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.16e+00\n",
      "Loss: 122.919, Residuals: 0.029\n",
      "Loss: 122.530, Residuals: 0.028\n",
      "Loss: 122.284, Residuals: 0.023\n",
      "Loss: 121.896, Residuals: 0.025\n",
      "Loss: 121.863, Residuals: 0.026\n",
      "Loss: 121.800, Residuals: 0.026\n",
      "Loss: 121.687, Residuals: 0.027\n",
      "Loss: 121.529, Residuals: 0.028\n",
      "Loss: 121.518, Residuals: 0.026\n",
      "Loss: 121.497, Residuals: 0.027\n",
      "Loss: 121.467, Residuals: 0.027\n",
      "Loss: 121.466, Residuals: 0.027\n",
      "Loss: 121.457, Residuals: 0.027\n",
      "Loss: 121.456, Residuals: 0.027\n",
      "Loss: 121.455, Residuals: 0.027\n",
      "Loss: 121.453, Residuals: 0.027\n",
      "Loss: 121.453, Residuals: 0.027\n",
      "Loss: 121.453, Residuals: 0.027\n",
      "Loss: 121.452, Residuals: 0.027\n",
      "Loss: 121.452, Residuals: 0.027\n",
      "Loss: 121.452, Residuals: 0.027\n",
      "Loss: 121.452, Residuals: 0.027\n",
      "Evidence 436.156\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.55e+00\n",
      "Loss: 141.455, Residuals: 0.030\n",
      "Loss: 141.215, Residuals: 0.030\n",
      "Loss: 141.038, Residuals: 0.024\n",
      "Loss: 140.849, Residuals: 0.026\n",
      "Loss: 140.842, Residuals: 0.027\n",
      "Loss: 140.780, Residuals: 0.027\n",
      "Loss: 140.680, Residuals: 0.027\n",
      "Loss: 140.670, Residuals: 0.026\n",
      "Loss: 140.653, Residuals: 0.026\n",
      "Loss: 140.623, Residuals: 0.026\n",
      "Loss: 140.620, Residuals: 0.026\n",
      "Loss: 140.601, Residuals: 0.026\n",
      "Loss: 140.584, Residuals: 0.025\n",
      "Loss: 140.583, Residuals: 0.026\n",
      "Loss: 140.582, Residuals: 0.025\n",
      "Loss: 140.582, Residuals: 0.025\n",
      "Loss: 140.582, Residuals: 0.025\n",
      "Loss: 140.582, Residuals: 0.025\n",
      "Loss: 140.581, Residuals: 0.025\n",
      "Loss: 140.581, Residuals: 0.025\n",
      "Loss: 140.581, Residuals: 0.025\n",
      "Loss: 140.581, Residuals: 0.025\n",
      "Loss: 140.581, Residuals: 0.025\n",
      "Loss: 140.581, Residuals: 0.025\n",
      "Loss: 140.581, Residuals: 0.025\n",
      "Loss: 140.581, Residuals: 0.025\n",
      "Evidence 447.002\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.67e+00\n",
      "Loss: 147.837, Residuals: 0.031\n",
      "Loss: 147.594, Residuals: 0.026\n",
      "Loss: 147.497, Residuals: 0.025\n",
      "Loss: 147.378, Residuals: 0.025\n",
      "Loss: 147.376, Residuals: 0.024\n",
      "Loss: 147.353, Residuals: 0.024\n",
      "Loss: 147.316, Residuals: 0.024\n",
      "Loss: 147.291, Residuals: 0.024\n",
      "Loss: 147.290, Residuals: 0.024\n",
      "Loss: 147.289, Residuals: 0.024\n",
      "Loss: 147.289, Residuals: 0.024\n",
      "Loss: 147.288, Residuals: 0.024\n",
      "Loss: 147.287, Residuals: 0.024\n",
      "Loss: 147.287, Residuals: 0.024\n",
      "Loss: 147.287, Residuals: 0.024\n",
      "Loss: 147.287, Residuals: 0.024\n",
      "Loss: 147.287, Residuals: 0.024\n",
      "Loss: 147.287, Residuals: 0.024\n",
      "Evidence 451.254\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.66e+00\n",
      "Loss: 149.788, Residuals: 0.028\n",
      "Loss: 149.662, Residuals: 0.025\n",
      "Loss: 149.596, Residuals: 0.023\n",
      "Loss: 149.594, Residuals: 0.023\n",
      "Loss: 149.570, Residuals: 0.023\n",
      "Loss: 149.538, Residuals: 0.023\n",
      "Loss: 149.525, Residuals: 0.023\n",
      "Loss: 149.524, Residuals: 0.023\n",
      "Loss: 149.522, Residuals: 0.023\n",
      "Loss: 149.520, Residuals: 0.023\n",
      "Loss: 149.520, Residuals: 0.023\n",
      "Loss: 149.520, Residuals: 0.023\n",
      "Loss: 149.519, Residuals: 0.023\n",
      "Loss: 149.519, Residuals: 0.023\n",
      "Loss: 149.519, Residuals: 0.023\n",
      "Loss: 149.519, Residuals: 0.023\n",
      "Evidence 453.856\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.59e+00\n",
      "Loss: 150.625, Residuals: 0.028\n",
      "Loss: 150.583, Residuals: 0.023\n",
      "Loss: 150.538, Residuals: 0.023\n",
      "Loss: 150.525, Residuals: 0.023\n",
      "Loss: 150.517, Residuals: 0.022\n",
      "Loss: 150.505, Residuals: 0.022\n",
      "Loss: 150.493, Residuals: 0.022\n",
      "Loss: 150.492, Residuals: 0.022\n",
      "Loss: 150.490, Residuals: 0.022\n",
      "Loss: 150.486, Residuals: 0.022\n",
      "Loss: 150.486, Residuals: 0.022\n",
      "Loss: 150.486, Residuals: 0.022\n",
      "Loss: 150.485, Residuals: 0.022\n",
      "Loss: 150.485, Residuals: 0.022\n",
      "Loss: 150.485, Residuals: 0.022\n",
      "Loss: 150.485, Residuals: 0.022\n",
      "Loss: 150.485, Residuals: 0.022\n",
      "Loss: 150.485, Residuals: 0.022\n",
      "Loss: 150.485, Residuals: 0.022\n",
      "Evidence 455.575\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.52e+00\n",
      "Loss: 151.135, Residuals: 0.025\n",
      "Loss: 151.110, Residuals: 0.021\n",
      "Loss: 151.081, Residuals: 0.022\n",
      "Loss: 151.066, Residuals: 0.021\n",
      "Loss: 151.064, Residuals: 0.021\n",
      "Loss: 151.061, Residuals: 0.021\n",
      "Loss: 151.057, Residuals: 0.021\n",
      "Loss: 151.057, Residuals: 0.021\n",
      "Loss: 151.056, Residuals: 0.021\n",
      "Loss: 151.055, Residuals: 0.021\n",
      "Loss: 151.055, Residuals: 0.021\n",
      "Loss: 151.055, Residuals: 0.021\n",
      "Loss: 151.055, Residuals: 0.021\n",
      "Loss: 151.055, Residuals: 0.021\n",
      "Evidence 456.669\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.48e+00\n",
      "Loss: 151.491, Residuals: 0.022\n",
      "Loss: 151.480, Residuals: 0.022\n",
      "Loss: 151.467, Residuals: 0.021\n",
      "Loss: 151.459, Residuals: 0.020\n",
      "Loss: 151.459, Residuals: 0.021\n",
      "Loss: 151.457, Residuals: 0.021\n",
      "Loss: 151.457, Residuals: 0.021\n",
      "Loss: 151.457, Residuals: 0.020\n",
      "Loss: 151.457, Residuals: 0.020\n",
      "Loss: 151.456, Residuals: 0.020\n",
      "Loss: 151.456, Residuals: 0.020\n",
      "Loss: 151.456, Residuals: 0.020\n",
      "Loss: 151.456, Residuals: 0.020\n",
      "Loss: 151.456, Residuals: 0.020\n",
      "Loss: 151.455, Residuals: 0.020\n",
      "Evidence 457.357\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.46e+00\n",
      "Loss: 151.758, Residuals: 0.022\n",
      "Loss: 151.750, Residuals: 0.020\n",
      "Loss: 151.743, Residuals: 0.020\n",
      "Loss: 151.741, Residuals: 0.020\n",
      "Loss: 151.740, Residuals: 0.020\n",
      "Loss: 151.738, Residuals: 0.020\n",
      "Loss: 151.738, Residuals: 0.020\n",
      "Loss: 151.738, Residuals: 0.020\n",
      "Loss: 151.737, Residuals: 0.020\n",
      "Loss: 151.737, Residuals: 0.020\n",
      "Evidence 457.825\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.46e+00\n",
      "Loss: 151.941, Residuals: 0.020\n",
      "Loss: 151.935, Residuals: 0.021\n",
      "Loss: 151.932, Residuals: 0.020\n",
      "Loss: 151.932, Residuals: 0.020\n",
      "Loss: 151.931, Residuals: 0.020\n",
      "Loss: 151.931, Residuals: 0.020\n",
      "Evidence 458.159\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.606, Residuals: -0.073\n",
      "Loss: 7.743, Residuals: -0.043\n",
      "Loss: 5.146, Residuals: -0.041\n",
      "Loss: 4.455, Residuals: 0.050\n",
      "Loss: 4.300, Residuals: 0.033\n",
      "Loss: 4.058, Residuals: 0.009\n",
      "Loss: 4.037, Residuals: 0.020\n",
      "Loss: 3.862, Residuals: 0.006\n",
      "Loss: 3.630, Residuals: -0.018\n",
      "Loss: 3.582, Residuals: -0.019\n",
      "Loss: 3.500, Residuals: -0.020\n",
      "Loss: 3.493, Residuals: -0.007\n",
      "Loss: 3.435, Residuals: -0.013\n",
      "Loss: 3.341, Residuals: -0.023\n",
      "Loss: 3.333, Residuals: -0.019\n",
      "Loss: 3.319, Residuals: -0.023\n",
      "Loss: 3.302, Residuals: -0.030\n",
      "Loss: 3.301, Residuals: -0.031\n",
      "Loss: 3.269, Residuals: -0.038\n",
      "Loss: 3.269, Residuals: -0.038\n",
      "Loss: 3.264, Residuals: -0.038\n",
      "Loss: 3.262, Residuals: -0.039\n",
      "Loss: 3.247, Residuals: -0.043\n",
      "Loss: 3.247, Residuals: -0.043\n",
      "Loss: 3.235, Residuals: -0.047\n",
      "Loss: 3.213, Residuals: -0.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.213, Residuals: -0.053\n",
      "Loss: 3.213, Residuals: -0.052\n",
      "Loss: 3.209, Residuals: -0.053\n",
      "Loss: 3.209, Residuals: -0.052\n",
      "Loss: 3.172, Residuals: -0.063\n",
      "Loss: 3.172, Residuals: -0.063\n",
      "Evidence -413.238\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.20e-02\n",
      "Loss: 14.315, Residuals: -0.060\n",
      "Loss: 14.308, Residuals: -0.059\n",
      "Loss: 14.294, Residuals: -0.057\n",
      "Loss: 14.271, Residuals: -0.051\n",
      "Loss: 14.074, Residuals: -0.043\n",
      "Loss: 14.073, Residuals: -0.044\n",
      "Loss: 13.944, Residuals: -0.036\n",
      "Loss: 13.770, Residuals: -0.017\n",
      "Loss: 13.765, Residuals: -0.018\n",
      "Loss: 13.765, Residuals: -0.018\n",
      "Evidence 113.513\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.35e-01\n",
      "Loss: 43.922, Residuals: -0.018\n",
      "Loss: 43.800, Residuals: -0.018\n",
      "Loss: 42.806, Residuals: -0.009\n",
      "Loss: 42.794, Residuals: -0.009\n",
      "Loss: 42.778, Residuals: -0.010\n",
      "Loss: 42.631, Residuals: -0.006\n",
      "Loss: 42.394, Residuals: 0.001\n",
      "Loss: 42.389, Residuals: 0.002\n",
      "Loss: 42.214, Residuals: 0.005\n",
      "Loss: 42.185, Residuals: 0.011\n",
      "Loss: 41.949, Residuals: 0.014\n",
      "Loss: 41.949, Residuals: 0.014\n",
      "Evidence 315.723\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.13e-01\n",
      "Loss: 89.399, Residuals: 0.014\n",
      "Loss: 89.155, Residuals: 0.012\n",
      "Loss: 88.774, Residuals: 0.014\n",
      "Loss: 88.451, Residuals: 0.010\n",
      "Loss: 88.373, Residuals: 0.005\n",
      "Loss: 88.225, Residuals: 0.006\n",
      "Loss: 87.961, Residuals: 0.008\n",
      "Loss: 87.550, Residuals: 0.011\n",
      "Loss: 87.510, Residuals: 0.011\n",
      "Loss: 87.177, Residuals: 0.013\n",
      "Loss: 87.174, Residuals: 0.013\n",
      "Loss: 87.169, Residuals: 0.013\n",
      "Loss: 87.122, Residuals: 0.014\n",
      "Loss: 87.116, Residuals: 0.012\n",
      "Loss: 86.898, Residuals: 0.015\n",
      "Loss: 86.895, Residuals: 0.015\n",
      "Loss: 86.766, Residuals: 0.017\n",
      "Loss: 86.763, Residuals: 0.017\n",
      "Loss: 86.758, Residuals: 0.017\n",
      "Loss: 86.750, Residuals: 0.017\n",
      "Loss: 86.677, Residuals: 0.017\n",
      "Loss: 86.673, Residuals: 0.017\n",
      "Loss: 86.534, Residuals: 0.019\n",
      "Loss: 86.517, Residuals: 0.019\n",
      "Loss: 86.510, Residuals: 0.019\n",
      "Loss: 86.451, Residuals: 0.019\n",
      "Loss: 86.448, Residuals: 0.019\n",
      "Loss: 86.364, Residuals: 0.021\n",
      "Loss: 86.358, Residuals: 0.020\n",
      "Loss: 86.310, Residuals: 0.021\n",
      "Loss: 86.308, Residuals: 0.021\n",
      "Loss: 86.292, Residuals: 0.021\n",
      "Loss: 86.288, Residuals: 0.021\n",
      "Loss: 86.283, Residuals: 0.021\n",
      "Loss: 86.283, Residuals: 0.021\n",
      "Loss: 86.280, Residuals: 0.021\n",
      "Loss: 86.277, Residuals: 0.021\n",
      "Loss: 86.277, Residuals: 0.021\n",
      "Loss: 86.277, Residuals: 0.021\n",
      "Loss: 86.277, Residuals: 0.021\n",
      "Loss: 86.277, Residuals: 0.021\n",
      "Loss: 86.277, Residuals: 0.021\n",
      "Loss: 86.276, Residuals: 0.021\n",
      "Loss: 86.276, Residuals: 0.021\n",
      "Loss: 86.276, Residuals: 0.021\n",
      "Loss: 86.276, Residuals: 0.021\n",
      "Evidence 432.921\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.28e+00\n",
      "Loss: 127.657, Residuals: 0.022\n",
      "Loss: 127.377, Residuals: 0.019\n",
      "Loss: 127.290, Residuals: 0.019\n",
      "Loss: 127.135, Residuals: 0.020\n",
      "Loss: 126.883, Residuals: 0.020\n",
      "Loss: 126.639, Residuals: 0.020\n",
      "Loss: 126.630, Residuals: 0.020\n",
      "Loss: 126.621, Residuals: 0.019\n",
      "Loss: 126.606, Residuals: 0.019\n",
      "Loss: 126.602, Residuals: 0.019\n",
      "Loss: 126.595, Residuals: 0.019\n",
      "Loss: 126.595, Residuals: 0.019\n",
      "Loss: 126.593, Residuals: 0.019\n",
      "Loss: 126.590, Residuals: 0.019\n",
      "Loss: 126.590, Residuals: 0.019\n",
      "Loss: 126.589, Residuals: 0.019\n",
      "Loss: 126.588, Residuals: 0.019\n",
      "Evidence 476.385\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.46e+00\n",
      "Loss: 147.347, Residuals: 0.024\n",
      "Loss: 147.103, Residuals: 0.022\n",
      "Loss: 146.960, Residuals: 0.019\n",
      "Loss: 146.787, Residuals: 0.017\n",
      "Loss: 146.777, Residuals: 0.019\n",
      "Loss: 146.691, Residuals: 0.018\n",
      "Loss: 146.622, Residuals: 0.017\n",
      "Loss: 146.620, Residuals: 0.017\n",
      "Loss: 146.619, Residuals: 0.017\n",
      "Loss: 146.617, Residuals: 0.017\n",
      "Loss: 146.614, Residuals: 0.017\n",
      "Loss: 146.613, Residuals: 0.017\n",
      "Loss: 146.612, Residuals: 0.017\n",
      "Loss: 146.612, Residuals: 0.017\n",
      "Loss: 146.611, Residuals: 0.017\n",
      "Evidence 487.425\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.41e+00\n",
      "Loss: 153.836, Residuals: 0.021\n",
      "Loss: 153.650, Residuals: 0.020\n",
      "Loss: 153.584, Residuals: 0.017\n",
      "Loss: 153.565, Residuals: 0.019\n",
      "Loss: 153.554, Residuals: 0.018\n",
      "Loss: 153.535, Residuals: 0.018\n",
      "Loss: 153.506, Residuals: 0.018\n",
      "Loss: 153.480, Residuals: 0.018\n",
      "Loss: 153.480, Residuals: 0.018\n",
      "Evidence 491.401\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.34e+00\n",
      "Loss: 156.073, Residuals: 0.020\n",
      "Loss: 155.977, Residuals: 0.019\n",
      "Loss: 155.947, Residuals: 0.017\n",
      "Loss: 155.940, Residuals: 0.018\n",
      "Loss: 155.928, Residuals: 0.018\n",
      "Loss: 155.912, Residuals: 0.018\n",
      "Loss: 155.911, Residuals: 0.018\n",
      "Loss: 155.907, Residuals: 0.018\n",
      "Loss: 155.907, Residuals: 0.017\n",
      "Loss: 155.905, Residuals: 0.017\n",
      "Loss: 155.905, Residuals: 0.017\n",
      "Loss: 155.905, Residuals: 0.017\n",
      "Evidence 493.543\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.28e+00\n",
      "Loss: 157.046, Residuals: 0.020\n",
      "Loss: 157.006, Residuals: 0.020\n",
      "Loss: 156.986, Residuals: 0.018\n",
      "Loss: 156.983, Residuals: 0.018\n",
      "Loss: 156.978, Residuals: 0.018\n",
      "Loss: 156.970, Residuals: 0.018\n",
      "Loss: 156.965, Residuals: 0.017\n",
      "Loss: 156.963, Residuals: 0.017\n",
      "Loss: 156.963, Residuals: 0.017\n",
      "Loss: 156.963, Residuals: 0.017\n",
      "Loss: 156.962, Residuals: 0.017\n",
      "Loss: 156.962, Residuals: 0.017\n",
      "Loss: 156.962, Residuals: 0.017\n",
      "Loss: 156.962, Residuals: 0.017\n",
      "Loss: 156.962, Residuals: 0.017\n",
      "Loss: 156.962, Residuals: 0.017\n",
      "Evidence 494.871\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.24e+00\n",
      "Loss: 157.574, Residuals: 0.019\n",
      "Loss: 157.554, Residuals: 0.019\n",
      "Loss: 157.549, Residuals: 0.018\n",
      "Loss: 157.542, Residuals: 0.017\n",
      "Loss: 157.534, Residuals: 0.017\n",
      "Loss: 157.533, Residuals: 0.017\n",
      "Loss: 157.533, Residuals: 0.017\n",
      "Loss: 157.532, Residuals: 0.017\n",
      "Loss: 157.532, Residuals: 0.017\n",
      "Loss: 157.531, Residuals: 0.017\n",
      "Loss: 157.530, Residuals: 0.017\n",
      "Loss: 157.530, Residuals: 0.017\n",
      "Evidence 495.711\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.21e+00\n",
      "Loss: 157.894, Residuals: 0.018\n",
      "Loss: 157.887, Residuals: 0.017\n",
      "Loss: 157.878, Residuals: 0.017\n",
      "Loss: 157.874, Residuals: 0.016\n",
      "Loss: 157.874, Residuals: 0.016\n",
      "Loss: 157.872, Residuals: 0.016\n",
      "Loss: 157.871, Residuals: 0.016\n",
      "Loss: 157.871, Residuals: 0.016\n",
      "Loss: 157.871, Residuals: 0.016\n",
      "Loss: 157.871, Residuals: 0.016\n",
      "Loss: 157.871, Residuals: 0.016\n",
      "Loss: 157.871, Residuals: 0.016\n",
      "Loss: 157.871, Residuals: 0.016\n",
      "Loss: 157.871, Residuals: 0.016\n",
      "Evidence 496.267\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.20e+00\n",
      "Loss: 158.105, Residuals: 0.017\n",
      "Loss: 158.099, Residuals: 0.017\n",
      "Loss: 158.098, Residuals: 0.017\n",
      "Loss: 158.096, Residuals: 0.016\n",
      "Loss: 158.094, Residuals: 0.016\n",
      "Loss: 158.093, Residuals: 0.016\n",
      "Loss: 158.093, Residuals: 0.016\n",
      "Loss: 158.093, Residuals: 0.016\n",
      "Loss: 158.093, Residuals: 0.016\n",
      "Loss: 158.093, Residuals: 0.016\n",
      "Loss: 158.093, Residuals: 0.016\n",
      "Evidence 496.639\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.710, Residuals: -0.080\n",
      "Loss: 7.662, Residuals: -0.045\n",
      "Loss: 5.297, Residuals: -0.045\n",
      "Loss: 4.678, Residuals: -0.023\n",
      "Loss: 4.480, Residuals: -0.046\n",
      "Loss: 4.272, Residuals: 0.009\n",
      "Loss: 4.019, Residuals: 0.043\n",
      "Loss: 3.736, Residuals: -0.014\n",
      "Loss: 3.708, Residuals: -0.023\n",
      "Loss: 3.682, Residuals: -0.010\n",
      "Loss: 3.632, Residuals: -0.015\n",
      "Loss: 3.540, Residuals: -0.021\n",
      "Loss: 3.385, Residuals: -0.030\n",
      "Loss: 3.343, Residuals: -0.013\n",
      "Loss: 3.271, Residuals: -0.021\n",
      "Loss: 3.262, Residuals: -0.016\n",
      "Loss: 3.185, Residuals: -0.026\n",
      "Loss: 3.174, Residuals: -0.015\n",
      "Loss: 3.153, Residuals: -0.015\n",
      "Loss: 3.117, Residuals: -0.023\n",
      "Loss: 3.114, Residuals: -0.015\n",
      "Loss: 3.089, Residuals: -0.022\n",
      "Loss: 3.074, Residuals: -0.024\n",
      "Loss: 3.074, Residuals: -0.023\n",
      "Loss: 3.045, Residuals: -0.033\n",
      "Loss: 3.044, Residuals: -0.032\n",
      "Loss: 3.043, Residuals: -0.032\n",
      "Loss: 3.041, Residuals: -0.033\n",
      "Loss: 3.038, Residuals: -0.034\n",
      "Loss: 3.033, Residuals: -0.034\n",
      "Loss: 3.024, Residuals: -0.038\n",
      "Loss: 3.008, Residuals: -0.044\n",
      "Loss: 3.002, Residuals: -0.044\n",
      "Loss: 3.002, Residuals: -0.044\n",
      "Evidence -416.284\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.85e-02\n",
      "Loss: 14.450, Residuals: -0.045\n",
      "Loss: 14.267, Residuals: -0.042\n",
      "Loss: 13.970, Residuals: -0.032\n",
      "Loss: 13.794, Residuals: 0.001\n",
      "Loss: 13.784, Residuals: -0.000\n",
      "Loss: 13.770, Residuals: 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 13.745, Residuals: 0.005\n",
      "Loss: 13.699, Residuals: 0.006\n",
      "Loss: 13.634, Residuals: 0.012\n",
      "Loss: 13.634, Residuals: 0.012\n",
      "Loss: 13.619, Residuals: 0.013\n",
      "Loss: 13.596, Residuals: 0.017\n",
      "Loss: 13.590, Residuals: 0.018\n",
      "Loss: 13.581, Residuals: 0.020\n",
      "Loss: 13.580, Residuals: 0.020\n",
      "Loss: 13.571, Residuals: 0.021\n",
      "Loss: 13.558, Residuals: 0.022\n",
      "Loss: 13.557, Residuals: 0.022\n",
      "Loss: 13.551, Residuals: 0.022\n",
      "Loss: 13.546, Residuals: 0.026\n",
      "Loss: 13.545, Residuals: 0.025\n",
      "Loss: 13.545, Residuals: 0.025\n",
      "Evidence 115.753\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.61e-01\n",
      "Loss: 43.403, Residuals: 0.025\n",
      "Loss: 43.349, Residuals: 0.023\n",
      "Loss: 43.256, Residuals: 0.023\n",
      "Loss: 43.138, Residuals: 0.025\n",
      "Loss: 43.131, Residuals: 0.024\n",
      "Loss: 43.065, Residuals: 0.026\n",
      "Loss: 42.952, Residuals: 0.029\n",
      "Loss: 42.880, Residuals: 0.035\n",
      "Loss: 42.879, Residuals: 0.034\n",
      "Loss: 42.871, Residuals: 0.034\n",
      "Loss: 42.856, Residuals: 0.035\n",
      "Loss: 42.829, Residuals: 0.035\n",
      "Loss: 42.826, Residuals: 0.035\n",
      "Loss: 42.805, Residuals: 0.035\n",
      "Loss: 42.804, Residuals: 0.035\n",
      "Loss: 42.791, Residuals: 0.035\n",
      "Loss: 42.790, Residuals: 0.035\n",
      "Loss: 42.779, Residuals: 0.035\n",
      "Loss: 42.779, Residuals: 0.035\n",
      "Loss: 42.764, Residuals: 0.036\n",
      "Loss: 42.763, Residuals: 0.036\n",
      "Loss: 42.761, Residuals: 0.036\n",
      "Loss: 42.761, Residuals: 0.035\n",
      "Loss: 42.758, Residuals: 0.036\n",
      "Loss: 42.758, Residuals: 0.036\n",
      "Loss: 42.755, Residuals: 0.036\n",
      "Loss: 42.755, Residuals: 0.036\n",
      "Loss: 42.748, Residuals: 0.037\n",
      "Loss: 42.747, Residuals: 0.036\n",
      "Loss: 42.746, Residuals: 0.036\n",
      "Loss: 42.746, Residuals: 0.036\n",
      "Loss: 42.743, Residuals: 0.036\n",
      "Loss: 42.743, Residuals: 0.036\n",
      "Loss: 42.741, Residuals: 0.037\n",
      "Loss: 42.741, Residuals: 0.037\n",
      "Loss: 42.736, Residuals: 0.037\n",
      "Loss: 42.735, Residuals: 0.037\n",
      "Loss: 42.735, Residuals: 0.037\n",
      "Loss: 42.734, Residuals: 0.037\n",
      "Loss: 42.732, Residuals: 0.037\n",
      "Loss: 42.731, Residuals: 0.037\n",
      "Loss: 42.729, Residuals: 0.037\n",
      "Loss: 42.729, Residuals: 0.037\n",
      "Loss: 42.726, Residuals: 0.037\n",
      "Loss: 42.726, Residuals: 0.037\n",
      "Loss: 42.724, Residuals: 0.038\n",
      "Loss: 42.724, Residuals: 0.038\n",
      "Loss: 42.722, Residuals: 0.038\n",
      "Loss: 42.722, Residuals: 0.038\n",
      "Loss: 42.721, Residuals: 0.038\n",
      "Loss: 42.720, Residuals: 0.038\n",
      "Loss: 42.718, Residuals: 0.038\n",
      "Loss: 42.718, Residuals: 0.038\n",
      "Loss: 42.716, Residuals: 0.039\n",
      "Loss: 42.715, Residuals: 0.038\n",
      "Loss: 42.715, Residuals: 0.038\n",
      "Loss: 42.715, Residuals: 0.039\n",
      "Loss: 42.714, Residuals: 0.039\n",
      "Loss: 42.714, Residuals: 0.039\n",
      "Loss: 42.714, Residuals: 0.039\n",
      "Loss: 42.714, Residuals: 0.039\n",
      "Loss: 42.713, Residuals: 0.039\n",
      "Loss: 42.713, Residuals: 0.039\n",
      "Loss: 42.713, Residuals: 0.039\n",
      "Loss: 42.713, Residuals: 0.039\n",
      "Loss: 42.713, Residuals: 0.039\n",
      "Loss: 42.713, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Loss: 42.712, Residuals: 0.039\n",
      "Evidence 317.992\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.33e-01\n",
      "Loss: 87.986, Residuals: 0.039\n",
      "Loss: 87.846, Residuals: 0.030\n",
      "Loss: 87.604, Residuals: 0.031\n",
      "Loss: 87.261, Residuals: 0.033\n",
      "Loss: 87.232, Residuals: 0.031\n",
      "Loss: 87.178, Residuals: 0.031\n",
      "Loss: 87.091, Residuals: 0.032\n",
      "Loss: 87.024, Residuals: 0.032\n",
      "Loss: 87.021, Residuals: 0.032\n",
      "Loss: 87.019, Residuals: 0.032\n",
      "Loss: 87.015, Residuals: 0.032\n",
      "Loss: 87.010, Residuals: 0.032\n",
      "Loss: 87.010, Residuals: 0.032\n",
      "Loss: 87.008, Residuals: 0.032\n",
      "Loss: 87.007, Residuals: 0.032\n",
      "Loss: 87.007, Residuals: 0.032\n",
      "Loss: 87.007, Residuals: 0.032\n",
      "Loss: 87.007, Residuals: 0.032\n",
      "Loss: 87.006, Residuals: 0.032\n",
      "Loss: 87.006, Residuals: 0.032\n",
      "Loss: 87.006, Residuals: 0.032\n",
      "Loss: 87.006, Residuals: 0.032\n",
      "Evidence 433.681\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.57e+00\n",
      "Loss: 128.286, Residuals: 0.035\n",
      "Loss: 127.785, Residuals: 0.033\n",
      "Loss: 127.510, Residuals: 0.022\n",
      "Loss: 127.349, Residuals: 0.023\n",
      "Loss: 127.274, Residuals: 0.025\n",
      "Loss: 127.245, Residuals: 0.024\n",
      "Loss: 127.191, Residuals: 0.023\n",
      "Loss: 127.106, Residuals: 0.023\n",
      "Loss: 127.038, Residuals: 0.021\n",
      "Loss: 127.032, Residuals: 0.022\n",
      "Loss: 127.029, Residuals: 0.021\n",
      "Loss: 127.026, Residuals: 0.021\n",
      "Loss: 127.025, Residuals: 0.020\n",
      "Loss: 127.024, Residuals: 0.020\n",
      "Loss: 127.024, Residuals: 0.021\n",
      "Loss: 127.024, Residuals: 0.021\n",
      "Loss: 127.023, Residuals: 0.021\n",
      "Loss: 127.022, Residuals: 0.021\n",
      "Loss: 127.022, Residuals: 0.021\n",
      "Evidence 475.244\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.75e+00\n",
      "Loss: 147.724, Residuals: 0.024\n",
      "Loss: 147.467, Residuals: 0.023\n",
      "Loss: 147.248, Residuals: 0.018\n",
      "Loss: 147.101, Residuals: 0.017\n",
      "Loss: 147.088, Residuals: 0.017\n",
      "Loss: 146.988, Residuals: 0.016\n",
      "Loss: 146.913, Residuals: 0.015\n",
      "Loss: 146.912, Residuals: 0.015\n",
      "Loss: 146.909, Residuals: 0.014\n",
      "Loss: 146.906, Residuals: 0.014\n",
      "Loss: 146.905, Residuals: 0.014\n",
      "Loss: 146.905, Residuals: 0.014\n",
      "Loss: 146.905, Residuals: 0.014\n",
      "Loss: 146.904, Residuals: 0.014\n",
      "Loss: 146.904, Residuals: 0.014\n",
      "Evidence 486.175\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.73e+00\n",
      "Loss: 154.014, Residuals: 0.015\n",
      "Loss: 153.814, Residuals: 0.015\n",
      "Loss: 153.715, Residuals: 0.012\n",
      "Loss: 153.704, Residuals: 0.013\n",
      "Loss: 153.683, Residuals: 0.013\n",
      "Loss: 153.650, Residuals: 0.013\n",
      "Loss: 153.626, Residuals: 0.012\n",
      "Loss: 153.624, Residuals: 0.012\n",
      "Loss: 153.622, Residuals: 0.012\n",
      "Loss: 153.619, Residuals: 0.011\n",
      "Loss: 153.619, Residuals: 0.011\n",
      "Loss: 153.618, Residuals: 0.011\n",
      "Loss: 153.618, Residuals: 0.011\n",
      "Loss: 153.618, Residuals: 0.011\n",
      "Loss: 153.618, Residuals: 0.011\n",
      "Loss: 153.618, Residuals: 0.011\n",
      "Loss: 153.618, Residuals: 0.011\n",
      "Loss: 153.618, Residuals: 0.011\n",
      "Evidence 490.286\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.66e+00\n",
      "Loss: 156.009, Residuals: 0.015\n",
      "Loss: 155.964, Residuals: 0.014\n",
      "Loss: 155.911, Residuals: 0.012\n",
      "Loss: 155.860, Residuals: 0.010\n",
      "Loss: 155.857, Residuals: 0.010\n",
      "Loss: 155.850, Residuals: 0.010\n",
      "Loss: 155.841, Residuals: 0.010\n",
      "Loss: 155.841, Residuals: 0.010\n",
      "Loss: 155.838, Residuals: 0.010\n",
      "Loss: 155.834, Residuals: 0.010\n",
      "Loss: 155.834, Residuals: 0.010\n",
      "Loss: 155.833, Residuals: 0.010\n",
      "Loss: 155.831, Residuals: 0.010\n",
      "Loss: 155.831, Residuals: 0.010\n",
      "Loss: 155.831, Residuals: 0.010\n",
      "Loss: 155.831, Residuals: 0.010\n",
      "Loss: 155.831, Residuals: 0.010\n",
      "Evidence 492.706\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.58e+00\n",
      "Loss: 156.863, Residuals: 0.013\n",
      "Loss: 156.842, Residuals: 0.010\n",
      "Loss: 156.813, Residuals: 0.010\n",
      "Loss: 156.782, Residuals: 0.009\n",
      "Loss: 156.779, Residuals: 0.009\n",
      "Loss: 156.774, Residuals: 0.009\n",
      "Loss: 156.765, Residuals: 0.008\n",
      "Loss: 156.765, Residuals: 0.009\n",
      "Loss: 156.763, Residuals: 0.008\n",
      "Loss: 156.761, Residuals: 0.008\n",
      "Loss: 156.761, Residuals: 0.008\n",
      "Loss: 156.761, Residuals: 0.008\n",
      "Loss: 156.761, Residuals: 0.008\n",
      "Evidence 494.327\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.52e+00\n",
      "Loss: 157.329, Residuals: 0.010\n",
      "Loss: 157.315, Residuals: 0.009\n",
      "Loss: 157.297, Residuals: 0.008\n",
      "Loss: 157.283, Residuals: 0.007\n",
      "Loss: 157.282, Residuals: 0.007\n",
      "Loss: 157.280, Residuals: 0.007\n",
      "Loss: 157.277, Residuals: 0.007\n",
      "Loss: 157.275, Residuals: 0.007\n",
      "Loss: 157.274, Residuals: 0.007\n",
      "Loss: 157.274, Residuals: 0.007\n",
      "Loss: 157.274, Residuals: 0.007\n",
      "Loss: 157.273, Residuals: 0.007\n",
      "Loss: 157.273, Residuals: 0.007\n",
      "Loss: 157.273, Residuals: 0.007\n",
      "Loss: 157.273, Residuals: 0.007\n",
      "Evidence 495.427\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.48e+00\n",
      "Loss: 157.633, Residuals: 0.009\n",
      "Loss: 157.623, Residuals: 0.008\n",
      "Loss: 157.612, Residuals: 0.007\n",
      "Loss: 157.605, Residuals: 0.007\n",
      "Loss: 157.605, Residuals: 0.007\n",
      "Loss: 157.604, Residuals: 0.007\n",
      "Loss: 157.603, Residuals: 0.007\n",
      "Loss: 157.603, Residuals: 0.007\n",
      "Loss: 157.602, Residuals: 0.007\n",
      "Loss: 157.602, Residuals: 0.007\n",
      "Loss: 157.602, Residuals: 0.007\n",
      "Evidence 496.169\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.45e+00\n",
      "Loss: 157.850, Residuals: 0.008\n",
      "Loss: 157.843, Residuals: 0.007\n",
      "Loss: 157.838, Residuals: 0.007\n",
      "Loss: 157.837, Residuals: 0.007\n",
      "Loss: 157.835, Residuals: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 157.834, Residuals: 0.006\n",
      "Loss: 157.834, Residuals: 0.006\n",
      "Loss: 157.833, Residuals: 0.006\n",
      "Loss: 157.833, Residuals: 0.006\n",
      "Evidence 496.673\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.43e+00\n",
      "Loss: 158.007, Residuals: 0.007\n",
      "Loss: 158.003, Residuals: 0.006\n",
      "Loss: 158.000, Residuals: 0.006\n",
      "Loss: 157.999, Residuals: 0.006\n",
      "Loss: 157.999, Residuals: 0.006\n",
      "Loss: 157.999, Residuals: 0.006\n",
      "Loss: 157.999, Residuals: 0.006\n",
      "Loss: 157.998, Residuals: 0.006\n",
      "Loss: 157.998, Residuals: 0.006\n",
      "Evidence 497.025\n",
      "Pass count  1\n",
      "Total samples: 39, Updated regularization: 1.00e-05\n",
      "Loss: 13.522, Residuals: -0.042\n",
      "Loss: 7.938, Residuals: -0.035\n",
      "Loss: 6.607, Residuals: -0.030\n",
      "Loss: 5.722, Residuals: -0.029\n",
      "Loss: 5.223, Residuals: 0.029\n",
      "Loss: 4.566, Residuals: -0.013\n",
      "Loss: 4.472, Residuals: 0.042\n",
      "Loss: 4.297, Residuals: 0.025\n",
      "Loss: 4.019, Residuals: -0.005\n",
      "Loss: 4.016, Residuals: -0.008\n",
      "Loss: 3.988, Residuals: -0.004\n",
      "Loss: 3.935, Residuals: -0.009\n",
      "Loss: 3.851, Residuals: -0.016\n",
      "Loss: 3.718, Residuals: -0.024\n",
      "Loss: 3.700, Residuals: -0.000\n",
      "Loss: 3.566, Residuals: -0.016\n",
      "Loss: 3.559, Residuals: -0.018\n",
      "Loss: 3.547, Residuals: -0.006\n",
      "Loss: 3.458, Residuals: -0.015\n",
      "Loss: 3.453, Residuals: -0.013\n",
      "Loss: 3.445, Residuals: -0.011\n",
      "Loss: 3.433, Residuals: -0.009\n",
      "Loss: 3.411, Residuals: -0.013\n",
      "Loss: 3.372, Residuals: -0.022\n",
      "Loss: 3.366, Residuals: -0.013\n",
      "Loss: 3.315, Residuals: -0.025\n",
      "Loss: 3.306, Residuals: -0.023\n",
      "Loss: 3.294, Residuals: -0.016\n",
      "Loss: 3.293, Residuals: -0.010\n",
      "Loss: 3.248, Residuals: -0.024\n",
      "Loss: 3.247, Residuals: -0.024\n",
      "Loss: 3.238, Residuals: -0.025\n",
      "Loss: 3.169, Residuals: -0.045\n",
      "Loss: 3.167, Residuals: -0.043\n",
      "Loss: 3.165, Residuals: -0.040\n",
      "Loss: 3.147, Residuals: -0.037\n",
      "Loss: 3.131, Residuals: -0.031\n",
      "Loss: 3.130, Residuals: -0.030\n",
      "Loss: 3.082, Residuals: -0.043\n",
      "Loss: 3.081, Residuals: -0.042\n",
      "Loss: 3.074, Residuals: -0.042\n",
      "Loss: 3.014, Residuals: -0.057\n",
      "Loss: 3.011, Residuals: -0.057\n",
      "Loss: 3.007, Residuals: -0.052\n",
      "Loss: 3.001, Residuals: -0.053\n",
      "Loss: 2.989, Residuals: -0.056\n",
      "Loss: 2.979, Residuals: -0.058\n",
      "Loss: 2.979, Residuals: -0.058\n",
      "Loss: 2.978, Residuals: -0.058\n",
      "Loss: 2.960, Residuals: -0.062\n",
      "Loss: 2.960, Residuals: -0.061\n",
      "Loss: 2.959, Residuals: -0.061\n",
      "Loss: 2.936, Residuals: -0.066\n",
      "Loss: 2.936, Residuals: -0.067\n",
      "Loss: 2.935, Residuals: -0.065\n",
      "Loss: 2.921, Residuals: -0.069\n",
      "Loss: 2.920, Residuals: -0.069\n",
      "Loss: 2.902, Residuals: -0.074\n",
      "Loss: 2.902, Residuals: -0.071\n",
      "Loss: 2.901, Residuals: -0.073\n",
      "Loss: 2.899, Residuals: -0.073\n",
      "Loss: 2.899, Residuals: -0.073\n",
      "Loss: 2.878, Residuals: -0.078\n",
      "Loss: 2.878, Residuals: -0.078\n",
      "Loss: 2.874, Residuals: -0.077\n",
      "Loss: 2.874, Residuals: -0.076\n",
      "Loss: 2.861, Residuals: -0.079\n",
      "Loss: 2.860, Residuals: -0.077\n",
      "Loss: 2.859, Residuals: -0.077\n",
      "Loss: 2.859, Residuals: -0.080\n",
      "Loss: 2.841, Residuals: -0.073\n",
      "Loss: 2.836, Residuals: -0.077\n",
      "Loss: 2.829, Residuals: -0.070\n",
      "Loss: 2.819, Residuals: -0.072\n",
      "Loss: 2.817, Residuals: -0.070\n",
      "Loss: 2.800, Residuals: -0.071\n",
      "Loss: 2.785, Residuals: -0.068\n",
      "Loss: 2.784, Residuals: -0.069\n",
      "Loss: 2.784, Residuals: -0.068\n",
      "Loss: 2.783, Residuals: -0.066\n",
      "Loss: 2.776, Residuals: -0.067\n",
      "Loss: 2.773, Residuals: -0.070\n",
      "Loss: 2.767, Residuals: -0.071\n",
      "Loss: 2.757, Residuals: -0.073\n",
      "Loss: 2.757, Residuals: -0.071\n",
      "Loss: 2.740, Residuals: -0.074\n",
      "Loss: 2.740, Residuals: -0.075\n",
      "Loss: 2.740, Residuals: -0.074\n",
      "Loss: 2.738, Residuals: -0.075\n",
      "Loss: 2.727, Residuals: -0.077\n",
      "Loss: 2.726, Residuals: -0.076\n",
      "Loss: 2.726, Residuals: -0.076\n",
      "Loss: 2.701, Residuals: -0.083\n",
      "Loss: 2.701, Residuals: -0.082\n",
      "Loss: 2.701, Residuals: -0.084\n",
      "Loss: 2.697, Residuals: -0.083\n",
      "Loss: 2.697, Residuals: -0.082\n",
      "Loss: 2.687, Residuals: -0.085\n",
      "Loss: 2.687, Residuals: -0.085\n",
      "Evidence -392.990\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 3.83e-03\n",
      "Loss: 13.014, Residuals: -0.074\n",
      "Loss: 12.983, Residuals: -0.073\n",
      "Loss: 12.924, Residuals: -0.071\n",
      "Loss: 12.826, Residuals: -0.065\n",
      "Loss: 12.708, Residuals: -0.049\n",
      "Loss: 12.696, Residuals: -0.049\n",
      "Loss: 12.674, Residuals: -0.048\n",
      "Loss: 12.637, Residuals: -0.045\n",
      "Loss: 12.573, Residuals: -0.043\n",
      "Loss: 12.573, Residuals: -0.042\n",
      "Evidence 108.759\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 2.18e-02\n",
      "Loss: 49.185, Residuals: -0.046\n",
      "Loss: 49.179, Residuals: -0.045\n",
      "Loss: 48.938, Residuals: -0.043\n",
      "Loss: 48.564, Residuals: -0.038\n",
      "Loss: 48.562, Residuals: -0.038\n",
      "Loss: 48.214, Residuals: -0.035\n",
      "Loss: 47.979, Residuals: -0.049\n",
      "Loss: 47.929, Residuals: -0.048\n",
      "Loss: 47.866, Residuals: -0.035\n",
      "Loss: 47.840, Residuals: -0.034\n",
      "Loss: 47.615, Residuals: -0.031\n",
      "Loss: 47.212, Residuals: -0.028\n",
      "Loss: 47.211, Residuals: -0.029\n",
      "Loss: 46.911, Residuals: -0.026\n",
      "Loss: 46.877, Residuals: -0.026\n",
      "Loss: 46.870, Residuals: -0.028\n",
      "Loss: 46.045, Residuals: -0.014\n",
      "Loss: 45.985, Residuals: -0.013\n",
      "Loss: 45.943, Residuals: -0.014\n",
      "Loss: 45.925, Residuals: -0.015\n",
      "Loss: 45.738, Residuals: -0.017\n",
      "Loss: 45.687, Residuals: -0.016\n",
      "Loss: 45.648, Residuals: -0.012\n",
      "Loss: 45.639, Residuals: -0.013\n",
      "Loss: 45.560, Residuals: -0.013\n",
      "Loss: 45.560, Residuals: -0.013\n",
      "Evidence 297.851\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 6.46e-02\n",
      "Loss: 94.880, Residuals: -0.013\n",
      "Loss: 94.830, Residuals: -0.013\n",
      "Loss: 94.736, Residuals: -0.014\n",
      "Loss: 94.572, Residuals: -0.016\n",
      "Loss: 94.289, Residuals: -0.018\n",
      "Loss: 94.288, Residuals: -0.018\n",
      "Evidence 389.177\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 8.85e-02\n",
      "Loss: 129.668, Residuals: -0.019\n",
      "Loss: 129.540, Residuals: -0.019\n",
      "Loss: 129.306, Residuals: -0.022\n",
      "Loss: 128.981, Residuals: -0.024\n",
      "Loss: 128.979, Residuals: -0.024\n",
      "Evidence 415.892\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 9.71e-02\n",
      "Loss: 145.446, Residuals: -0.024\n",
      "Loss: 145.221, Residuals: -0.025\n",
      "Loss: 144.850, Residuals: -0.028\n",
      "Loss: 144.849, Residuals: -0.028\n",
      "Evidence 422.574\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 9.93e-02\n",
      "Loss: 150.840, Residuals: -0.025\n",
      "Loss: 150.692, Residuals: -0.026\n",
      "Loss: 150.434, Residuals: -0.027\n",
      "Loss: 150.052, Residuals: -0.030\n",
      "Loss: 150.051, Residuals: -0.030\n",
      "Evidence 425.311\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.00e-01\n",
      "Loss: 152.310, Residuals: -0.028\n",
      "Loss: 151.835, Residuals: -0.027\n",
      "Loss: 151.834, Residuals: -0.027\n",
      "Evidence 426.690\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.01e-01\n",
      "Loss: 151.908, Residuals: -0.022\n",
      "Loss: 151.873, Residuals: -0.022\n",
      "Loss: 151.871, Residuals: -0.022\n",
      "Evidence 426.852\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.665, Residuals: -0.072\n",
      "Loss: 7.781, Residuals: -0.045\n",
      "Loss: 6.170, Residuals: -0.042\n",
      "Loss: 4.960, Residuals: -0.041\n",
      "Loss: 4.354, Residuals: -0.013\n",
      "Loss: 4.232, Residuals: -0.013\n",
      "Loss: 4.026, Residuals: -0.022\n",
      "Loss: 4.014, Residuals: -0.001\n",
      "Loss: 3.905, Residuals: -0.007\n",
      "Loss: 3.716, Residuals: -0.014\n",
      "Loss: 3.632, Residuals: -0.001\n",
      "Loss: 3.502, Residuals: -0.017\n",
      "Loss: 3.489, Residuals: -0.000\n",
      "Loss: 3.388, Residuals: -0.016\n",
      "Loss: 3.384, Residuals: -0.013\n",
      "Loss: 3.376, Residuals: -0.014\n",
      "Loss: 3.364, Residuals: -0.018\n",
      "Loss: 3.342, Residuals: -0.023\n",
      "Loss: 3.328, Residuals: -0.027\n",
      "Loss: 3.327, Residuals: -0.029\n",
      "Loss: 3.325, Residuals: -0.027\n",
      "Loss: 3.305, Residuals: -0.033\n",
      "Loss: 3.305, Residuals: -0.032\n",
      "Loss: 3.305, Residuals: -0.034\n",
      "Loss: 3.293, Residuals: -0.037\n",
      "Loss: 3.293, Residuals: -0.037\n",
      "Loss: 3.278, Residuals: -0.043\n",
      "Loss: 3.278, Residuals: -0.042\n",
      "Loss: 3.277, Residuals: -0.043\n",
      "Loss: 3.277, Residuals: -0.043\n",
      "Loss: 3.276, Residuals: -0.043\n",
      "Loss: 3.268, Residuals: -0.046\n",
      "Loss: 3.268, Residuals: -0.046\n",
      "Evidence -414.188\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.00e-02\n",
      "Loss: 15.032, Residuals: -0.033\n",
      "Loss: 14.941, Residuals: -0.027\n",
      "Loss: 14.781, Residuals: -0.021\n",
      "Loss: 14.603, Residuals: -0.009\n",
      "Loss: 14.601, Residuals: -0.009\n",
      "Loss: 14.598, Residuals: -0.007\n",
      "Loss: 14.593, Residuals: -0.005\n",
      "Loss: 14.583, Residuals: -0.004\n",
      "Loss: 14.565, Residuals: -0.003\n",
      "Loss: 14.533, Residuals: 0.001\n",
      "Loss: 14.487, Residuals: 0.009\n",
      "Loss: 14.482, Residuals: 0.010\n",
      "Loss: 14.478, Residuals: 0.012\n",
      "Loss: 14.469, Residuals: 0.013\n",
      "Loss: 14.454, Residuals: 0.014\n",
      "Loss: 14.453, Residuals: 0.014\n",
      "Loss: 14.443, Residuals: 0.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 14.439, Residuals: 0.017\n",
      "Loss: 14.439, Residuals: 0.016\n",
      "Loss: 14.437, Residuals: 0.017\n",
      "Loss: 14.433, Residuals: 0.017\n",
      "Loss: 14.433, Residuals: 0.019\n",
      "Loss: 14.431, Residuals: 0.019\n",
      "Loss: 14.429, Residuals: 0.018\n",
      "Loss: 14.428, Residuals: 0.019\n",
      "Loss: 14.428, Residuals: 0.019\n",
      "Loss: 14.428, Residuals: 0.019\n",
      "Loss: 14.427, Residuals: 0.019\n",
      "Loss: 14.427, Residuals: 0.019\n",
      "Loss: 14.427, Residuals: 0.019\n",
      "Loss: 14.427, Residuals: 0.019\n",
      "Loss: 14.427, Residuals: 0.020\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Loss: 14.426, Residuals: 0.019\n",
      "Evidence 114.069\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.63e-01\n",
      "Loss: 45.062, Residuals: 0.019\n",
      "Loss: 45.011, Residuals: 0.019\n",
      "Loss: 44.928, Residuals: 0.019\n",
      "Loss: 44.841, Residuals: 0.020\n",
      "Loss: 44.727, Residuals: 0.023\n",
      "Loss: 44.720, Residuals: 0.025\n",
      "Loss: 44.659, Residuals: 0.027\n",
      "Loss: 44.559, Residuals: 0.029\n",
      "Loss: 44.554, Residuals: 0.027\n",
      "Loss: 44.512, Residuals: 0.029\n",
      "Loss: 44.511, Residuals: 0.029\n",
      "Loss: 44.501, Residuals: 0.029\n",
      "Loss: 44.482, Residuals: 0.030\n",
      "Loss: 44.481, Residuals: 0.030\n",
      "Loss: 44.473, Residuals: 0.030\n",
      "Loss: 44.469, Residuals: 0.030\n",
      "Loss: 44.469, Residuals: 0.030\n",
      "Loss: 44.458, Residuals: 0.031\n",
      "Loss: 44.457, Residuals: 0.031\n",
      "Loss: 44.454, Residuals: 0.031\n",
      "Loss: 44.448, Residuals: 0.031\n",
      "Loss: 44.447, Residuals: 0.031\n",
      "Loss: 44.444, Residuals: 0.032\n",
      "Loss: 44.443, Residuals: 0.032\n",
      "Loss: 44.440, Residuals: 0.032\n",
      "Loss: 44.440, Residuals: 0.032\n",
      "Loss: 44.438, Residuals: 0.032\n",
      "Loss: 44.437, Residuals: 0.032\n",
      "Loss: 44.437, Residuals: 0.032\n",
      "Loss: 44.437, Residuals: 0.032\n",
      "Loss: 44.436, Residuals: 0.032\n",
      "Loss: 44.435, Residuals: 0.032\n",
      "Loss: 44.435, Residuals: 0.032\n",
      "Loss: 44.435, Residuals: 0.032\n",
      "Loss: 44.434, Residuals: 0.033\n",
      "Loss: 44.434, Residuals: 0.033\n",
      "Evidence 314.251\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.26e-01\n",
      "Loss: 90.107, Residuals: 0.026\n",
      "Loss: 89.823, Residuals: 0.019\n",
      "Loss: 89.608, Residuals: 0.023\n",
      "Loss: 89.595, Residuals: 0.025\n",
      "Loss: 89.569, Residuals: 0.025\n",
      "Loss: 89.527, Residuals: 0.025\n",
      "Loss: 89.474, Residuals: 0.024\n",
      "Loss: 89.376, Residuals: 0.024\n",
      "Loss: 89.212, Residuals: 0.025\n",
      "Loss: 89.206, Residuals: 0.024\n",
      "Loss: 89.148, Residuals: 0.025\n",
      "Loss: 89.073, Residuals: 0.026\n",
      "Loss: 89.068, Residuals: 0.026\n",
      "Loss: 89.067, Residuals: 0.026\n",
      "Loss: 89.056, Residuals: 0.026\n",
      "Loss: 89.056, Residuals: 0.026\n",
      "Loss: 89.054, Residuals: 0.026\n",
      "Loss: 89.051, Residuals: 0.026\n",
      "Loss: 89.051, Residuals: 0.026\n",
      "Loss: 89.049, Residuals: 0.026\n",
      "Loss: 89.048, Residuals: 0.026\n",
      "Loss: 89.047, Residuals: 0.026\n",
      "Loss: 89.047, Residuals: 0.026\n",
      "Loss: 89.047, Residuals: 0.026\n",
      "Loss: 89.047, Residuals: 0.026\n",
      "Loss: 89.047, Residuals: 0.026\n",
      "Evidence 427.197\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.57e+00\n",
      "Loss: 128.553, Residuals: 0.025\n",
      "Loss: 128.161, Residuals: 0.021\n",
      "Loss: 128.068, Residuals: 0.021\n",
      "Loss: 127.917, Residuals: 0.020\n",
      "Loss: 127.715, Residuals: 0.020\n",
      "Loss: 127.710, Residuals: 0.020\n",
      "Loss: 127.664, Residuals: 0.020\n",
      "Loss: 127.602, Residuals: 0.019\n",
      "Loss: 127.601, Residuals: 0.019\n",
      "Loss: 127.599, Residuals: 0.019\n",
      "Loss: 127.595, Residuals: 0.018\n",
      "Loss: 127.589, Residuals: 0.018\n",
      "Loss: 127.588, Residuals: 0.018\n",
      "Loss: 127.587, Residuals: 0.018\n",
      "Loss: 127.587, Residuals: 0.018\n",
      "Loss: 127.586, Residuals: 0.018\n",
      "Loss: 127.586, Residuals: 0.018\n",
      "Loss: 127.586, Residuals: 0.018\n",
      "Loss: 127.586, Residuals: 0.018\n",
      "Loss: 127.586, Residuals: 0.018\n",
      "Evidence 468.942\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.72e+00\n",
      "Loss: 147.564, Residuals: 0.024\n",
      "Loss: 147.235, Residuals: 0.024\n",
      "Loss: 147.016, Residuals: 0.019\n",
      "Loss: 146.886, Residuals: 0.016\n",
      "Loss: 146.862, Residuals: 0.017\n",
      "Loss: 146.818, Residuals: 0.017\n",
      "Loss: 146.751, Residuals: 0.016\n",
      "Loss: 146.742, Residuals: 0.015\n",
      "Loss: 146.727, Residuals: 0.015\n",
      "Loss: 146.704, Residuals: 0.015\n",
      "Loss: 146.704, Residuals: 0.015\n",
      "Loss: 146.700, Residuals: 0.015\n",
      "Loss: 146.695, Residuals: 0.015\n",
      "Loss: 146.695, Residuals: 0.015\n",
      "Loss: 146.694, Residuals: 0.015\n",
      "Loss: 146.694, Residuals: 0.015\n",
      "Loss: 146.693, Residuals: 0.015\n",
      "Loss: 146.693, Residuals: 0.015\n",
      "Evidence 480.882\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.66e+00\n",
      "Loss: 153.808, Residuals: 0.021\n",
      "Loss: 153.542, Residuals: 0.018\n",
      "Loss: 153.421, Residuals: 0.014\n",
      "Loss: 153.302, Residuals: 0.013\n",
      "Loss: 153.300, Residuals: 0.013\n",
      "Loss: 153.294, Residuals: 0.013\n",
      "Loss: 153.284, Residuals: 0.013\n",
      "Loss: 153.267, Residuals: 0.013\n",
      "Loss: 153.242, Residuals: 0.013\n",
      "Loss: 153.242, Residuals: 0.013\n",
      "Loss: 153.240, Residuals: 0.013\n",
      "Loss: 153.236, Residuals: 0.013\n",
      "Loss: 153.235, Residuals: 0.013\n",
      "Loss: 153.234, Residuals: 0.013\n",
      "Loss: 153.232, Residuals: 0.013\n",
      "Loss: 153.232, Residuals: 0.013\n",
      "Loss: 153.232, Residuals: 0.013\n",
      "Loss: 153.232, Residuals: 0.013\n",
      "Loss: 153.232, Residuals: 0.013\n",
      "Evidence 485.866\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.55e+00\n",
      "Loss: 155.738, Residuals: 0.019\n",
      "Loss: 155.670, Residuals: 0.013\n",
      "Loss: 155.586, Residuals: 0.013\n",
      "Loss: 155.506, Residuals: 0.013\n",
      "Loss: 155.505, Residuals: 0.013\n",
      "Loss: 155.503, Residuals: 0.013\n",
      "Loss: 155.499, Residuals: 0.013\n",
      "Loss: 155.493, Residuals: 0.012\n",
      "Loss: 155.484, Residuals: 0.012\n",
      "Loss: 155.473, Residuals: 0.012\n",
      "Loss: 155.473, Residuals: 0.012\n",
      "Loss: 155.473, Residuals: 0.012\n",
      "Loss: 155.472, Residuals: 0.012\n",
      "Loss: 155.472, Residuals: 0.012\n",
      "Loss: 155.471, Residuals: 0.012\n",
      "Loss: 155.471, Residuals: 0.012\n",
      "Loss: 155.471, Residuals: 0.012\n",
      "Loss: 155.470, Residuals: 0.012\n",
      "Loss: 155.470, Residuals: 0.012\n",
      "Evidence 488.789\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.47e+00\n",
      "Loss: 156.548, Residuals: 0.014\n",
      "Loss: 156.513, Residuals: 0.013\n",
      "Loss: 156.476, Residuals: 0.013\n",
      "Loss: 156.441, Residuals: 0.012\n",
      "Loss: 156.437, Residuals: 0.012\n",
      "Loss: 156.435, Residuals: 0.012\n",
      "Loss: 156.432, Residuals: 0.012\n",
      "Loss: 156.428, Residuals: 0.012\n",
      "Loss: 156.428, Residuals: 0.012\n",
      "Loss: 156.427, Residuals: 0.012\n",
      "Loss: 156.426, Residuals: 0.012\n",
      "Evidence 490.632\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.43e+00\n",
      "Loss: 157.028, Residuals: 0.014\n",
      "Loss: 157.012, Residuals: 0.013\n",
      "Loss: 156.993, Residuals: 0.012\n",
      "Loss: 156.975, Residuals: 0.012\n",
      "Loss: 156.974, Residuals: 0.012\n",
      "Loss: 156.973, Residuals: 0.012\n",
      "Loss: 156.972, Residuals: 0.012\n",
      "Loss: 156.971, Residuals: 0.012\n",
      "Loss: 156.971, Residuals: 0.012\n",
      "Loss: 156.971, Residuals: 0.012\n",
      "Loss: 156.970, Residuals: 0.012\n",
      "Evidence 491.789\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.41e+00\n",
      "Loss: 157.365, Residuals: 0.013\n",
      "Loss: 157.357, Residuals: 0.012\n",
      "Loss: 157.347, Residuals: 0.012\n",
      "Loss: 157.339, Residuals: 0.012\n",
      "Loss: 157.338, Residuals: 0.012\n",
      "Loss: 157.338, Residuals: 0.012\n",
      "Loss: 157.338, Residuals: 0.012\n",
      "Loss: 157.337, Residuals: 0.012\n",
      "Loss: 157.337, Residuals: 0.012\n",
      "Evidence 492.526\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.40e+00\n",
      "Loss: 157.632, Residuals: 0.013\n",
      "Loss: 157.628, Residuals: 0.013\n",
      "Loss: 157.622, Residuals: 0.012\n",
      "Loss: 157.618, Residuals: 0.012\n",
      "Loss: 157.617, Residuals: 0.012\n",
      "Loss: 157.617, Residuals: 0.012\n",
      "Loss: 157.617, Residuals: 0.012\n",
      "Loss: 157.617, Residuals: 0.012\n",
      "Loss: 157.617, Residuals: 0.012\n",
      "Loss: 157.616, Residuals: 0.012\n",
      "Loss: 157.616, Residuals: 0.012\n",
      "Loss: 157.616, Residuals: 0.012\n",
      "Evidence 493.006\n",
      "Pass count  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.975, Residuals: -0.053\n",
      "Loss: 7.490, Residuals: 0.011\n",
      "Loss: 5.091, Residuals: -0.049\n",
      "Loss: 4.306, Residuals: -0.040\n",
      "Loss: 3.854, Residuals: -0.023\n",
      "Loss: 3.791, Residuals: -0.010\n",
      "Loss: 3.744, Residuals: -0.013\n",
      "Loss: 3.654, Residuals: -0.017\n",
      "Loss: 3.497, Residuals: -0.022\n",
      "Loss: 3.263, Residuals: -0.033\n",
      "Loss: 3.228, Residuals: -0.002\n",
      "Loss: 3.171, Residuals: -0.012\n",
      "Loss: 3.083, Residuals: -0.029\n",
      "Loss: 3.076, Residuals: -0.021\n",
      "Loss: 3.064, Residuals: -0.023\n",
      "Loss: 3.041, Residuals: -0.028\n",
      "Loss: 3.000, Residuals: -0.038\n",
      "Loss: 2.980, Residuals: -0.036\n",
      "Loss: 2.947, Residuals: -0.046\n",
      "Loss: 2.944, Residuals: -0.042\n",
      "Loss: 2.916, Residuals: -0.053\n",
      "Loss: 2.912, Residuals: -0.051\n",
      "Loss: 2.885, Residuals: -0.062\n",
      "Loss: 2.884, Residuals: -0.058\n",
      "Loss: 2.862, Residuals: -0.067\n",
      "Loss: 2.861, Residuals: -0.064\n",
      "Loss: 2.847, Residuals: -0.071\n",
      "Loss: 2.846, Residuals: -0.071\n",
      "Loss: 2.846, Residuals: -0.071\n",
      "Loss: 2.840, Residuals: -0.073\n",
      "Loss: 2.839, Residuals: -0.076\n",
      "Loss: 2.839, Residuals: -0.075\n",
      "Loss: 2.826, Residuals: -0.079\n",
      "Loss: 2.826, Residuals: -0.078\n",
      "Loss: 2.826, Residuals: -0.078\n",
      "Loss: 2.826, Residuals: -0.077\n",
      "Loss: 2.824, Residuals: -0.079\n",
      "Loss: 2.814, Residuals: -0.082\n",
      "Loss: 2.814, Residuals: -0.081\n",
      "Loss: 2.814, Residuals: -0.081\n",
      "Evidence -410.486\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.89e-02\n",
      "Loss: 13.454, Residuals: -0.049\n",
      "Loss: 13.436, Residuals: -0.052\n",
      "Loss: 13.435, Residuals: -0.051\n",
      "Loss: 13.389, Residuals: -0.051\n",
      "Loss: 13.308, Residuals: -0.051\n",
      "Loss: 13.201, Residuals: -0.050\n",
      "Loss: 13.201, Residuals: -0.051\n",
      "Evidence 100.272\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.03e-01\n",
      "Loss: 42.023, Residuals: -0.041\n",
      "Loss: 41.450, Residuals: -0.034\n",
      "Loss: 41.445, Residuals: -0.035\n",
      "Evidence 286.247\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.40e-01\n",
      "Loss: 86.295, Residuals: -0.028\n",
      "Loss: 86.292, Residuals: -0.028\n",
      "Evidence 386.992\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 5.61e-01\n",
      "Loss: 124.972, Residuals: -0.040\n",
      "Loss: 123.367, Residuals: -0.041\n",
      "Loss: 123.360, Residuals: -0.041\n",
      "Evidence 421.285\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.68e-01\n",
      "Loss: 142.583, Residuals: -0.040\n",
      "Loss: 141.126, Residuals: -0.040\n",
      "Loss: 138.957, Residuals: -0.041\n",
      "Loss: 138.951, Residuals: -0.041\n",
      "Evidence 432.038\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.41e-01\n",
      "Loss: 147.071, Residuals: -0.042\n",
      "Loss: 147.069, Residuals: -0.042\n",
      "Evidence 435.246\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.72e-01\n",
      "Loss: 150.109, Residuals: -0.042\n",
      "Loss: 149.137, Residuals: -0.040\n",
      "Loss: 147.755, Residuals: -0.037\n",
      "Loss: 147.749, Residuals: -0.037\n",
      "Evidence 438.365\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.22e-01\n",
      "Loss: 149.730, Residuals: -0.032\n",
      "Loss: 148.308, Residuals: -0.029\n",
      "Loss: 148.274, Residuals: -0.029\n",
      "Loss: 147.039, Residuals: -0.026\n",
      "Loss: 147.035, Residuals: -0.026\n",
      "Loss: 146.472, Residuals: -0.025\n",
      "Loss: 146.469, Residuals: -0.025\n",
      "Evidence 442.819\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 9.66e-01\n",
      "Loss: 149.519, Residuals: -0.027\n",
      "Loss: 148.940, Residuals: -0.022\n",
      "Loss: 147.932, Residuals: -0.021\n",
      "Loss: 147.916, Residuals: -0.020\n",
      "Evidence 446.581\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.04e+00\n",
      "Loss: 150.050, Residuals: -0.020\n",
      "Loss: 149.811, Residuals: -0.020\n",
      "Loss: 149.487, Residuals: -0.021\n",
      "Loss: 148.887, Residuals: -0.021\n",
      "Loss: 148.880, Residuals: -0.020\n",
      "Evidence 448.995\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.09e+00\n",
      "Loss: 150.394, Residuals: -0.019\n",
      "Loss: 149.966, Residuals: -0.019\n",
      "Loss: 149.964, Residuals: -0.019\n",
      "Evidence 450.402\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.12e+00\n",
      "Loss: 150.789, Residuals: -0.018\n",
      "Loss: 150.213, Residuals: -0.018\n",
      "Loss: 150.207, Residuals: -0.018\n",
      "Loss: 149.966, Residuals: -0.018\n",
      "Loss: 149.950, Residuals: -0.020\n",
      "Loss: 149.801, Residuals: -0.020\n",
      "Loss: 149.799, Residuals: -0.019\n",
      "Loss: 149.497, Residuals: -0.019\n",
      "Loss: 149.491, Residuals: -0.018\n",
      "Loss: 149.479, Residuals: -0.018\n",
      "Loss: 149.371, Residuals: -0.018\n",
      "Loss: 149.370, Residuals: -0.018\n",
      "Loss: 148.891, Residuals: -0.016\n",
      "Loss: 148.872, Residuals: -0.015\n",
      "Loss: 148.860, Residuals: -0.015\n",
      "Loss: 148.751, Residuals: -0.014\n",
      "Loss: 148.561, Residuals: -0.011\n",
      "Loss: 148.557, Residuals: -0.012\n",
      "Loss: 148.556, Residuals: -0.012\n",
      "Loss: 148.503, Residuals: -0.011\n",
      "Loss: 148.499, Residuals: -0.012\n",
      "Loss: 148.461, Residuals: -0.011\n",
      "Loss: 148.460, Residuals: -0.011\n",
      "Loss: 148.378, Residuals: -0.008\n",
      "Loss: 148.375, Residuals: -0.008\n",
      "Loss: 148.375, Residuals: -0.008\n",
      "Loss: 147.929, Residuals: 0.005\n",
      "Loss: 147.722, Residuals: 0.004\n",
      "Loss: 147.642, Residuals: 0.005\n",
      "Loss: 147.577, Residuals: 0.005\n",
      "Loss: 147.487, Residuals: 0.007\n",
      "Loss: 147.483, Residuals: 0.007\n",
      "Loss: 147.449, Residuals: 0.007\n",
      "Loss: 147.395, Residuals: 0.008\n",
      "Loss: 147.390, Residuals: 0.008\n",
      "Loss: 147.351, Residuals: 0.009\n",
      "Loss: 147.348, Residuals: 0.009\n",
      "Loss: 147.320, Residuals: 0.009\n",
      "Loss: 147.318, Residuals: 0.009\n",
      "Loss: 147.299, Residuals: 0.009\n",
      "Loss: 147.298, Residuals: 0.009\n",
      "Loss: 147.285, Residuals: 0.009\n",
      "Loss: 147.283, Residuals: 0.009\n",
      "Loss: 147.279, Residuals: 0.009\n",
      "Loss: 147.272, Residuals: 0.009\n",
      "Loss: 147.271, Residuals: 0.009\n",
      "Loss: 147.265, Residuals: 0.009\n",
      "Loss: 147.263, Residuals: 0.009\n",
      "Loss: 147.247, Residuals: 0.009\n",
      "Loss: 147.245, Residuals: 0.009\n",
      "Loss: 147.243, Residuals: 0.009\n",
      "Loss: 147.225, Residuals: 0.009\n",
      "Loss: 147.223, Residuals: 0.009\n",
      "Loss: 147.222, Residuals: 0.009\n",
      "Loss: 147.208, Residuals: 0.009\n",
      "Loss: 147.207, Residuals: 0.009\n",
      "Loss: 147.204, Residuals: 0.009\n",
      "Loss: 147.199, Residuals: 0.009\n",
      "Loss: 147.196, Residuals: 0.009\n",
      "Loss: 147.189, Residuals: 0.009\n",
      "Loss: 147.188, Residuals: 0.009\n",
      "Loss: 147.171, Residuals: 0.009\n",
      "Loss: 147.169, Residuals: 0.009\n",
      "Loss: 147.167, Residuals: 0.009\n",
      "Loss: 147.148, Residuals: 0.008\n",
      "Loss: 147.146, Residuals: 0.008\n",
      "Loss: 147.144, Residuals: 0.009\n",
      "Loss: 147.124, Residuals: 0.008\n",
      "Loss: 147.123, Residuals: 0.008\n",
      "Loss: 147.120, Residuals: 0.008\n",
      "Loss: 147.116, Residuals: 0.008\n",
      "Loss: 147.115, Residuals: 0.008\n",
      "Loss: 147.110, Residuals: 0.008\n",
      "Loss: 147.102, Residuals: 0.008\n",
      "Loss: 147.101, Residuals: 0.008\n",
      "Loss: 147.097, Residuals: 0.008\n",
      "Loss: 147.096, Residuals: 0.008\n",
      "Loss: 147.093, Residuals: 0.007\n",
      "Loss: 147.093, Residuals: 0.007\n",
      "Loss: 147.092, Residuals: 0.007\n",
      "Loss: 147.091, Residuals: 0.007\n",
      "Evidence 454.262\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.78e+00\n",
      "Loss: 149.675, Residuals: 0.009\n",
      "Loss: 149.614, Residuals: 0.009\n",
      "Loss: 149.500, Residuals: 0.010\n",
      "Loss: 149.330, Residuals: 0.012\n",
      "Loss: 149.199, Residuals: 0.014\n",
      "Loss: 149.193, Residuals: 0.013\n",
      "Loss: 149.188, Residuals: 0.014\n",
      "Loss: 149.179, Residuals: 0.014\n",
      "Loss: 149.175, Residuals: 0.014\n",
      "Loss: 149.174, Residuals: 0.014\n",
      "Loss: 149.173, Residuals: 0.014\n",
      "Loss: 149.173, Residuals: 0.014\n",
      "Loss: 149.173, Residuals: 0.014\n",
      "Loss: 149.172, Residuals: 0.014\n",
      "Evidence 459.500\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.80e+00\n",
      "Loss: 150.312, Residuals: 0.018\n",
      "Loss: 150.228, Residuals: 0.015\n",
      "Loss: 150.218, Residuals: 0.015\n",
      "Loss: 150.203, Residuals: 0.015\n",
      "Loss: 150.191, Residuals: 0.015\n",
      "Loss: 150.190, Residuals: 0.015\n",
      "Loss: 150.189, Residuals: 0.015\n",
      "Loss: 150.188, Residuals: 0.015\n",
      "Loss: 150.188, Residuals: 0.015\n",
      "Loss: 150.188, Residuals: 0.015\n",
      "Loss: 150.188, Residuals: 0.015\n",
      "Loss: 150.188, Residuals: 0.015\n",
      "Loss: 150.188, Residuals: 0.015\n",
      "Loss: 150.188, Residuals: 0.015\n",
      "Evidence 460.919\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.78e+00\n",
      "Loss: 150.714, Residuals: 0.016\n",
      "Loss: 150.674, Residuals: 0.015\n",
      "Loss: 150.669, Residuals: 0.015\n",
      "Loss: 150.661, Residuals: 0.015\n",
      "Loss: 150.653, Residuals: 0.015\n",
      "Loss: 150.652, Residuals: 0.015\n",
      "Loss: 150.652, Residuals: 0.015\n",
      "Loss: 150.652, Residuals: 0.015\n",
      "Loss: 150.651, Residuals: 0.015\n",
      "Loss: 150.651, Residuals: 0.015\n",
      "Loss: 150.651, Residuals: 0.015\n",
      "Loss: 150.651, Residuals: 0.015\n",
      "Loss: 150.651, Residuals: 0.015\n",
      "Evidence 461.840\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.76e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 150.963, Residuals: 0.016\n",
      "Loss: 150.944, Residuals: 0.016\n",
      "Loss: 150.942, Residuals: 0.015\n",
      "Loss: 150.938, Residuals: 0.015\n",
      "Loss: 150.936, Residuals: 0.015\n",
      "Loss: 150.935, Residuals: 0.015\n",
      "Loss: 150.935, Residuals: 0.015\n",
      "Loss: 150.935, Residuals: 0.015\n",
      "Loss: 150.935, Residuals: 0.015\n",
      "Loss: 150.935, Residuals: 0.015\n",
      "Evidence 462.462\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.75e+00\n",
      "Loss: 151.158, Residuals: 0.016\n",
      "Loss: 151.150, Residuals: 0.014\n",
      "Loss: 151.144, Residuals: 0.015\n",
      "Loss: 151.143, Residuals: 0.015\n",
      "Loss: 151.141, Residuals: 0.015\n",
      "Loss: 151.141, Residuals: 0.015\n",
      "Loss: 151.141, Residuals: 0.015\n",
      "Loss: 151.141, Residuals: 0.015\n",
      "Loss: 151.141, Residuals: 0.015\n",
      "Loss: 151.140, Residuals: 0.015\n",
      "Evidence 462.895\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.325, Residuals: -0.052\n",
      "Loss: 6.924, Residuals: -0.034\n",
      "Loss: 4.869, Residuals: -0.031\n",
      "Loss: 4.166, Residuals: -0.024\n",
      "Loss: 3.723, Residuals: -0.039\n",
      "Loss: 3.550, Residuals: 0.013\n",
      "Loss: 3.321, Residuals: -0.011\n",
      "Loss: 3.314, Residuals: -0.015\n",
      "Loss: 3.252, Residuals: -0.017\n",
      "Loss: 3.144, Residuals: -0.019\n",
      "Loss: 3.112, Residuals: -0.003\n",
      "Loss: 3.108, Residuals: -0.001\n",
      "Loss: 3.072, Residuals: -0.005\n",
      "Loss: 3.010, Residuals: -0.014\n",
      "Loss: 3.007, Residuals: -0.011\n",
      "Loss: 2.929, Residuals: -0.019\n",
      "Loss: 2.926, Residuals: -0.012\n",
      "Loss: 2.920, Residuals: -0.012\n",
      "Loss: 2.870, Residuals: -0.023\n",
      "Loss: 2.868, Residuals: -0.020\n",
      "Loss: 2.864, Residuals: -0.021\n",
      "Loss: 2.859, Residuals: -0.024\n",
      "Loss: 2.848, Residuals: -0.027\n",
      "Loss: 2.830, Residuals: -0.032\n",
      "Loss: 2.824, Residuals: -0.033\n",
      "Loss: 2.814, Residuals: -0.035\n",
      "Loss: 2.795, Residuals: -0.042\n",
      "Loss: 2.793, Residuals: -0.035\n",
      "Loss: 2.775, Residuals: -0.041\n",
      "Loss: 2.767, Residuals: -0.039\n",
      "Loss: 2.766, Residuals: -0.035\n",
      "Loss: 2.749, Residuals: -0.037\n",
      "Loss: 2.739, Residuals: -0.032\n",
      "Loss: 2.736, Residuals: -0.030\n",
      "Loss: 2.708, Residuals: -0.037\n",
      "Loss: 2.685, Residuals: -0.034\n",
      "Loss: 2.685, Residuals: -0.035\n",
      "Loss: 2.668, Residuals: -0.038\n",
      "Loss: 2.637, Residuals: -0.044\n",
      "Loss: 2.636, Residuals: -0.042\n",
      "Loss: 2.618, Residuals: -0.038\n",
      "Loss: 2.618, Residuals: -0.039\n",
      "Loss: 2.616, Residuals: -0.037\n",
      "Loss: 2.601, Residuals: -0.039\n",
      "Loss: 2.598, Residuals: -0.032\n",
      "Loss: 2.574, Residuals: -0.035\n",
      "Loss: 2.573, Residuals: -0.034\n",
      "Loss: 2.572, Residuals: -0.033\n",
      "Loss: 2.569, Residuals: -0.030\n",
      "Loss: 2.569, Residuals: -0.029\n",
      "Loss: 2.552, Residuals: -0.032\n",
      "Loss: 2.552, Residuals: -0.031\n",
      "Loss: 2.550, Residuals: -0.030\n",
      "Loss: 2.535, Residuals: -0.033\n",
      "Loss: 2.535, Residuals: -0.032\n",
      "Loss: 2.535, Residuals: -0.032\n",
      "Loss: 2.505, Residuals: -0.038\n",
      "Loss: 2.504, Residuals: -0.037\n",
      "Loss: 2.504, Residuals: -0.037\n",
      "Loss: 2.503, Residuals: -0.035\n",
      "Loss: 2.502, Residuals: -0.034\n",
      "Loss: 2.499, Residuals: -0.030\n",
      "Loss: 2.499, Residuals: -0.026\n",
      "Loss: 2.478, Residuals: -0.032\n",
      "Loss: 2.477, Residuals: -0.033\n",
      "Loss: 2.477, Residuals: -0.032\n",
      "Loss: 2.475, Residuals: -0.029\n",
      "Loss: 2.472, Residuals: -0.029\n",
      "Loss: 2.467, Residuals: -0.028\n",
      "Loss: 2.466, Residuals: -0.023\n",
      "Loss: 2.454, Residuals: -0.027\n",
      "Loss: 2.453, Residuals: -0.026\n",
      "Loss: 2.443, Residuals: -0.028\n",
      "Loss: 2.443, Residuals: -0.028\n",
      "Loss: 2.443, Residuals: -0.028\n",
      "Evidence -402.640\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.20e-02\n",
      "Loss: 12.894, Residuals: -0.040\n",
      "Loss: 12.891, Residuals: -0.039\n",
      "Loss: 12.497, Residuals: -0.032\n",
      "Loss: 12.261, Residuals: 0.009\n",
      "Loss: 12.180, Residuals: 0.001\n",
      "Loss: 12.149, Residuals: 0.000\n",
      "Loss: 12.140, Residuals: -0.003\n",
      "Loss: 12.122, Residuals: -0.002\n",
      "Loss: 12.090, Residuals: 0.001\n",
      "Loss: 12.072, Residuals: -0.000\n",
      "Loss: 12.072, Residuals: -0.000\n",
      "Evidence 99.651\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.68e-02\n",
      "Loss: 41.563, Residuals: -0.001\n",
      "Loss: 41.553, Residuals: -0.001\n",
      "Loss: 41.535, Residuals: -0.001\n",
      "Loss: 41.502, Residuals: -0.001\n",
      "Loss: 41.439, Residuals: -0.000\n",
      "Loss: 41.324, Residuals: 0.002\n",
      "Loss: 41.127, Residuals: 0.005\n",
      "Loss: 41.117, Residuals: 0.005\n",
      "Loss: 41.030, Residuals: 0.006\n",
      "Loss: 40.864, Residuals: 0.007\n",
      "Loss: 40.631, Residuals: 0.009\n",
      "Loss: 40.621, Residuals: 0.009\n",
      "Loss: 40.620, Residuals: 0.009\n",
      "Evidence 288.716\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.00e-01\n",
      "Loss: 88.368, Residuals: 0.008\n",
      "Loss: 88.312, Residuals: 0.008\n",
      "Loss: 88.212, Residuals: 0.009\n",
      "Loss: 88.028, Residuals: 0.007\n",
      "Loss: 87.713, Residuals: 0.005\n",
      "Loss: 87.270, Residuals: -0.001\n",
      "Loss: 86.759, Residuals: -0.012\n",
      "Loss: 86.741, Residuals: -0.011\n",
      "Loss: 86.014, Residuals: -0.010\n",
      "Loss: 84.742, Residuals: -0.005\n",
      "Loss: 84.739, Residuals: -0.005\n",
      "Loss: 84.710, Residuals: -0.005\n",
      "Loss: 83.605, Residuals: 0.002\n",
      "Loss: 83.595, Residuals: 0.002\n",
      "Loss: 83.508, Residuals: 0.002\n",
      "Loss: 83.472, Residuals: 0.003\n",
      "Loss: 83.131, Residuals: 0.005\n",
      "Loss: 82.574, Residuals: 0.008\n",
      "Loss: 82.572, Residuals: 0.008\n",
      "Evidence 389.035\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.04e-01\n",
      "Loss: 121.317, Residuals: 0.007\n",
      "Loss: 121.109, Residuals: 0.008\n",
      "Loss: 120.719, Residuals: 0.007\n",
      "Loss: 120.066, Residuals: 0.005\n",
      "Loss: 119.339, Residuals: -0.004\n",
      "Loss: 119.306, Residuals: -0.006\n",
      "Loss: 118.216, Residuals: -0.004\n",
      "Loss: 118.214, Residuals: -0.004\n",
      "Loss: 117.832, Residuals: -0.001\n",
      "Loss: 117.827, Residuals: -0.000\n",
      "Loss: 117.647, Residuals: -0.000\n",
      "Loss: 117.333, Residuals: 0.000\n",
      "Loss: 117.286, Residuals: -0.002\n",
      "Loss: 117.197, Residuals: -0.001\n",
      "Loss: 117.193, Residuals: 0.000\n",
      "Loss: 116.612, Residuals: 0.002\n",
      "Loss: 116.606, Residuals: 0.002\n",
      "Loss: 116.551, Residuals: 0.001\n",
      "Loss: 116.450, Residuals: 0.002\n",
      "Loss: 116.448, Residuals: 0.001\n",
      "Loss: 116.132, Residuals: 0.003\n",
      "Loss: 116.053, Residuals: 0.000\n",
      "Loss: 115.910, Residuals: 0.003\n",
      "Loss: 115.905, Residuals: 0.003\n",
      "Loss: 115.119, Residuals: 0.006\n",
      "Loss: 115.085, Residuals: 0.007\n",
      "Loss: 114.771, Residuals: 0.007\n",
      "Loss: 114.492, Residuals: 0.009\n",
      "Loss: 114.128, Residuals: 0.009\n",
      "Loss: 114.051, Residuals: 0.009\n",
      "Loss: 114.051, Residuals: 0.009\n",
      "Evidence 431.781\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 9.68e-01\n",
      "Loss: 136.310, Residuals: 0.012\n",
      "Loss: 135.610, Residuals: 0.014\n",
      "Loss: 134.762, Residuals: 0.011\n",
      "Loss: 134.650, Residuals: 0.010\n",
      "Loss: 133.825, Residuals: 0.015\n",
      "Loss: 133.809, Residuals: 0.014\n",
      "Loss: 133.788, Residuals: 0.014\n",
      "Loss: 133.620, Residuals: 0.016\n",
      "Loss: 133.608, Residuals: 0.016\n",
      "Loss: 133.585, Residuals: 0.016\n",
      "Loss: 133.545, Residuals: 0.017\n",
      "Loss: 133.537, Residuals: 0.018\n",
      "Loss: 133.522, Residuals: 0.019\n",
      "Loss: 133.499, Residuals: 0.019\n",
      "Loss: 133.498, Residuals: 0.019\n",
      "Loss: 133.491, Residuals: 0.019\n",
      "Loss: 133.481, Residuals: 0.020\n",
      "Loss: 133.481, Residuals: 0.020\n",
      "Loss: 133.480, Residuals: 0.020\n",
      "Loss: 133.479, Residuals: 0.020\n",
      "Loss: 133.479, Residuals: 0.020\n",
      "Loss: 133.479, Residuals: 0.020\n",
      "Loss: 133.479, Residuals: 0.020\n",
      "Loss: 133.479, Residuals: 0.020\n",
      "Loss: 133.479, Residuals: 0.020\n",
      "Evidence 453.594\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.49e+00\n",
      "Loss: 145.441, Residuals: 0.021\n",
      "Loss: 145.216, Residuals: 0.020\n",
      "Loss: 145.027, Residuals: 0.022\n",
      "Loss: 144.892, Residuals: 0.017\n",
      "Loss: 144.822, Residuals: 0.020\n",
      "Loss: 144.795, Residuals: 0.017\n",
      "Loss: 144.747, Residuals: 0.018\n",
      "Loss: 144.695, Residuals: 0.020\n",
      "Loss: 144.691, Residuals: 0.020\n",
      "Loss: 144.686, Residuals: 0.020\n",
      "Loss: 144.686, Residuals: 0.020\n",
      "Loss: 144.685, Residuals: 0.020\n",
      "Loss: 144.683, Residuals: 0.021\n",
      "Evidence 459.972\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.64e+00\n",
      "Loss: 149.095, Residuals: 0.021\n",
      "Loss: 148.969, Residuals: 0.022\n",
      "Loss: 148.844, Residuals: 0.021\n",
      "Loss: 148.752, Residuals: 0.018\n",
      "Loss: 148.731, Residuals: 0.019\n",
      "Loss: 148.699, Residuals: 0.019\n",
      "Loss: 148.673, Residuals: 0.020\n",
      "Loss: 148.671, Residuals: 0.019\n",
      "Loss: 148.670, Residuals: 0.019\n",
      "Loss: 148.669, Residuals: 0.019\n",
      "Loss: 148.669, Residuals: 0.020\n",
      "Loss: 148.668, Residuals: 0.020\n",
      "Loss: 148.666, Residuals: 0.020\n",
      "Loss: 148.666, Residuals: 0.020\n",
      "Loss: 148.666, Residuals: 0.020\n",
      "Loss: 148.666, Residuals: 0.020\n",
      "Evidence 462.303\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.72e+00\n",
      "Loss: 150.251, Residuals: 0.019\n",
      "Loss: 150.155, Residuals: 0.019\n",
      "Loss: 150.101, Residuals: 0.017\n",
      "Loss: 150.043, Residuals: 0.019\n",
      "Loss: 150.035, Residuals: 0.018\n",
      "Loss: 150.021, Residuals: 0.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 150.007, Residuals: 0.018\n",
      "Loss: 150.006, Residuals: 0.018\n",
      "Loss: 150.005, Residuals: 0.018\n",
      "Loss: 150.005, Residuals: 0.018\n",
      "Loss: 150.003, Residuals: 0.018\n",
      "Evidence 463.760\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.77e+00\n",
      "Loss: 150.668, Residuals: 0.017\n",
      "Loss: 150.592, Residuals: 0.017\n",
      "Loss: 150.537, Residuals: 0.018\n",
      "Loss: 150.504, Residuals: 0.017\n",
      "Loss: 150.495, Residuals: 0.017\n",
      "Loss: 150.482, Residuals: 0.017\n",
      "Loss: 150.473, Residuals: 0.017\n",
      "Loss: 150.472, Residuals: 0.017\n",
      "Loss: 150.472, Residuals: 0.017\n",
      "Loss: 150.471, Residuals: 0.017\n",
      "Loss: 150.470, Residuals: 0.017\n",
      "Loss: 150.470, Residuals: 0.017\n",
      "Loss: 150.470, Residuals: 0.017\n",
      "Loss: 150.469, Residuals: 0.017\n",
      "Loss: 150.469, Residuals: 0.017\n",
      "Loss: 150.469, Residuals: 0.017\n",
      "Loss: 150.469, Residuals: 0.017\n",
      "Loss: 150.469, Residuals: 0.017\n",
      "Loss: 150.469, Residuals: 0.017\n",
      "Evidence 464.995\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.81e+00\n",
      "Loss: 150.791, Residuals: 0.017\n",
      "Loss: 150.742, Residuals: 0.017\n",
      "Loss: 150.709, Residuals: 0.016\n",
      "Loss: 150.703, Residuals: 0.016\n",
      "Loss: 150.693, Residuals: 0.016\n",
      "Loss: 150.683, Residuals: 0.016\n",
      "Loss: 150.683, Residuals: 0.016\n",
      "Loss: 150.683, Residuals: 0.016\n",
      "Loss: 150.682, Residuals: 0.016\n",
      "Loss: 150.681, Residuals: 0.016\n",
      "Loss: 150.681, Residuals: 0.016\n",
      "Loss: 150.680, Residuals: 0.016\n",
      "Loss: 150.680, Residuals: 0.016\n",
      "Loss: 150.679, Residuals: 0.016\n",
      "Loss: 150.679, Residuals: 0.016\n",
      "Loss: 150.679, Residuals: 0.016\n",
      "Loss: 150.679, Residuals: 0.016\n",
      "Loss: 150.679, Residuals: 0.016\n",
      "Loss: 150.679, Residuals: 0.016\n",
      "Loss: 150.679, Residuals: 0.016\n",
      "Evidence 466.082\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.86e+00\n",
      "Loss: 150.908, Residuals: 0.016\n",
      "Loss: 150.871, Residuals: 0.015\n",
      "Loss: 150.854, Residuals: 0.015\n",
      "Loss: 150.841, Residuals: 0.015\n",
      "Loss: 150.838, Residuals: 0.014\n",
      "Loss: 150.834, Residuals: 0.014\n",
      "Loss: 150.834, Residuals: 0.014\n",
      "Loss: 150.834, Residuals: 0.014\n",
      "Loss: 150.833, Residuals: 0.014\n",
      "Loss: 150.831, Residuals: 0.014\n",
      "Loss: 150.831, Residuals: 0.014\n",
      "Loss: 150.831, Residuals: 0.014\n",
      "Loss: 150.831, Residuals: 0.014\n",
      "Loss: 150.831, Residuals: 0.014\n",
      "Loss: 150.831, Residuals: 0.014\n",
      "Loss: 150.831, Residuals: 0.014\n",
      "Evidence 466.994\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.90e+00\n",
      "Loss: 151.025, Residuals: 0.015\n",
      "Loss: 151.000, Residuals: 0.014\n",
      "Loss: 150.999, Residuals: 0.014\n",
      "Loss: 150.990, Residuals: 0.014\n",
      "Loss: 150.977, Residuals: 0.014\n",
      "Loss: 150.976, Residuals: 0.014\n",
      "Loss: 150.975, Residuals: 0.013\n",
      "Loss: 150.972, Residuals: 0.013\n",
      "Loss: 150.972, Residuals: 0.013\n",
      "Loss: 150.972, Residuals: 0.013\n",
      "Loss: 150.971, Residuals: 0.013\n",
      "Loss: 150.971, Residuals: 0.013\n",
      "Loss: 150.971, Residuals: 0.013\n",
      "Loss: 150.971, Residuals: 0.013\n",
      "Loss: 150.971, Residuals: 0.013\n",
      "Loss: 150.970, Residuals: 0.013\n",
      "Evidence 467.724\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.93e+00\n",
      "Loss: 151.140, Residuals: 0.014\n",
      "Loss: 151.123, Residuals: 0.013\n",
      "Loss: 151.122, Residuals: 0.013\n",
      "Loss: 151.115, Residuals: 0.013\n",
      "Loss: 151.107, Residuals: 0.012\n",
      "Loss: 151.105, Residuals: 0.012\n",
      "Loss: 151.103, Residuals: 0.012\n",
      "Loss: 151.101, Residuals: 0.012\n",
      "Loss: 151.101, Residuals: 0.012\n",
      "Loss: 151.101, Residuals: 0.012\n",
      "Loss: 151.101, Residuals: 0.012\n",
      "Loss: 151.100, Residuals: 0.012\n",
      "Evidence 468.304\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.96e+00\n",
      "Loss: 151.244, Residuals: 0.012\n",
      "Loss: 151.231, Residuals: 0.012\n",
      "Loss: 151.223, Residuals: 0.011\n",
      "Loss: 151.217, Residuals: 0.011\n",
      "Loss: 151.216, Residuals: 0.011\n",
      "Loss: 151.215, Residuals: 0.011\n",
      "Loss: 151.215, Residuals: 0.011\n",
      "Loss: 151.214, Residuals: 0.011\n",
      "Evidence 468.747\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.104, Residuals: -0.057\n",
      "Loss: 7.439, Residuals: -0.053\n",
      "Loss: 5.318, Residuals: -0.042\n",
      "Loss: 4.620, Residuals: -0.035\n",
      "Loss: 4.051, Residuals: -0.042\n",
      "Loss: 3.968, Residuals: 0.060\n",
      "Loss: 3.812, Residuals: 0.041\n",
      "Loss: 3.545, Residuals: 0.020\n",
      "Loss: 3.361, Residuals: -0.045\n",
      "Loss: 3.296, Residuals: -0.013\n",
      "Loss: 3.183, Residuals: -0.029\n",
      "Loss: 3.000, Residuals: -0.044\n",
      "Loss: 2.982, Residuals: -0.033\n",
      "Loss: 2.948, Residuals: -0.037\n",
      "Loss: 2.888, Residuals: -0.044\n",
      "Loss: 2.877, Residuals: -0.035\n",
      "Loss: 2.856, Residuals: -0.038\n",
      "Loss: 2.819, Residuals: -0.044\n",
      "Loss: 2.799, Residuals: -0.039\n",
      "Loss: 2.766, Residuals: -0.044\n",
      "Loss: 2.763, Residuals: -0.041\n",
      "Loss: 2.740, Residuals: -0.045\n",
      "Loss: 2.729, Residuals: -0.043\n",
      "Loss: 2.710, Residuals: -0.048\n",
      "Loss: 2.707, Residuals: -0.047\n",
      "Loss: 2.682, Residuals: -0.054\n",
      "Loss: 2.682, Residuals: -0.051\n",
      "Loss: 2.675, Residuals: -0.053\n",
      "Loss: 2.664, Residuals: -0.058\n",
      "Loss: 2.663, Residuals: -0.057\n",
      "Loss: 2.650, Residuals: -0.062\n",
      "Loss: 2.647, Residuals: -0.066\n",
      "Loss: 2.646, Residuals: -0.066\n",
      "Loss: 2.627, Residuals: -0.070\n",
      "Loss: 2.626, Residuals: -0.069\n",
      "Loss: 2.625, Residuals: -0.069\n",
      "Loss: 2.578, Residuals: -0.071\n",
      "Loss: 2.575, Residuals: -0.062\n",
      "Loss: 2.571, Residuals: -0.063\n",
      "Loss: 2.540, Residuals: -0.067\n",
      "Loss: 2.539, Residuals: -0.070\n",
      "Loss: 2.537, Residuals: -0.067\n",
      "Loss: 2.534, Residuals: -0.068\n",
      "Loss: 2.533, Residuals: -0.058\n",
      "Loss: 2.530, Residuals: -0.059\n",
      "Loss: 2.527, Residuals: -0.061\n",
      "Loss: 2.525, Residuals: -0.064\n",
      "Loss: 2.522, Residuals: -0.066\n",
      "Loss: 2.522, Residuals: -0.065\n",
      "Loss: 2.522, Residuals: -0.065\n",
      "Loss: 2.522, Residuals: -0.065\n",
      "Loss: 2.516, Residuals: -0.065\n",
      "Loss: 2.515, Residuals: -0.066\n",
      "Loss: 2.515, Residuals: -0.066\n",
      "Loss: 2.515, Residuals: -0.065\n",
      "Loss: 2.511, Residuals: -0.065\n",
      "Loss: 2.505, Residuals: -0.066\n",
      "Loss: 2.505, Residuals: -0.065\n",
      "Loss: 2.505, Residuals: -0.065\n",
      "Loss: 2.494, Residuals: -0.065\n",
      "Loss: 2.493, Residuals: -0.063\n",
      "Loss: 2.492, Residuals: -0.063\n",
      "Loss: 2.491, Residuals: -0.060\n",
      "Loss: 2.488, Residuals: -0.061\n",
      "Loss: 2.487, Residuals: -0.059\n",
      "Loss: 2.486, Residuals: -0.056\n",
      "Loss: 2.486, Residuals: -0.057\n",
      "Loss: 2.476, Residuals: -0.058\n",
      "Loss: 2.474, Residuals: -0.057\n",
      "Loss: 2.473, Residuals: -0.058\n",
      "Loss: 2.459, Residuals: -0.057\n",
      "Loss: 2.456, Residuals: -0.055\n",
      "Loss: 2.451, Residuals: -0.054\n",
      "Loss: 2.442, Residuals: -0.054\n",
      "Loss: 2.434, Residuals: -0.051\n",
      "Loss: 2.433, Residuals: -0.048\n",
      "Loss: 2.433, Residuals: -0.049\n",
      "Loss: 2.433, Residuals: -0.049\n",
      "Loss: 2.417, Residuals: -0.049\n",
      "Loss: 2.417, Residuals: -0.048\n",
      "Loss: 2.417, Residuals: -0.048\n",
      "Loss: 2.415, Residuals: -0.049\n",
      "Loss: 2.412, Residuals: -0.050\n",
      "Loss: 2.406, Residuals: -0.050\n",
      "Loss: 2.405, Residuals: -0.051\n",
      "Loss: 2.405, Residuals: -0.052\n",
      "Loss: 2.405, Residuals: -0.052\n",
      "Loss: 2.397, Residuals: -0.053\n",
      "Loss: 2.397, Residuals: -0.052\n",
      "Loss: 2.397, Residuals: -0.052\n",
      "Loss: 2.397, Residuals: -0.052\n",
      "Evidence -401.690\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.05e-03\n",
      "Loss: 12.737, Residuals: -0.040\n",
      "Loss: 12.474, Residuals: -0.022\n",
      "Loss: 12.469, Residuals: -0.027\n",
      "Loss: 12.466, Residuals: -0.024\n",
      "Loss: 12.447, Residuals: -0.018\n",
      "Loss: 12.292, Residuals: 0.003\n",
      "Loss: 12.268, Residuals: 0.012\n",
      "Loss: 12.263, Residuals: 0.011\n",
      "Loss: 12.263, Residuals: 0.010\n",
      "Loss: 12.263, Residuals: 0.010\n",
      "Evidence 114.998\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.78e-02\n",
      "Loss: 43.555, Residuals: 0.013\n",
      "Loss: 43.378, Residuals: 0.014\n",
      "Loss: 43.123, Residuals: 0.015\n",
      "Loss: 43.103, Residuals: 0.013\n",
      "Loss: 43.096, Residuals: 0.012\n",
      "Loss: 43.089, Residuals: 0.011\n",
      "Loss: 42.828, Residuals: 0.015\n",
      "Loss: 42.825, Residuals: 0.014\n",
      "Loss: 42.820, Residuals: 0.015\n",
      "Loss: 42.817, Residuals: 0.017\n",
      "Loss: 42.720, Residuals: 0.019\n",
      "Loss: 42.720, Residuals: 0.018\n",
      "Loss: 42.718, Residuals: 0.019\n",
      "Loss: 42.717, Residuals: 0.019\n",
      "Loss: 42.532, Residuals: 0.023\n",
      "Loss: 42.532, Residuals: 0.022\n",
      "Loss: 42.531, Residuals: 0.022\n",
      "Evidence 315.742\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.34e-02\n",
      "Loss: 93.766, Residuals: 0.028\n",
      "Loss: 93.691, Residuals: 0.025\n",
      "Loss: 93.057, Residuals: 0.021\n",
      "Loss: 92.211, Residuals: 0.014\n",
      "Loss: 92.151, Residuals: 0.009\n",
      "Loss: 92.120, Residuals: 0.008\n",
      "Loss: 91.830, Residuals: 0.009\n",
      "Loss: 91.826, Residuals: 0.010\n",
      "Loss: 91.819, Residuals: 0.010\n",
      "Loss: 91.573, Residuals: 0.011\n",
      "Loss: 91.140, Residuals: 0.013\n",
      "Loss: 91.137, Residuals: 0.012\n",
      "Loss: 90.716, Residuals: 0.016\n",
      "Loss: 90.692, Residuals: 0.015\n",
      "Loss: 90.682, Residuals: 0.012\n",
      "Loss: 90.672, Residuals: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 90.327, Residuals: 0.016\n",
      "Loss: 90.321, Residuals: 0.014\n",
      "Loss: 90.309, Residuals: 0.015\n",
      "Loss: 90.287, Residuals: 0.016\n",
      "Loss: 90.248, Residuals: 0.017\n",
      "Loss: 89.950, Residuals: 0.018\n",
      "Loss: 89.929, Residuals: 0.017\n",
      "Loss: 89.905, Residuals: 0.019\n",
      "Loss: 89.903, Residuals: 0.020\n",
      "Loss: 89.903, Residuals: 0.020\n",
      "Loss: 89.902, Residuals: 0.020\n",
      "Loss: 89.614, Residuals: 0.020\n",
      "Loss: 89.595, Residuals: 0.022\n",
      "Loss: 89.587, Residuals: 0.020\n",
      "Loss: 89.586, Residuals: 0.020\n",
      "Loss: 89.584, Residuals: 0.020\n",
      "Loss: 89.372, Residuals: 0.020\n",
      "Loss: 89.361, Residuals: 0.021\n",
      "Loss: 89.340, Residuals: 0.021\n",
      "Loss: 89.338, Residuals: 0.021\n",
      "Loss: 89.338, Residuals: 0.021\n",
      "Loss: 89.337, Residuals: 0.021\n",
      "Loss: 89.251, Residuals: 0.021\n",
      "Loss: 89.250, Residuals: 0.021\n",
      "Loss: 89.250, Residuals: 0.021\n",
      "Loss: 89.231, Residuals: 0.021\n",
      "Loss: 89.196, Residuals: 0.021\n",
      "Loss: 89.140, Residuals: 0.021\n",
      "Loss: 89.137, Residuals: 0.021\n",
      "Loss: 89.137, Residuals: 0.021\n",
      "Loss: 89.137, Residuals: 0.022\n",
      "Loss: 89.088, Residuals: 0.022\n",
      "Loss: 89.088, Residuals: 0.022\n",
      "Loss: 89.087, Residuals: 0.022\n",
      "Loss: 89.085, Residuals: 0.022\n",
      "Loss: 89.058, Residuals: 0.022\n",
      "Loss: 89.058, Residuals: 0.022\n",
      "Loss: 89.058, Residuals: 0.022\n",
      "Loss: 89.026, Residuals: 0.022\n",
      "Loss: 89.025, Residuals: 0.022\n",
      "Loss: 89.025, Residuals: 0.022\n",
      "Loss: 89.024, Residuals: 0.022\n",
      "Loss: 89.022, Residuals: 0.022\n",
      "Loss: 89.022, Residuals: 0.022\n",
      "Loss: 89.019, Residuals: 0.022\n",
      "Loss: 88.924, Residuals: 0.021\n",
      "Loss: 88.922, Residuals: 0.022\n",
      "Loss: 88.921, Residuals: 0.022\n",
      "Loss: 88.921, Residuals: 0.023\n",
      "Loss: 88.920, Residuals: 0.022\n",
      "Loss: 88.918, Residuals: 0.022\n",
      "Loss: 88.914, Residuals: 0.022\n",
      "Loss: 88.910, Residuals: 0.022\n",
      "Loss: 88.905, Residuals: 0.022\n",
      "Loss: 88.905, Residuals: 0.021\n",
      "Evidence 421.101\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.22e-01\n",
      "Loss: 129.919, Residuals: 0.025\n",
      "Loss: 129.667, Residuals: 0.023\n",
      "Loss: 129.209, Residuals: 0.020\n",
      "Loss: 128.489, Residuals: 0.012\n",
      "Loss: 127.803, Residuals: -0.002\n",
      "Loss: 127.454, Residuals: -0.004\n",
      "Loss: 127.444, Residuals: -0.005\n",
      "Loss: 127.431, Residuals: -0.003\n",
      "Loss: 127.407, Residuals: -0.002\n",
      "Loss: 127.369, Residuals: -0.001\n",
      "Loss: 127.363, Residuals: -0.002\n",
      "Loss: 127.361, Residuals: -0.001\n",
      "Loss: 127.360, Residuals: -0.002\n",
      "Loss: 127.330, Residuals: -0.002\n",
      "Loss: 127.276, Residuals: -0.002\n",
      "Loss: 127.209, Residuals: -0.001\n",
      "Loss: 127.208, Residuals: -0.001\n",
      "Loss: 127.195, Residuals: -0.001\n",
      "Loss: 127.190, Residuals: -0.002\n",
      "Loss: 127.182, Residuals: -0.001\n",
      "Loss: 127.166, Residuals: -0.002\n",
      "Loss: 127.165, Residuals: -0.001\n",
      "Evidence 460.733\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.35e-01\n",
      "Loss: 145.753, Residuals: -0.005\n",
      "Loss: 145.570, Residuals: -0.001\n",
      "Loss: 145.480, Residuals: -0.007\n",
      "Loss: 145.320, Residuals: -0.008\n",
      "Loss: 145.076, Residuals: -0.012\n",
      "Loss: 144.815, Residuals: -0.016\n",
      "Loss: 144.811, Residuals: -0.015\n",
      "Loss: 144.779, Residuals: -0.016\n",
      "Loss: 144.723, Residuals: -0.016\n",
      "Loss: 144.701, Residuals: -0.017\n",
      "Loss: 144.664, Residuals: -0.017\n",
      "Loss: 144.663, Residuals: -0.017\n",
      "Loss: 144.631, Residuals: -0.017\n",
      "Loss: 144.630, Residuals: -0.017\n",
      "Loss: 144.619, Residuals: -0.017\n",
      "Loss: 144.601, Residuals: -0.016\n",
      "Loss: 144.600, Residuals: -0.016\n",
      "Loss: 144.600, Residuals: -0.016\n",
      "Loss: 144.599, Residuals: -0.016\n",
      "Loss: 144.592, Residuals: -0.016\n",
      "Evidence 473.729\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.38e-01\n",
      "Loss: 151.983, Residuals: -0.017\n",
      "Loss: 151.820, Residuals: -0.018\n",
      "Loss: 151.712, Residuals: -0.025\n",
      "Loss: 151.704, Residuals: -0.023\n",
      "Loss: 151.691, Residuals: -0.023\n",
      "Loss: 151.667, Residuals: -0.023\n",
      "Loss: 151.623, Residuals: -0.023\n",
      "Loss: 151.622, Residuals: -0.023\n",
      "Loss: 151.571, Residuals: -0.023\n",
      "Loss: 151.571, Residuals: -0.023\n",
      "Loss: 151.554, Residuals: -0.023\n",
      "Loss: 151.526, Residuals: -0.022\n",
      "Loss: 151.525, Residuals: -0.022\n",
      "Loss: 151.524, Residuals: -0.022\n",
      "Loss: 151.522, Residuals: -0.022\n",
      "Loss: 151.507, Residuals: -0.022\n",
      "Loss: 151.507, Residuals: -0.022\n",
      "Evidence 478.455\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.38e-01\n",
      "Loss: 154.496, Residuals: -0.021\n",
      "Loss: 154.486, Residuals: -0.023\n",
      "Loss: 154.410, Residuals: -0.022\n",
      "Loss: 154.388, Residuals: -0.025\n",
      "Loss: 154.349, Residuals: -0.025\n",
      "Loss: 154.280, Residuals: -0.025\n",
      "Loss: 154.279, Residuals: -0.024\n",
      "Loss: 154.278, Residuals: -0.024\n",
      "Loss: 154.233, Residuals: -0.024\n",
      "Loss: 154.233, Residuals: -0.024\n",
      "Loss: 154.231, Residuals: -0.024\n",
      "Loss: 154.218, Residuals: -0.024\n",
      "Loss: 154.217, Residuals: -0.024\n",
      "Loss: 154.202, Residuals: -0.024\n",
      "Loss: 154.202, Residuals: -0.024\n",
      "Loss: 154.197, Residuals: -0.024\n",
      "Loss: 154.194, Residuals: -0.024\n",
      "Loss: 154.189, Residuals: -0.024\n",
      "Loss: 154.189, Residuals: -0.024\n",
      "Evidence 480.411\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.37e-01\n",
      "Loss: 155.458, Residuals: -0.022\n",
      "Loss: 155.441, Residuals: -0.024\n",
      "Loss: 155.304, Residuals: -0.024\n",
      "Loss: 155.303, Residuals: -0.023\n",
      "Loss: 155.248, Residuals: -0.023\n",
      "Loss: 155.244, Residuals: -0.023\n",
      "Loss: 155.206, Residuals: -0.023\n",
      "Loss: 155.206, Residuals: -0.022\n",
      "Loss: 155.194, Residuals: -0.022\n",
      "Loss: 155.190, Residuals: -0.024\n",
      "Loss: 155.182, Residuals: -0.023\n",
      "Loss: 155.182, Residuals: -0.023\n",
      "Loss: 155.178, Residuals: -0.023\n",
      "Loss: 155.178, Residuals: -0.023\n",
      "Loss: 155.174, Residuals: -0.023\n",
      "Loss: 155.174, Residuals: -0.023\n",
      "Evidence 481.659\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.35e-01\n",
      "Loss: 155.880, Residuals: -0.022\n",
      "Loss: 155.858, Residuals: -0.021\n",
      "Loss: 155.816, Residuals: -0.022\n",
      "Loss: 155.752, Residuals: -0.021\n",
      "Loss: 155.751, Residuals: -0.021\n",
      "Loss: 155.742, Residuals: -0.022\n",
      "Loss: 155.727, Residuals: -0.022\n",
      "Loss: 155.701, Residuals: -0.022\n",
      "Loss: 155.701, Residuals: -0.021\n",
      "Loss: 155.700, Residuals: -0.021\n",
      "Loss: 155.694, Residuals: -0.021\n",
      "Loss: 155.692, Residuals: -0.021\n",
      "Loss: 155.681, Residuals: -0.021\n",
      "Loss: 155.681, Residuals: -0.021\n",
      "Loss: 155.677, Residuals: -0.021\n",
      "Loss: 155.677, Residuals: -0.021\n",
      "Loss: 155.673, Residuals: -0.021\n",
      "Loss: 155.673, Residuals: -0.021\n",
      "Evidence 482.665\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.33e-01\n",
      "Loss: 156.134, Residuals: -0.020\n",
      "Loss: 156.123, Residuals: -0.020\n",
      "Loss: 156.106, Residuals: -0.021\n",
      "Loss: 156.075, Residuals: -0.020\n",
      "Loss: 156.072, Residuals: -0.020\n",
      "Loss: 156.040, Residuals: -0.020\n",
      "Loss: 156.040, Residuals: -0.020\n",
      "Loss: 156.034, Residuals: -0.020\n",
      "Loss: 156.023, Residuals: -0.020\n",
      "Loss: 156.023, Residuals: -0.020\n",
      "Evidence 483.260\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.31e-01\n",
      "Loss: 156.347, Residuals: -0.019\n",
      "Loss: 156.341, Residuals: -0.019\n",
      "Loss: 156.330, Residuals: -0.020\n",
      "Loss: 156.311, Residuals: -0.019\n",
      "Loss: 156.306, Residuals: -0.019\n",
      "Loss: 156.296, Residuals: -0.019\n",
      "Loss: 156.278, Residuals: -0.019\n",
      "Loss: 156.278, Residuals: -0.019\n",
      "Loss: 156.261, Residuals: -0.019\n",
      "Loss: 156.261, Residuals: -0.019\n",
      "Evidence 483.694\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.615, Residuals: -0.090\n",
      "Loss: 6.854, Residuals: -0.050\n",
      "Loss: 5.016, Residuals: -0.050\n",
      "Loss: 4.280, Residuals: -0.044\n",
      "Loss: 3.875, Residuals: -0.059\n",
      "Loss: 3.680, Residuals: 0.025\n",
      "Loss: 3.362, Residuals: -0.005\n",
      "Loss: 3.029, Residuals: -0.018\n",
      "Loss: 2.977, Residuals: -0.034\n",
      "Loss: 2.970, Residuals: -0.042\n",
      "Loss: 2.913, Residuals: -0.049\n",
      "Loss: 2.906, Residuals: -0.044\n",
      "Loss: 2.844, Residuals: -0.052\n",
      "Loss: 2.839, Residuals: -0.042\n",
      "Loss: 2.795, Residuals: -0.049\n",
      "Loss: 2.721, Residuals: -0.063\n",
      "Loss: 2.719, Residuals: -0.062\n",
      "Loss: 2.709, Residuals: -0.059\n",
      "Loss: 2.690, Residuals: -0.061\n",
      "Loss: 2.655, Residuals: -0.067\n",
      "Loss: 2.645, Residuals: -0.056\n",
      "Loss: 2.626, Residuals: -0.056\n",
      "Loss: 2.604, Residuals: -0.052\n",
      "Loss: 2.602, Residuals: -0.052\n",
      "Loss: 2.581, Residuals: -0.056\n",
      "Loss: 2.548, Residuals: -0.055\n",
      "Loss: 2.544, Residuals: -0.060\n",
      "Loss: 2.542, Residuals: -0.054\n",
      "Loss: 2.490, Residuals: -0.062\n",
      "Loss: 2.489, Residuals: -0.064\n",
      "Loss: 2.487, Residuals: -0.062\n",
      "Loss: 2.483, Residuals: -0.061\n",
      "Loss: 2.446, Residuals: -0.066\n",
      "Loss: 2.443, Residuals: -0.056\n",
      "Loss: 2.407, Residuals: -0.062\n",
      "Loss: 2.403, Residuals: -0.053\n",
      "Loss: 2.369, Residuals: -0.059\n",
      "Loss: 2.360, Residuals: -0.055\n",
      "Loss: 2.298, Residuals: -0.069\n",
      "Loss: 2.295, Residuals: -0.072\n",
      "Loss: 2.294, Residuals: -0.068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.291, Residuals: -0.069\n",
      "Loss: 2.271, Residuals: -0.075\n",
      "Loss: 2.270, Residuals: -0.076\n",
      "Loss: 2.269, Residuals: -0.075\n",
      "Loss: 2.267, Residuals: -0.074\n",
      "Loss: 2.262, Residuals: -0.073\n",
      "Loss: 2.262, Residuals: -0.068\n",
      "Loss: 2.229, Residuals: -0.077\n",
      "Loss: 2.176, Residuals: -0.091\n",
      "Loss: 2.172, Residuals: -0.076\n",
      "Loss: 2.167, Residuals: -0.081\n",
      "Loss: 2.128, Residuals: -0.093\n",
      "Loss: 2.128, Residuals: -0.089\n",
      "Loss: 2.127, Residuals: -0.089\n",
      "Loss: 2.125, Residuals: -0.090\n",
      "Loss: 2.124, Residuals: -0.091\n",
      "Loss: 2.124, Residuals: -0.091\n",
      "Loss: 2.107, Residuals: -0.098\n",
      "Loss: 2.106, Residuals: -0.097\n",
      "Loss: 2.106, Residuals: -0.098\n",
      "Evidence -386.814\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.96e-03\n",
      "Loss: 11.694, Residuals: -0.078\n",
      "Loss: 11.685, Residuals: -0.081\n",
      "Loss: 11.673, Residuals: -0.076\n",
      "Loss: 11.651, Residuals: -0.074\n",
      "Loss: 11.610, Residuals: -0.072\n",
      "Loss: 11.540, Residuals: -0.068\n",
      "Loss: 11.455, Residuals: -0.057\n",
      "Loss: 11.454, Residuals: -0.058\n",
      "Loss: 11.452, Residuals: -0.058\n",
      "Loss: 11.449, Residuals: -0.058\n",
      "Loss: 11.418, Residuals: -0.056\n",
      "Loss: 11.359, Residuals: -0.054\n",
      "Loss: 11.267, Residuals: -0.048\n",
      "Loss: 11.263, Residuals: -0.049\n",
      "Loss: 11.257, Residuals: -0.048\n",
      "Loss: 11.201, Residuals: -0.045\n",
      "Loss: 11.195, Residuals: -0.044\n",
      "Loss: 11.194, Residuals: -0.043\n",
      "Loss: 11.167, Residuals: -0.042\n",
      "Loss: 11.154, Residuals: -0.039\n",
      "Loss: 11.153, Residuals: -0.040\n",
      "Loss: 11.143, Residuals: -0.039\n",
      "Loss: 11.143, Residuals: -0.039\n",
      "Loss: 11.143, Residuals: -0.039\n",
      "Loss: 11.106, Residuals: -0.039\n",
      "Loss: 11.106, Residuals: -0.038\n",
      "Loss: 11.106, Residuals: -0.038\n",
      "Loss: 11.093, Residuals: -0.037\n",
      "Loss: 11.092, Residuals: -0.037\n",
      "Loss: 11.092, Residuals: -0.037\n",
      "Loss: 11.085, Residuals: -0.037\n",
      "Loss: 11.083, Residuals: -0.036\n",
      "Loss: 11.067, Residuals: -0.035\n",
      "Loss: 11.067, Residuals: -0.035\n",
      "Evidence 112.967\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.32e-02\n",
      "Loss: 41.150, Residuals: -0.041\n",
      "Loss: 41.138, Residuals: -0.043\n",
      "Loss: 41.048, Residuals: -0.039\n",
      "Loss: 41.022, Residuals: -0.039\n",
      "Loss: 40.801, Residuals: -0.035\n",
      "Loss: 40.721, Residuals: -0.034\n",
      "Loss: 40.720, Residuals: -0.033\n",
      "Evidence 319.014\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.17e-02\n",
      "Loss: 91.072, Residuals: -0.041\n",
      "Loss: 90.973, Residuals: -0.047\n",
      "Loss: 90.782, Residuals: -0.047\n",
      "Loss: 90.553, Residuals: -0.047\n",
      "Loss: 90.530, Residuals: -0.047\n",
      "Loss: 90.301, Residuals: -0.046\n",
      "Loss: 89.887, Residuals: -0.044\n",
      "Loss: 89.862, Residuals: -0.044\n",
      "Loss: 89.622, Residuals: -0.044\n",
      "Loss: 89.212, Residuals: -0.041\n",
      "Loss: 89.211, Residuals: -0.041\n",
      "Evidence 422.935\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.76e-01\n",
      "Loss: 128.912, Residuals: -0.048\n",
      "Loss: 128.851, Residuals: -0.049\n",
      "Loss: 128.736, Residuals: -0.050\n",
      "Loss: 128.528, Residuals: -0.050\n",
      "Loss: 128.144, Residuals: -0.049\n",
      "Loss: 127.479, Residuals: -0.046\n",
      "Loss: 127.421, Residuals: -0.048\n",
      "Loss: 127.398, Residuals: -0.049\n",
      "Loss: 126.607, Residuals: -0.048\n",
      "Loss: 126.467, Residuals: -0.049\n",
      "Loss: 126.462, Residuals: -0.049\n",
      "Loss: 126.452, Residuals: -0.049\n",
      "Loss: 126.434, Residuals: -0.049\n",
      "Loss: 125.749, Residuals: -0.049\n",
      "Loss: 125.731, Residuals: -0.049\n",
      "Loss: 125.558, Residuals: -0.048\n",
      "Loss: 124.714, Residuals: -0.047\n",
      "Loss: 124.709, Residuals: -0.047\n",
      "Loss: 124.700, Residuals: -0.047\n",
      "Loss: 124.685, Residuals: -0.046\n",
      "Loss: 124.658, Residuals: -0.046\n",
      "Loss: 124.657, Residuals: -0.046\n",
      "Loss: 124.538, Residuals: -0.045\n",
      "Loss: 124.538, Residuals: -0.045\n",
      "Evidence 457.011\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.32e-01\n",
      "Loss: 144.558, Residuals: -0.050\n",
      "Loss: 144.539, Residuals: -0.051\n",
      "Loss: 144.372, Residuals: -0.052\n",
      "Loss: 144.114, Residuals: -0.051\n",
      "Loss: 143.764, Residuals: -0.049\n",
      "Loss: 143.250, Residuals: -0.047\n",
      "Loss: 143.234, Residuals: -0.047\n",
      "Loss: 143.215, Residuals: -0.047\n",
      "Loss: 142.566, Residuals: -0.044\n",
      "Loss: 142.564, Residuals: -0.044\n",
      "Loss: 142.562, Residuals: -0.044\n",
      "Loss: 142.558, Residuals: -0.044\n",
      "Loss: 142.551, Residuals: -0.044\n",
      "Loss: 142.548, Residuals: -0.044\n",
      "Loss: 142.411, Residuals: -0.043\n",
      "Loss: 142.328, Residuals: -0.040\n",
      "Loss: 142.325, Residuals: -0.041\n",
      "Loss: 142.322, Residuals: -0.040\n",
      "Loss: 142.318, Residuals: -0.041\n",
      "Loss: 142.277, Residuals: -0.040\n",
      "Loss: 142.272, Residuals: -0.041\n",
      "Loss: 142.272, Residuals: -0.041\n",
      "Evidence 470.202\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.78e-01\n",
      "Loss: 151.254, Residuals: -0.043\n",
      "Loss: 150.904, Residuals: -0.044\n",
      "Loss: 150.889, Residuals: -0.042\n",
      "Loss: 150.752, Residuals: -0.042\n",
      "Loss: 150.531, Residuals: -0.042\n",
      "Loss: 150.251, Residuals: -0.040\n",
      "Loss: 150.206, Residuals: -0.041\n",
      "Loss: 150.204, Residuals: -0.041\n",
      "Loss: 150.201, Residuals: -0.041\n",
      "Loss: 150.090, Residuals: -0.040\n",
      "Loss: 150.089, Residuals: -0.041\n",
      "Loss: 149.922, Residuals: -0.039\n",
      "Loss: 149.920, Residuals: -0.040\n",
      "Loss: 149.920, Residuals: -0.039\n",
      "Loss: 149.866, Residuals: -0.039\n",
      "Loss: 149.832, Residuals: -0.037\n",
      "Loss: 149.831, Residuals: -0.037\n",
      "Evidence 475.636\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.96e-01\n",
      "Loss: 153.797, Residuals: -0.040\n",
      "Loss: 153.583, Residuals: -0.040\n",
      "Loss: 153.343, Residuals: -0.038\n",
      "Loss: 153.292, Residuals: -0.039\n",
      "Loss: 153.226, Residuals: -0.037\n",
      "Loss: 153.107, Residuals: -0.036\n",
      "Loss: 152.890, Residuals: -0.035\n",
      "Loss: 152.854, Residuals: -0.036\n",
      "Loss: 152.559, Residuals: -0.033\n",
      "Loss: 152.545, Residuals: -0.035\n",
      "Loss: 152.525, Residuals: -0.034\n",
      "Loss: 152.353, Residuals: -0.032\n",
      "Loss: 152.331, Residuals: -0.033\n",
      "Loss: 152.317, Residuals: -0.032\n",
      "Loss: 152.201, Residuals: -0.030\n",
      "Loss: 152.195, Residuals: -0.031\n",
      "Loss: 152.194, Residuals: -0.031\n",
      "Loss: 152.191, Residuals: -0.031\n",
      "Loss: 152.185, Residuals: -0.031\n",
      "Loss: 152.135, Residuals: -0.030\n",
      "Loss: 152.131, Residuals: -0.030\n",
      "Loss: 152.131, Residuals: -0.030\n",
      "Loss: 152.130, Residuals: -0.030\n",
      "Loss: 152.088, Residuals: -0.029\n",
      "Loss: 152.085, Residuals: -0.030\n",
      "Loss: 152.085, Residuals: -0.030\n",
      "Loss: 152.080, Residuals: -0.029\n",
      "Loss: 152.038, Residuals: -0.029\n",
      "Loss: 152.037, Residuals: -0.029\n",
      "Loss: 152.036, Residuals: -0.029\n",
      "Loss: 152.032, Residuals: -0.029\n",
      "Loss: 151.992, Residuals: -0.028\n",
      "Loss: 151.990, Residuals: -0.028\n",
      "Loss: 151.990, Residuals: -0.028\n",
      "Loss: 151.988, Residuals: -0.028\n",
      "Loss: 151.978, Residuals: -0.028\n",
      "Loss: 151.977, Residuals: -0.028\n",
      "Loss: 151.940, Residuals: -0.027\n",
      "Loss: 151.939, Residuals: -0.027\n",
      "Loss: 151.938, Residuals: -0.027\n",
      "Loss: 151.937, Residuals: -0.027\n",
      "Loss: 151.928, Residuals: -0.027\n",
      "Loss: 151.927, Residuals: -0.027\n",
      "Loss: 151.883, Residuals: -0.025\n",
      "Loss: 151.881, Residuals: -0.026\n",
      "Loss: 151.878, Residuals: -0.026\n",
      "Loss: 151.874, Residuals: -0.026\n",
      "Loss: 151.866, Residuals: -0.025\n",
      "Loss: 151.864, Residuals: -0.025\n",
      "Loss: 151.605, Residuals: -0.018\n",
      "Loss: 151.522, Residuals: -0.022\n",
      "Loss: 151.385, Residuals: -0.021\n",
      "Loss: 151.154, Residuals: -0.020\n",
      "Loss: 151.080, Residuals: -0.019\n",
      "Loss: 150.961, Residuals: -0.019\n",
      "Loss: 150.953, Residuals: -0.018\n",
      "Loss: 150.883, Residuals: -0.018\n",
      "Loss: 150.792, Residuals: -0.017\n",
      "Loss: 150.787, Residuals: -0.017\n",
      "Loss: 150.739, Residuals: -0.017\n",
      "Loss: 150.734, Residuals: -0.017\n",
      "Loss: 150.694, Residuals: -0.016\n",
      "Loss: 150.661, Residuals: -0.015\n",
      "Loss: 150.659, Residuals: -0.014\n",
      "Loss: 150.644, Residuals: -0.014\n",
      "Loss: 150.640, Residuals: -0.014\n",
      "Loss: 150.631, Residuals: -0.014\n",
      "Loss: 150.616, Residuals: -0.013\n",
      "Loss: 150.615, Residuals: -0.013\n",
      "Loss: 150.597, Residuals: -0.012\n",
      "Loss: 150.597, Residuals: -0.013\n",
      "Loss: 150.596, Residuals: -0.013\n",
      "Loss: 150.594, Residuals: -0.012\n",
      "Loss: 150.581, Residuals: -0.011\n",
      "Loss: 150.580, Residuals: -0.012\n",
      "Loss: 150.580, Residuals: -0.011\n",
      "Loss: 150.574, Residuals: -0.011\n",
      "Loss: 150.574, Residuals: -0.011\n",
      "Loss: 150.573, Residuals: -0.011\n",
      "Loss: 150.573, Residuals: -0.010\n",
      "Loss: 150.572, Residuals: -0.011\n",
      "Loss: 150.571, Residuals: -0.010\n",
      "Loss: 150.570, Residuals: -0.010\n",
      "Loss: 150.570, Residuals: -0.010\n",
      "Loss: 150.569, Residuals: -0.010\n",
      "Loss: 150.569, Residuals: -0.010\n",
      "Loss: 150.568, Residuals: -0.010\n",
      "Loss: 150.567, Residuals: -0.010\n",
      "Loss: 150.567, Residuals: -0.010\n",
      "Evidence 478.013\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.30e+00\n",
      "Loss: 154.026, Residuals: -0.002\n",
      "Loss: 153.530, Residuals: 0.003\n",
      "Loss: 153.075, Residuals: 0.004\n",
      "Loss: 153.071, Residuals: 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 153.036, Residuals: 0.005\n",
      "Loss: 152.985, Residuals: 0.006\n",
      "Loss: 152.897, Residuals: 0.007\n",
      "Loss: 152.787, Residuals: 0.008\n",
      "Loss: 152.778, Residuals: 0.008\n",
      "Loss: 152.767, Residuals: 0.009\n",
      "Loss: 152.767, Residuals: 0.009\n",
      "Loss: 152.751, Residuals: 0.009\n",
      "Loss: 152.738, Residuals: 0.010\n",
      "Loss: 152.736, Residuals: 0.010\n",
      "Loss: 152.736, Residuals: 0.010\n",
      "Loss: 152.734, Residuals: 0.010\n",
      "Loss: 152.732, Residuals: 0.011\n",
      "Loss: 152.732, Residuals: 0.011\n",
      "Loss: 152.732, Residuals: 0.011\n",
      "Loss: 152.732, Residuals: 0.011\n",
      "Loss: 152.732, Residuals: 0.011\n",
      "Loss: 152.732, Residuals: 0.011\n",
      "Evidence 485.550\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.58e+00\n",
      "Loss: 154.925, Residuals: 0.016\n",
      "Loss: 154.787, Residuals: 0.017\n",
      "Loss: 154.684, Residuals: 0.017\n",
      "Loss: 154.656, Residuals: 0.016\n",
      "Loss: 154.646, Residuals: 0.017\n",
      "Loss: 154.630, Residuals: 0.018\n",
      "Loss: 154.607, Residuals: 0.018\n",
      "Loss: 154.605, Residuals: 0.019\n",
      "Loss: 154.604, Residuals: 0.019\n",
      "Loss: 154.600, Residuals: 0.019\n",
      "Loss: 154.597, Residuals: 0.019\n",
      "Loss: 154.596, Residuals: 0.019\n",
      "Loss: 154.596, Residuals: 0.019\n",
      "Loss: 154.596, Residuals: 0.019\n",
      "Loss: 154.596, Residuals: 0.019\n",
      "Loss: 154.596, Residuals: 0.020\n",
      "Evidence 488.153\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.69e+00\n",
      "Loss: 155.690, Residuals: 0.022\n",
      "Loss: 155.620, Residuals: 0.022\n",
      "Loss: 155.555, Residuals: 0.022\n",
      "Loss: 155.553, Residuals: 0.022\n",
      "Loss: 155.549, Residuals: 0.022\n",
      "Loss: 155.545, Residuals: 0.023\n",
      "Loss: 155.540, Residuals: 0.023\n",
      "Loss: 155.540, Residuals: 0.023\n",
      "Loss: 155.539, Residuals: 0.023\n",
      "Loss: 155.538, Residuals: 0.023\n",
      "Loss: 155.538, Residuals: 0.023\n",
      "Loss: 155.538, Residuals: 0.023\n",
      "Loss: 155.538, Residuals: 0.023\n",
      "Evidence 489.425\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.74e+00\n",
      "Loss: 156.105, Residuals: 0.024\n",
      "Loss: 156.067, Residuals: 0.024\n",
      "Loss: 156.029, Residuals: 0.024\n",
      "Loss: 156.028, Residuals: 0.024\n",
      "Loss: 156.027, Residuals: 0.024\n",
      "Loss: 156.025, Residuals: 0.024\n",
      "Loss: 156.022, Residuals: 0.024\n",
      "Loss: 156.018, Residuals: 0.024\n",
      "Loss: 156.018, Residuals: 0.024\n",
      "Loss: 156.018, Residuals: 0.024\n",
      "Loss: 156.017, Residuals: 0.024\n",
      "Loss: 156.017, Residuals: 0.024\n",
      "Loss: 156.017, Residuals: 0.024\n",
      "Evidence 490.175\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.76e+00\n",
      "Loss: 156.336, Residuals: 0.025\n",
      "Loss: 156.307, Residuals: 0.025\n",
      "Loss: 156.293, Residuals: 0.025\n",
      "Loss: 156.289, Residuals: 0.025\n",
      "Loss: 156.286, Residuals: 0.025\n",
      "Loss: 156.282, Residuals: 0.025\n",
      "Loss: 156.282, Residuals: 0.025\n",
      "Loss: 156.279, Residuals: 0.025\n",
      "Loss: 156.277, Residuals: 0.025\n",
      "Loss: 156.277, Residuals: 0.025\n",
      "Loss: 156.277, Residuals: 0.025\n",
      "Loss: 156.277, Residuals: 0.025\n",
      "Loss: 156.277, Residuals: 0.025\n",
      "Loss: 156.276, Residuals: 0.025\n",
      "Loss: 156.276, Residuals: 0.025\n",
      "Evidence 490.688\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.76e+00\n",
      "Loss: 156.478, Residuals: 0.025\n",
      "Loss: 156.454, Residuals: 0.025\n",
      "Loss: 156.448, Residuals: 0.026\n",
      "Loss: 156.440, Residuals: 0.025\n",
      "Loss: 156.439, Residuals: 0.025\n",
      "Loss: 156.437, Residuals: 0.025\n",
      "Loss: 156.434, Residuals: 0.025\n",
      "Loss: 156.434, Residuals: 0.025\n",
      "Loss: 156.434, Residuals: 0.025\n",
      "Loss: 156.433, Residuals: 0.025\n",
      "Loss: 156.433, Residuals: 0.025\n",
      "Evidence 491.068\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.979, Residuals: -0.079\n",
      "Loss: 7.221, Residuals: -0.037\n",
      "Loss: 5.316, Residuals: -0.042\n",
      "Loss: 4.792, Residuals: -0.047\n",
      "Loss: 4.076, Residuals: -0.022\n",
      "Loss: 3.945, Residuals: 0.025\n",
      "Loss: 3.703, Residuals: 0.009\n",
      "Loss: 3.314, Residuals: 0.003\n",
      "Loss: 3.294, Residuals: 0.012\n",
      "Loss: 3.116, Residuals: -0.000\n",
      "Loss: 3.074, Residuals: 0.020\n",
      "Loss: 3.003, Residuals: 0.008\n",
      "Loss: 2.890, Residuals: -0.012\n",
      "Loss: 2.885, Residuals: -0.007\n",
      "Loss: 2.877, Residuals: 0.004\n",
      "Loss: 2.815, Residuals: -0.010\n",
      "Loss: 2.789, Residuals: -0.012\n",
      "Loss: 2.750, Residuals: -0.020\n",
      "Loss: 2.747, Residuals: -0.010\n",
      "Loss: 2.725, Residuals: -0.020\n",
      "Loss: 2.696, Residuals: -0.037\n",
      "Loss: 2.695, Residuals: -0.037\n",
      "Loss: 2.695, Residuals: -0.037\n",
      "Loss: 2.693, Residuals: -0.037\n",
      "Loss: 2.691, Residuals: -0.037\n",
      "Loss: 2.688, Residuals: -0.038\n",
      "Loss: 2.683, Residuals: -0.039\n",
      "Loss: 2.683, Residuals: -0.038\n",
      "Loss: 2.678, Residuals: -0.040\n",
      "Loss: 2.671, Residuals: -0.044\n",
      "Loss: 2.669, Residuals: -0.044\n",
      "Loss: 2.656, Residuals: -0.050\n",
      "Loss: 2.655, Residuals: -0.047\n",
      "Loss: 2.643, Residuals: -0.051\n",
      "Loss: 2.639, Residuals: -0.048\n",
      "Loss: 2.638, Residuals: -0.049\n",
      "Loss: 2.635, Residuals: -0.048\n",
      "Loss: 2.611, Residuals: -0.055\n",
      "Loss: 2.611, Residuals: -0.055\n",
      "Loss: 2.610, Residuals: -0.054\n",
      "Loss: 2.609, Residuals: -0.054\n",
      "Loss: 2.595, Residuals: -0.057\n",
      "Loss: 2.595, Residuals: -0.057\n",
      "Loss: 2.595, Residuals: -0.055\n",
      "Loss: 2.583, Residuals: -0.058\n",
      "Loss: 2.583, Residuals: -0.056\n",
      "Loss: 2.582, Residuals: -0.055\n",
      "Loss: 2.575, Residuals: -0.057\n",
      "Loss: 2.575, Residuals: -0.058\n",
      "Loss: 2.574, Residuals: -0.056\n",
      "Loss: 2.566, Residuals: -0.058\n",
      "Loss: 2.566, Residuals: -0.057\n",
      "Loss: 2.555, Residuals: -0.059\n",
      "Loss: 2.555, Residuals: -0.059\n",
      "Loss: 2.554, Residuals: -0.057\n",
      "Loss: 2.554, Residuals: -0.055\n",
      "Loss: 2.548, Residuals: -0.057\n",
      "Loss: 2.547, Residuals: -0.057\n",
      "Loss: 2.543, Residuals: -0.058\n",
      "Loss: 2.538, Residuals: -0.056\n",
      "Loss: 2.538, Residuals: -0.055\n",
      "Loss: 2.537, Residuals: -0.055\n",
      "Loss: 2.535, Residuals: -0.054\n",
      "Loss: 2.524, Residuals: -0.059\n",
      "Loss: 2.523, Residuals: -0.059\n",
      "Loss: 2.519, Residuals: -0.056\n",
      "Loss: 2.518, Residuals: -0.052\n",
      "Loss: 2.517, Residuals: -0.053\n",
      "Loss: 2.512, Residuals: -0.055\n",
      "Loss: 2.511, Residuals: -0.053\n",
      "Loss: 2.503, Residuals: -0.052\n",
      "Loss: 2.502, Residuals: -0.050\n",
      "Loss: 2.501, Residuals: -0.051\n",
      "Loss: 2.493, Residuals: -0.052\n",
      "Loss: 2.493, Residuals: -0.051\n",
      "Loss: 2.492, Residuals: -0.050\n",
      "Loss: 2.492, Residuals: -0.048\n",
      "Loss: 2.485, Residuals: -0.050\n",
      "Loss: 2.485, Residuals: -0.049\n",
      "Loss: 2.476, Residuals: -0.051\n",
      "Loss: 2.475, Residuals: -0.050\n",
      "Loss: 2.475, Residuals: -0.049\n",
      "Loss: 2.473, Residuals: -0.049\n",
      "Loss: 2.473, Residuals: -0.049\n",
      "Loss: 2.466, Residuals: -0.050\n",
      "Loss: 2.466, Residuals: -0.050\n",
      "Loss: 2.459, Residuals: -0.051\n",
      "Loss: 2.459, Residuals: -0.051\n",
      "Loss: 2.459, Residuals: -0.050\n",
      "Loss: 2.451, Residuals: -0.052\n",
      "Loss: 2.451, Residuals: -0.052\n",
      "Loss: 2.451, Residuals: -0.051\n",
      "Loss: 2.450, Residuals: -0.050\n",
      "Loss: 2.436, Residuals: -0.054\n",
      "Loss: 2.435, Residuals: -0.053\n",
      "Loss: 2.435, Residuals: -0.054\n",
      "Loss: 2.435, Residuals: -0.054\n",
      "Loss: 2.434, Residuals: -0.054\n",
      "Loss: 2.427, Residuals: -0.057\n",
      "Loss: 2.427, Residuals: -0.056\n",
      "Loss: 2.427, Residuals: -0.056\n",
      "Evidence -383.937\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.93e-03\n",
      "Loss: 11.608, Residuals: -0.037\n",
      "Loss: 11.509, Residuals: -0.037\n",
      "Loss: 11.482, Residuals: -0.031\n",
      "Loss: 11.443, Residuals: -0.033\n",
      "Loss: 11.405, Residuals: -0.039\n",
      "Loss: 11.403, Residuals: -0.039\n",
      "Loss: 11.388, Residuals: -0.037\n",
      "Loss: 11.361, Residuals: -0.035\n",
      "Loss: 11.321, Residuals: -0.030\n",
      "Loss: 11.319, Residuals: -0.027\n",
      "Loss: 11.299, Residuals: -0.027\n",
      "Loss: 11.275, Residuals: -0.024\n",
      "Loss: 11.275, Residuals: -0.023\n",
      "Loss: 11.273, Residuals: -0.023\n",
      "Loss: 11.273, Residuals: -0.024\n",
      "Loss: 11.257, Residuals: -0.022\n",
      "Loss: 11.257, Residuals: -0.022\n",
      "Loss: 11.246, Residuals: -0.020\n",
      "Loss: 11.228, Residuals: -0.018\n",
      "Loss: 11.228, Residuals: -0.018\n",
      "Loss: 11.227, Residuals: -0.018\n",
      "Loss: 11.226, Residuals: -0.018\n",
      "Loss: 11.224, Residuals: -0.018\n",
      "Loss: 11.223, Residuals: -0.018\n",
      "Loss: 11.221, Residuals: -0.018\n",
      "Loss: 11.219, Residuals: -0.018\n",
      "Loss: 11.217, Residuals: -0.017\n",
      "Loss: 11.217, Residuals: -0.018\n",
      "Loss: 11.217, Residuals: -0.018\n",
      "Loss: 11.217, Residuals: -0.018\n",
      "Loss: 11.217, Residuals: -0.018\n",
      "Loss: 11.214, Residuals: -0.017\n",
      "Loss: 11.214, Residuals: -0.017\n",
      "Loss: 11.213, Residuals: -0.017\n",
      "Loss: 11.210, Residuals: -0.016\n",
      "Loss: 11.210, Residuals: -0.016\n",
      "Loss: 11.210, Residuals: -0.016\n",
      "Loss: 11.209, Residuals: -0.016\n",
      "Loss: 11.209, Residuals: -0.016\n",
      "Loss: 11.207, Residuals: -0.016\n",
      "Loss: 11.207, Residuals: -0.016\n",
      "Loss: 11.207, Residuals: -0.016\n",
      "Loss: 11.207, Residuals: -0.016\n",
      "Loss: 11.207, Residuals: -0.016\n",
      "Loss: 11.207, Residuals: -0.016\n",
      "Loss: 11.206, Residuals: -0.016\n",
      "Loss: 11.206, Residuals: -0.016\n",
      "Evidence 99.828\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.01e-02\n",
      "Loss: 39.850, Residuals: -0.018\n",
      "Loss: 39.786, Residuals: -0.019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 39.673, Residuals: -0.019\n",
      "Loss: 39.506, Residuals: -0.019\n",
      "Loss: 39.483, Residuals: -0.018\n",
      "Loss: 39.441, Residuals: -0.017\n",
      "Loss: 39.368, Residuals: -0.016\n",
      "Loss: 39.241, Residuals: -0.014\n",
      "Loss: 39.228, Residuals: -0.013\n",
      "Loss: 39.115, Residuals: -0.011\n",
      "Loss: 39.114, Residuals: -0.011\n",
      "Loss: 38.945, Residuals: -0.007\n",
      "Loss: 38.942, Residuals: -0.006\n",
      "Loss: 38.937, Residuals: -0.006\n",
      "Loss: 38.928, Residuals: -0.007\n",
      "Loss: 38.928, Residuals: -0.007\n",
      "Loss: 38.830, Residuals: -0.005\n",
      "Loss: 38.830, Residuals: -0.005\n",
      "Loss: 38.825, Residuals: -0.006\n",
      "Loss: 38.825, Residuals: -0.006\n",
      "Loss: 38.798, Residuals: -0.005\n",
      "Loss: 38.798, Residuals: -0.005\n",
      "Loss: 38.795, Residuals: -0.005\n",
      "Loss: 38.718, Residuals: -0.002\n",
      "Loss: 38.717, Residuals: -0.003\n",
      "Loss: 38.715, Residuals: -0.003\n",
      "Loss: 38.712, Residuals: -0.004\n",
      "Loss: 38.710, Residuals: -0.004\n",
      "Loss: 38.697, Residuals: -0.004\n",
      "Loss: 38.696, Residuals: -0.004\n",
      "Loss: 38.694, Residuals: -0.004\n",
      "Loss: 38.675, Residuals: -0.003\n",
      "Loss: 38.674, Residuals: -0.004\n",
      "Loss: 38.673, Residuals: -0.004\n",
      "Loss: 38.672, Residuals: -0.004\n",
      "Loss: 38.670, Residuals: -0.004\n",
      "Loss: 38.669, Residuals: -0.004\n",
      "Loss: 38.669, Residuals: -0.004\n",
      "Loss: 38.669, Residuals: -0.004\n",
      "Loss: 38.669, Residuals: -0.004\n",
      "Loss: 38.556, Residuals: -0.002\n",
      "Loss: 38.544, Residuals: -0.002\n",
      "Loss: 38.527, Residuals: -0.004\n",
      "Loss: 38.525, Residuals: -0.005\n",
      "Loss: 38.510, Residuals: -0.005\n",
      "Loss: 38.498, Residuals: -0.006\n",
      "Loss: 38.497, Residuals: -0.007\n",
      "Loss: 38.454, Residuals: -0.006\n",
      "Loss: 38.452, Residuals: -0.007\n",
      "Loss: 38.430, Residuals: -0.007\n",
      "Loss: 38.428, Residuals: -0.008\n",
      "Loss: 38.360, Residuals: -0.007\n",
      "Loss: 38.356, Residuals: -0.008\n",
      "Loss: 38.329, Residuals: -0.008\n",
      "Loss: 38.285, Residuals: -0.009\n",
      "Loss: 38.282, Residuals: -0.010\n",
      "Loss: 38.189, Residuals: -0.008\n",
      "Loss: 38.185, Residuals: -0.009\n",
      "Loss: 38.178, Residuals: -0.009\n",
      "Loss: 38.166, Residuals: -0.008\n",
      "Loss: 38.146, Residuals: -0.007\n",
      "Loss: 38.143, Residuals: -0.008\n",
      "Loss: 38.058, Residuals: -0.006\n",
      "Loss: 38.057, Residuals: -0.005\n",
      "Loss: 38.046, Residuals: -0.005\n",
      "Loss: 38.029, Residuals: -0.005\n",
      "Loss: 38.027, Residuals: -0.005\n",
      "Loss: 38.009, Residuals: -0.005\n",
      "Loss: 38.009, Residuals: -0.005\n",
      "Loss: 38.008, Residuals: -0.005\n",
      "Loss: 38.002, Residuals: -0.005\n",
      "Loss: 37.990, Residuals: -0.005\n",
      "Loss: 37.990, Residuals: -0.005\n",
      "Loss: 37.987, Residuals: -0.005\n",
      "Loss: 37.981, Residuals: -0.005\n",
      "Loss: 37.981, Residuals: -0.005\n",
      "Loss: 37.980, Residuals: -0.005\n",
      "Loss: 37.978, Residuals: -0.005\n",
      "Loss: 37.974, Residuals: -0.005\n",
      "Loss: 37.974, Residuals: -0.005\n",
      "Loss: 37.972, Residuals: -0.005\n",
      "Loss: 37.971, Residuals: -0.005\n",
      "Loss: 37.971, Residuals: -0.005\n",
      "Loss: 37.968, Residuals: -0.005\n",
      "Loss: 37.968, Residuals: -0.005\n",
      "Loss: 37.968, Residuals: -0.005\n",
      "Loss: 37.954, Residuals: -0.004\n",
      "Loss: 37.952, Residuals: -0.005\n",
      "Loss: 37.949, Residuals: -0.006\n",
      "Loss: 37.944, Residuals: -0.005\n",
      "Loss: 37.943, Residuals: -0.006\n",
      "Loss: 37.939, Residuals: -0.006\n",
      "Loss: 37.939, Residuals: -0.006\n",
      "Loss: 37.934, Residuals: -0.005\n",
      "Loss: 37.933, Residuals: -0.006\n",
      "Loss: 37.926, Residuals: -0.006\n",
      "Loss: 37.924, Residuals: -0.006\n",
      "Loss: 37.923, Residuals: -0.006\n",
      "Loss: 37.921, Residuals: -0.006\n",
      "Loss: 37.920, Residuals: -0.006\n",
      "Loss: 37.918, Residuals: -0.006\n",
      "Loss: 37.916, Residuals: -0.006\n",
      "Loss: 37.915, Residuals: -0.006\n",
      "Loss: 37.914, Residuals: -0.006\n",
      "Loss: 37.914, Residuals: -0.006\n",
      "Loss: 37.913, Residuals: -0.006\n",
      "Loss: 37.912, Residuals: -0.006\n",
      "Loss: 37.912, Residuals: -0.006\n",
      "Loss: 37.912, Residuals: -0.006\n",
      "Loss: 37.912, Residuals: -0.006\n",
      "Loss: 37.911, Residuals: -0.006\n",
      "Loss: 37.911, Residuals: -0.006\n",
      "Loss: 37.911, Residuals: -0.006\n",
      "Loss: 37.910, Residuals: -0.005\n",
      "Loss: 37.910, Residuals: -0.006\n",
      "Loss: 37.910, Residuals: -0.006\n",
      "Loss: 37.910, Residuals: -0.006\n",
      "Loss: 37.910, Residuals: -0.006\n",
      "Loss: 37.909, Residuals: -0.006\n",
      "Loss: 37.909, Residuals: -0.006\n",
      "Loss: 37.909, Residuals: -0.006\n",
      "Loss: 37.909, Residuals: -0.006\n",
      "Loss: 37.909, Residuals: -0.006\n",
      "Loss: 37.909, Residuals: -0.005\n",
      "Loss: 37.909, Residuals: -0.006\n",
      "Loss: 37.909, Residuals: -0.006\n",
      "Loss: 37.909, Residuals: -0.006\n",
      "Loss: 37.909, Residuals: -0.006\n",
      "Loss: 37.909, Residuals: -0.005\n",
      "Loss: 37.909, Residuals: -0.005\n",
      "Loss: 37.908, Residuals: -0.005\n",
      "Loss: 37.908, Residuals: -0.005\n",
      "Loss: 37.908, Residuals: -0.005\n",
      "Loss: 37.908, Residuals: -0.005\n",
      "Loss: 37.908, Residuals: -0.005\n",
      "Loss: 37.908, Residuals: -0.005\n",
      "Loss: 37.908, Residuals: -0.005\n",
      "Loss: 37.908, Residuals: -0.005\n",
      "Loss: 37.908, Residuals: -0.005\n",
      "Loss: 37.908, Residuals: -0.005\n",
      "Evidence 301.807\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.66e-01\n",
      "Loss: 79.653, Residuals: -0.013\n",
      "Loss: 79.439, Residuals: -0.011\n",
      "Loss: 79.053, Residuals: -0.008\n",
      "Loss: 78.523, Residuals: -0.003\n",
      "Loss: 78.514, Residuals: -0.002\n",
      "Loss: 78.427, Residuals: -0.002\n",
      "Loss: 78.279, Residuals: -0.001\n",
      "Loss: 78.103, Residuals: -0.001\n",
      "Loss: 78.096, Residuals: -0.001\n",
      "Loss: 78.087, Residuals: -0.002\n",
      "Loss: 78.078, Residuals: -0.002\n",
      "Loss: 78.065, Residuals: -0.002\n",
      "Loss: 78.064, Residuals: -0.003\n",
      "Loss: 78.059, Residuals: -0.003\n",
      "Loss: 78.051, Residuals: -0.002\n",
      "Loss: 78.050, Residuals: -0.003\n",
      "Loss: 77.877, Residuals: -0.001\n",
      "Loss: 77.872, Residuals: -0.000\n",
      "Loss: 77.864, Residuals: -0.001\n",
      "Loss: 77.852, Residuals: -0.001\n",
      "Loss: 77.843, Residuals: -0.000\n",
      "Loss: 77.843, Residuals: -0.000\n",
      "Loss: 77.842, Residuals: -0.000\n",
      "Loss: 77.841, Residuals: -0.000\n",
      "Loss: 77.839, Residuals: 0.000\n",
      "Loss: 77.838, Residuals: 0.000\n",
      "Loss: 77.837, Residuals: 0.000\n",
      "Loss: 77.835, Residuals: 0.001\n",
      "Loss: 77.835, Residuals: 0.000\n",
      "Loss: 77.835, Residuals: 0.000\n",
      "Loss: 77.834, Residuals: 0.001\n",
      "Loss: 77.833, Residuals: 0.001\n",
      "Loss: 77.833, Residuals: 0.001\n",
      "Loss: 77.833, Residuals: 0.001\n",
      "Loss: 77.832, Residuals: 0.001\n",
      "Loss: 77.832, Residuals: 0.001\n",
      "Loss: 77.832, Residuals: 0.001\n",
      "Loss: 77.832, Residuals: 0.001\n",
      "Loss: 77.832, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Loss: 77.831, Residuals: 0.001\n",
      "Evidence 430.893\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.94e-01\n",
      "Loss: 118.015, Residuals: -0.002\n",
      "Loss: 117.834, Residuals: -0.003\n",
      "Loss: 117.549, Residuals: -0.003\n",
      "Loss: 117.342, Residuals: -0.002\n",
      "Loss: 117.321, Residuals: -0.003\n",
      "Loss: 117.284, Residuals: -0.003\n",
      "Loss: 117.222, Residuals: -0.002\n",
      "Loss: 117.205, Residuals: -0.001\n",
      "Loss: 117.176, Residuals: -0.001\n",
      "Loss: 117.174, Residuals: -0.002\n",
      "Loss: 117.150, Residuals: -0.001\n",
      "Loss: 117.141, Residuals: -0.000\n",
      "Loss: 117.138, Residuals: -0.000\n",
      "Loss: 117.132, Residuals: 0.000\n",
      "Loss: 117.131, Residuals: 0.000\n",
      "Loss: 117.128, Residuals: 0.001\n",
      "Loss: 117.124, Residuals: 0.001\n",
      "Loss: 117.124, Residuals: 0.001\n",
      "Loss: 117.124, Residuals: 0.001\n",
      "Loss: 117.123, Residuals: 0.001\n",
      "Loss: 117.123, Residuals: 0.001\n",
      "Loss: 117.123, Residuals: 0.001\n",
      "Evidence 484.320\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.39e+00\n",
      "Loss: 140.607, Residuals: -0.002\n",
      "Loss: 140.438, Residuals: -0.002\n",
      "Loss: 140.174, Residuals: -0.002\n",
      "Loss: 139.972, Residuals: -0.001\n",
      "Loss: 139.858, Residuals: -0.002\n",
      "Loss: 139.854, Residuals: -0.003\n",
      "Loss: 139.847, Residuals: -0.002\n",
      "Loss: 139.836, Residuals: -0.002\n",
      "Loss: 139.824, Residuals: -0.002\n",
      "Loss: 139.823, Residuals: -0.001\n",
      "Loss: 139.821, Residuals: -0.001\n",
      "Loss: 139.818, Residuals: -0.001\n",
      "Loss: 139.817, Residuals: -0.001\n",
      "Loss: 139.816, Residuals: -0.001\n",
      "Loss: 139.816, Residuals: -0.001\n",
      "Loss: 139.816, Residuals: -0.001\n",
      "Loss: 139.815, Residuals: -0.001\n",
      "Loss: 139.815, Residuals: -0.001\n",
      "Loss: 139.815, Residuals: -0.001\n",
      "Evidence 499.685\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.49e+00\n",
      "Loss: 149.608, Residuals: -0.003\n",
      "Loss: 149.390, Residuals: -0.001\n",
      "Loss: 149.361, Residuals: -0.003\n",
      "Loss: 149.307, Residuals: -0.004\n",
      "Loss: 149.225, Residuals: -0.004\n",
      "Loss: 149.181, Residuals: -0.005\n",
      "Loss: 149.168, Residuals: -0.005\n",
      "Loss: 149.152, Residuals: -0.005\n",
      "Loss: 149.152, Residuals: -0.005\n",
      "Loss: 149.151, Residuals: -0.005\n",
      "Loss: 149.150, Residuals: -0.005\n",
      "Loss: 149.148, Residuals: -0.005\n",
      "Loss: 149.148, Residuals: -0.005\n",
      "Loss: 149.148, Residuals: -0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 149.148, Residuals: -0.005\n",
      "Loss: 149.147, Residuals: -0.005\n",
      "Loss: 149.147, Residuals: -0.005\n",
      "Loss: 149.147, Residuals: -0.005\n",
      "Evidence 504.709\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.50e+00\n",
      "Loss: 153.458, Residuals: -0.007\n",
      "Loss: 153.335, Residuals: -0.006\n",
      "Loss: 153.258, Residuals: -0.008\n",
      "Loss: 153.251, Residuals: -0.009\n",
      "Loss: 153.242, Residuals: -0.009\n",
      "Loss: 153.232, Residuals: -0.009\n",
      "Loss: 153.232, Residuals: -0.009\n",
      "Loss: 153.231, Residuals: -0.009\n",
      "Loss: 153.229, Residuals: -0.009\n",
      "Loss: 153.228, Residuals: -0.009\n",
      "Loss: 153.227, Residuals: -0.009\n",
      "Loss: 153.226, Residuals: -0.009\n",
      "Loss: 153.226, Residuals: -0.009\n",
      "Loss: 153.226, Residuals: -0.009\n",
      "Evidence 506.502\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.51e+00\n",
      "Loss: 155.119, Residuals: -0.011\n",
      "Loss: 155.078, Residuals: -0.009\n",
      "Loss: 155.047, Residuals: -0.012\n",
      "Loss: 155.031, Residuals: -0.011\n",
      "Loss: 155.028, Residuals: -0.012\n",
      "Loss: 155.027, Residuals: -0.012\n",
      "Loss: 155.026, Residuals: -0.012\n",
      "Loss: 155.024, Residuals: -0.011\n",
      "Loss: 155.023, Residuals: -0.012\n",
      "Loss: 155.023, Residuals: -0.012\n",
      "Evidence 507.280\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.51e+00\n",
      "Loss: 155.887, Residuals: -0.014\n",
      "Loss: 155.862, Residuals: -0.012\n",
      "Loss: 155.836, Residuals: -0.014\n",
      "Loss: 155.834, Residuals: -0.013\n",
      "Loss: 155.830, Residuals: -0.014\n",
      "Loss: 155.825, Residuals: -0.014\n",
      "Loss: 155.825, Residuals: -0.014\n",
      "Loss: 155.824, Residuals: -0.014\n",
      "Loss: 155.822, Residuals: -0.014\n",
      "Loss: 155.821, Residuals: -0.014\n",
      "Loss: 155.821, Residuals: -0.014\n",
      "Loss: 155.820, Residuals: -0.014\n",
      "Loss: 155.820, Residuals: -0.014\n",
      "Loss: 155.820, Residuals: -0.014\n",
      "Loss: 155.819, Residuals: -0.014\n",
      "Loss: 155.819, Residuals: -0.014\n",
      "Loss: 155.819, Residuals: -0.014\n",
      "Loss: 155.819, Residuals: -0.014\n",
      "Loss: 155.819, Residuals: -0.014\n",
      "Loss: 155.818, Residuals: -0.014\n",
      "Loss: 155.818, Residuals: -0.014\n",
      "Evidence 507.743\n",
      "Pass count  1\n",
      "Total samples: 37, Updated regularization: 1.00e-05\n",
      "Loss: 12.856, Residuals: -0.045\n",
      "Loss: 6.873, Residuals: 0.024\n",
      "Loss: 5.143, Residuals: 0.025\n",
      "Loss: 4.450, Residuals: -0.017\n",
      "Loss: 3.784, Residuals: -0.055\n",
      "Loss: 3.686, Residuals: -0.036\n",
      "Loss: 3.528, Residuals: -0.002\n",
      "Loss: 3.259, Residuals: -0.020\n",
      "Loss: 3.243, Residuals: -0.005\n",
      "Loss: 3.119, Residuals: -0.010\n",
      "Loss: 2.960, Residuals: -0.036\n",
      "Loss: 2.950, Residuals: -0.012\n",
      "Loss: 2.864, Residuals: -0.027\n",
      "Loss: 2.844, Residuals: -0.030\n",
      "Loss: 2.806, Residuals: -0.035\n",
      "Loss: 2.748, Residuals: -0.043\n",
      "Loss: 2.746, Residuals: -0.047\n",
      "Loss: 2.742, Residuals: -0.045\n",
      "Loss: 2.736, Residuals: -0.042\n",
      "Loss: 2.687, Residuals: -0.049\n",
      "Loss: 2.686, Residuals: -0.052\n",
      "Loss: 2.685, Residuals: -0.046\n",
      "Loss: 2.655, Residuals: -0.053\n",
      "Loss: 2.655, Residuals: -0.054\n",
      "Loss: 2.652, Residuals: -0.053\n",
      "Loss: 2.632, Residuals: -0.058\n",
      "Loss: 2.632, Residuals: -0.059\n",
      "Loss: 2.631, Residuals: -0.059\n",
      "Loss: 2.631, Residuals: -0.051\n",
      "Loss: 2.612, Residuals: -0.058\n",
      "Loss: 2.608, Residuals: -0.061\n",
      "Loss: 2.608, Residuals: -0.060\n",
      "Evidence -383.898\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.01e-02\n",
      "Loss: 11.322, Residuals: -0.061\n",
      "Loss: 11.318, Residuals: -0.062\n",
      "Loss: 11.157, Residuals: -0.059\n",
      "Loss: 10.915, Residuals: -0.053\n",
      "Loss: 10.915, Residuals: -0.053\n",
      "Evidence 85.161\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 5.94e-02\n",
      "Loss: 35.473, Residuals: -0.054\n",
      "Evidence 271.808\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.30e-01\n",
      "Loss: 74.782, Residuals: -0.055\n",
      "Evidence 383.167\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 4.81e-01\n",
      "Loss: 111.370, Residuals: -0.052\n",
      "Loss: 110.730, Residuals: -0.061\n",
      "Loss: 110.721, Residuals: -0.061\n",
      "Evidence 427.954\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 6.32e-01\n",
      "Loss: 133.890, Residuals: -0.061\n",
      "Evidence 438.715\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 6.93e-01\n",
      "Loss: 141.872, Residuals: -0.061\n",
      "Loss: 141.871, Residuals: -0.061\n",
      "Evidence 440.866\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 7.20e-01\n",
      "Loss: 142.943, Residuals: -0.060\n",
      "Loss: 142.906, Residuals: -0.060\n",
      "Evidence 443.568\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 7.38e-01\n",
      "Loss: 145.440, Residuals: -0.061\n",
      "Loss: 144.569, Residuals: -0.061\n",
      "Loss: 144.568, Residuals: -0.061\n",
      "Evidence 444.844\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 7.51e-01\n",
      "Loss: 144.702, Residuals: -0.056\n",
      "Loss: 143.740, Residuals: -0.058\n",
      "Loss: 143.684, Residuals: -0.062\n",
      "Loss: 143.587, Residuals: -0.062\n",
      "Loss: 143.430, Residuals: -0.061\n",
      "Loss: 142.219, Residuals: -0.057\n",
      "Loss: 142.199, Residuals: -0.056\n",
      "Evidence 447.695\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 8.31e-01\n",
      "Loss: 143.715, Residuals: -0.046\n",
      "Loss: 143.667, Residuals: -0.047\n",
      "Evidence 449.885\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 9.26e-01\n",
      "Loss: 145.877, Residuals: -0.046\n",
      "Loss: 145.876, Residuals: -0.046\n",
      "Evidence 450.499\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 9.38e-01\n",
      "Loss: 144.840, Residuals: -0.033\n",
      "Loss: 144.792, Residuals: -0.033\n",
      "Loss: 144.721, Residuals: -0.037\n",
      "Loss: 144.608, Residuals: -0.039\n",
      "Loss: 144.598, Residuals: -0.040\n",
      "Loss: 144.502, Residuals: -0.040\n",
      "Loss: 144.501, Residuals: -0.041\n",
      "Loss: 144.438, Residuals: -0.040\n",
      "Loss: 144.355, Residuals: -0.042\n",
      "Loss: 144.354, Residuals: -0.041\n",
      "Evidence 451.495\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.12e+00\n",
      "Loss: 145.413, Residuals: -0.038\n",
      "Loss: 145.355, Residuals: -0.040\n",
      "Loss: 144.865, Residuals: -0.039\n",
      "Loss: 144.856, Residuals: -0.039\n",
      "Loss: 144.548, Residuals: -0.037\n",
      "Loss: 144.547, Residuals: -0.037\n",
      "Evidence 453.395\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.23e+00\n",
      "Loss: 145.318, Residuals: -0.035\n",
      "Loss: 145.314, Residuals: -0.034\n",
      "Loss: 145.172, Residuals: -0.034\n",
      "Loss: 144.927, Residuals: -0.033\n",
      "Loss: 144.601, Residuals: -0.032\n",
      "Loss: 144.600, Residuals: -0.032\n",
      "Evidence 454.717\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.41e+00\n",
      "Loss: 145.806, Residuals: -0.032\n",
      "Loss: 145.622, Residuals: -0.031\n",
      "Loss: 145.389, Residuals: -0.028\n",
      "Loss: 145.378, Residuals: -0.029\n",
      "Loss: 145.286, Residuals: -0.028\n",
      "Loss: 145.283, Residuals: -0.028\n",
      "Loss: 145.182, Residuals: -0.026\n",
      "Loss: 145.178, Residuals: -0.026\n",
      "Loss: 145.176, Residuals: -0.026\n",
      "Loss: 145.154, Residuals: -0.026\n",
      "Loss: 145.154, Residuals: -0.026\n",
      "Loss: 145.135, Residuals: -0.025\n",
      "Loss: 145.135, Residuals: -0.025\n",
      "Evidence 455.925\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 1.83e+00\n",
      "Loss: 146.118, Residuals: -0.021\n",
      "Loss: 146.011, Residuals: -0.022\n",
      "Loss: 145.985, Residuals: -0.020\n",
      "Loss: 145.939, Residuals: -0.019\n",
      "Loss: 145.867, Residuals: -0.018\n",
      "Loss: 145.866, Residuals: -0.018\n",
      "Loss: 145.865, Residuals: -0.019\n",
      "Loss: 145.855, Residuals: -0.018\n",
      "Loss: 145.838, Residuals: -0.017\n",
      "Loss: 145.837, Residuals: -0.018\n",
      "Loss: 145.824, Residuals: -0.017\n",
      "Loss: 145.824, Residuals: -0.017\n",
      "Loss: 145.818, Residuals: -0.016\n",
      "Loss: 145.808, Residuals: -0.015\n",
      "Loss: 145.807, Residuals: -0.015\n",
      "Loss: 145.805, Residuals: -0.015\n",
      "Loss: 145.801, Residuals: -0.015\n",
      "Loss: 145.797, Residuals: -0.014\n",
      "Loss: 145.794, Residuals: -0.014\n",
      "Loss: 145.791, Residuals: -0.014\n",
      "Loss: 145.789, Residuals: -0.013\n",
      "Loss: 145.787, Residuals: -0.013\n",
      "Loss: 145.785, Residuals: -0.013\n",
      "Loss: 145.781, Residuals: -0.012\n",
      "Loss: 145.777, Residuals: -0.012\n",
      "Loss: 145.774, Residuals: -0.012\n",
      "Loss: 145.770, Residuals: -0.010\n",
      "Loss: 145.765, Residuals: -0.011\n",
      "Loss: 145.759, Residuals: -0.010\n",
      "Loss: 145.751, Residuals: -0.010\n",
      "Loss: 145.742, Residuals: -0.008\n",
      "Loss: 145.734, Residuals: -0.008\n",
      "Loss: 145.720, Residuals: -0.007\n",
      "Loss: 145.705, Residuals: -0.006\n",
      "Loss: 145.689, Residuals: -0.004\n",
      "Loss: 145.677, Residuals: -0.004\n",
      "Loss: 145.662, Residuals: -0.003\n",
      "Loss: 145.653, Residuals: -0.002\n",
      "Loss: 145.639, Residuals: -0.000\n",
      "Loss: 145.633, Residuals: -0.000\n",
      "Loss: 145.624, Residuals: 0.001\n",
      "Loss: 145.620, Residuals: 0.001\n",
      "Loss: 145.615, Residuals: 0.002\n",
      "Loss: 145.615, Residuals: 0.002\n",
      "Loss: 145.611, Residuals: 0.003\n",
      "Loss: 145.608, Residuals: 0.003\n",
      "Loss: 145.607, Residuals: 0.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 145.604, Residuals: 0.004\n",
      "Loss: 145.604, Residuals: 0.004\n",
      "Loss: 145.603, Residuals: 0.004\n",
      "Loss: 145.602, Residuals: 0.004\n",
      "Loss: 145.602, Residuals: 0.004\n",
      "Loss: 145.601, Residuals: 0.004\n",
      "Loss: 145.601, Residuals: 0.004\n",
      "Loss: 145.601, Residuals: 0.005\n",
      "Loss: 145.601, Residuals: 0.005\n",
      "Loss: 145.601, Residuals: 0.005\n",
      "Loss: 145.601, Residuals: 0.005\n",
      "Loss: 145.601, Residuals: 0.005\n",
      "Loss: 145.601, Residuals: 0.005\n",
      "Evidence 456.227\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.249, Residuals: -0.076\n",
      "Loss: 7.557, Residuals: -0.027\n",
      "Loss: 5.312, Residuals: -0.041\n",
      "Loss: 4.575, Residuals: -0.037\n",
      "Loss: 4.061, Residuals: -0.067\n",
      "Loss: 3.850, Residuals: -0.049\n",
      "Loss: 3.801, Residuals: -0.007\n",
      "Loss: 3.705, Residuals: -0.009\n",
      "Loss: 3.534, Residuals: -0.019\n",
      "Loss: 3.287, Residuals: -0.035\n",
      "Loss: 3.257, Residuals: -0.008\n",
      "Loss: 3.204, Residuals: -0.015\n",
      "Loss: 3.128, Residuals: -0.024\n",
      "Loss: 3.125, Residuals: -0.027\n",
      "Loss: 3.119, Residuals: -0.026\n",
      "Loss: 3.072, Residuals: -0.036\n",
      "Loss: 3.055, Residuals: -0.035\n",
      "Loss: 3.028, Residuals: -0.042\n",
      "Loss: 2.987, Residuals: -0.059\n",
      "Loss: 2.983, Residuals: -0.053\n",
      "Loss: 2.978, Residuals: -0.057\n",
      "Loss: 2.968, Residuals: -0.059\n",
      "Loss: 2.953, Residuals: -0.061\n",
      "Loss: 2.950, Residuals: -0.060\n",
      "Loss: 2.925, Residuals: -0.065\n",
      "Loss: 2.913, Residuals: -0.061\n",
      "Loss: 2.911, Residuals: -0.052\n",
      "Loss: 2.891, Residuals: -0.056\n",
      "Loss: 2.862, Residuals: -0.056\n",
      "Loss: 2.860, Residuals: -0.047\n",
      "Loss: 2.837, Residuals: -0.052\n",
      "Loss: 2.833, Residuals: -0.053\n",
      "Loss: 2.832, Residuals: -0.049\n",
      "Loss: 2.813, Residuals: -0.053\n",
      "Loss: 2.781, Residuals: -0.061\n",
      "Loss: 2.780, Residuals: -0.060\n",
      "Loss: 2.779, Residuals: -0.057\n",
      "Loss: 2.770, Residuals: -0.060\n",
      "Loss: 2.759, Residuals: -0.060\n",
      "Loss: 2.757, Residuals: -0.053\n",
      "Loss: 2.755, Residuals: -0.054\n",
      "Loss: 2.739, Residuals: -0.059\n",
      "Loss: 2.739, Residuals: -0.059\n",
      "Loss: 2.721, Residuals: -0.066\n",
      "Loss: 2.720, Residuals: -0.066\n",
      "Loss: 2.720, Residuals: -0.066\n",
      "Loss: 2.712, Residuals: -0.069\n",
      "Loss: 2.708, Residuals: -0.070\n",
      "Loss: 2.708, Residuals: -0.069\n",
      "Loss: 2.708, Residuals: -0.068\n",
      "Loss: 2.693, Residuals: -0.073\n",
      "Loss: 2.693, Residuals: -0.072\n",
      "Loss: 2.692, Residuals: -0.073\n",
      "Loss: 2.689, Residuals: -0.074\n",
      "Loss: 2.689, Residuals: -0.074\n",
      "Loss: 2.685, Residuals: -0.076\n",
      "Loss: 2.678, Residuals: -0.080\n",
      "Loss: 2.678, Residuals: -0.079\n",
      "Loss: 2.677, Residuals: -0.079\n",
      "Loss: 2.677, Residuals: -0.080\n",
      "Loss: 2.676, Residuals: -0.080\n",
      "Loss: 2.676, Residuals: -0.080\n",
      "Loss: 2.667, Residuals: -0.083\n",
      "Loss: 2.667, Residuals: -0.083\n",
      "Loss: 2.667, Residuals: -0.084\n",
      "Loss: 2.667, Residuals: -0.083\n",
      "Loss: 2.661, Residuals: -0.086\n",
      "Loss: 2.661, Residuals: -0.086\n",
      "Loss: 2.660, Residuals: -0.087\n",
      "Loss: 2.660, Residuals: -0.087\n",
      "Loss: 2.659, Residuals: -0.087\n",
      "Loss: 2.659, Residuals: -0.088\n",
      "Loss: 2.659, Residuals: -0.087\n",
      "Loss: 2.656, Residuals: -0.089\n",
      "Loss: 2.656, Residuals: -0.089\n",
      "Loss: 2.654, Residuals: -0.090\n",
      "Loss: 2.653, Residuals: -0.092\n",
      "Loss: 2.652, Residuals: -0.091\n",
      "Loss: 2.652, Residuals: -0.091\n",
      "Loss: 2.651, Residuals: -0.092\n",
      "Loss: 2.651, Residuals: -0.093\n",
      "Loss: 2.651, Residuals: -0.093\n",
      "Loss: 2.646, Residuals: -0.096\n",
      "Loss: 2.646, Residuals: -0.096\n",
      "Loss: 2.646, Residuals: -0.096\n",
      "Loss: 2.646, Residuals: -0.097\n",
      "Loss: 2.646, Residuals: -0.096\n",
      "Loss: 2.646, Residuals: -0.096\n",
      "Loss: 2.641, Residuals: -0.099\n",
      "Loss: 2.641, Residuals: -0.099\n",
      "Evidence -401.769\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.15e-03\n",
      "Loss: 13.787, Residuals: -0.080\n",
      "Loss: 13.783, Residuals: -0.078\n",
      "Loss: 13.629, Residuals: -0.075\n",
      "Loss: 13.391, Residuals: -0.069\n",
      "Loss: 13.373, Residuals: -0.061\n",
      "Loss: 13.338, Residuals: -0.060\n",
      "Loss: 13.280, Residuals: -0.057\n",
      "Loss: 13.185, Residuals: -0.050\n",
      "Loss: 13.184, Residuals: -0.052\n",
      "Loss: 13.164, Residuals: -0.049\n",
      "Loss: 13.005, Residuals: -0.030\n",
      "Loss: 13.002, Residuals: -0.029\n",
      "Loss: 12.996, Residuals: -0.031\n",
      "Loss: 12.991, Residuals: -0.032\n",
      "Loss: 12.841, Residuals: -0.017\n",
      "Loss: 12.822, Residuals: -0.016\n",
      "Loss: 12.807, Residuals: -0.019\n",
      "Loss: 12.785, Residuals: -0.016\n",
      "Loss: 12.785, Residuals: -0.016\n",
      "Evidence 114.025\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.26e-02\n",
      "Loss: 44.254, Residuals: -0.010\n",
      "Loss: 44.115, Residuals: -0.010\n",
      "Loss: 43.880, Residuals: -0.006\n",
      "Loss: 43.814, Residuals: -0.006\n",
      "Loss: 43.314, Residuals: 0.004\n",
      "Loss: 43.311, Residuals: 0.005\n",
      "Loss: 43.306, Residuals: 0.004\n",
      "Loss: 43.297, Residuals: 0.004\n",
      "Loss: 43.279, Residuals: 0.004\n",
      "Loss: 43.247, Residuals: 0.005\n",
      "Loss: 43.184, Residuals: 0.006\n",
      "Loss: 43.095, Residuals: 0.010\n",
      "Loss: 43.083, Residuals: 0.008\n",
      "Loss: 43.082, Residuals: 0.008\n",
      "Loss: 43.073, Residuals: 0.008\n",
      "Loss: 42.992, Residuals: 0.010\n",
      "Loss: 42.908, Residuals: 0.017\n",
      "Loss: 42.896, Residuals: 0.016\n",
      "Loss: 42.885, Residuals: 0.016\n",
      "Loss: 42.883, Residuals: 0.015\n",
      "Loss: 42.879, Residuals: 0.015\n",
      "Loss: 42.874, Residuals: 0.015\n",
      "Loss: 42.867, Residuals: 0.016\n",
      "Loss: 42.866, Residuals: 0.016\n",
      "Loss: 42.863, Residuals: 0.016\n",
      "Loss: 42.859, Residuals: 0.016\n",
      "Loss: 42.857, Residuals: 0.016\n",
      "Loss: 42.854, Residuals: 0.016\n",
      "Loss: 42.852, Residuals: 0.016\n",
      "Loss: 42.851, Residuals: 0.016\n",
      "Loss: 42.851, Residuals: 0.016\n",
      "Evidence 314.234\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.26e-02\n",
      "Loss: 92.496, Residuals: 0.019\n",
      "Loss: 91.732, Residuals: 0.003\n",
      "Loss: 91.398, Residuals: 0.007\n",
      "Loss: 91.355, Residuals: 0.005\n",
      "Loss: 91.277, Residuals: 0.005\n",
      "Loss: 91.265, Residuals: 0.009\n",
      "Loss: 91.157, Residuals: 0.009\n",
      "Loss: 91.014, Residuals: 0.011\n",
      "Loss: 91.012, Residuals: 0.012\n",
      "Loss: 91.008, Residuals: 0.012\n",
      "Loss: 90.978, Residuals: 0.012\n",
      "Loss: 90.976, Residuals: 0.011\n",
      "Loss: 90.898, Residuals: 0.012\n",
      "Loss: 90.898, Residuals: 0.012\n",
      "Evidence 419.283\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.36e-02\n",
      "Loss: 130.130, Residuals: 0.017\n",
      "Loss: 129.456, Residuals: 0.010\n",
      "Loss: 128.872, Residuals: 0.001\n",
      "Loss: 128.855, Residuals: -0.000\n",
      "Loss: 128.713, Residuals: -0.001\n",
      "Loss: 128.534, Residuals: -0.002\n",
      "Loss: 128.529, Residuals: -0.001\n",
      "Loss: 128.354, Residuals: -0.000\n",
      "Loss: 128.354, Residuals: -0.000\n",
      "Evidence 453.004\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.12e-02\n",
      "Loss: 146.761, Residuals: -0.001\n",
      "Loss: 146.592, Residuals: -0.002\n",
      "Loss: 146.290, Residuals: -0.002\n",
      "Loss: 145.834, Residuals: -0.003\n",
      "Loss: 145.458, Residuals: -0.007\n",
      "Loss: 145.457, Residuals: -0.006\n",
      "Evidence 462.951\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.67e-02\n",
      "Loss: 152.762, Residuals: -0.007\n",
      "Loss: 152.606, Residuals: -0.007\n",
      "Loss: 152.326, Residuals: -0.008\n",
      "Loss: 151.924, Residuals: -0.007\n",
      "Loss: 151.887, Residuals: -0.009\n",
      "Loss: 151.587, Residuals: -0.008\n",
      "Loss: 151.358, Residuals: -0.007\n",
      "Loss: 151.358, Residuals: -0.007\n",
      "Evidence 467.312\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.78e-02\n",
      "Loss: 154.455, Residuals: -0.007\n",
      "Loss: 154.360, Residuals: -0.007\n",
      "Loss: 154.194, Residuals: -0.007\n",
      "Loss: 153.971, Residuals: -0.009\n",
      "Loss: 153.951, Residuals: -0.010\n",
      "Loss: 153.792, Residuals: -0.009\n",
      "Loss: 153.572, Residuals: -0.008\n",
      "Loss: 153.559, Residuals: -0.008\n",
      "Loss: 153.082, Residuals: -0.006\n",
      "Loss: 153.073, Residuals: -0.006\n",
      "Loss: 153.066, Residuals: -0.006\n",
      "Loss: 153.056, Residuals: -0.006\n",
      "Loss: 152.973, Residuals: -0.006\n",
      "Loss: 152.622, Residuals: -0.002\n",
      "Loss: 152.416, Residuals: -0.000\n",
      "Loss: 152.348, Residuals: -0.006\n",
      "Loss: 152.290, Residuals: -0.003\n",
      "Loss: 152.272, Residuals: -0.004\n",
      "Loss: 152.260, Residuals: -0.004\n",
      "Loss: 152.151, Residuals: -0.003\n",
      "Loss: 152.151, Residuals: -0.003\n",
      "Evidence 470.567\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.25e-01\n",
      "Loss: 154.797, Residuals: -0.005\n",
      "Loss: 154.691, Residuals: -0.005\n",
      "Loss: 154.517, Residuals: -0.006\n",
      "Loss: 154.355, Residuals: -0.007\n",
      "Loss: 154.228, Residuals: -0.006\n",
      "Loss: 154.222, Residuals: -0.006\n",
      "Loss: 153.983, Residuals: -0.005\n",
      "Loss: 153.977, Residuals: -0.005\n",
      "Loss: 153.768, Residuals: -0.004\n",
      "Loss: 153.759, Residuals: -0.003\n",
      "Loss: 153.403, Residuals: -0.003\n",
      "Loss: 153.402, Residuals: -0.003\n",
      "Loss: 153.258, Residuals: -0.002\n",
      "Loss: 153.246, Residuals: -0.002\n",
      "Loss: 153.130, Residuals: -0.002\n",
      "Loss: 153.117, Residuals: -0.002\n",
      "Loss: 152.998, Residuals: -0.002\n",
      "Loss: 152.995, Residuals: -0.002\n",
      "Loss: 151.956, Residuals: -0.002\n",
      "Loss: 151.857, Residuals: -0.003\n",
      "Loss: 151.792, Residuals: -0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 151.720, Residuals: -0.004\n",
      "Loss: 151.717, Residuals: -0.004\n",
      "Loss: 151.059, Residuals: -0.003\n",
      "Loss: 151.048, Residuals: -0.004\n",
      "Loss: 151.034, Residuals: -0.002\n",
      "Loss: 150.563, Residuals: -0.001\n",
      "Loss: 150.539, Residuals: -0.002\n",
      "Loss: 150.529, Residuals: -0.001\n",
      "Loss: 150.438, Residuals: -0.001\n",
      "Loss: 150.360, Residuals: -0.001\n",
      "Loss: 150.320, Residuals: -0.001\n",
      "Loss: 150.292, Residuals: 0.000\n",
      "Loss: 150.271, Residuals: 0.000\n",
      "Loss: 150.233, Residuals: 0.000\n",
      "Loss: 150.221, Residuals: 0.000\n",
      "Loss: 150.211, Residuals: 0.001\n",
      "Loss: 150.136, Residuals: 0.001\n",
      "Loss: 150.133, Residuals: 0.002\n",
      "Loss: 150.127, Residuals: 0.002\n",
      "Loss: 150.116, Residuals: 0.002\n",
      "Loss: 150.104, Residuals: 0.002\n",
      "Loss: 150.104, Residuals: 0.001\n",
      "Loss: 150.095, Residuals: 0.001\n",
      "Loss: 150.081, Residuals: 0.002\n",
      "Loss: 150.081, Residuals: 0.002\n",
      "Loss: 150.075, Residuals: 0.002\n",
      "Loss: 150.069, Residuals: 0.002\n",
      "Loss: 150.069, Residuals: 0.002\n",
      "Loss: 150.059, Residuals: 0.002\n",
      "Loss: 150.058, Residuals: 0.003\n",
      "Loss: 150.056, Residuals: 0.002\n",
      "Loss: 150.052, Residuals: 0.003\n",
      "Loss: 150.052, Residuals: 0.003\n",
      "Loss: 150.048, Residuals: 0.003\n",
      "Loss: 150.042, Residuals: 0.003\n",
      "Loss: 150.042, Residuals: 0.003\n",
      "Loss: 150.041, Residuals: 0.003\n",
      "Loss: 150.040, Residuals: 0.003\n",
      "Loss: 150.038, Residuals: 0.003\n",
      "Loss: 150.038, Residuals: 0.003\n",
      "Loss: 150.036, Residuals: 0.003\n",
      "Loss: 150.033, Residuals: 0.003\n",
      "Loss: 150.033, Residuals: 0.003\n",
      "Loss: 150.028, Residuals: 0.003\n",
      "Loss: 150.027, Residuals: 0.004\n",
      "Loss: 150.026, Residuals: 0.004\n",
      "Loss: 150.025, Residuals: 0.004\n",
      "Loss: 150.023, Residuals: 0.004\n",
      "Loss: 150.023, Residuals: 0.003\n",
      "Loss: 150.016, Residuals: 0.004\n",
      "Loss: 150.015, Residuals: 0.004\n",
      "Loss: 150.014, Residuals: 0.004\n",
      "Loss: 150.012, Residuals: 0.004\n",
      "Loss: 150.010, Residuals: 0.004\n",
      "Loss: 150.010, Residuals: 0.004\n",
      "Loss: 150.004, Residuals: 0.004\n",
      "Loss: 150.004, Residuals: 0.005\n",
      "Loss: 150.000, Residuals: 0.005\n",
      "Loss: 150.000, Residuals: 0.005\n",
      "Loss: 149.997, Residuals: 0.005\n",
      "Loss: 149.996, Residuals: 0.005\n",
      "Loss: 149.986, Residuals: 0.005\n",
      "Loss: 149.985, Residuals: 0.005\n",
      "Loss: 149.983, Residuals: 0.005\n",
      "Loss: 149.981, Residuals: 0.005\n",
      "Loss: 149.976, Residuals: 0.005\n",
      "Loss: 149.976, Residuals: 0.006\n",
      "Loss: 149.963, Residuals: 0.006\n",
      "Loss: 149.962, Residuals: 0.006\n",
      "Loss: 149.953, Residuals: 0.006\n",
      "Loss: 149.952, Residuals: 0.006\n",
      "Loss: 149.942, Residuals: 0.006\n",
      "Loss: 149.933, Residuals: 0.006\n",
      "Loss: 149.932, Residuals: 0.007\n",
      "Loss: 149.885, Residuals: 0.008\n",
      "Loss: 149.883, Residuals: 0.007\n",
      "Loss: 149.817, Residuals: 0.008\n",
      "Loss: 149.807, Residuals: 0.008\n",
      "Loss: 149.729, Residuals: 0.010\n",
      "Loss: 149.714, Residuals: 0.011\n",
      "Loss: 149.688, Residuals: 0.011\n",
      "Loss: 149.637, Residuals: 0.012\n",
      "Loss: 149.616, Residuals: 0.011\n",
      "Loss: 149.579, Residuals: 0.012\n",
      "Loss: 149.513, Residuals: 0.013\n",
      "Loss: 149.508, Residuals: 0.013\n",
      "Loss: 149.496, Residuals: 0.013\n",
      "Loss: 149.411, Residuals: 0.014\n",
      "Loss: 149.406, Residuals: 0.015\n",
      "Loss: 149.396, Residuals: 0.015\n",
      "Loss: 149.382, Residuals: 0.015\n",
      "Loss: 149.380, Residuals: 0.016\n",
      "Loss: 149.364, Residuals: 0.016\n",
      "Loss: 149.357, Residuals: 0.016\n",
      "Loss: 149.345, Residuals: 0.017\n",
      "Loss: 149.344, Residuals: 0.017\n",
      "Loss: 149.340, Residuals: 0.017\n",
      "Loss: 149.332, Residuals: 0.017\n",
      "Loss: 149.332, Residuals: 0.017\n",
      "Loss: 149.327, Residuals: 0.017\n",
      "Loss: 149.320, Residuals: 0.018\n",
      "Loss: 149.320, Residuals: 0.018\n",
      "Loss: 149.319, Residuals: 0.018\n",
      "Loss: 149.318, Residuals: 0.018\n",
      "Loss: 149.315, Residuals: 0.018\n",
      "Loss: 149.315, Residuals: 0.018\n",
      "Loss: 149.314, Residuals: 0.018\n",
      "Loss: 149.314, Residuals: 0.018\n",
      "Loss: 149.313, Residuals: 0.018\n",
      "Loss: 149.313, Residuals: 0.018\n",
      "Loss: 149.312, Residuals: 0.018\n",
      "Loss: 149.312, Residuals: 0.018\n",
      "Loss: 149.311, Residuals: 0.018\n",
      "Loss: 149.311, Residuals: 0.019\n",
      "Loss: 149.311, Residuals: 0.018\n",
      "Loss: 149.311, Residuals: 0.018\n",
      "Loss: 149.311, Residuals: 0.019\n",
      "Loss: 149.310, Residuals: 0.019\n",
      "Loss: 149.310, Residuals: 0.019\n",
      "Evidence 467.944\n",
      "Fail count  1\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.40e+00\n",
      "Loss: 152.596, Residuals: 0.025\n",
      "Loss: 152.031, Residuals: 0.024\n",
      "Loss: 151.638, Residuals: 0.024\n",
      "Loss: 151.512, Residuals: 0.024\n",
      "Loss: 151.450, Residuals: 0.027\n",
      "Loss: 151.337, Residuals: 0.027\n",
      "Loss: 151.162, Residuals: 0.027\n",
      "Loss: 151.156, Residuals: 0.026\n",
      "Loss: 151.099, Residuals: 0.026\n",
      "Loss: 151.096, Residuals: 0.027\n",
      "Loss: 151.068, Residuals: 0.027\n",
      "Loss: 151.065, Residuals: 0.027\n",
      "Loss: 151.059, Residuals: 0.027\n",
      "Loss: 151.049, Residuals: 0.027\n",
      "Loss: 151.048, Residuals: 0.027\n",
      "Loss: 151.046, Residuals: 0.027\n",
      "Loss: 151.042, Residuals: 0.027\n",
      "Loss: 151.041, Residuals: 0.027\n",
      "Loss: 151.037, Residuals: 0.027\n",
      "Loss: 151.036, Residuals: 0.027\n",
      "Loss: 151.035, Residuals: 0.027\n",
      "Loss: 151.032, Residuals: 0.027\n",
      "Loss: 151.032, Residuals: 0.027\n",
      "Loss: 151.032, Residuals: 0.027\n",
      "Loss: 151.032, Residuals: 0.027\n",
      "Evidence 479.216\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.70e+00\n",
      "Loss: 153.677, Residuals: 0.026\n",
      "Loss: 153.425, Residuals: 0.026\n",
      "Loss: 153.059, Residuals: 0.026\n",
      "Loss: 153.023, Residuals: 0.027\n",
      "Loss: 152.960, Residuals: 0.027\n",
      "Loss: 152.877, Residuals: 0.027\n",
      "Loss: 152.877, Residuals: 0.027\n",
      "Evidence 482.510\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.78e+00\n",
      "Loss: 154.524, Residuals: 0.026\n",
      "Loss: 154.417, Residuals: 0.026\n",
      "Loss: 154.257, Residuals: 0.026\n",
      "Loss: 154.103, Residuals: 0.026\n",
      "Loss: 154.103, Residuals: 0.026\n",
      "Evidence 483.815\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.80e+00\n",
      "Loss: 155.120, Residuals: 0.027\n",
      "Loss: 155.058, Residuals: 0.025\n",
      "Loss: 154.967, Residuals: 0.024\n",
      "Loss: 154.876, Residuals: 0.024\n",
      "Loss: 154.876, Residuals: 0.024\n",
      "Evidence 484.487\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.79e+00\n",
      "Loss: 155.478, Residuals: 0.022\n",
      "Loss: 155.469, Residuals: 0.022\n",
      "Loss: 155.395, Residuals: 0.022\n",
      "Loss: 155.394, Residuals: 0.022\n",
      "Loss: 155.364, Residuals: 0.022\n",
      "Loss: 155.338, Residuals: 0.022\n",
      "Loss: 155.338, Residuals: 0.022\n",
      "Evidence 484.898\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.695, Residuals: -0.077\n",
      "Loss: 6.888, Residuals: -0.029\n",
      "Loss: 4.839, Residuals: -0.039\n",
      "Loss: 3.981, Residuals: -0.058\n",
      "Loss: 3.657, Residuals: 0.008\n",
      "Loss: 3.594, Residuals: -0.026\n",
      "Loss: 3.209, Residuals: -0.024\n",
      "Loss: 3.128, Residuals: 0.035\n",
      "Loss: 2.988, Residuals: 0.010\n",
      "Loss: 2.801, Residuals: -0.020\n",
      "Loss: 2.781, Residuals: -0.001\n",
      "Loss: 2.759, Residuals: -0.015\n",
      "Loss: 2.719, Residuals: -0.024\n",
      "Loss: 2.643, Residuals: -0.037\n",
      "Loss: 2.631, Residuals: -0.028\n",
      "Loss: 2.606, Residuals: -0.033\n",
      "Loss: 2.563, Residuals: -0.041\n",
      "Loss: 2.494, Residuals: -0.052\n",
      "Loss: 2.492, Residuals: -0.055\n",
      "Loss: 2.489, Residuals: -0.053\n",
      "Loss: 2.484, Residuals: -0.052\n",
      "Loss: 2.441, Residuals: -0.064\n",
      "Loss: 2.440, Residuals: -0.062\n",
      "Loss: 2.438, Residuals: -0.059\n",
      "Loss: 2.435, Residuals: -0.052\n",
      "Loss: 2.431, Residuals: -0.055\n",
      "Loss: 2.408, Residuals: -0.068\n",
      "Loss: 2.396, Residuals: -0.064\n",
      "Loss: 2.395, Residuals: -0.065\n",
      "Loss: 2.395, Residuals: -0.064\n",
      "Loss: 2.394, Residuals: -0.064\n",
      "Loss: 2.393, Residuals: -0.062\n",
      "Loss: 2.391, Residuals: -0.059\n",
      "Loss: 2.374, Residuals: -0.066\n",
      "Loss: 2.371, Residuals: -0.064\n",
      "Loss: 2.371, Residuals: -0.065\n",
      "Evidence -413.920\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.14e-02\n",
      "Loss: 12.172, Residuals: -0.035\n",
      "Loss: 12.162, Residuals: -0.037\n",
      "Loss: 12.160, Residuals: -0.037\n",
      "Loss: 12.097, Residuals: -0.033\n",
      "Loss: 12.011, Residuals: -0.029\n",
      "Loss: 11.898, Residuals: -0.028\n",
      "Loss: 11.897, Residuals: -0.029\n",
      "Evidence 101.103\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.79e-01\n",
      "Loss: 39.316, Residuals: -0.025\n",
      "Loss: 39.166, Residuals: -0.024\n",
      "Loss: 38.926, Residuals: -0.016\n",
      "Loss: 38.512, Residuals: -0.009\n",
      "Loss: 38.471, Residuals: -0.005\n",
      "Loss: 38.134, Residuals: 0.000\n",
      "Loss: 38.132, Residuals: -0.000\n",
      "Loss: 38.115, Residuals: 0.001\n",
      "Loss: 37.963, Residuals: 0.004\n",
      "Loss: 37.963, Residuals: 0.004\n",
      "Evidence 290.624\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.40e-01\n",
      "Loss: 80.750, Residuals: -0.005\n",
      "Loss: 80.220, Residuals: -0.002\n",
      "Loss: 80.146, Residuals: -0.002\n",
      "Loss: 79.532, Residuals: 0.001\n",
      "Loss: 79.522, Residuals: 0.001\n",
      "Loss: 79.507, Residuals: 0.002\n",
      "Loss: 78.991, Residuals: 0.007\n",
      "Loss: 78.965, Residuals: 0.008\n",
      "Loss: 78.953, Residuals: 0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 78.841, Residuals: 0.009\n",
      "Loss: 78.840, Residuals: 0.009\n",
      "Evidence 403.008\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.25e+00\n",
      "Loss: 117.995, Residuals: 0.004\n",
      "Loss: 117.223, Residuals: 0.004\n",
      "Loss: 116.748, Residuals: 0.001\n",
      "Loss: 116.705, Residuals: 0.005\n",
      "Loss: 116.324, Residuals: 0.006\n",
      "Loss: 116.320, Residuals: 0.006\n",
      "Loss: 115.889, Residuals: 0.008\n",
      "Loss: 115.880, Residuals: 0.009\n",
      "Loss: 115.874, Residuals: 0.009\n",
      "Loss: 115.663, Residuals: 0.010\n",
      "Loss: 115.662, Residuals: 0.010\n",
      "Loss: 115.609, Residuals: 0.010\n",
      "Loss: 115.513, Residuals: 0.011\n",
      "Loss: 115.380, Residuals: 0.013\n",
      "Loss: 115.380, Residuals: 0.013\n",
      "Evidence 447.695\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.82e+00\n",
      "Loss: 136.902, Residuals: 0.009\n",
      "Loss: 136.489, Residuals: 0.014\n",
      "Loss: 136.236, Residuals: 0.009\n",
      "Loss: 136.222, Residuals: 0.009\n",
      "Loss: 136.087, Residuals: 0.010\n",
      "Loss: 135.880, Residuals: 0.012\n",
      "Loss: 135.860, Residuals: 0.013\n",
      "Loss: 135.824, Residuals: 0.013\n",
      "Loss: 135.768, Residuals: 0.013\n",
      "Loss: 135.766, Residuals: 0.013\n",
      "Loss: 135.752, Residuals: 0.013\n",
      "Loss: 135.733, Residuals: 0.013\n",
      "Loss: 135.732, Residuals: 0.013\n",
      "Loss: 135.732, Residuals: 0.013\n",
      "Loss: 135.731, Residuals: 0.013\n",
      "Loss: 135.730, Residuals: 0.013\n",
      "Loss: 135.729, Residuals: 0.013\n",
      "Loss: 135.729, Residuals: 0.013\n",
      "Loss: 135.729, Residuals: 0.013\n",
      "Loss: 135.728, Residuals: 0.013\n",
      "Loss: 135.728, Residuals: 0.013\n",
      "Evidence 462.699\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.86e+00\n",
      "Loss: 144.246, Residuals: 0.021\n",
      "Loss: 143.956, Residuals: 0.016\n",
      "Loss: 143.758, Residuals: 0.011\n",
      "Loss: 143.734, Residuals: 0.013\n",
      "Loss: 143.691, Residuals: 0.013\n",
      "Loss: 143.635, Residuals: 0.013\n",
      "Loss: 143.634, Residuals: 0.013\n",
      "Loss: 143.631, Residuals: 0.013\n",
      "Loss: 143.626, Residuals: 0.013\n",
      "Loss: 143.618, Residuals: 0.013\n",
      "Loss: 143.617, Residuals: 0.013\n",
      "Loss: 143.615, Residuals: 0.013\n",
      "Loss: 143.615, Residuals: 0.013\n",
      "Loss: 143.613, Residuals: 0.013\n",
      "Loss: 143.613, Residuals: 0.013\n",
      "Evidence 468.778\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.78e+00\n",
      "Loss: 147.027, Residuals: 0.016\n",
      "Loss: 146.898, Residuals: 0.013\n",
      "Loss: 146.821, Residuals: 0.012\n",
      "Loss: 146.742, Residuals: 0.014\n",
      "Loss: 146.737, Residuals: 0.012\n",
      "Loss: 146.731, Residuals: 0.012\n",
      "Loss: 146.720, Residuals: 0.012\n",
      "Loss: 146.720, Residuals: 0.012\n",
      "Loss: 146.718, Residuals: 0.012\n",
      "Loss: 146.715, Residuals: 0.012\n",
      "Loss: 146.714, Residuals: 0.012\n",
      "Loss: 146.713, Residuals: 0.012\n",
      "Loss: 146.713, Residuals: 0.012\n",
      "Evidence 471.813\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.73e+00\n",
      "Loss: 148.403, Residuals: 0.012\n",
      "Loss: 148.335, Residuals: 0.014\n",
      "Loss: 148.281, Residuals: 0.012\n",
      "Loss: 148.270, Residuals: 0.013\n",
      "Loss: 148.253, Residuals: 0.013\n",
      "Loss: 148.252, Residuals: 0.012\n",
      "Loss: 148.250, Residuals: 0.012\n",
      "Loss: 148.247, Residuals: 0.012\n",
      "Loss: 148.243, Residuals: 0.012\n",
      "Loss: 148.243, Residuals: 0.012\n",
      "Loss: 148.243, Residuals: 0.012\n",
      "Loss: 148.242, Residuals: 0.012\n",
      "Loss: 148.242, Residuals: 0.012\n",
      "Loss: 148.241, Residuals: 0.012\n",
      "Loss: 148.241, Residuals: 0.012\n",
      "Evidence 473.365\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.71e+00\n",
      "Loss: 149.189, Residuals: 0.013\n",
      "Loss: 149.150, Residuals: 0.013\n",
      "Loss: 149.127, Residuals: 0.012\n",
      "Loss: 149.126, Residuals: 0.012\n",
      "Loss: 149.125, Residuals: 0.012\n",
      "Loss: 149.122, Residuals: 0.012\n",
      "Loss: 149.118, Residuals: 0.012\n",
      "Loss: 149.118, Residuals: 0.012\n",
      "Evidence 474.227\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.72e+00\n",
      "Loss: 149.691, Residuals: 0.013\n",
      "Loss: 149.665, Residuals: 0.013\n",
      "Loss: 149.651, Residuals: 0.012\n",
      "Loss: 149.650, Residuals: 0.013\n",
      "Loss: 149.648, Residuals: 0.013\n",
      "Loss: 149.646, Residuals: 0.013\n",
      "Loss: 149.646, Residuals: 0.013\n",
      "Loss: 149.646, Residuals: 0.013\n",
      "Loss: 149.646, Residuals: 0.013\n",
      "Loss: 149.646, Residuals: 0.013\n",
      "Evidence 474.772\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.72e+00\n",
      "Loss: 149.999, Residuals: 0.013\n",
      "Loss: 149.982, Residuals: 0.013\n",
      "Loss: 149.973, Residuals: 0.013\n",
      "Loss: 149.973, Residuals: 0.013\n",
      "Loss: 149.972, Residuals: 0.013\n",
      "Loss: 149.971, Residuals: 0.013\n",
      "Loss: 149.971, Residuals: 0.013\n",
      "Loss: 149.971, Residuals: 0.013\n",
      "Loss: 149.971, Residuals: 0.013\n",
      "Evidence 475.150\n",
      "Pass count  1\n",
      "Total samples: 37, Updated regularization: 1.00e-05\n",
      "Loss: 11.946, Residuals: -0.042\n",
      "Loss: 6.657, Residuals: 0.009\n",
      "Loss: 4.652, Residuals: 0.007\n",
      "Loss: 3.913, Residuals: -0.007\n",
      "Loss: 3.572, Residuals: 0.097\n",
      "Loss: 3.528, Residuals: 0.046\n",
      "Loss: 3.142, Residuals: 0.025\n",
      "Loss: 2.900, Residuals: 0.001\n",
      "Loss: 2.804, Residuals: 0.057\n",
      "Loss: 2.641, Residuals: 0.039\n",
      "Loss: 2.411, Residuals: 0.007\n",
      "Loss: 2.401, Residuals: 0.016\n",
      "Loss: 2.315, Residuals: 0.001\n",
      "Loss: 2.312, Residuals: 0.005\n",
      "Loss: 2.280, Residuals: -0.001\n",
      "Loss: 2.260, Residuals: 0.006\n",
      "Loss: 2.260, Residuals: 0.007\n",
      "Loss: 2.230, Residuals: -0.003\n",
      "Loss: 2.190, Residuals: -0.025\n",
      "Loss: 2.190, Residuals: -0.024\n",
      "Loss: 2.189, Residuals: -0.025\n",
      "Loss: 2.173, Residuals: -0.032\n",
      "Loss: 2.171, Residuals: -0.027\n",
      "Loss: 2.168, Residuals: -0.026\n",
      "Loss: 2.161, Residuals: -0.029\n",
      "Loss: 2.159, Residuals: -0.022\n",
      "Loss: 2.159, Residuals: -0.024\n",
      "Loss: 2.155, Residuals: -0.025\n",
      "Loss: 2.148, Residuals: -0.028\n",
      "Loss: 2.137, Residuals: -0.034\n",
      "Loss: 2.136, Residuals: -0.031\n",
      "Loss: 2.126, Residuals: -0.033\n",
      "Loss: 2.126, Residuals: -0.033\n",
      "Loss: 2.126, Residuals: -0.032\n",
      "Loss: 2.125, Residuals: -0.032\n",
      "Loss: 2.125, Residuals: -0.031\n",
      "Loss: 2.123, Residuals: -0.029\n",
      "Loss: 2.121, Residuals: -0.026\n",
      "Loss: 2.120, Residuals: -0.023\n",
      "Loss: 2.112, Residuals: -0.028\n",
      "Loss: 2.104, Residuals: -0.028\n",
      "Loss: 2.101, Residuals: -0.022\n",
      "Loss: 2.101, Residuals: -0.019\n",
      "Loss: 2.089, Residuals: -0.026\n",
      "Loss: 2.089, Residuals: -0.025\n",
      "Loss: 2.070, Residuals: -0.035\n",
      "Loss: 2.069, Residuals: -0.029\n",
      "Loss: 2.068, Residuals: -0.028\n",
      "Loss: 2.064, Residuals: -0.025\n",
      "Loss: 2.060, Residuals: -0.023\n",
      "Loss: 2.060, Residuals: -0.023\n",
      "Loss: 2.059, Residuals: -0.023\n",
      "Loss: 2.044, Residuals: -0.031\n",
      "Loss: 2.044, Residuals: -0.028\n",
      "Loss: 2.040, Residuals: -0.029\n",
      "Loss: 2.040, Residuals: -0.028\n",
      "Loss: 2.030, Residuals: -0.033\n",
      "Loss: 2.030, Residuals: -0.033\n",
      "Loss: 2.029, Residuals: -0.032\n",
      "Loss: 2.023, Residuals: -0.035\n",
      "Loss: 2.011, Residuals: -0.037\n",
      "Loss: 2.011, Residuals: -0.036\n",
      "Loss: 2.010, Residuals: -0.035\n",
      "Loss: 1.992, Residuals: -0.039\n",
      "Loss: 1.990, Residuals: -0.036\n",
      "Loss: 1.987, Residuals: -0.035\n",
      "Loss: 1.985, Residuals: -0.035\n",
      "Loss: 1.982, Residuals: -0.035\n",
      "Loss: 1.981, Residuals: -0.033\n",
      "Loss: 1.972, Residuals: -0.038\n",
      "Loss: 1.971, Residuals: -0.036\n",
      "Loss: 1.969, Residuals: -0.037\n",
      "Loss: 1.968, Residuals: -0.037\n",
      "Loss: 1.967, Residuals: -0.037\n",
      "Loss: 1.959, Residuals: -0.043\n",
      "Loss: 1.959, Residuals: -0.041\n",
      "Loss: 1.954, Residuals: -0.044\n",
      "Loss: 1.947, Residuals: -0.046\n",
      "Loss: 1.947, Residuals: -0.045\n",
      "Loss: 1.946, Residuals: -0.044\n",
      "Loss: 1.945, Residuals: -0.044\n",
      "Loss: 1.944, Residuals: -0.044\n",
      "Loss: 1.943, Residuals: -0.044\n",
      "Loss: 1.934, Residuals: -0.051\n",
      "Loss: 1.934, Residuals: -0.051\n",
      "Loss: 1.933, Residuals: -0.051\n",
      "Loss: 1.930, Residuals: -0.050\n",
      "Loss: 1.930, Residuals: -0.048\n",
      "Loss: 1.925, Residuals: -0.051\n",
      "Loss: 1.918, Residuals: -0.056\n",
      "Loss: 1.918, Residuals: -0.054\n",
      "Loss: 1.918, Residuals: -0.053\n",
      "Loss: 1.915, Residuals: -0.053\n",
      "Loss: 1.912, Residuals: -0.051\n",
      "Loss: 1.912, Residuals: -0.049\n",
      "Loss: 1.905, Residuals: -0.052\n",
      "Loss: 1.894, Residuals: -0.057\n",
      "Loss: 1.893, Residuals: -0.058\n",
      "Loss: 1.892, Residuals: -0.058\n",
      "Loss: 1.889, Residuals: -0.059\n",
      "Loss: 1.889, Residuals: -0.059\n",
      "Loss: 1.888, Residuals: -0.058\n",
      "Loss: 1.884, Residuals: -0.060\n",
      "Loss: 1.876, Residuals: -0.064\n",
      "Loss: 1.876, Residuals: -0.065\n",
      "Loss: 1.875, Residuals: -0.066\n",
      "Loss: 1.868, Residuals: -0.069\n",
      "Loss: 1.868, Residuals: -0.069\n",
      "Loss: 1.868, Residuals: -0.070\n",
      "Loss: 1.867, Residuals: -0.071\n",
      "Loss: 1.865, Residuals: -0.072\n",
      "Loss: 1.865, Residuals: -0.072\n",
      "Loss: 1.859, Residuals: -0.075\n",
      "Loss: 1.859, Residuals: -0.074\n",
      "Loss: 1.859, Residuals: -0.074\n",
      "Loss: 1.859, Residuals: -0.075\n",
      "Loss: 1.858, Residuals: -0.075\n",
      "Loss: 1.858, Residuals: -0.076\n",
      "Loss: 1.858, Residuals: -0.077\n",
      "Loss: 1.855, Residuals: -0.078\n",
      "Loss: 1.851, Residuals: -0.080\n",
      "Loss: 1.851, Residuals: -0.080\n",
      "Loss: 1.851, Residuals: -0.080\n",
      "Loss: 1.851, Residuals: -0.081\n",
      "Loss: 1.850, Residuals: -0.081\n",
      "Loss: 1.850, Residuals: -0.081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.848, Residuals: -0.082\n",
      "Loss: 1.848, Residuals: -0.082\n",
      "Loss: 1.848, Residuals: -0.082\n",
      "Loss: 1.846, Residuals: -0.084\n",
      "Loss: 1.846, Residuals: -0.084\n",
      "Evidence -347.053\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 6.09e-04\n",
      "Loss: 8.011, Residuals: -0.072\n",
      "Loss: 8.009, Residuals: -0.071\n",
      "Loss: 8.007, Residuals: -0.070\n",
      "Loss: 8.003, Residuals: -0.067\n",
      "Loss: 7.970, Residuals: -0.067\n",
      "Loss: 7.921, Residuals: -0.066\n",
      "Loss: 7.865, Residuals: -0.065\n",
      "Loss: 7.861, Residuals: -0.068\n",
      "Loss: 7.859, Residuals: -0.064\n",
      "Loss: 7.856, Residuals: -0.063\n",
      "Loss: 7.853, Residuals: -0.062\n",
      "Loss: 7.847, Residuals: -0.062\n",
      "Loss: 7.837, Residuals: -0.062\n",
      "Loss: 7.836, Residuals: -0.062\n",
      "Loss: 7.827, Residuals: -0.062\n",
      "Loss: 7.811, Residuals: -0.060\n",
      "Loss: 7.811, Residuals: -0.061\n",
      "Loss: 7.811, Residuals: -0.061\n",
      "Loss: 7.804, Residuals: -0.060\n",
      "Loss: 7.802, Residuals: -0.061\n",
      "Loss: 7.801, Residuals: -0.060\n",
      "Loss: 7.800, Residuals: -0.060\n",
      "Loss: 7.789, Residuals: -0.060\n",
      "Loss: 7.789, Residuals: -0.060\n",
      "Loss: 7.773, Residuals: -0.058\n",
      "Loss: 7.771, Residuals: -0.056\n",
      "Loss: 7.770, Residuals: -0.058\n",
      "Loss: 7.756, Residuals: -0.056\n",
      "Loss: 7.756, Residuals: -0.057\n",
      "Loss: 7.756, Residuals: -0.057\n",
      "Loss: 7.756, Residuals: -0.057\n",
      "Loss: 7.755, Residuals: -0.057\n",
      "Loss: 7.754, Residuals: -0.057\n",
      "Loss: 7.754, Residuals: -0.057\n",
      "Loss: 7.753, Residuals: -0.057\n",
      "Loss: 7.743, Residuals: -0.058\n",
      "Loss: 7.743, Residuals: -0.058\n",
      "Loss: 7.743, Residuals: -0.058\n",
      "Loss: 7.741, Residuals: -0.058\n",
      "Loss: 7.740, Residuals: -0.059\n",
      "Loss: 7.740, Residuals: -0.059\n",
      "Loss: 7.740, Residuals: -0.059\n",
      "Loss: 7.737, Residuals: -0.059\n",
      "Loss: 7.737, Residuals: -0.059\n",
      "Loss: 7.737, Residuals: -0.059\n",
      "Loss: 7.735, Residuals: -0.059\n",
      "Loss: 7.734, Residuals: -0.059\n",
      "Loss: 7.734, Residuals: -0.059\n",
      "Loss: 7.734, Residuals: -0.059\n",
      "Loss: 7.734, Residuals: -0.059\n",
      "Evidence 47.796\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 6.00e-03\n",
      "Loss: 29.856, Residuals: -0.061\n",
      "Loss: 29.794, Residuals: -0.058\n",
      "Loss: 29.677, Residuals: -0.057\n",
      "Loss: 29.516, Residuals: -0.056\n",
      "Loss: 29.505, Residuals: -0.055\n",
      "Loss: 29.403, Residuals: -0.054\n",
      "Loss: 29.401, Residuals: -0.055\n",
      "Loss: 29.331, Residuals: -0.055\n",
      "Loss: 29.216, Residuals: -0.052\n",
      "Loss: 29.212, Residuals: -0.049\n",
      "Loss: 29.095, Residuals: -0.047\n",
      "Loss: 29.094, Residuals: -0.048\n",
      "Loss: 29.066, Residuals: -0.047\n",
      "Loss: 29.063, Residuals: -0.047\n",
      "Loss: 29.034, Residuals: -0.046\n",
      "Loss: 29.033, Residuals: -0.047\n",
      "Loss: 29.002, Residuals: -0.045\n",
      "Loss: 29.000, Residuals: -0.044\n",
      "Loss: 28.999, Residuals: -0.045\n",
      "Loss: 28.999, Residuals: -0.045\n",
      "Loss: 28.998, Residuals: -0.045\n",
      "Loss: 28.960, Residuals: -0.043\n",
      "Loss: 28.959, Residuals: -0.044\n",
      "Loss: 28.956, Residuals: -0.044\n",
      "Loss: 28.954, Residuals: -0.044\n",
      "Loss: 28.938, Residuals: -0.043\n",
      "Loss: 28.937, Residuals: -0.044\n",
      "Loss: 28.937, Residuals: -0.043\n",
      "Loss: 28.935, Residuals: -0.043\n",
      "Loss: 28.922, Residuals: -0.043\n",
      "Loss: 28.920, Residuals: -0.043\n",
      "Loss: 28.920, Residuals: -0.043\n",
      "Loss: 28.913, Residuals: -0.043\n",
      "Loss: 28.910, Residuals: -0.043\n",
      "Loss: 28.909, Residuals: -0.043\n",
      "Loss: 28.909, Residuals: -0.043\n",
      "Loss: 28.895, Residuals: -0.042\n",
      "Loss: 28.895, Residuals: -0.042\n",
      "Loss: 28.895, Residuals: -0.042\n",
      "Loss: 28.894, Residuals: -0.042\n",
      "Loss: 28.893, Residuals: -0.042\n",
      "Loss: 28.890, Residuals: -0.042\n",
      "Loss: 28.889, Residuals: -0.042\n",
      "Loss: 28.889, Residuals: -0.042\n",
      "Loss: 28.887, Residuals: -0.041\n",
      "Loss: 28.887, Residuals: -0.042\n",
      "Loss: 28.887, Residuals: -0.041\n",
      "Loss: 28.882, Residuals: -0.041\n",
      "Loss: 28.882, Residuals: -0.041\n",
      "Loss: 28.882, Residuals: -0.041\n",
      "Loss: 28.882, Residuals: -0.041\n",
      "Loss: 28.880, Residuals: -0.041\n",
      "Loss: 28.880, Residuals: -0.041\n",
      "Loss: 28.878, Residuals: -0.041\n",
      "Loss: 28.878, Residuals: -0.041\n",
      "Loss: 28.878, Residuals: -0.041\n",
      "Loss: 28.876, Residuals: -0.040\n",
      "Loss: 28.876, Residuals: -0.040\n",
      "Evidence 255.431\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.94e-02\n",
      "Loss: 73.177, Residuals: -0.047\n",
      "Loss: 72.916, Residuals: -0.044\n",
      "Loss: 72.845, Residuals: -0.040\n",
      "Loss: 72.713, Residuals: -0.040\n",
      "Loss: 72.476, Residuals: -0.038\n",
      "Loss: 72.293, Residuals: -0.032\n",
      "Loss: 72.288, Residuals: -0.034\n",
      "Loss: 72.245, Residuals: -0.033\n",
      "Loss: 72.179, Residuals: -0.034\n",
      "Loss: 72.058, Residuals: -0.033\n",
      "Loss: 72.050, Residuals: -0.033\n",
      "Loss: 71.980, Residuals: -0.032\n",
      "Loss: 71.962, Residuals: -0.033\n",
      "Loss: 71.819, Residuals: -0.031\n",
      "Loss: 71.816, Residuals: -0.031\n",
      "Loss: 71.797, Residuals: -0.032\n",
      "Loss: 71.652, Residuals: -0.030\n",
      "Loss: 71.649, Residuals: -0.030\n",
      "Loss: 71.642, Residuals: -0.030\n",
      "Loss: 71.631, Residuals: -0.030\n",
      "Loss: 71.612, Residuals: -0.030\n",
      "Loss: 71.611, Residuals: -0.030\n",
      "Loss: 71.594, Residuals: -0.030\n",
      "Loss: 71.563, Residuals: -0.029\n",
      "Loss: 71.558, Residuals: -0.030\n",
      "Loss: 71.550, Residuals: -0.030\n",
      "Loss: 71.534, Residuals: -0.029\n",
      "Loss: 71.532, Residuals: -0.029\n",
      "Loss: 71.507, Residuals: -0.029\n",
      "Loss: 71.498, Residuals: -0.029\n",
      "Loss: 71.481, Residuals: -0.028\n",
      "Loss: 71.478, Residuals: -0.029\n",
      "Loss: 71.450, Residuals: -0.028\n",
      "Loss: 71.407, Residuals: -0.027\n",
      "Loss: 71.402, Residuals: -0.027\n",
      "Loss: 71.393, Residuals: -0.027\n",
      "Loss: 71.376, Residuals: -0.027\n",
      "Loss: 71.346, Residuals: -0.027\n",
      "Loss: 71.340, Residuals: -0.027\n",
      "Loss: 71.328, Residuals: -0.027\n",
      "Loss: 71.305, Residuals: -0.026\n",
      "Loss: 71.296, Residuals: -0.026\n",
      "Loss: 71.277, Residuals: -0.026\n",
      "Loss: 71.275, Residuals: -0.026\n",
      "Loss: 71.041, Residuals: -0.021\n",
      "Loss: 71.014, Residuals: -0.020\n",
      "Loss: 70.995, Residuals: -0.021\n",
      "Loss: 70.964, Residuals: -0.020\n",
      "Loss: 70.958, Residuals: -0.020\n",
      "Loss: 70.553, Residuals: -0.015\n",
      "Loss: 70.541, Residuals: -0.014\n",
      "Loss: 70.522, Residuals: -0.014\n",
      "Loss: 70.488, Residuals: -0.014\n",
      "Loss: 70.442, Residuals: -0.014\n",
      "Loss: 70.358, Residuals: -0.014\n",
      "Loss: 70.224, Residuals: -0.013\n",
      "Loss: 70.086, Residuals: -0.009\n",
      "Loss: 70.084, Residuals: -0.009\n",
      "Loss: 70.080, Residuals: -0.009\n",
      "Loss: 70.073, Residuals: -0.010\n",
      "Loss: 70.064, Residuals: -0.010\n",
      "Loss: 69.984, Residuals: -0.010\n",
      "Loss: 69.973, Residuals: -0.009\n",
      "Loss: 69.864, Residuals: -0.009\n",
      "Loss: 69.847, Residuals: -0.007\n",
      "Loss: 69.816, Residuals: -0.007\n",
      "Loss: 69.805, Residuals: -0.007\n",
      "Loss: 69.697, Residuals: -0.007\n",
      "Loss: 69.680, Residuals: -0.007\n",
      "Loss: 69.650, Residuals: -0.006\n",
      "Loss: 69.595, Residuals: -0.006\n",
      "Loss: 69.585, Residuals: -0.005\n",
      "Loss: 69.497, Residuals: -0.005\n",
      "Loss: 69.485, Residuals: -0.005\n",
      "Loss: 69.462, Residuals: -0.004\n",
      "Loss: 69.457, Residuals: -0.004\n",
      "Loss: 69.405, Residuals: -0.004\n",
      "Loss: 69.402, Residuals: -0.005\n",
      "Loss: 69.378, Residuals: -0.004\n",
      "Loss: 69.337, Residuals: -0.003\n",
      "Loss: 69.334, Residuals: -0.003\n",
      "Loss: 69.329, Residuals: -0.003\n",
      "Loss: 69.326, Residuals: -0.003\n",
      "Loss: 69.301, Residuals: -0.003\n",
      "Loss: 69.301, Residuals: -0.003\n",
      "Loss: 69.284, Residuals: -0.002\n",
      "Loss: 69.274, Residuals: -0.002\n",
      "Loss: 69.273, Residuals: -0.001\n",
      "Loss: 69.272, Residuals: -0.002\n",
      "Loss: 69.256, Residuals: -0.002\n",
      "Loss: 69.256, Residuals: -0.002\n",
      "Loss: 69.240, Residuals: -0.001\n",
      "Loss: 69.239, Residuals: -0.001\n",
      "Loss: 69.239, Residuals: -0.001\n",
      "Loss: 69.228, Residuals: -0.001\n",
      "Loss: 69.228, Residuals: -0.001\n",
      "Loss: 69.219, Residuals: -0.000\n",
      "Loss: 69.219, Residuals: -0.000\n",
      "Loss: 69.219, Residuals: -0.000\n",
      "Loss: 69.217, Residuals: 0.000\n",
      "Loss: 69.214, Residuals: 0.000\n",
      "Loss: 69.213, Residuals: 0.000\n",
      "Loss: 69.213, Residuals: 0.000\n",
      "Loss: 69.211, Residuals: 0.000\n",
      "Loss: 69.211, Residuals: 0.001\n",
      "Loss: 69.209, Residuals: 0.001\n",
      "Loss: 69.209, Residuals: 0.001\n",
      "Loss: 69.209, Residuals: 0.001\n",
      "Loss: 69.209, Residuals: 0.001\n",
      "Evidence 371.810\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 2.28e-01\n",
      "Loss: 111.332, Residuals: 0.004\n",
      "Loss: 110.883, Residuals: 0.002\n",
      "Loss: 110.314, Residuals: 0.004\n",
      "Loss: 110.267, Residuals: 0.005\n",
      "Loss: 110.249, Residuals: 0.002\n",
      "Loss: 110.106, Residuals: 0.004\n",
      "Loss: 109.917, Residuals: 0.008\n",
      "Loss: 109.897, Residuals: 0.007\n",
      "Loss: 109.876, Residuals: 0.006\n",
      "Loss: 109.711, Residuals: 0.007\n",
      "Loss: 109.701, Residuals: 0.006\n",
      "Loss: 109.610, Residuals: 0.007\n",
      "Loss: 109.571, Residuals: 0.005\n",
      "Loss: 109.506, Residuals: 0.006\n",
      "Loss: 109.490, Residuals: 0.005\n",
      "Loss: 109.485, Residuals: 0.006\n",
      "Loss: 109.481, Residuals: 0.006\n",
      "Loss: 109.447, Residuals: 0.006\n",
      "Loss: 109.445, Residuals: 0.006\n",
      "Loss: 109.426, Residuals: 0.007\n",
      "Loss: 109.424, Residuals: 0.006\n",
      "Loss: 109.419, Residuals: 0.007\n",
      "Loss: 109.414, Residuals: 0.007\n",
      "Loss: 109.413, Residuals: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 109.413, Residuals: 0.007\n",
      "Loss: 109.408, Residuals: 0.007\n",
      "Loss: 109.408, Residuals: 0.007\n",
      "Loss: 109.405, Residuals: 0.007\n",
      "Loss: 109.400, Residuals: 0.007\n",
      "Loss: 109.400, Residuals: 0.007\n",
      "Loss: 109.399, Residuals: 0.007\n",
      "Loss: 109.397, Residuals: 0.007\n",
      "Loss: 109.397, Residuals: 0.007\n",
      "Loss: 109.397, Residuals: 0.007\n",
      "Loss: 109.397, Residuals: 0.007\n",
      "Loss: 109.396, Residuals: 0.007\n",
      "Loss: 109.396, Residuals: 0.007\n",
      "Loss: 109.396, Residuals: 0.007\n",
      "Loss: 109.396, Residuals: 0.007\n",
      "Loss: 109.395, Residuals: 0.007\n",
      "Loss: 109.395, Residuals: 0.007\n",
      "Loss: 109.394, Residuals: 0.007\n",
      "Loss: 109.394, Residuals: 0.007\n",
      "Loss: 109.394, Residuals: 0.007\n",
      "Loss: 109.394, Residuals: 0.007\n",
      "Loss: 109.394, Residuals: 0.007\n",
      "Loss: 109.394, Residuals: 0.007\n",
      "Loss: 109.393, Residuals: 0.007\n",
      "Loss: 109.393, Residuals: 0.007\n",
      "Evidence 419.628\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 3.21e-01\n",
      "Loss: 132.521, Residuals: 0.012\n",
      "Loss: 132.158, Residuals: 0.009\n",
      "Loss: 131.611, Residuals: 0.009\n",
      "Loss: 131.520, Residuals: 0.005\n",
      "Loss: 131.369, Residuals: 0.007\n",
      "Loss: 131.179, Residuals: 0.010\n",
      "Loss: 131.166, Residuals: 0.010\n",
      "Loss: 131.150, Residuals: 0.010\n",
      "Loss: 131.122, Residuals: 0.010\n",
      "Loss: 131.074, Residuals: 0.010\n",
      "Loss: 131.037, Residuals: 0.011\n",
      "Loss: 131.034, Residuals: 0.011\n",
      "Loss: 131.032, Residuals: 0.011\n",
      "Loss: 131.031, Residuals: 0.011\n",
      "Loss: 131.013, Residuals: 0.011\n",
      "Loss: 131.012, Residuals: 0.011\n",
      "Loss: 131.012, Residuals: 0.011\n",
      "Loss: 131.007, Residuals: 0.011\n",
      "Loss: 131.006, Residuals: 0.011\n",
      "Loss: 131.006, Residuals: 0.011\n",
      "Loss: 131.005, Residuals: 0.011\n",
      "Loss: 131.004, Residuals: 0.011\n",
      "Evidence 432.208\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 3.37e-01\n",
      "Loss: 140.160, Residuals: 0.011\n",
      "Loss: 140.065, Residuals: 0.007\n",
      "Loss: 139.927, Residuals: 0.009\n",
      "Loss: 139.797, Residuals: 0.012\n",
      "Loss: 139.777, Residuals: 0.011\n",
      "Loss: 139.753, Residuals: 0.011\n",
      "Loss: 139.732, Residuals: 0.012\n",
      "Loss: 139.728, Residuals: 0.012\n",
      "Loss: 139.726, Residuals: 0.012\n",
      "Loss: 139.720, Residuals: 0.012\n",
      "Loss: 139.719, Residuals: 0.012\n",
      "Loss: 139.711, Residuals: 0.012\n",
      "Loss: 139.711, Residuals: 0.012\n",
      "Loss: 139.707, Residuals: 0.012\n",
      "Loss: 139.702, Residuals: 0.012\n",
      "Loss: 139.702, Residuals: 0.012\n",
      "Loss: 139.701, Residuals: 0.012\n",
      "Loss: 139.698, Residuals: 0.012\n",
      "Loss: 139.698, Residuals: 0.012\n",
      "Loss: 139.695, Residuals: 0.012\n",
      "Loss: 139.695, Residuals: 0.012\n",
      "Loss: 139.695, Residuals: 0.012\n",
      "Loss: 139.695, Residuals: 0.012\n",
      "Loss: 139.695, Residuals: 0.012\n",
      "Loss: 139.694, Residuals: 0.012\n",
      "Loss: 139.694, Residuals: 0.012\n",
      "Evidence 436.190\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 3.21e-01\n",
      "Loss: 143.164, Residuals: 0.012\n",
      "Loss: 143.127, Residuals: 0.010\n",
      "Loss: 143.074, Residuals: 0.011\n",
      "Loss: 143.030, Residuals: 0.013\n",
      "Loss: 143.027, Residuals: 0.013\n",
      "Loss: 143.021, Residuals: 0.013\n",
      "Loss: 143.020, Residuals: 0.012\n",
      "Loss: 143.017, Residuals: 0.012\n",
      "Loss: 143.012, Residuals: 0.013\n",
      "Loss: 143.012, Residuals: 0.012\n",
      "Loss: 143.011, Residuals: 0.012\n",
      "Loss: 143.010, Residuals: 0.012\n",
      "Loss: 143.008, Residuals: 0.012\n",
      "Loss: 143.008, Residuals: 0.012\n",
      "Loss: 143.008, Residuals: 0.012\n",
      "Loss: 143.007, Residuals: 0.012\n",
      "Loss: 143.007, Residuals: 0.012\n",
      "Loss: 143.007, Residuals: 0.012\n",
      "Loss: 143.007, Residuals: 0.012\n",
      "Loss: 143.006, Residuals: 0.012\n",
      "Loss: 143.006, Residuals: 0.012\n",
      "Loss: 143.006, Residuals: 0.012\n",
      "Evidence 437.782\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 3.18e-01\n",
      "Loss: 144.405, Residuals: 0.013\n",
      "Loss: 144.372, Residuals: 0.013\n",
      "Loss: 144.365, Residuals: 0.013\n",
      "Loss: 144.355, Residuals: 0.013\n",
      "Loss: 144.350, Residuals: 0.013\n",
      "Loss: 144.350, Residuals: 0.013\n",
      "Loss: 144.349, Residuals: 0.013\n",
      "Loss: 144.348, Residuals: 0.013\n",
      "Loss: 144.348, Residuals: 0.013\n",
      "Loss: 144.347, Residuals: 0.013\n",
      "Loss: 144.347, Residuals: 0.013\n",
      "Loss: 144.347, Residuals: 0.013\n",
      "Evidence 438.556\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 3.23e-01\n",
      "Loss: 145.000, Residuals: 0.013\n",
      "Loss: 144.976, Residuals: 0.012\n",
      "Loss: 144.964, Residuals: 0.013\n",
      "Loss: 144.962, Residuals: 0.013\n",
      "Loss: 144.961, Residuals: 0.013\n",
      "Loss: 144.958, Residuals: 0.013\n",
      "Loss: 144.958, Residuals: 0.013\n",
      "Evidence 439.014\n",
      "Updating hyper-parameters...\n",
      "Total samples: 37, Updated regularization: 3.27e-01\n",
      "Loss: 145.308, Residuals: 0.013\n",
      "Loss: 145.294, Residuals: 0.013\n",
      "Loss: 145.287, Residuals: 0.013\n",
      "Loss: 145.286, Residuals: 0.013\n",
      "Loss: 145.285, Residuals: 0.013\n",
      "Loss: 145.284, Residuals: 0.013\n",
      "Loss: 145.282, Residuals: 0.013\n",
      "Loss: 145.281, Residuals: 0.013\n",
      "Loss: 145.281, Residuals: 0.013\n",
      "Loss: 145.280, Residuals: 0.013\n",
      "Loss: 145.280, Residuals: 0.013\n",
      "Evidence 439.325\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.562, Residuals: -0.090\n",
      "Loss: 7.258, Residuals: -0.035\n",
      "Loss: 5.203, Residuals: -0.060\n",
      "Loss: 4.403, Residuals: -0.047\n",
      "Loss: 3.964, Residuals: -0.028\n",
      "Loss: 3.886, Residuals: -0.056\n",
      "Loss: 3.738, Residuals: -0.043\n",
      "Loss: 3.482, Residuals: -0.039\n",
      "Loss: 3.398, Residuals: 0.015\n",
      "Loss: 3.265, Residuals: -0.000\n",
      "Loss: 3.104, Residuals: -0.031\n",
      "Loss: 3.095, Residuals: -0.036\n",
      "Loss: 3.086, Residuals: -0.020\n",
      "Loss: 3.070, Residuals: -0.027\n",
      "Loss: 3.042, Residuals: -0.028\n",
      "Loss: 3.036, Residuals: -0.024\n",
      "Loss: 2.984, Residuals: -0.031\n",
      "Loss: 2.980, Residuals: -0.021\n",
      "Loss: 2.941, Residuals: -0.027\n",
      "Loss: 2.925, Residuals: -0.031\n",
      "Loss: 2.925, Residuals: -0.031\n",
      "Loss: 2.906, Residuals: -0.033\n",
      "Loss: 2.905, Residuals: -0.024\n",
      "Loss: 2.850, Residuals: -0.036\n",
      "Loss: 2.849, Residuals: -0.035\n",
      "Loss: 2.849, Residuals: -0.035\n",
      "Loss: 2.842, Residuals: -0.034\n",
      "Loss: 2.792, Residuals: -0.046\n",
      "Loss: 2.788, Residuals: -0.046\n",
      "Loss: 2.787, Residuals: -0.044\n",
      "Loss: 2.784, Residuals: -0.037\n",
      "Loss: 2.780, Residuals: -0.038\n",
      "Loss: 2.772, Residuals: -0.039\n",
      "Loss: 2.768, Residuals: -0.035\n",
      "Loss: 2.735, Residuals: -0.041\n",
      "Loss: 2.735, Residuals: -0.042\n",
      "Loss: 2.732, Residuals: -0.038\n",
      "Loss: 2.713, Residuals: -0.040\n",
      "Loss: 2.708, Residuals: -0.027\n",
      "Loss: 2.700, Residuals: -0.028\n",
      "Loss: 2.700, Residuals: -0.028\n",
      "Evidence -402.997\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.74e-02\n",
      "Loss: 13.339, Residuals: -0.014\n",
      "Loss: 13.333, Residuals: -0.014\n",
      "Loss: 13.321, Residuals: -0.014\n",
      "Loss: 13.300, Residuals: -0.014\n",
      "Loss: 13.267, Residuals: -0.013\n",
      "Loss: 13.203, Residuals: -0.012\n",
      "Loss: 13.087, Residuals: -0.009\n",
      "Loss: 13.052, Residuals: -0.017\n",
      "Loss: 12.988, Residuals: -0.012\n",
      "Loss: 12.889, Residuals: -0.003\n",
      "Loss: 12.888, Residuals: -0.003\n",
      "Loss: 12.861, Residuals: -0.000\n",
      "Loss: 12.816, Residuals: 0.006\n",
      "Loss: 12.810, Residuals: 0.010\n",
      "Loss: 12.808, Residuals: 0.008\n",
      "Loss: 12.785, Residuals: 0.009\n",
      "Loss: 12.783, Residuals: 0.012\n",
      "Loss: 12.722, Residuals: 0.014\n",
      "Loss: 12.721, Residuals: 0.014\n",
      "Loss: 12.721, Residuals: 0.014\n",
      "Loss: 12.698, Residuals: 0.014\n",
      "Loss: 12.675, Residuals: 0.017\n",
      "Loss: 12.675, Residuals: 0.017\n",
      "Evidence 114.901\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.03e-01\n",
      "Loss: 42.901, Residuals: 0.016\n",
      "Loss: 42.880, Residuals: 0.018\n",
      "Loss: 42.839, Residuals: 0.017\n",
      "Loss: 42.763, Residuals: 0.017\n",
      "Loss: 42.633, Residuals: 0.015\n",
      "Loss: 42.486, Residuals: 0.016\n",
      "Loss: 42.485, Residuals: 0.016\n",
      "Loss: 42.367, Residuals: 0.017\n",
      "Loss: 42.357, Residuals: 0.018\n",
      "Loss: 42.259, Residuals: 0.019\n",
      "Loss: 42.258, Residuals: 0.019\n",
      "Loss: 42.037, Residuals: 0.020\n",
      "Loss: 42.026, Residuals: 0.021\n",
      "Loss: 42.025, Residuals: 0.020\n",
      "Loss: 42.024, Residuals: 0.020\n",
      "Loss: 41.978, Residuals: 0.022\n",
      "Loss: 41.898, Residuals: 0.023\n",
      "Loss: 41.897, Residuals: 0.022\n",
      "Loss: 41.887, Residuals: 0.022\n",
      "Loss: 41.806, Residuals: 0.024\n",
      "Loss: 41.805, Residuals: 0.024\n",
      "Loss: 41.801, Residuals: 0.023\n",
      "Loss: 41.796, Residuals: 0.022\n",
      "Loss: 41.742, Residuals: 0.023\n",
      "Loss: 41.742, Residuals: 0.023\n",
      "Loss: 41.736, Residuals: 0.023\n",
      "Loss: 41.394, Residuals: 0.022\n",
      "Loss: 41.381, Residuals: 0.020\n",
      "Loss: 41.360, Residuals: 0.021\n",
      "Loss: 41.332, Residuals: 0.022\n",
      "Loss: 41.295, Residuals: 0.024\n",
      "Loss: 41.292, Residuals: 0.025\n",
      "Loss: 41.291, Residuals: 0.026\n",
      "Loss: 41.282, Residuals: 0.025\n",
      "Loss: 41.269, Residuals: 0.025\n",
      "Loss: 41.269, Residuals: 0.024\n",
      "Loss: 41.266, Residuals: 0.025\n",
      "Loss: 41.266, Residuals: 0.025\n",
      "Loss: 41.261, Residuals: 0.025\n",
      "Loss: 41.254, Residuals: 0.024\n",
      "Loss: 41.254, Residuals: 0.024\n",
      "Loss: 41.254, Residuals: 0.024\n",
      "Loss: 41.253, Residuals: 0.024\n",
      "Loss: 41.251, Residuals: 0.024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 41.251, Residuals: 0.024\n",
      "Loss: 41.250, Residuals: 0.023\n",
      "Loss: 41.250, Residuals: 0.023\n",
      "Loss: 41.250, Residuals: 0.023\n",
      "Loss: 41.249, Residuals: 0.023\n",
      "Loss: 41.249, Residuals: 0.023\n",
      "Evidence 313.631\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.94e-01\n",
      "Loss: 88.124, Residuals: 0.022\n",
      "Loss: 87.686, Residuals: 0.019\n",
      "Loss: 87.240, Residuals: 0.012\n",
      "Loss: 86.959, Residuals: 0.016\n",
      "Loss: 86.895, Residuals: 0.014\n",
      "Loss: 86.860, Residuals: 0.015\n",
      "Loss: 86.795, Residuals: 0.016\n",
      "Loss: 86.694, Residuals: 0.017\n",
      "Loss: 86.687, Residuals: 0.015\n",
      "Loss: 86.628, Residuals: 0.016\n",
      "Loss: 86.539, Residuals: 0.018\n",
      "Loss: 86.536, Residuals: 0.017\n",
      "Loss: 86.533, Residuals: 0.017\n",
      "Loss: 86.527, Residuals: 0.017\n",
      "Loss: 86.514, Residuals: 0.017\n",
      "Loss: 86.493, Residuals: 0.017\n",
      "Loss: 86.491, Residuals: 0.017\n",
      "Loss: 86.473, Residuals: 0.017\n",
      "Loss: 86.466, Residuals: 0.017\n",
      "Loss: 86.465, Residuals: 0.017\n",
      "Loss: 86.456, Residuals: 0.017\n",
      "Loss: 86.447, Residuals: 0.018\n",
      "Loss: 86.447, Residuals: 0.017\n",
      "Loss: 86.387, Residuals: 0.018\n",
      "Loss: 86.368, Residuals: 0.016\n",
      "Loss: 86.362, Residuals: 0.017\n",
      "Loss: 86.350, Residuals: 0.017\n",
      "Loss: 86.328, Residuals: 0.017\n",
      "Loss: 86.290, Residuals: 0.018\n",
      "Loss: 86.218, Residuals: 0.019\n",
      "Loss: 86.161, Residuals: 0.019\n",
      "Loss: 86.070, Residuals: 0.020\n",
      "Loss: 86.020, Residuals: 0.020\n",
      "Loss: 85.926, Residuals: 0.021\n",
      "Loss: 85.895, Residuals: 0.021\n",
      "Loss: 85.662, Residuals: 0.024\n",
      "Loss: 85.653, Residuals: 0.024\n",
      "Loss: 85.638, Residuals: 0.024\n",
      "Loss: 85.612, Residuals: 0.024\n",
      "Loss: 85.570, Residuals: 0.024\n",
      "Loss: 85.555, Residuals: 0.024\n",
      "Loss: 85.527, Residuals: 0.025\n",
      "Loss: 85.479, Residuals: 0.025\n",
      "Loss: 85.474, Residuals: 0.025\n",
      "Loss: 85.427, Residuals: 0.026\n",
      "Loss: 85.422, Residuals: 0.026\n",
      "Loss: 85.381, Residuals: 0.027\n",
      "Loss: 85.381, Residuals: 0.026\n",
      "Loss: 85.355, Residuals: 0.027\n",
      "Loss: 85.353, Residuals: 0.028\n",
      "Loss: 85.351, Residuals: 0.027\n",
      "Loss: 85.327, Residuals: 0.027\n",
      "Loss: 85.326, Residuals: 0.027\n",
      "Loss: 85.304, Residuals: 0.027\n",
      "Loss: 85.303, Residuals: 0.027\n",
      "Loss: 85.265, Residuals: 0.027\n",
      "Loss: 85.263, Residuals: 0.028\n",
      "Loss: 85.246, Residuals: 0.028\n",
      "Loss: 85.214, Residuals: 0.028\n",
      "Loss: 85.191, Residuals: 0.028\n",
      "Loss: 85.186, Residuals: 0.029\n",
      "Loss: 85.184, Residuals: 0.028\n",
      "Loss: 85.181, Residuals: 0.028\n",
      "Loss: 85.176, Residuals: 0.028\n",
      "Loss: 85.175, Residuals: 0.028\n",
      "Loss: 85.174, Residuals: 0.028\n",
      "Loss: 85.174, Residuals: 0.029\n",
      "Loss: 85.173, Residuals: 0.029\n",
      "Loss: 85.172, Residuals: 0.029\n",
      "Loss: 85.172, Residuals: 0.029\n",
      "Loss: 85.172, Residuals: 0.029\n",
      "Loss: 85.172, Residuals: 0.029\n",
      "Loss: 85.172, Residuals: 0.029\n",
      "Loss: 85.172, Residuals: 0.029\n",
      "Loss: 85.172, Residuals: 0.029\n",
      "Loss: 85.172, Residuals: 0.029\n",
      "Evidence 426.485\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.73e-01\n",
      "Loss: 123.389, Residuals: 0.041\n",
      "Loss: 122.910, Residuals: 0.036\n",
      "Loss: 122.532, Residuals: 0.029\n",
      "Loss: 122.315, Residuals: 0.027\n",
      "Loss: 122.263, Residuals: 0.027\n",
      "Loss: 122.168, Residuals: 0.027\n",
      "Loss: 122.035, Residuals: 0.028\n",
      "Loss: 122.032, Residuals: 0.028\n",
      "Loss: 122.025, Residuals: 0.028\n",
      "Loss: 121.980, Residuals: 0.028\n",
      "Loss: 121.976, Residuals: 0.027\n",
      "Loss: 121.970, Residuals: 0.028\n",
      "Loss: 121.961, Residuals: 0.028\n",
      "Loss: 121.959, Residuals: 0.028\n",
      "Loss: 121.955, Residuals: 0.028\n",
      "Loss: 121.955, Residuals: 0.028\n",
      "Loss: 121.950, Residuals: 0.028\n",
      "Loss: 121.950, Residuals: 0.028\n",
      "Loss: 121.948, Residuals: 0.027\n",
      "Loss: 121.948, Residuals: 0.027\n",
      "Loss: 121.948, Residuals: 0.027\n",
      "Loss: 121.947, Residuals: 0.027\n",
      "Loss: 121.946, Residuals: 0.027\n",
      "Loss: 121.946, Residuals: 0.027\n",
      "Loss: 121.946, Residuals: 0.027\n",
      "Loss: 121.946, Residuals: 0.027\n",
      "Evidence 475.803\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.40e-01\n",
      "Loss: 143.831, Residuals: 0.027\n",
      "Loss: 143.628, Residuals: 0.023\n",
      "Loss: 143.487, Residuals: 0.025\n",
      "Loss: 143.353, Residuals: 0.026\n",
      "Loss: 143.344, Residuals: 0.025\n",
      "Loss: 143.328, Residuals: 0.025\n",
      "Loss: 143.306, Residuals: 0.025\n",
      "Loss: 143.305, Residuals: 0.026\n",
      "Loss: 143.297, Residuals: 0.026\n",
      "Loss: 143.297, Residuals: 0.026\n",
      "Loss: 143.292, Residuals: 0.026\n",
      "Loss: 143.288, Residuals: 0.026\n",
      "Loss: 143.288, Residuals: 0.026\n",
      "Loss: 143.288, Residuals: 0.026\n",
      "Loss: 143.288, Residuals: 0.026\n",
      "Loss: 143.288, Residuals: 0.026\n",
      "Loss: 143.287, Residuals: 0.026\n",
      "Loss: 143.286, Residuals: 0.025\n",
      "Loss: 143.286, Residuals: 0.026\n",
      "Evidence 488.228\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.41e-01\n",
      "Loss: 151.856, Residuals: 0.024\n",
      "Loss: 151.766, Residuals: 0.023\n",
      "Loss: 151.681, Residuals: 0.025\n",
      "Loss: 151.627, Residuals: 0.024\n",
      "Loss: 151.616, Residuals: 0.024\n",
      "Loss: 151.598, Residuals: 0.024\n",
      "Loss: 151.597, Residuals: 0.024\n",
      "Loss: 151.588, Residuals: 0.024\n",
      "Loss: 151.587, Residuals: 0.024\n",
      "Loss: 151.586, Residuals: 0.024\n",
      "Loss: 151.585, Residuals: 0.024\n",
      "Loss: 151.584, Residuals: 0.024\n",
      "Loss: 151.583, Residuals: 0.024\n",
      "Loss: 151.581, Residuals: 0.024\n",
      "Evidence 491.655\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.41e-01\n",
      "Loss: 154.608, Residuals: 0.024\n",
      "Loss: 154.587, Residuals: 0.022\n",
      "Loss: 154.553, Residuals: 0.022\n",
      "Loss: 154.518, Residuals: 0.023\n",
      "Loss: 154.485, Residuals: 0.022\n",
      "Loss: 154.483, Residuals: 0.023\n",
      "Loss: 154.480, Residuals: 0.023\n",
      "Loss: 154.480, Residuals: 0.023\n",
      "Loss: 154.479, Residuals: 0.023\n",
      "Loss: 154.477, Residuals: 0.023\n",
      "Loss: 154.475, Residuals: 0.023\n",
      "Loss: 154.475, Residuals: 0.023\n",
      "Loss: 154.475, Residuals: 0.023\n",
      "Loss: 154.474, Residuals: 0.023\n",
      "Loss: 154.473, Residuals: 0.023\n",
      "Loss: 154.473, Residuals: 0.023\n",
      "Loss: 154.473, Residuals: 0.023\n",
      "Evidence 493.133\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.29e-01\n",
      "Loss: 155.611, Residuals: 0.022\n",
      "Loss: 155.593, Residuals: 0.021\n",
      "Loss: 155.565, Residuals: 0.021\n",
      "Loss: 155.537, Residuals: 0.022\n",
      "Loss: 155.536, Residuals: 0.022\n",
      "Loss: 155.535, Residuals: 0.021\n",
      "Loss: 155.534, Residuals: 0.021\n",
      "Loss: 155.531, Residuals: 0.021\n",
      "Loss: 155.529, Residuals: 0.021\n",
      "Loss: 155.529, Residuals: 0.021\n",
      "Evidence 494.044\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.30e-01\n",
      "Loss: 156.041, Residuals: 0.021\n",
      "Loss: 156.029, Residuals: 0.020\n",
      "Loss: 156.009, Residuals: 0.020\n",
      "Loss: 155.990, Residuals: 0.020\n",
      "Loss: 155.989, Residuals: 0.020\n",
      "Loss: 155.983, Residuals: 0.020\n",
      "Loss: 155.980, Residuals: 0.020\n",
      "Loss: 155.980, Residuals: 0.020\n",
      "Loss: 155.980, Residuals: 0.020\n",
      "Loss: 155.979, Residuals: 0.020\n",
      "Loss: 155.979, Residuals: 0.020\n",
      "Loss: 155.978, Residuals: 0.020\n",
      "Loss: 155.978, Residuals: 0.020\n",
      "Loss: 155.978, Residuals: 0.020\n",
      "Loss: 155.978, Residuals: 0.020\n",
      "Loss: 155.978, Residuals: 0.020\n",
      "Loss: 155.978, Residuals: 0.020\n",
      "Loss: 155.978, Residuals: 0.020\n",
      "Loss: 155.978, Residuals: 0.020\n",
      "Loss: 155.978, Residuals: 0.020\n",
      "Loss: 155.978, Residuals: 0.020\n",
      "Evidence 494.794\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.15e-01\n",
      "Loss: 156.235, Residuals: 0.020\n",
      "Loss: 156.209, Residuals: 0.019\n",
      "Loss: 156.203, Residuals: 0.019\n",
      "Loss: 156.194, Residuals: 0.019\n",
      "Loss: 156.187, Residuals: 0.018\n",
      "Loss: 156.187, Residuals: 0.019\n",
      "Loss: 156.187, Residuals: 0.018\n",
      "Loss: 156.186, Residuals: 0.018\n",
      "Loss: 156.186, Residuals: 0.018\n",
      "Loss: 156.186, Residuals: 0.018\n",
      "Loss: 156.185, Residuals: 0.018\n",
      "Loss: 156.185, Residuals: 0.018\n",
      "Evidence 495.411\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.06e-01\n",
      "Loss: 156.344, Residuals: 0.018\n",
      "Loss: 156.321, Residuals: 0.017\n",
      "Loss: 156.317, Residuals: 0.018\n",
      "Loss: 156.315, Residuals: 0.017\n",
      "Loss: 156.313, Residuals: 0.017\n",
      "Loss: 156.308, Residuals: 0.017\n",
      "Loss: 156.306, Residuals: 0.017\n",
      "Loss: 156.306, Residuals: 0.017\n",
      "Loss: 156.305, Residuals: 0.017\n",
      "Evidence 495.921\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.04e-01\n",
      "Loss: 156.423, Residuals: 0.017\n",
      "Loss: 156.404, Residuals: 0.016\n",
      "Loss: 156.400, Residuals: 0.017\n",
      "Loss: 156.395, Residuals: 0.017\n",
      "Loss: 156.392, Residuals: 0.016\n",
      "Loss: 156.392, Residuals: 0.016\n",
      "Loss: 156.391, Residuals: 0.016\n",
      "Loss: 156.391, Residuals: 0.016\n",
      "Loss: 156.391, Residuals: 0.016\n",
      "Loss: 156.390, Residuals: 0.016\n",
      "Evidence 496.360\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.209, Residuals: -0.045\n",
      "Loss: 6.894, Residuals: -0.026\n",
      "Loss: 4.833, Residuals: -0.052\n",
      "Loss: 4.106, Residuals: -0.057\n",
      "Loss: 3.713, Residuals: -0.064\n",
      "Loss: 3.604, Residuals: -0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.570, Residuals: -0.011\n",
      "Loss: 3.297, Residuals: -0.020\n",
      "Loss: 3.154, Residuals: 0.000\n",
      "Loss: 3.137, Residuals: -0.008\n",
      "Loss: 3.001, Residuals: -0.020\n",
      "Loss: 2.991, Residuals: -0.003\n",
      "Loss: 2.912, Residuals: -0.005\n",
      "Loss: 2.787, Residuals: -0.018\n",
      "Loss: 2.763, Residuals: 0.005\n",
      "Loss: 2.746, Residuals: -0.005\n",
      "Loss: 2.618, Residuals: -0.015\n",
      "Loss: 2.612, Residuals: -0.007\n",
      "Loss: 2.601, Residuals: -0.006\n",
      "Loss: 2.509, Residuals: -0.021\n",
      "Loss: 2.487, Residuals: -0.009\n",
      "Loss: 2.446, Residuals: -0.018\n",
      "Loss: 2.444, Residuals: -0.013\n",
      "Loss: 2.430, Residuals: -0.013\n",
      "Loss: 2.402, Residuals: -0.019\n",
      "Loss: 2.399, Residuals: -0.013\n",
      "Loss: 2.365, Residuals: -0.020\n",
      "Loss: 2.365, Residuals: -0.017\n",
      "Loss: 2.351, Residuals: -0.018\n",
      "Loss: 2.350, Residuals: -0.018\n",
      "Loss: 2.330, Residuals: -0.022\n",
      "Loss: 2.325, Residuals: -0.017\n",
      "Loss: 2.283, Residuals: -0.027\n",
      "Loss: 2.282, Residuals: -0.026\n",
      "Loss: 2.280, Residuals: -0.025\n",
      "Loss: 2.269, Residuals: -0.028\n",
      "Loss: 2.259, Residuals: -0.026\n",
      "Loss: 2.259, Residuals: -0.026\n",
      "Loss: 2.258, Residuals: -0.026\n",
      "Loss: 2.257, Residuals: -0.027\n",
      "Loss: 2.246, Residuals: -0.030\n",
      "Loss: 2.244, Residuals: -0.032\n",
      "Loss: 2.226, Residuals: -0.037\n",
      "Loss: 2.226, Residuals: -0.036\n",
      "Loss: 2.214, Residuals: -0.039\n",
      "Loss: 2.194, Residuals: -0.045\n",
      "Loss: 2.194, Residuals: -0.044\n",
      "Loss: 2.193, Residuals: -0.044\n",
      "Loss: 2.192, Residuals: -0.044\n",
      "Loss: 2.184, Residuals: -0.047\n",
      "Loss: 2.182, Residuals: -0.046\n",
      "Loss: 2.182, Residuals: -0.044\n",
      "Loss: 2.175, Residuals: -0.046\n",
      "Loss: 2.169, Residuals: -0.048\n",
      "Loss: 2.169, Residuals: -0.049\n",
      "Loss: 2.168, Residuals: -0.048\n",
      "Loss: 2.167, Residuals: -0.048\n",
      "Loss: 2.165, Residuals: -0.048\n",
      "Loss: 2.164, Residuals: -0.046\n",
      "Loss: 2.164, Residuals: -0.046\n",
      "Loss: 2.156, Residuals: -0.049\n",
      "Loss: 2.156, Residuals: -0.049\n",
      "Loss: 2.146, Residuals: -0.054\n",
      "Loss: 2.145, Residuals: -0.054\n",
      "Loss: 2.143, Residuals: -0.055\n",
      "Loss: 2.142, Residuals: -0.056\n",
      "Loss: 2.142, Residuals: -0.056\n",
      "Loss: 2.137, Residuals: -0.058\n",
      "Loss: 2.134, Residuals: -0.059\n",
      "Loss: 2.134, Residuals: -0.061\n",
      "Loss: 2.129, Residuals: -0.062\n",
      "Loss: 2.128, Residuals: -0.062\n",
      "Loss: 2.124, Residuals: -0.064\n",
      "Loss: 2.123, Residuals: -0.064\n",
      "Loss: 2.116, Residuals: -0.067\n",
      "Loss: 2.116, Residuals: -0.067\n",
      "Loss: 2.114, Residuals: -0.067\n",
      "Loss: 2.114, Residuals: -0.066\n",
      "Loss: 2.109, Residuals: -0.068\n",
      "Loss: 2.100, Residuals: -0.073\n",
      "Loss: 2.100, Residuals: -0.072\n",
      "Loss: 2.099, Residuals: -0.073\n",
      "Loss: 2.098, Residuals: -0.072\n",
      "Loss: 2.098, Residuals: -0.072\n",
      "Loss: 2.096, Residuals: -0.073\n",
      "Loss: 2.094, Residuals: -0.073\n",
      "Loss: 2.094, Residuals: -0.073\n",
      "Loss: 2.091, Residuals: -0.073\n",
      "Loss: 2.091, Residuals: -0.074\n",
      "Loss: 2.091, Residuals: -0.073\n",
      "Loss: 2.091, Residuals: -0.073\n",
      "Loss: 2.079, Residuals: -0.077\n",
      "Loss: 2.079, Residuals: -0.077\n",
      "Loss: 2.079, Residuals: -0.078\n",
      "Loss: 2.073, Residuals: -0.080\n",
      "Loss: 2.068, Residuals: -0.081\n",
      "Loss: 2.068, Residuals: -0.082\n",
      "Loss: 2.067, Residuals: -0.080\n",
      "Loss: 2.066, Residuals: -0.080\n",
      "Loss: 2.065, Residuals: -0.081\n",
      "Loss: 2.065, Residuals: -0.081\n",
      "Loss: 2.064, Residuals: -0.081\n",
      "Loss: 2.064, Residuals: -0.080\n",
      "Loss: 2.064, Residuals: -0.080\n",
      "Loss: 2.060, Residuals: -0.082\n",
      "Loss: 2.060, Residuals: -0.083\n",
      "Loss: 2.056, Residuals: -0.085\n",
      "Loss: 2.056, Residuals: -0.084\n",
      "Loss: 2.052, Residuals: -0.087\n",
      "Loss: 2.052, Residuals: -0.087\n",
      "Loss: 2.051, Residuals: -0.087\n",
      "Loss: 2.050, Residuals: -0.089\n",
      "Loss: 2.049, Residuals: -0.088\n",
      "Loss: 2.046, Residuals: -0.089\n",
      "Loss: 2.046, Residuals: -0.089\n",
      "Loss: 2.042, Residuals: -0.093\n",
      "Loss: 2.041, Residuals: -0.093\n",
      "Loss: 2.041, Residuals: -0.092\n",
      "Loss: 2.041, Residuals: -0.092\n",
      "Loss: 2.040, Residuals: -0.092\n",
      "Loss: 2.040, Residuals: -0.092\n",
      "Evidence -383.243\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.17e-03\n",
      "Loss: 10.631, Residuals: -0.068\n",
      "Loss: 10.617, Residuals: -0.070\n",
      "Loss: 10.593, Residuals: -0.069\n",
      "Loss: 10.549, Residuals: -0.072\n",
      "Loss: 10.485, Residuals: -0.076\n",
      "Loss: 10.372, Residuals: -0.072\n",
      "Loss: 10.226, Residuals: -0.062\n",
      "Loss: 10.215, Residuals: -0.062\n",
      "Loss: 10.195, Residuals: -0.061\n",
      "Loss: 10.159, Residuals: -0.058\n",
      "Loss: 10.114, Residuals: -0.050\n",
      "Loss: 10.112, Residuals: -0.050\n",
      "Loss: 10.109, Residuals: -0.050\n",
      "Loss: 10.081, Residuals: -0.048\n",
      "Loss: 10.081, Residuals: -0.048\n",
      "Loss: 10.043, Residuals: -0.044\n",
      "Loss: 10.042, Residuals: -0.045\n",
      "Loss: 10.041, Residuals: -0.045\n",
      "Loss: 10.039, Residuals: -0.044\n",
      "Loss: 10.020, Residuals: -0.042\n",
      "Loss: 10.019, Residuals: -0.042\n",
      "Loss: 10.003, Residuals: -0.040\n",
      "Loss: 10.002, Residuals: -0.040\n",
      "Loss: 9.999, Residuals: -0.039\n",
      "Loss: 9.975, Residuals: -0.035\n",
      "Loss: 9.975, Residuals: -0.035\n",
      "Loss: 9.974, Residuals: -0.035\n",
      "Loss: 9.974, Residuals: -0.035\n",
      "Loss: 9.972, Residuals: -0.035\n",
      "Loss: 9.972, Residuals: -0.036\n",
      "Loss: 9.962, Residuals: -0.034\n",
      "Loss: 9.962, Residuals: -0.034\n",
      "Loss: 9.962, Residuals: -0.034\n",
      "Loss: 9.961, Residuals: -0.034\n",
      "Loss: 9.961, Residuals: -0.033\n",
      "Loss: 9.937, Residuals: -0.029\n",
      "Loss: 9.936, Residuals: -0.028\n",
      "Loss: 9.936, Residuals: -0.031\n",
      "Loss: 9.936, Residuals: -0.029\n",
      "Loss: 9.933, Residuals: -0.029\n",
      "Loss: 9.932, Residuals: -0.029\n",
      "Loss: 9.930, Residuals: -0.028\n",
      "Loss: 9.930, Residuals: -0.028\n",
      "Loss: 9.927, Residuals: -0.027\n",
      "Loss: 9.927, Residuals: -0.027\n",
      "Loss: 9.925, Residuals: -0.026\n",
      "Loss: 9.924, Residuals: -0.026\n",
      "Loss: 9.922, Residuals: -0.025\n",
      "Loss: 9.922, Residuals: -0.025\n",
      "Loss: 9.922, Residuals: -0.025\n",
      "Loss: 9.921, Residuals: -0.025\n",
      "Loss: 9.920, Residuals: -0.024\n",
      "Loss: 9.920, Residuals: -0.024\n",
      "Loss: 9.918, Residuals: -0.023\n",
      "Loss: 9.918, Residuals: -0.023\n",
      "Loss: 9.917, Residuals: -0.023\n",
      "Loss: 9.916, Residuals: -0.022\n",
      "Loss: 9.916, Residuals: -0.022\n",
      "Loss: 9.916, Residuals: -0.022\n",
      "Loss: 9.916, Residuals: -0.022\n",
      "Loss: 9.915, Residuals: -0.021\n",
      "Loss: 9.915, Residuals: -0.021\n",
      "Loss: 9.915, Residuals: -0.021\n",
      "Loss: 9.914, Residuals: -0.021\n",
      "Loss: 9.914, Residuals: -0.021\n",
      "Loss: 9.914, Residuals: -0.021\n",
      "Loss: 9.914, Residuals: -0.021\n",
      "Loss: 9.914, Residuals: -0.020\n",
      "Loss: 9.914, Residuals: -0.020\n",
      "Loss: 9.913, Residuals: -0.020\n",
      "Loss: 9.913, Residuals: -0.020\n",
      "Loss: 9.913, Residuals: -0.020\n",
      "Loss: 9.912, Residuals: -0.020\n",
      "Loss: 9.912, Residuals: -0.020\n",
      "Loss: 9.912, Residuals: -0.020\n",
      "Loss: 9.912, Residuals: -0.020\n",
      "Loss: 9.912, Residuals: -0.020\n",
      "Loss: 9.912, Residuals: -0.020\n",
      "Loss: 9.912, Residuals: -0.020\n",
      "Loss: 9.912, Residuals: -0.020\n",
      "Loss: 9.912, Residuals: -0.020\n",
      "Evidence 102.988\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.04e-03\n",
      "Loss: 36.746, Residuals: -0.020\n",
      "Loss: 36.585, Residuals: -0.020\n",
      "Loss: 36.317, Residuals: -0.015\n",
      "Loss: 36.057, Residuals: -0.003\n",
      "Loss: 36.052, Residuals: -0.003\n",
      "Loss: 36.044, Residuals: -0.005\n",
      "Loss: 36.029, Residuals: -0.006\n",
      "Loss: 36.008, Residuals: -0.008\n",
      "Loss: 35.828, Residuals: -0.005\n",
      "Loss: 35.762, Residuals: -0.001\n",
      "Loss: 35.757, Residuals: -0.005\n",
      "Loss: 35.749, Residuals: -0.005\n",
      "Loss: 35.673, Residuals: -0.003\n",
      "Loss: 35.542, Residuals: 0.000\n",
      "Loss: 35.538, Residuals: 0.000\n",
      "Loss: 35.531, Residuals: -0.000\n",
      "Loss: 35.467, Residuals: 0.001\n",
      "Loss: 35.357, Residuals: 0.004\n",
      "Loss: 35.347, Residuals: 0.003\n",
      "Loss: 35.262, Residuals: 0.005\n",
      "Loss: 35.257, Residuals: 0.005\n",
      "Loss: 35.256, Residuals: 0.004\n",
      "Loss: 35.210, Residuals: 0.007\n",
      "Loss: 35.209, Residuals: 0.007\n",
      "Loss: 35.209, Residuals: 0.007\n",
      "Loss: 35.191, Residuals: 0.008\n",
      "Loss: 35.191, Residuals: 0.008\n",
      "Loss: 35.184, Residuals: 0.009\n",
      "Loss: 35.183, Residuals: 0.008\n",
      "Loss: 35.170, Residuals: 0.010\n",
      "Loss: 35.170, Residuals: 0.010\n",
      "Loss: 35.157, Residuals: 0.011\n",
      "Loss: 35.157, Residuals: 0.011\n",
      "Loss: 35.155, Residuals: 0.011\n",
      "Loss: 35.144, Residuals: 0.012\n",
      "Loss: 35.144, Residuals: 0.012\n",
      "Evidence 310.243\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.67e-02\n",
      "Loss: 82.193, Residuals: -0.002\n",
      "Loss: 82.184, Residuals: -0.002\n",
      "Loss: 81.884, Residuals: -0.002\n",
      "Loss: 81.534, Residuals: 0.000\n",
      "Loss: 81.529, Residuals: -0.000\n",
      "Loss: 81.361, Residuals: 0.002\n",
      "Loss: 81.104, Residuals: 0.005\n",
      "Loss: 80.730, Residuals: 0.011\n",
      "Loss: 80.695, Residuals: 0.010\n",
      "Loss: 80.631, Residuals: 0.011\n",
      "Loss: 80.507, Residuals: 0.012\n",
      "Loss: 80.499, Residuals: 0.012\n",
      "Loss: 80.255, Residuals: 0.015\n",
      "Loss: 80.246, Residuals: 0.015\n",
      "Loss: 80.232, Residuals: 0.015\n",
      "Loss: 80.213, Residuals: 0.016\n",
      "Loss: 80.200, Residuals: 0.016\n",
      "Loss: 80.180, Residuals: 0.016\n",
      "Loss: 80.151, Residuals: 0.017\n",
      "Loss: 80.150, Residuals: 0.017\n",
      "Loss: 80.138, Residuals: 0.017\n",
      "Loss: 80.135, Residuals: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 80.115, Residuals: 0.017\n",
      "Loss: 80.115, Residuals: 0.018\n",
      "Loss: 80.111, Residuals: 0.017\n",
      "Loss: 80.105, Residuals: 0.017\n",
      "Loss: 80.104, Residuals: 0.017\n",
      "Loss: 80.065, Residuals: 0.017\n",
      "Loss: 80.065, Residuals: 0.017\n",
      "Evidence 421.335\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.81e-02\n",
      "Loss: 121.601, Residuals: 0.007\n",
      "Loss: 121.473, Residuals: 0.015\n",
      "Loss: 121.259, Residuals: 0.012\n",
      "Loss: 121.053, Residuals: 0.011\n",
      "Loss: 121.035, Residuals: 0.009\n",
      "Loss: 120.889, Residuals: 0.010\n",
      "Loss: 120.883, Residuals: 0.012\n",
      "Loss: 120.823, Residuals: 0.011\n",
      "Loss: 120.728, Residuals: 0.011\n",
      "Loss: 120.725, Residuals: 0.012\n",
      "Loss: 120.693, Residuals: 0.012\n",
      "Loss: 120.639, Residuals: 0.012\n",
      "Loss: 120.615, Residuals: 0.011\n",
      "Loss: 120.606, Residuals: 0.012\n",
      "Loss: 120.603, Residuals: 0.012\n",
      "Loss: 120.602, Residuals: 0.012\n",
      "Loss: 120.592, Residuals: 0.012\n",
      "Loss: 120.578, Residuals: 0.012\n",
      "Loss: 120.577, Residuals: 0.012\n",
      "Loss: 120.577, Residuals: 0.012\n",
      "Loss: 120.281, Residuals: 0.013\n",
      "Loss: 120.251, Residuals: 0.014\n",
      "Loss: 120.247, Residuals: 0.014\n",
      "Loss: 120.241, Residuals: 0.014\n",
      "Loss: 120.235, Residuals: 0.013\n",
      "Loss: 120.235, Residuals: 0.012\n",
      "Loss: 120.233, Residuals: 0.013\n",
      "Loss: 120.231, Residuals: 0.013\n",
      "Loss: 120.228, Residuals: 0.013\n",
      "Loss: 120.227, Residuals: 0.013\n",
      "Loss: 120.223, Residuals: 0.013\n",
      "Loss: 120.116, Residuals: 0.013\n",
      "Loss: 120.113, Residuals: 0.014\n",
      "Loss: 120.112, Residuals: 0.014\n",
      "Loss: 120.112, Residuals: 0.014\n",
      "Loss: 120.111, Residuals: 0.013\n",
      "Loss: 120.110, Residuals: 0.014\n",
      "Loss: 120.110, Residuals: 0.013\n",
      "Loss: 120.108, Residuals: 0.013\n",
      "Loss: 120.106, Residuals: 0.013\n",
      "Loss: 120.106, Residuals: 0.013\n",
      "Loss: 120.106, Residuals: 0.013\n",
      "Evidence 458.719\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 5.73e-02\n",
      "Loss: 140.494, Residuals: 0.013\n",
      "Loss: 140.453, Residuals: 0.009\n",
      "Loss: 140.435, Residuals: 0.013\n",
      "Loss: 140.425, Residuals: 0.011\n",
      "Loss: 140.417, Residuals: 0.013\n",
      "Loss: 140.348, Residuals: 0.013\n",
      "Loss: 140.240, Residuals: 0.012\n",
      "Loss: 140.225, Residuals: 0.013\n",
      "Loss: 140.223, Residuals: 0.013\n",
      "Loss: 140.221, Residuals: 0.012\n",
      "Loss: 140.207, Residuals: 0.012\n",
      "Loss: 140.183, Residuals: 0.012\n",
      "Loss: 140.151, Residuals: 0.013\n",
      "Loss: 140.150, Residuals: 0.013\n",
      "Loss: 140.123, Residuals: 0.013\n",
      "Loss: 140.123, Residuals: 0.012\n",
      "Loss: 140.123, Residuals: 0.013\n",
      "Loss: 140.123, Residuals: 0.013\n",
      "Loss: 140.108, Residuals: 0.013\n",
      "Loss: 140.107, Residuals: 0.013\n",
      "Loss: 140.107, Residuals: 0.013\n",
      "Loss: 139.949, Residuals: 0.014\n",
      "Loss: 139.943, Residuals: 0.014\n",
      "Loss: 139.943, Residuals: 0.014\n",
      "Evidence 467.309\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.18e-02\n",
      "Loss: 147.444, Residuals: 0.015\n",
      "Loss: 147.396, Residuals: 0.016\n",
      "Loss: 147.390, Residuals: 0.015\n",
      "Loss: 147.387, Residuals: 0.015\n",
      "Loss: 147.354, Residuals: 0.015\n",
      "Loss: 147.310, Residuals: 0.015\n",
      "Loss: 147.307, Residuals: 0.015\n",
      "Loss: 147.301, Residuals: 0.015\n",
      "Loss: 147.291, Residuals: 0.015\n",
      "Loss: 147.290, Residuals: 0.015\n",
      "Loss: 147.282, Residuals: 0.015\n",
      "Loss: 147.266, Residuals: 0.015\n",
      "Loss: 147.266, Residuals: 0.015\n",
      "Loss: 147.265, Residuals: 0.015\n",
      "Loss: 147.252, Residuals: 0.015\n",
      "Loss: 147.252, Residuals: 0.015\n",
      "Loss: 147.250, Residuals: 0.015\n",
      "Loss: 147.189, Residuals: 0.015\n",
      "Loss: 147.189, Residuals: 0.015\n",
      "Evidence 469.503\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.85e-02\n",
      "Loss: 149.930, Residuals: 0.016\n",
      "Loss: 149.904, Residuals: 0.017\n",
      "Loss: 149.902, Residuals: 0.017\n",
      "Loss: 149.897, Residuals: 0.017\n",
      "Loss: 149.865, Residuals: 0.017\n",
      "Loss: 149.848, Residuals: 0.017\n",
      "Loss: 149.846, Residuals: 0.016\n",
      "Loss: 149.831, Residuals: 0.016\n",
      "Loss: 149.831, Residuals: 0.016\n",
      "Evidence 470.387\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 7.95e-02\n",
      "Loss: 150.878, Residuals: 0.017\n",
      "Loss: 150.873, Residuals: 0.018\n",
      "Loss: 150.872, Residuals: 0.017\n",
      "Loss: 150.871, Residuals: 0.017\n",
      "Loss: 150.864, Residuals: 0.017\n",
      "Loss: 150.853, Residuals: 0.017\n",
      "Loss: 150.839, Residuals: 0.017\n",
      "Loss: 150.838, Residuals: 0.017\n",
      "Loss: 150.830, Residuals: 0.017\n",
      "Loss: 150.830, Residuals: 0.017\n",
      "Loss: 150.736, Residuals: 0.018\n",
      "Loss: 150.735, Residuals: 0.018\n",
      "Evidence 470.860\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.71e-02\n",
      "Loss: 151.317, Residuals: 0.018\n",
      "Loss: 151.311, Residuals: 0.018\n",
      "Loss: 151.310, Residuals: 0.019\n",
      "Loss: 151.309, Residuals: 0.018\n",
      "Loss: 151.301, Residuals: 0.018\n",
      "Loss: 151.288, Residuals: 0.018\n",
      "Loss: 151.279, Residuals: 0.018\n",
      "Loss: 151.279, Residuals: 0.018\n",
      "Loss: 151.278, Residuals: 0.018\n",
      "Loss: 151.167, Residuals: 0.019\n",
      "Loss: 151.165, Residuals: 0.019\n",
      "Evidence 471.292\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.496, Residuals: -0.091\n",
      "Loss: 6.945, Residuals: -0.044\n",
      "Loss: 4.604, Residuals: -0.051\n",
      "Loss: 3.728, Residuals: 0.008\n",
      "Loss: 3.290, Residuals: -0.009\n",
      "Loss: 2.982, Residuals: -0.023\n",
      "Loss: 2.887, Residuals: -0.007\n",
      "Loss: 2.718, Residuals: -0.015\n",
      "Loss: 2.479, Residuals: -0.024\n",
      "Loss: 2.469, Residuals: 0.002\n",
      "Loss: 2.450, Residuals: -0.003\n",
      "Loss: 2.414, Residuals: -0.012\n",
      "Loss: 2.355, Residuals: -0.029\n",
      "Loss: 2.350, Residuals: -0.018\n",
      "Loss: 2.302, Residuals: -0.035\n",
      "Loss: 2.301, Residuals: -0.034\n",
      "Loss: 2.296, Residuals: -0.034\n",
      "Loss: 2.285, Residuals: -0.037\n",
      "Loss: 2.265, Residuals: -0.043\n",
      "Loss: 2.253, Residuals: -0.041\n",
      "Loss: 2.234, Residuals: -0.047\n",
      "Loss: 2.229, Residuals: -0.045\n",
      "Loss: 2.228, Residuals: -0.041\n",
      "Loss: 2.218, Residuals: -0.046\n",
      "Loss: 2.202, Residuals: -0.056\n",
      "Loss: 2.198, Residuals: -0.057\n",
      "Loss: 2.197, Residuals: -0.054\n",
      "Loss: 2.187, Residuals: -0.060\n",
      "Loss: 2.175, Residuals: -0.070\n",
      "Loss: 2.174, Residuals: -0.073\n",
      "Loss: 2.172, Residuals: -0.070\n",
      "Loss: 2.171, Residuals: -0.067\n",
      "Loss: 2.167, Residuals: -0.069\n",
      "Loss: 2.161, Residuals: -0.073\n",
      "Loss: 2.160, Residuals: -0.071\n",
      "Loss: 2.157, Residuals: -0.073\n",
      "Loss: 2.157, Residuals: -0.073\n",
      "Loss: 2.152, Residuals: -0.077\n",
      "Loss: 2.150, Residuals: -0.077\n",
      "Loss: 2.150, Residuals: -0.077\n",
      "Loss: 2.146, Residuals: -0.080\n",
      "Loss: 2.146, Residuals: -0.079\n",
      "Loss: 2.144, Residuals: -0.080\n",
      "Loss: 2.144, Residuals: -0.080\n",
      "Loss: 2.135, Residuals: -0.087\n",
      "Loss: 2.135, Residuals: -0.087\n",
      "Loss: 2.133, Residuals: -0.087\n",
      "Loss: 2.131, Residuals: -0.085\n",
      "Loss: 2.131, Residuals: -0.084\n",
      "Loss: 2.107, Residuals: -0.090\n",
      "Loss: 2.104, Residuals: -0.091\n",
      "Loss: 2.100, Residuals: -0.089\n",
      "Loss: 2.093, Residuals: -0.085\n",
      "Loss: 2.080, Residuals: -0.078\n",
      "Loss: 2.080, Residuals: -0.079\n",
      "Loss: 2.079, Residuals: -0.078\n",
      "Loss: 2.077, Residuals: -0.074\n",
      "Loss: 2.074, Residuals: -0.074\n",
      "Loss: 2.069, Residuals: -0.075\n",
      "Loss: 2.061, Residuals: -0.073\n",
      "Loss: 2.061, Residuals: -0.074\n",
      "Loss: 2.060, Residuals: -0.073\n",
      "Loss: 2.046, Residuals: -0.079\n",
      "Loss: 2.041, Residuals: -0.074\n",
      "Loss: 2.041, Residuals: -0.074\n",
      "Loss: 2.041, Residuals: -0.074\n",
      "Loss: 2.040, Residuals: -0.075\n",
      "Loss: 2.033, Residuals: -0.077\n",
      "Loss: 2.033, Residuals: -0.076\n",
      "Loss: 2.026, Residuals: -0.078\n",
      "Loss: 2.015, Residuals: -0.085\n",
      "Loss: 2.015, Residuals: -0.083\n",
      "Loss: 2.014, Residuals: -0.083\n",
      "Loss: 2.013, Residuals: -0.086\n",
      "Loss: 2.013, Residuals: -0.086\n",
      "Loss: 2.008, Residuals: -0.088\n",
      "Loss: 1.999, Residuals: -0.093\n",
      "Loss: 1.999, Residuals: -0.092\n",
      "Loss: 1.998, Residuals: -0.092\n",
      "Loss: 1.998, Residuals: -0.091\n",
      "Loss: 1.994, Residuals: -0.093\n",
      "Loss: 1.994, Residuals: -0.093\n",
      "Loss: 1.993, Residuals: -0.093\n",
      "Loss: 1.992, Residuals: -0.093\n",
      "Loss: 1.992, Residuals: -0.093\n",
      "Loss: 1.988, Residuals: -0.095\n",
      "Loss: 1.988, Residuals: -0.095\n",
      "Loss: 1.987, Residuals: -0.095\n",
      "Loss: 1.987, Residuals: -0.096\n",
      "Loss: 1.986, Residuals: -0.096\n",
      "Loss: 1.986, Residuals: -0.095\n",
      "Loss: 1.983, Residuals: -0.097\n",
      "Loss: 1.982, Residuals: -0.097\n",
      "Loss: 1.981, Residuals: -0.098\n",
      "Loss: 1.981, Residuals: -0.098\n",
      "Loss: 1.981, Residuals: -0.098\n",
      "Loss: 1.981, Residuals: -0.098\n",
      "Loss: 1.981, Residuals: -0.098\n",
      "Loss: 1.980, Residuals: -0.099\n",
      "Loss: 1.980, Residuals: -0.098\n",
      "Loss: 1.979, Residuals: -0.099\n",
      "Loss: 1.976, Residuals: -0.104\n",
      "Loss: 1.976, Residuals: -0.103\n",
      "Loss: 1.976, Residuals: -0.103\n",
      "Loss: 1.976, Residuals: -0.103\n",
      "Loss: 1.976, Residuals: -0.103\n",
      "Loss: 1.975, Residuals: -0.103\n",
      "Loss: 1.975, Residuals: -0.102\n",
      "Loss: 1.974, Residuals: -0.103\n",
      "Loss: 1.973, Residuals: -0.104\n",
      "Loss: 1.973, Residuals: -0.103\n",
      "Loss: 1.971, Residuals: -0.104\n",
      "Loss: 1.971, Residuals: -0.104\n",
      "Loss: 1.969, Residuals: -0.105\n",
      "Loss: 1.969, Residuals: -0.105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.969, Residuals: -0.105\n",
      "Loss: 1.969, Residuals: -0.105\n",
      "Loss: 1.968, Residuals: -0.105\n",
      "Loss: 1.967, Residuals: -0.107\n",
      "Loss: 1.967, Residuals: -0.106\n",
      "Loss: 1.967, Residuals: -0.107\n",
      "Loss: 1.967, Residuals: -0.107\n",
      "Loss: 1.965, Residuals: -0.108\n",
      "Loss: 1.965, Residuals: -0.108\n",
      "Evidence -373.014\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.39e-04\n",
      "Loss: 10.600, Residuals: -0.095\n",
      "Loss: 10.520, Residuals: -0.072\n",
      "Loss: 10.420, Residuals: -0.066\n",
      "Loss: 10.401, Residuals: -0.064\n",
      "Loss: 10.388, Residuals: -0.063\n",
      "Loss: 10.386, Residuals: -0.062\n",
      "Loss: 10.314, Residuals: -0.060\n",
      "Loss: 10.314, Residuals: -0.060\n",
      "Loss: 10.266, Residuals: -0.057\n",
      "Loss: 10.265, Residuals: -0.055\n",
      "Loss: 10.258, Residuals: -0.055\n",
      "Loss: 10.200, Residuals: -0.051\n",
      "Loss: 10.199, Residuals: -0.053\n",
      "Loss: 10.131, Residuals: -0.051\n",
      "Loss: 10.130, Residuals: -0.050\n",
      "Evidence 105.284\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.70e-03\n",
      "Loss: 40.158, Residuals: -0.047\n",
      "Loss: 40.131, Residuals: -0.048\n",
      "Loss: 39.886, Residuals: -0.045\n",
      "Loss: 39.506, Residuals: -0.037\n",
      "Loss: 39.494, Residuals: -0.038\n",
      "Loss: 39.382, Residuals: -0.036\n",
      "Loss: 39.179, Residuals: -0.033\n",
      "Loss: 39.168, Residuals: -0.031\n",
      "Loss: 38.747, Residuals: -0.030\n",
      "Loss: 38.727, Residuals: -0.029\n",
      "Loss: 38.726, Residuals: -0.030\n",
      "Loss: 38.710, Residuals: -0.030\n",
      "Loss: 38.361, Residuals: -0.028\n",
      "Loss: 38.341, Residuals: -0.028\n",
      "Loss: 38.327, Residuals: -0.027\n",
      "Loss: 38.316, Residuals: -0.029\n",
      "Loss: 38.297, Residuals: -0.028\n",
      "Loss: 38.121, Residuals: -0.026\n",
      "Loss: 38.119, Residuals: -0.026\n",
      "Loss: 38.119, Residuals: -0.026\n",
      "Evidence 308.380\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.75e-02\n",
      "Loss: 88.402, Residuals: -0.026\n",
      "Loss: 88.346, Residuals: -0.023\n",
      "Loss: 88.248, Residuals: -0.026\n",
      "Loss: 88.106, Residuals: -0.029\n",
      "Loss: 87.876, Residuals: -0.032\n",
      "Loss: 87.507, Residuals: -0.032\n",
      "Loss: 87.505, Residuals: -0.032\n",
      "Loss: 86.453, Residuals: -0.032\n",
      "Loss: 86.384, Residuals: -0.032\n",
      "Loss: 86.359, Residuals: -0.031\n",
      "Loss: 86.317, Residuals: -0.032\n",
      "Loss: 86.246, Residuals: -0.034\n",
      "Loss: 86.245, Residuals: -0.034\n",
      "Loss: 85.550, Residuals: -0.032\n",
      "Loss: 85.490, Residuals: -0.032\n",
      "Loss: 85.489, Residuals: -0.032\n",
      "Evidence 421.417\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.84e-02\n",
      "Loss: 128.417, Residuals: -0.032\n",
      "Evidence 456.401\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.21e-02\n",
      "Loss: 148.687, Residuals: -0.032\n",
      "Evidence 461.567\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.61e-02\n",
      "Loss: 152.399, Residuals: -0.042\n",
      "Loss: 152.303, Residuals: -0.042\n",
      "Loss: 152.120, Residuals: -0.043\n",
      "Loss: 151.793, Residuals: -0.045\n",
      "Loss: 151.168, Residuals: -0.045\n",
      "Loss: 151.168, Residuals: -0.045\n",
      "Evidence 467.055\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.77e-02\n",
      "Loss: 154.615, Residuals: -0.045\n",
      "Evidence 468.885\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.83e-02\n",
      "Loss: 154.898, Residuals: -0.045\n",
      "Loss: 154.810, Residuals: -0.047\n",
      "Loss: 151.766, Residuals: -0.046\n",
      "Loss: 151.749, Residuals: -0.046\n",
      "Evidence 474.805\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.09e-02\n",
      "Loss: 154.844, Residuals: -0.041\n",
      "Loss: 154.188, Residuals: -0.046\n",
      "Loss: 149.914, Residuals: -0.044\n",
      "Loss: 149.781, Residuals: -0.044\n",
      "Loss: 149.663, Residuals: -0.043\n",
      "Loss: 149.632, Residuals: -0.043\n",
      "Loss: 149.618, Residuals: -0.043\n",
      "Evidence 481.572\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.58e-02\n",
      "Loss: 154.308, Residuals: -0.043\n",
      "Loss: 154.093, Residuals: -0.044\n",
      "Loss: 154.091, Residuals: -0.044\n",
      "Evidence 485.163\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.69e-02\n",
      "Loss: 156.247, Residuals: -0.044\n",
      "Evidence 485.399\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 12.411, Residuals: -0.030\n",
      "Loss: 7.240, Residuals: -0.030\n",
      "Loss: 5.170, Residuals: -0.056\n",
      "Loss: 4.644, Residuals: -0.051\n",
      "Loss: 3.908, Residuals: -0.032\n",
      "Loss: 3.552, Residuals: 0.038\n",
      "Loss: 3.451, Residuals: -0.002\n",
      "Loss: 3.274, Residuals: -0.011\n",
      "Loss: 2.985, Residuals: -0.029\n",
      "Loss: 2.919, Residuals: -0.017\n",
      "Loss: 2.905, Residuals: -0.010\n",
      "Loss: 2.790, Residuals: -0.029\n",
      "Loss: 2.783, Residuals: -0.021\n",
      "Loss: 2.722, Residuals: -0.034\n",
      "Loss: 2.618, Residuals: -0.054\n",
      "Loss: 2.606, Residuals: -0.036\n",
      "Loss: 2.588, Residuals: -0.037\n",
      "Loss: 2.553, Residuals: -0.043\n",
      "Loss: 2.524, Residuals: -0.038\n",
      "Loss: 2.522, Residuals: -0.034\n",
      "Loss: 2.496, Residuals: -0.041\n",
      "Loss: 2.456, Residuals: -0.052\n",
      "Loss: 2.456, Residuals: -0.051\n",
      "Loss: 2.454, Residuals: -0.051\n",
      "Loss: 2.450, Residuals: -0.049\n",
      "Loss: 2.444, Residuals: -0.046\n",
      "Loss: 2.433, Residuals: -0.050\n",
      "Loss: 2.432, Residuals: -0.047\n",
      "Loss: 2.405, Residuals: -0.057\n",
      "Loss: 2.405, Residuals: -0.056\n",
      "Loss: 2.397, Residuals: -0.055\n",
      "Loss: 2.394, Residuals: -0.052\n",
      "Loss: 2.370, Residuals: -0.060\n",
      "Loss: 2.370, Residuals: -0.059\n",
      "Loss: 2.365, Residuals: -0.057\n",
      "Loss: 2.358, Residuals: -0.055\n",
      "Loss: 2.302, Residuals: -0.069\n",
      "Loss: 2.299, Residuals: -0.066\n",
      "Loss: 2.295, Residuals: -0.063\n",
      "Loss: 2.289, Residuals: -0.052\n",
      "Loss: 2.281, Residuals: -0.054\n",
      "Loss: 2.280, Residuals: -0.052\n",
      "Loss: 2.265, Residuals: -0.058\n",
      "Loss: 2.261, Residuals: -0.055\n",
      "Loss: 2.260, Residuals: -0.053\n",
      "Loss: 2.248, Residuals: -0.058\n",
      "Loss: 2.248, Residuals: -0.058\n",
      "Evidence -381.845\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.27e-03\n",
      "Loss: 11.048, Residuals: -0.043\n",
      "Loss: 11.030, Residuals: -0.039\n",
      "Loss: 11.019, Residuals: -0.046\n",
      "Loss: 11.002, Residuals: -0.043\n",
      "Loss: 10.865, Residuals: -0.036\n",
      "Loss: 10.864, Residuals: -0.036\n",
      "Loss: 10.812, Residuals: -0.033\n",
      "Loss: 10.724, Residuals: -0.027\n",
      "Loss: 10.713, Residuals: -0.023\n",
      "Loss: 10.616, Residuals: -0.017\n",
      "Loss: 10.555, Residuals: -0.006\n",
      "Loss: 10.548, Residuals: -0.011\n",
      "Loss: 10.539, Residuals: -0.010\n",
      "Loss: 10.469, Residuals: -0.006\n",
      "Loss: 10.465, Residuals: -0.007\n",
      "Loss: 10.431, Residuals: -0.004\n",
      "Loss: 10.427, Residuals: -0.006\n",
      "Loss: 10.422, Residuals: -0.007\n",
      "Loss: 10.414, Residuals: -0.006\n",
      "Loss: 10.411, Residuals: -0.007\n",
      "Loss: 10.410, Residuals: -0.006\n",
      "Loss: 10.406, Residuals: -0.006\n",
      "Loss: 10.406, Residuals: -0.007\n",
      "Loss: 10.393, Residuals: -0.007\n",
      "Loss: 10.393, Residuals: -0.007\n",
      "Evidence 100.444\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 3.22e-02\n",
      "Loss: 37.420, Residuals: -0.003\n",
      "Loss: 37.395, Residuals: -0.002\n",
      "Loss: 37.351, Residuals: -0.003\n",
      "Loss: 37.284, Residuals: -0.003\n",
      "Loss: 37.172, Residuals: -0.002\n",
      "Loss: 37.003, Residuals: 0.003\n",
      "Loss: 36.996, Residuals: 0.005\n",
      "Loss: 36.935, Residuals: 0.006\n",
      "Loss: 36.832, Residuals: 0.007\n",
      "Loss: 36.825, Residuals: 0.009\n",
      "Loss: 36.816, Residuals: 0.008\n",
      "Loss: 36.733, Residuals: 0.009\n",
      "Loss: 36.732, Residuals: 0.008\n",
      "Loss: 36.693, Residuals: 0.009\n",
      "Loss: 36.681, Residuals: 0.009\n",
      "Loss: 36.680, Residuals: 0.008\n",
      "Loss: 36.625, Residuals: 0.008\n",
      "Loss: 36.624, Residuals: 0.009\n",
      "Loss: 36.561, Residuals: 0.010\n",
      "Loss: 36.557, Residuals: 0.008\n",
      "Loss: 36.414, Residuals: 0.010\n",
      "Loss: 36.387, Residuals: 0.010\n",
      "Loss: 36.356, Residuals: 0.009\n",
      "Loss: 36.350, Residuals: 0.010\n",
      "Loss: 36.101, Residuals: 0.010\n",
      "Loss: 36.095, Residuals: 0.010\n",
      "Loss: 36.086, Residuals: 0.010\n",
      "Loss: 36.067, Residuals: 0.010\n",
      "Loss: 36.035, Residuals: 0.011\n",
      "Loss: 36.028, Residuals: 0.011\n",
      "Loss: 35.971, Residuals: 0.012\n",
      "Loss: 35.970, Residuals: 0.013\n",
      "Loss: 35.919, Residuals: 0.015\n",
      "Loss: 35.915, Residuals: 0.014\n",
      "Loss: 35.910, Residuals: 0.014\n",
      "Loss: 35.902, Residuals: 0.015\n",
      "Loss: 35.901, Residuals: 0.015\n",
      "Loss: 35.892, Residuals: 0.015\n",
      "Loss: 35.877, Residuals: 0.015\n",
      "Loss: 35.877, Residuals: 0.016\n",
      "Loss: 35.876, Residuals: 0.016\n",
      "Loss: 35.866, Residuals: 0.016\n",
      "Loss: 35.864, Residuals: 0.016\n",
      "Loss: 35.852, Residuals: 0.016\n",
      "Loss: 35.852, Residuals: 0.016\n",
      "Loss: 35.847, Residuals: 0.017\n",
      "Loss: 35.846, Residuals: 0.017\n",
      "Loss: 35.838, Residuals: 0.017\n",
      "Loss: 35.838, Residuals: 0.017\n",
      "Loss: 35.835, Residuals: 0.017\n",
      "Loss: 35.833, Residuals: 0.017\n",
      "Loss: 35.830, Residuals: 0.017\n",
      "Loss: 35.829, Residuals: 0.017\n",
      "Loss: 35.826, Residuals: 0.017\n",
      "Loss: 35.826, Residuals: 0.017\n",
      "Loss: 35.822, Residuals: 0.017\n",
      "Loss: 35.822, Residuals: 0.017\n",
      "Loss: 35.818, Residuals: 0.017\n",
      "Loss: 35.817, Residuals: 0.017\n",
      "Loss: 35.813, Residuals: 0.017\n",
      "Loss: 35.812, Residuals: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 35.805, Residuals: 0.017\n",
      "Loss: 35.805, Residuals: 0.017\n",
      "Loss: 35.804, Residuals: 0.017\n",
      "Loss: 35.800, Residuals: 0.017\n",
      "Loss: 35.799, Residuals: 0.017\n",
      "Loss: 35.794, Residuals: 0.017\n",
      "Loss: 35.794, Residuals: 0.018\n",
      "Loss: 35.793, Residuals: 0.018\n",
      "Loss: 35.791, Residuals: 0.017\n",
      "Loss: 35.791, Residuals: 0.018\n",
      "Loss: 35.790, Residuals: 0.018\n",
      "Loss: 35.790, Residuals: 0.018\n",
      "Loss: 35.789, Residuals: 0.018\n",
      "Loss: 35.788, Residuals: 0.017\n",
      "Loss: 35.788, Residuals: 0.018\n",
      "Loss: 35.787, Residuals: 0.018\n",
      "Loss: 35.787, Residuals: 0.018\n",
      "Loss: 35.787, Residuals: 0.018\n",
      "Loss: 35.787, Residuals: 0.018\n",
      "Loss: 35.787, Residuals: 0.018\n",
      "Loss: 35.787, Residuals: 0.018\n",
      "Loss: 35.787, Residuals: 0.018\n",
      "Loss: 35.787, Residuals: 0.018\n",
      "Loss: 35.787, Residuals: 0.017\n",
      "Loss: 35.787, Residuals: 0.018\n",
      "Loss: 35.786, Residuals: 0.018\n",
      "Loss: 35.786, Residuals: 0.018\n",
      "Loss: 35.786, Residuals: 0.018\n",
      "Loss: 35.786, Residuals: 0.018\n",
      "Loss: 35.786, Residuals: 0.018\n",
      "Loss: 35.786, Residuals: 0.018\n",
      "Loss: 35.786, Residuals: 0.018\n",
      "Loss: 35.786, Residuals: 0.018\n",
      "Loss: 35.786, Residuals: 0.018\n",
      "Loss: 35.786, Residuals: 0.018\n",
      "Evidence 297.601\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.78e-01\n",
      "Loss: 78.902, Residuals: 0.007\n",
      "Loss: 78.767, Residuals: 0.012\n",
      "Loss: 78.522, Residuals: 0.013\n",
      "Loss: 78.424, Residuals: 0.011\n",
      "Loss: 78.253, Residuals: 0.012\n",
      "Loss: 77.997, Residuals: 0.015\n",
      "Loss: 77.980, Residuals: 0.015\n",
      "Loss: 77.833, Residuals: 0.016\n",
      "Loss: 77.820, Residuals: 0.016\n",
      "Loss: 77.710, Residuals: 0.017\n",
      "Loss: 77.705, Residuals: 0.016\n",
      "Loss: 77.658, Residuals: 0.016\n",
      "Loss: 77.655, Residuals: 0.015\n",
      "Loss: 77.627, Residuals: 0.016\n",
      "Loss: 77.592, Residuals: 0.016\n",
      "Loss: 77.589, Residuals: 0.015\n",
      "Loss: 77.558, Residuals: 0.016\n",
      "Loss: 77.556, Residuals: 0.016\n",
      "Loss: 77.537, Residuals: 0.016\n",
      "Loss: 77.535, Residuals: 0.016\n",
      "Loss: 77.520, Residuals: 0.016\n",
      "Loss: 77.519, Residuals: 0.016\n",
      "Loss: 77.515, Residuals: 0.016\n",
      "Loss: 77.514, Residuals: 0.016\n",
      "Loss: 77.509, Residuals: 0.016\n",
      "Loss: 77.509, Residuals: 0.016\n",
      "Loss: 77.507, Residuals: 0.016\n",
      "Loss: 77.504, Residuals: 0.016\n",
      "Loss: 77.503, Residuals: 0.016\n",
      "Loss: 77.503, Residuals: 0.016\n",
      "Loss: 77.503, Residuals: 0.016\n",
      "Loss: 77.503, Residuals: 0.016\n",
      "Loss: 77.503, Residuals: 0.016\n",
      "Evidence 416.296\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 4.11e-01\n",
      "Loss: 116.377, Residuals: 0.016\n",
      "Loss: 116.076, Residuals: 0.007\n",
      "Loss: 115.772, Residuals: 0.010\n",
      "Loss: 115.763, Residuals: 0.009\n",
      "Loss: 115.684, Residuals: 0.009\n",
      "Loss: 115.660, Residuals: 0.009\n",
      "Loss: 115.624, Residuals: 0.009\n",
      "Loss: 115.559, Residuals: 0.010\n",
      "Loss: 115.556, Residuals: 0.011\n",
      "Loss: 115.526, Residuals: 0.011\n",
      "Loss: 115.475, Residuals: 0.011\n",
      "Loss: 115.472, Residuals: 0.010\n",
      "Loss: 115.446, Residuals: 0.010\n",
      "Loss: 115.446, Residuals: 0.010\n",
      "Loss: 115.430, Residuals: 0.010\n",
      "Loss: 115.417, Residuals: 0.010\n",
      "Loss: 115.416, Residuals: 0.010\n",
      "Loss: 115.415, Residuals: 0.010\n",
      "Loss: 115.414, Residuals: 0.010\n",
      "Loss: 115.414, Residuals: 0.010\n",
      "Loss: 115.410, Residuals: 0.010\n",
      "Loss: 115.410, Residuals: 0.010\n",
      "Loss: 115.409, Residuals: 0.010\n",
      "Loss: 115.408, Residuals: 0.010\n",
      "Loss: 115.408, Residuals: 0.010\n",
      "Loss: 115.408, Residuals: 0.010\n",
      "Evidence 463.833\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 5.49e-01\n",
      "Loss: 137.234, Residuals: 0.011\n",
      "Loss: 136.989, Residuals: 0.005\n",
      "Loss: 136.725, Residuals: 0.006\n",
      "Loss: 136.659, Residuals: 0.006\n",
      "Loss: 136.608, Residuals: 0.007\n",
      "Loss: 136.604, Residuals: 0.005\n",
      "Loss: 136.575, Residuals: 0.005\n",
      "Loss: 136.568, Residuals: 0.006\n",
      "Loss: 136.557, Residuals: 0.006\n",
      "Loss: 136.545, Residuals: 0.006\n",
      "Loss: 136.530, Residuals: 0.006\n",
      "Loss: 136.530, Residuals: 0.006\n",
      "Loss: 136.527, Residuals: 0.006\n",
      "Loss: 136.526, Residuals: 0.006\n",
      "Loss: 136.523, Residuals: 0.006\n",
      "Loss: 136.517, Residuals: 0.006\n",
      "Loss: 136.517, Residuals: 0.006\n",
      "Loss: 136.516, Residuals: 0.006\n",
      "Loss: 136.515, Residuals: 0.006\n",
      "Loss: 136.515, Residuals: 0.006\n",
      "Evidence 477.587\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.07e-01\n",
      "Loss: 145.207, Residuals: 0.006\n",
      "Loss: 145.021, Residuals: 0.003\n",
      "Loss: 144.967, Residuals: 0.005\n",
      "Loss: 144.938, Residuals: 0.003\n",
      "Loss: 144.892, Residuals: 0.003\n",
      "Loss: 144.865, Residuals: 0.004\n",
      "Loss: 144.852, Residuals: 0.003\n",
      "Loss: 144.850, Residuals: 0.003\n",
      "Loss: 144.846, Residuals: 0.003\n",
      "Loss: 144.845, Residuals: 0.003\n",
      "Loss: 144.844, Residuals: 0.003\n",
      "Loss: 144.841, Residuals: 0.003\n",
      "Loss: 144.839, Residuals: 0.003\n",
      "Loss: 144.839, Residuals: 0.003\n",
      "Loss: 144.837, Residuals: 0.003\n",
      "Loss: 144.835, Residuals: 0.003\n",
      "Loss: 144.832, Residuals: 0.003\n",
      "Evidence 481.906\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.43e-01\n",
      "Loss: 148.134, Residuals: -0.000\n",
      "Loss: 147.989, Residuals: 0.000\n",
      "Loss: 147.980, Residuals: 0.001\n",
      "Loss: 147.967, Residuals: 0.001\n",
      "Loss: 147.958, Residuals: 0.001\n",
      "Loss: 147.958, Residuals: 0.001\n",
      "Loss: 147.957, Residuals: 0.001\n",
      "Loss: 147.957, Residuals: 0.001\n",
      "Loss: 147.955, Residuals: 0.001\n",
      "Loss: 147.953, Residuals: 0.001\n",
      "Loss: 147.953, Residuals: 0.001\n",
      "Loss: 147.952, Residuals: 0.001\n",
      "Loss: 147.951, Residuals: 0.001\n",
      "Loss: 147.951, Residuals: 0.001\n",
      "Evidence 483.804\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.65e-01\n",
      "Loss: 149.399, Residuals: -0.001\n",
      "Loss: 149.337, Residuals: -0.000\n",
      "Loss: 149.318, Residuals: 0.000\n",
      "Loss: 149.299, Residuals: -0.000\n",
      "Loss: 149.298, Residuals: -0.000\n",
      "Loss: 149.297, Residuals: -0.000\n",
      "Loss: 149.297, Residuals: -0.000\n",
      "Loss: 149.295, Residuals: -0.000\n",
      "Loss: 149.295, Residuals: -0.000\n",
      "Loss: 149.295, Residuals: -0.000\n",
      "Loss: 149.294, Residuals: -0.000\n",
      "Loss: 149.293, Residuals: -0.000\n",
      "Loss: 149.293, Residuals: -0.000\n",
      "Loss: 149.293, Residuals: -0.000\n",
      "Loss: 149.293, Residuals: -0.000\n",
      "Loss: 149.293, Residuals: -0.000\n",
      "Loss: 149.293, Residuals: -0.000\n",
      "Loss: 149.293, Residuals: -0.000\n",
      "Evidence 484.812\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.84e-01\n",
      "Loss: 150.054, Residuals: -0.002\n",
      "Loss: 150.036, Residuals: -0.000\n",
      "Loss: 150.012, Residuals: -0.000\n",
      "Loss: 150.004, Residuals: -0.001\n",
      "Loss: 150.002, Residuals: -0.002\n",
      "Loss: 150.002, Residuals: -0.001\n",
      "Loss: 150.001, Residuals: -0.001\n",
      "Loss: 150.001, Residuals: -0.001\n",
      "Loss: 150.001, Residuals: -0.001\n",
      "Loss: 150.000, Residuals: -0.001\n",
      "Loss: 150.000, Residuals: -0.001\n",
      "Loss: 150.000, Residuals: -0.001\n",
      "Loss: 150.000, Residuals: -0.001\n",
      "Evidence 485.435\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 6.95e-01\n",
      "Loss: 150.472, Residuals: -0.002\n",
      "Loss: 150.450, Residuals: -0.002\n",
      "Loss: 150.446, Residuals: -0.002\n",
      "Loss: 150.443, Residuals: -0.001\n",
      "Loss: 150.442, Residuals: -0.002\n",
      "Loss: 150.442, Residuals: -0.002\n",
      "Loss: 150.442, Residuals: -0.002\n",
      "Loss: 150.441, Residuals: -0.002\n",
      "Loss: 150.441, Residuals: -0.002\n",
      "Loss: 150.441, Residuals: -0.002\n",
      "Loss: 150.441, Residuals: -0.002\n",
      "Evidence 485.849\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.878, Residuals: -0.073\n",
      "Loss: 7.255, Residuals: -0.055\n",
      "Loss: 5.218, Residuals: -0.042\n",
      "Loss: 4.410, Residuals: -0.036\n",
      "Loss: 3.900, Residuals: -0.065\n",
      "Loss: 3.750, Residuals: -0.033\n",
      "Loss: 3.516, Residuals: -0.018\n",
      "Loss: 3.235, Residuals: -0.033\n",
      "Loss: 3.190, Residuals: -0.043\n",
      "Loss: 3.116, Residuals: -0.052\n",
      "Loss: 3.017, Residuals: -0.070\n",
      "Loss: 3.012, Residuals: -0.068\n",
      "Loss: 3.004, Residuals: -0.068\n",
      "Loss: 2.991, Residuals: -0.069\n",
      "Loss: 2.968, Residuals: -0.072\n",
      "Loss: 2.956, Residuals: -0.068\n",
      "Loss: 2.935, Residuals: -0.072\n",
      "Loss: 2.901, Residuals: -0.081\n",
      "Loss: 2.887, Residuals: -0.079\n",
      "Loss: 2.886, Residuals: -0.076\n",
      "Loss: 2.857, Residuals: -0.081\n",
      "Loss: 2.841, Residuals: -0.074\n",
      "Loss: 2.839, Residuals: -0.064\n",
      "Loss: 2.814, Residuals: -0.072\n",
      "Loss: 2.776, Residuals: -0.083\n",
      "Loss: 2.775, Residuals: -0.083\n",
      "Loss: 2.774, Residuals: -0.083\n",
      "Loss: 2.771, Residuals: -0.082\n",
      "Loss: 2.766, Residuals: -0.083\n",
      "Loss: 2.755, Residuals: -0.086\n",
      "Loss: 2.738, Residuals: -0.090\n",
      "Loss: 2.738, Residuals: -0.090\n",
      "Loss: 2.736, Residuals: -0.090\n",
      "Loss: 2.712, Residuals: -0.100\n",
      "Loss: 2.711, Residuals: -0.101\n",
      "Loss: 2.705, Residuals: -0.100\n",
      "Loss: 2.700, Residuals: -0.096\n",
      "Loss: 2.692, Residuals: -0.097\n",
      "Loss: 2.691, Residuals: -0.096\n",
      "Loss: 2.681, Residuals: -0.098\n",
      "Loss: 2.666, Residuals: -0.101\n",
      "Loss: 2.664, Residuals: -0.098\n",
      "Loss: 2.661, Residuals: -0.099\n",
      "Loss: 2.661, Residuals: -0.098\n",
      "Loss: 2.654, Residuals: -0.099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.654, Residuals: -0.098\n",
      "Loss: 2.638, Residuals: -0.102\n",
      "Loss: 2.638, Residuals: -0.099\n",
      "Loss: 2.637, Residuals: -0.101\n",
      "Loss: 2.631, Residuals: -0.102\n",
      "Loss: 2.631, Residuals: -0.104\n",
      "Loss: 2.630, Residuals: -0.105\n",
      "Loss: 2.629, Residuals: -0.106\n",
      "Loss: 2.629, Residuals: -0.104\n",
      "Loss: 2.615, Residuals: -0.108\n",
      "Loss: 2.615, Residuals: -0.106\n",
      "Loss: 2.614, Residuals: -0.107\n",
      "Loss: 2.604, Residuals: -0.108\n",
      "Loss: 2.603, Residuals: -0.107\n",
      "Loss: 2.603, Residuals: -0.107\n",
      "Loss: 2.603, Residuals: -0.108\n",
      "Loss: 2.603, Residuals: -0.107\n",
      "Loss: 2.597, Residuals: -0.108\n",
      "Loss: 2.597, Residuals: -0.108\n",
      "Loss: 2.596, Residuals: -0.109\n",
      "Loss: 2.596, Residuals: -0.109\n",
      "Loss: 2.591, Residuals: -0.110\n",
      "Loss: 2.590, Residuals: -0.109\n",
      "Loss: 2.590, Residuals: -0.110\n",
      "Loss: 2.589, Residuals: -0.109\n",
      "Loss: 2.586, Residuals: -0.110\n",
      "Loss: 2.586, Residuals: -0.110\n",
      "Loss: 2.580, Residuals: -0.111\n",
      "Loss: 2.580, Residuals: -0.111\n",
      "Loss: 2.580, Residuals: -0.111\n",
      "Loss: 2.576, Residuals: -0.112\n",
      "Loss: 2.576, Residuals: -0.112\n",
      "Loss: 2.575, Residuals: -0.113\n",
      "Loss: 2.575, Residuals: -0.114\n",
      "Loss: 2.571, Residuals: -0.114\n",
      "Loss: 2.571, Residuals: -0.114\n",
      "Loss: 2.571, Residuals: -0.114\n",
      "Loss: 2.571, Residuals: -0.115\n",
      "Loss: 2.564, Residuals: -0.116\n",
      "Loss: 2.564, Residuals: -0.114\n",
      "Loss: 2.564, Residuals: -0.115\n",
      "Loss: 2.563, Residuals: -0.115\n",
      "Loss: 2.563, Residuals: -0.116\n",
      "Loss: 2.561, Residuals: -0.118\n",
      "Loss: 2.561, Residuals: -0.118\n",
      "Evidence -381.570\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.34e-04\n",
      "Loss: 12.665, Residuals: -0.102\n",
      "Loss: 12.512, Residuals: -0.098\n",
      "Loss: 12.311, Residuals: -0.092\n",
      "Loss: 12.303, Residuals: -0.092\n",
      "Loss: 12.293, Residuals: -0.090\n",
      "Loss: 12.197, Residuals: -0.087\n",
      "Loss: 12.032, Residuals: -0.081\n",
      "Loss: 12.025, Residuals: -0.082\n",
      "Loss: 11.964, Residuals: -0.078\n",
      "Loss: 11.862, Residuals: -0.071\n",
      "Loss: 11.856, Residuals: -0.068\n",
      "Loss: 11.854, Residuals: -0.071\n",
      "Loss: 11.854, Residuals: -0.071\n",
      "Loss: 11.854, Residuals: -0.070\n",
      "Loss: 11.853, Residuals: -0.070\n",
      "Loss: 11.847, Residuals: -0.070\n",
      "Loss: 11.790, Residuals: -0.064\n",
      "Loss: 11.790, Residuals: -0.064\n",
      "Loss: 11.784, Residuals: -0.064\n",
      "Loss: 11.737, Residuals: -0.058\n",
      "Loss: 11.737, Residuals: -0.058\n",
      "Loss: 11.735, Residuals: -0.059\n",
      "Loss: 11.723, Residuals: -0.057\n",
      "Loss: 11.714, Residuals: -0.055\n",
      "Loss: 11.713, Residuals: -0.054\n",
      "Loss: 11.713, Residuals: -0.054\n",
      "Loss: 11.713, Residuals: -0.054\n",
      "Loss: 11.712, Residuals: -0.054\n",
      "Loss: 11.712, Residuals: -0.054\n",
      "Loss: 11.693, Residuals: -0.053\n",
      "Loss: 11.693, Residuals: -0.052\n",
      "Loss: 11.692, Residuals: -0.052\n",
      "Loss: 11.692, Residuals: -0.052\n",
      "Loss: 11.692, Residuals: -0.052\n",
      "Evidence 106.980\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.85e-03\n",
      "Loss: 43.103, Residuals: -0.054\n",
      "Loss: 43.063, Residuals: -0.055\n",
      "Loss: 42.987, Residuals: -0.054\n",
      "Loss: 42.850, Residuals: -0.051\n",
      "Loss: 42.636, Residuals: -0.047\n",
      "Loss: 42.628, Residuals: -0.041\n",
      "Loss: 42.622, Residuals: -0.040\n",
      "Loss: 42.614, Residuals: -0.045\n",
      "Loss: 42.541, Residuals: -0.044\n",
      "Loss: 42.419, Residuals: -0.040\n",
      "Loss: 42.389, Residuals: -0.038\n",
      "Loss: 42.336, Residuals: -0.037\n",
      "Loss: 42.241, Residuals: -0.036\n",
      "Loss: 42.235, Residuals: -0.033\n",
      "Loss: 42.226, Residuals: -0.034\n",
      "Loss: 42.146, Residuals: -0.033\n",
      "Loss: 42.144, Residuals: -0.032\n",
      "Loss: 42.142, Residuals: -0.032\n",
      "Loss: 42.120, Residuals: -0.032\n",
      "Loss: 42.118, Residuals: -0.034\n",
      "Loss: 42.118, Residuals: -0.034\n",
      "Loss: 42.054, Residuals: -0.033\n",
      "Loss: 42.051, Residuals: -0.032\n",
      "Loss: 42.046, Residuals: -0.031\n",
      "Loss: 42.046, Residuals: -0.031\n",
      "Loss: 42.037, Residuals: -0.031\n",
      "Loss: 42.030, Residuals: -0.031\n",
      "Loss: 42.030, Residuals: -0.030\n",
      "Loss: 42.030, Residuals: -0.030\n",
      "Evidence 316.672\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.65e-02\n",
      "Loss: 94.230, Residuals: -0.025\n",
      "Loss: 94.185, Residuals: -0.027\n",
      "Loss: 93.818, Residuals: -0.028\n",
      "Loss: 93.449, Residuals: -0.035\n",
      "Loss: 93.437, Residuals: -0.036\n",
      "Loss: 93.413, Residuals: -0.036\n",
      "Loss: 93.374, Residuals: -0.035\n",
      "Loss: 93.300, Residuals: -0.035\n",
      "Loss: 93.167, Residuals: -0.034\n",
      "Loss: 92.956, Residuals: -0.032\n",
      "Loss: 92.931, Residuals: -0.032\n",
      "Loss: 92.929, Residuals: -0.031\n",
      "Loss: 92.928, Residuals: -0.030\n",
      "Loss: 92.928, Residuals: -0.030\n",
      "Evidence 421.197\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.36e-02\n",
      "Loss: 133.751, Residuals: -0.034\n",
      "Loss: 133.698, Residuals: -0.037\n",
      "Loss: 133.639, Residuals: -0.036\n",
      "Loss: 133.543, Residuals: -0.035\n",
      "Loss: 133.374, Residuals: -0.035\n",
      "Loss: 133.211, Residuals: -0.038\n",
      "Loss: 133.208, Residuals: -0.038\n",
      "Loss: 133.105, Residuals: -0.038\n",
      "Loss: 132.915, Residuals: -0.037\n",
      "Loss: 132.900, Residuals: -0.038\n",
      "Loss: 132.900, Residuals: -0.038\n",
      "Evidence 450.375\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.84e-02\n",
      "Loss: 150.990, Residuals: -0.042\n",
      "Loss: 150.849, Residuals: -0.041\n",
      "Loss: 150.795, Residuals: -0.043\n",
      "Loss: 150.788, Residuals: -0.044\n",
      "Loss: 150.566, Residuals: -0.043\n",
      "Loss: 150.229, Residuals: -0.041\n",
      "Loss: 149.839, Residuals: -0.038\n",
      "Loss: 149.823, Residuals: -0.037\n",
      "Loss: 149.820, Residuals: -0.037\n",
      "Loss: 149.815, Residuals: -0.037\n",
      "Loss: 149.804, Residuals: -0.037\n",
      "Loss: 149.787, Residuals: -0.037\n",
      "Loss: 149.759, Residuals: -0.036\n",
      "Loss: 149.716, Residuals: -0.036\n",
      "Loss: 149.707, Residuals: -0.036\n",
      "Loss: 149.706, Residuals: -0.036\n",
      "Loss: 149.706, Residuals: -0.036\n",
      "Evidence 455.575\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.24e-02\n",
      "Loss: 156.217, Residuals: -0.038\n",
      "Loss: 156.131, Residuals: -0.037\n",
      "Loss: 155.992, Residuals: -0.037\n",
      "Loss: 155.992, Residuals: -0.037\n",
      "Loss: 155.988, Residuals: -0.037\n",
      "Loss: 155.952, Residuals: -0.037\n",
      "Loss: 155.887, Residuals: -0.037\n",
      "Loss: 155.788, Residuals: -0.036\n",
      "Loss: 155.777, Residuals: -0.036\n",
      "Loss: 155.776, Residuals: -0.036\n",
      "Evidence 456.922\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.76e-02\n",
      "Loss: 158.099, Residuals: -0.036\n",
      "Loss: 158.033, Residuals: -0.036\n",
      "Loss: 157.940, Residuals: -0.037\n",
      "Loss: 157.932, Residuals: -0.035\n",
      "Loss: 157.653, Residuals: -0.034\n",
      "Loss: 157.650, Residuals: -0.035\n",
      "Loss: 157.649, Residuals: -0.035\n",
      "Evidence 456.984\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.272, Residuals: -0.097\n",
      "Loss: 7.552, Residuals: -0.029\n",
      "Loss: 5.340, Residuals: -0.043\n",
      "Loss: 4.594, Residuals: -0.036\n",
      "Loss: 4.066, Residuals: -0.061\n",
      "Loss: 3.863, Residuals: -0.042\n",
      "Loss: 3.816, Residuals: -0.010\n",
      "Loss: 3.459, Residuals: -0.022\n",
      "Loss: 3.430, Residuals: 0.008\n",
      "Loss: 3.376, Residuals: 0.002\n",
      "Loss: 3.282, Residuals: -0.010\n",
      "Loss: 3.156, Residuals: -0.025\n",
      "Loss: 3.142, Residuals: -0.017\n",
      "Loss: 3.044, Residuals: -0.035\n",
      "Loss: 3.028, Residuals: -0.024\n",
      "Loss: 3.016, Residuals: -0.044\n",
      "Loss: 2.996, Residuals: -0.047\n",
      "Loss: 2.964, Residuals: -0.054\n",
      "Loss: 2.961, Residuals: -0.045\n",
      "Loss: 2.943, Residuals: -0.052\n",
      "Loss: 2.941, Residuals: -0.055\n",
      "Loss: 2.936, Residuals: -0.057\n",
      "Loss: 2.933, Residuals: -0.057\n",
      "Loss: 2.912, Residuals: -0.063\n",
      "Loss: 2.910, Residuals: -0.060\n",
      "Loss: 2.885, Residuals: -0.067\n",
      "Loss: 2.884, Residuals: -0.064\n",
      "Loss: 2.878, Residuals: -0.063\n",
      "Loss: 2.829, Residuals: -0.074\n",
      "Loss: 2.828, Residuals: -0.073\n",
      "Loss: 2.824, Residuals: -0.072\n",
      "Loss: 2.819, Residuals: -0.071\n",
      "Loss: 2.810, Residuals: -0.069\n",
      "Loss: 2.795, Residuals: -0.066\n",
      "Loss: 2.793, Residuals: -0.059\n",
      "Loss: 2.779, Residuals: -0.061\n",
      "Loss: 2.762, Residuals: -0.058\n",
      "Loss: 2.762, Residuals: -0.059\n",
      "Loss: 2.760, Residuals: -0.058\n",
      "Loss: 2.745, Residuals: -0.063\n",
      "Loss: 2.745, Residuals: -0.063\n",
      "Loss: 2.744, Residuals: -0.062\n",
      "Loss: 2.736, Residuals: -0.066\n",
      "Loss: 2.734, Residuals: -0.065\n",
      "Loss: 2.720, Residuals: -0.072\n",
      "Loss: 2.720, Residuals: -0.071\n",
      "Loss: 2.719, Residuals: -0.070\n",
      "Loss: 2.717, Residuals: -0.071\n",
      "Loss: 2.702, Residuals: -0.080\n",
      "Loss: 2.702, Residuals: -0.079\n",
      "Loss: 2.702, Residuals: -0.080\n",
      "Loss: 2.701, Residuals: -0.079\n",
      "Loss: 2.701, Residuals: -0.079\n",
      "Loss: 2.699, Residuals: -0.079\n",
      "Loss: 2.699, Residuals: -0.078\n",
      "Loss: 2.693, Residuals: -0.083\n",
      "Loss: 2.692, Residuals: -0.084\n",
      "Loss: 2.692, Residuals: -0.084\n",
      "Loss: 2.692, Residuals: -0.083\n",
      "Loss: 2.692, Residuals: -0.082\n",
      "Loss: 2.692, Residuals: -0.082\n",
      "Loss: 2.688, Residuals: -0.084\n",
      "Loss: 2.687, Residuals: -0.083\n",
      "Loss: 2.682, Residuals: -0.086\n",
      "Loss: 2.682, Residuals: -0.086\n",
      "Loss: 2.682, Residuals: -0.086\n",
      "Loss: 2.682, Residuals: -0.086\n",
      "Loss: 2.676, Residuals: -0.089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.676, Residuals: -0.089\n",
      "Loss: 2.676, Residuals: -0.089\n",
      "Loss: 2.676, Residuals: -0.088\n",
      "Loss: 2.675, Residuals: -0.088\n",
      "Loss: 2.675, Residuals: -0.088\n",
      "Loss: 2.671, Residuals: -0.090\n",
      "Loss: 2.671, Residuals: -0.090\n",
      "Evidence -410.978\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.15e-02\n",
      "Loss: 14.620, Residuals: -0.094\n",
      "Loss: 14.615, Residuals: -0.094\n",
      "Loss: 14.455, Residuals: -0.086\n",
      "Loss: 14.217, Residuals: -0.069\n",
      "Loss: 14.187, Residuals: -0.063\n",
      "Loss: 14.179, Residuals: -0.059\n",
      "Loss: 14.111, Residuals: -0.057\n",
      "Loss: 14.109, Residuals: -0.055\n",
      "Loss: 14.046, Residuals: -0.053\n",
      "Loss: 13.946, Residuals: -0.048\n",
      "Loss: 13.945, Residuals: -0.048\n",
      "Loss: 13.945, Residuals: -0.048\n",
      "Evidence 117.541\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.56e-02\n",
      "Loss: 47.552, Residuals: -0.048\n",
      "Loss: 47.546, Residuals: -0.048\n",
      "Loss: 47.491, Residuals: -0.046\n",
      "Loss: 47.397, Residuals: -0.045\n",
      "Loss: 47.233, Residuals: -0.046\n",
      "Loss: 47.219, Residuals: -0.045\n",
      "Loss: 47.091, Residuals: -0.044\n",
      "Loss: 46.854, Residuals: -0.042\n",
      "Loss: 46.853, Residuals: -0.042\n",
      "Evidence 312.882\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.72e-01\n",
      "Loss: 99.625, Residuals: -0.042\n",
      "Loss: 99.553, Residuals: -0.041\n",
      "Loss: 99.001, Residuals: -0.039\n",
      "Loss: 98.143, Residuals: -0.043\n",
      "Loss: 96.817, Residuals: -0.044\n",
      "Loss: 96.813, Residuals: -0.044\n",
      "Evidence 408.976\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.38e-01\n",
      "Loss: 135.768, Residuals: -0.045\n",
      "Loss: 135.420, Residuals: -0.046\n",
      "Loss: 134.799, Residuals: -0.050\n",
      "Loss: 133.840, Residuals: -0.061\n",
      "Loss: 132.748, Residuals: -0.071\n",
      "Loss: 132.672, Residuals: -0.072\n",
      "Loss: 130.132, Residuals: -0.061\n",
      "Loss: 130.106, Residuals: -0.062\n",
      "Loss: 130.074, Residuals: -0.061\n",
      "Loss: 128.817, Residuals: -0.055\n",
      "Loss: 128.782, Residuals: -0.052\n",
      "Loss: 128.478, Residuals: -0.051\n",
      "Loss: 128.346, Residuals: -0.049\n",
      "Loss: 127.140, Residuals: -0.044\n",
      "Loss: 127.129, Residuals: -0.043\n",
      "Loss: 125.509, Residuals: -0.032\n",
      "Loss: 125.453, Residuals: -0.032\n",
      "Loss: 125.373, Residuals: -0.034\n",
      "Loss: 124.757, Residuals: -0.031\n",
      "Loss: 124.730, Residuals: -0.032\n",
      "Loss: 124.683, Residuals: -0.032\n",
      "Loss: 124.611, Residuals: -0.031\n",
      "Loss: 124.484, Residuals: -0.030\n",
      "Loss: 124.253, Residuals: -0.028\n",
      "Loss: 124.252, Residuals: -0.028\n",
      "Loss: 124.240, Residuals: -0.028\n",
      "Loss: 124.221, Residuals: -0.029\n",
      "Loss: 124.040, Residuals: -0.027\n",
      "Loss: 124.040, Residuals: -0.027\n",
      "Evidence 443.004\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 4.28e-01\n",
      "Loss: 145.485, Residuals: -0.028\n",
      "Loss: 144.615, Residuals: -0.028\n",
      "Loss: 143.919, Residuals: -0.033\n",
      "Loss: 142.978, Residuals: -0.029\n",
      "Loss: 142.971, Residuals: -0.029\n",
      "Loss: 142.698, Residuals: -0.027\n",
      "Loss: 142.190, Residuals: -0.024\n",
      "Loss: 142.150, Residuals: -0.024\n",
      "Loss: 141.762, Residuals: -0.022\n",
      "Loss: 141.582, Residuals: -0.023\n",
      "Loss: 141.368, Residuals: -0.021\n",
      "Loss: 140.053, Residuals: -0.013\n",
      "Loss: 139.847, Residuals: -0.013\n",
      "Loss: 139.485, Residuals: -0.012\n",
      "Loss: 139.103, Residuals: -0.011\n",
      "Loss: 139.035, Residuals: -0.009\n",
      "Loss: 139.008, Residuals: -0.007\n",
      "Loss: 138.111, Residuals: -0.004\n",
      "Loss: 138.084, Residuals: -0.003\n",
      "Loss: 138.049, Residuals: -0.003\n",
      "Loss: 137.989, Residuals: -0.002\n",
      "Loss: 137.879, Residuals: -0.001\n",
      "Loss: 137.866, Residuals: -0.000\n",
      "Loss: 137.754, Residuals: 0.001\n",
      "Loss: 137.752, Residuals: 0.001\n",
      "Loss: 137.676, Residuals: 0.002\n",
      "Loss: 137.667, Residuals: 0.004\n",
      "Loss: 137.665, Residuals: 0.003\n",
      "Loss: 137.646, Residuals: 0.004\n",
      "Loss: 137.646, Residuals: 0.004\n",
      "Loss: 137.641, Residuals: 0.004\n",
      "Loss: 137.633, Residuals: 0.004\n",
      "Loss: 137.631, Residuals: 0.004\n",
      "Loss: 137.631, Residuals: 0.004\n",
      "Loss: 137.629, Residuals: 0.004\n",
      "Loss: 137.626, Residuals: 0.004\n",
      "Loss: 137.626, Residuals: 0.004\n",
      "Loss: 137.626, Residuals: 0.004\n",
      "Loss: 137.626, Residuals: 0.004\n",
      "Loss: 137.626, Residuals: 0.004\n",
      "Loss: 137.626, Residuals: 0.004\n",
      "Loss: 137.626, Residuals: 0.005\n",
      "Loss: 137.626, Residuals: 0.005\n",
      "Loss: 137.626, Residuals: 0.005\n",
      "Loss: 137.625, Residuals: 0.005\n",
      "Evidence 464.897\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.41e+00\n",
      "Loss: 150.967, Residuals: 0.011\n",
      "Loss: 150.369, Residuals: 0.013\n",
      "Loss: 149.965, Residuals: 0.013\n",
      "Loss: 149.613, Residuals: 0.014\n",
      "Loss: 149.567, Residuals: 0.015\n",
      "Loss: 149.483, Residuals: 0.015\n",
      "Loss: 149.352, Residuals: 0.016\n",
      "Loss: 149.345, Residuals: 0.015\n",
      "Loss: 149.289, Residuals: 0.015\n",
      "Loss: 149.286, Residuals: 0.015\n",
      "Loss: 149.265, Residuals: 0.015\n",
      "Loss: 149.244, Residuals: 0.016\n",
      "Loss: 149.243, Residuals: 0.016\n",
      "Loss: 149.242, Residuals: 0.016\n",
      "Loss: 149.242, Residuals: 0.016\n",
      "Loss: 149.242, Residuals: 0.016\n",
      "Loss: 149.242, Residuals: 0.016\n",
      "Loss: 149.241, Residuals: 0.016\n",
      "Loss: 149.241, Residuals: 0.016\n",
      "Loss: 149.241, Residuals: 0.016\n",
      "Evidence 478.829\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.49e+00\n",
      "Loss: 154.992, Residuals: 0.018\n",
      "Loss: 154.735, Residuals: 0.018\n",
      "Loss: 154.528, Residuals: 0.019\n",
      "Loss: 154.370, Residuals: 0.018\n",
      "Loss: 154.355, Residuals: 0.019\n",
      "Loss: 154.326, Residuals: 0.018\n",
      "Loss: 154.283, Residuals: 0.018\n",
      "Loss: 154.275, Residuals: 0.018\n",
      "Loss: 154.262, Residuals: 0.018\n",
      "Loss: 154.261, Residuals: 0.018\n",
      "Loss: 154.256, Residuals: 0.018\n",
      "Loss: 154.256, Residuals: 0.018\n",
      "Loss: 154.254, Residuals: 0.018\n",
      "Loss: 154.252, Residuals: 0.018\n",
      "Loss: 154.252, Residuals: 0.018\n",
      "Loss: 154.252, Residuals: 0.018\n",
      "Loss: 154.252, Residuals: 0.018\n",
      "Loss: 154.252, Residuals: 0.018\n",
      "Loss: 154.251, Residuals: 0.018\n",
      "Loss: 154.251, Residuals: 0.018\n",
      "Evidence 483.568\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.48e+00\n",
      "Loss: 156.706, Residuals: 0.019\n",
      "Loss: 156.626, Residuals: 0.019\n",
      "Loss: 156.512, Residuals: 0.018\n",
      "Loss: 156.430, Residuals: 0.018\n",
      "Loss: 156.359, Residuals: 0.017\n",
      "Loss: 156.348, Residuals: 0.018\n",
      "Loss: 156.344, Residuals: 0.018\n",
      "Loss: 156.336, Residuals: 0.018\n",
      "Loss: 156.325, Residuals: 0.018\n",
      "Loss: 156.324, Residuals: 0.018\n",
      "Loss: 156.323, Residuals: 0.018\n",
      "Loss: 156.321, Residuals: 0.018\n",
      "Loss: 156.321, Residuals: 0.018\n",
      "Loss: 156.321, Residuals: 0.018\n",
      "Loss: 156.320, Residuals: 0.018\n",
      "Loss: 156.320, Residuals: 0.018\n",
      "Loss: 156.320, Residuals: 0.018\n",
      "Loss: 156.320, Residuals: 0.018\n",
      "Evidence 485.848\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.48e+00\n",
      "Loss: 157.476, Residuals: 0.018\n",
      "Loss: 157.437, Residuals: 0.018\n",
      "Loss: 157.373, Residuals: 0.017\n",
      "Loss: 157.322, Residuals: 0.017\n",
      "Loss: 157.279, Residuals: 0.017\n",
      "Loss: 157.274, Residuals: 0.018\n",
      "Loss: 157.272, Residuals: 0.017\n",
      "Loss: 157.269, Residuals: 0.017\n",
      "Loss: 157.263, Residuals: 0.017\n",
      "Loss: 157.262, Residuals: 0.017\n",
      "Loss: 157.261, Residuals: 0.017\n",
      "Loss: 157.261, Residuals: 0.017\n",
      "Loss: 157.261, Residuals: 0.017\n",
      "Loss: 157.261, Residuals: 0.017\n",
      "Loss: 157.261, Residuals: 0.017\n",
      "Loss: 157.260, Residuals: 0.017\n",
      "Loss: 157.260, Residuals: 0.017\n",
      "Loss: 157.260, Residuals: 0.017\n",
      "Loss: 157.260, Residuals: 0.017\n",
      "Loss: 157.260, Residuals: 0.017\n",
      "Loss: 157.260, Residuals: 0.017\n",
      "Loss: 157.260, Residuals: 0.017\n",
      "Loss: 157.260, Residuals: 0.017\n",
      "Evidence 487.202\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.51e+00\n",
      "Loss: 157.887, Residuals: 0.018\n",
      "Loss: 157.864, Residuals: 0.017\n",
      "Loss: 157.826, Residuals: 0.017\n",
      "Loss: 157.782, Residuals: 0.016\n",
      "Loss: 157.754, Residuals: 0.017\n",
      "Loss: 157.750, Residuals: 0.017\n",
      "Loss: 157.745, Residuals: 0.017\n",
      "Loss: 157.739, Residuals: 0.017\n",
      "Loss: 157.739, Residuals: 0.017\n",
      "Loss: 157.739, Residuals: 0.017\n",
      "Loss: 157.738, Residuals: 0.017\n",
      "Loss: 157.738, Residuals: 0.017\n",
      "Evidence 488.148\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.53e+00\n",
      "Loss: 158.107, Residuals: 0.016\n",
      "Loss: 158.078, Residuals: 0.015\n",
      "Loss: 158.045, Residuals: 0.016\n",
      "Loss: 158.027, Residuals: 0.017\n",
      "Loss: 158.019, Residuals: 0.016\n",
      "Loss: 158.017, Residuals: 0.016\n",
      "Loss: 158.013, Residuals: 0.016\n",
      "Loss: 158.013, Residuals: 0.016\n",
      "Loss: 158.012, Residuals: 0.016\n",
      "Loss: 158.011, Residuals: 0.016\n",
      "Loss: 158.010, Residuals: 0.016\n",
      "Loss: 158.010, Residuals: 0.016\n",
      "Loss: 158.010, Residuals: 0.016\n",
      "Loss: 158.010, Residuals: 0.016\n",
      "Loss: 158.010, Residuals: 0.016\n",
      "Loss: 158.010, Residuals: 0.016\n",
      "Loss: 158.010, Residuals: 0.016\n",
      "Loss: 158.010, Residuals: 0.016\n",
      "Evidence 488.906\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.57e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 158.261, Residuals: 0.016\n",
      "Loss: 158.236, Residuals: 0.015\n",
      "Loss: 158.213, Residuals: 0.016\n",
      "Loss: 158.202, Residuals: 0.016\n",
      "Loss: 158.200, Residuals: 0.016\n",
      "Loss: 158.196, Residuals: 0.016\n",
      "Loss: 158.193, Residuals: 0.016\n",
      "Loss: 158.193, Residuals: 0.016\n",
      "Loss: 158.193, Residuals: 0.016\n",
      "Loss: 158.192, Residuals: 0.016\n",
      "Loss: 158.192, Residuals: 0.016\n",
      "Loss: 158.192, Residuals: 0.016\n",
      "Loss: 158.192, Residuals: 0.016\n",
      "Evidence 489.509\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.59e+00\n",
      "Loss: 158.353, Residuals: 0.017\n",
      "Loss: 158.341, Residuals: 0.016\n",
      "Loss: 158.333, Residuals: 0.016\n",
      "Loss: 158.328, Residuals: 0.016\n",
      "Loss: 158.328, Residuals: 0.016\n",
      "Loss: 158.327, Residuals: 0.016\n",
      "Loss: 158.325, Residuals: 0.016\n",
      "Loss: 158.325, Residuals: 0.016\n",
      "Loss: 158.325, Residuals: 0.016\n",
      "Loss: 158.325, Residuals: 0.016\n",
      "Loss: 158.325, Residuals: 0.016\n",
      "Loss: 158.325, Residuals: 0.016\n",
      "Evidence 489.995\n",
      "Pass count  1\n",
      "Total samples: 38, Updated regularization: 1.00e-05\n",
      "Loss: 13.144, Residuals: -0.039\n",
      "Loss: 7.359, Residuals: -0.003\n",
      "Loss: 5.252, Residuals: -0.022\n",
      "Loss: 4.403, Residuals: -0.033\n",
      "Loss: 3.944, Residuals: -0.001\n",
      "Loss: 3.900, Residuals: 0.007\n",
      "Loss: 3.825, Residuals: 0.013\n",
      "Loss: 3.685, Residuals: -0.003\n",
      "Loss: 3.479, Residuals: -0.027\n",
      "Loss: 3.438, Residuals: 0.017\n",
      "Loss: 3.363, Residuals: 0.008\n",
      "Loss: 3.236, Residuals: -0.009\n",
      "Loss: 3.092, Residuals: -0.037\n",
      "Loss: 3.061, Residuals: -0.028\n",
      "Loss: 3.041, Residuals: -0.032\n",
      "Loss: 3.002, Residuals: -0.036\n",
      "Loss: 2.984, Residuals: -0.033\n",
      "Loss: 2.951, Residuals: -0.036\n",
      "Loss: 2.892, Residuals: -0.042\n",
      "Loss: 2.878, Residuals: -0.023\n",
      "Loss: 2.777, Residuals: -0.042\n",
      "Loss: 2.772, Residuals: -0.040\n",
      "Loss: 2.762, Residuals: -0.041\n",
      "Loss: 2.748, Residuals: -0.044\n",
      "Loss: 2.730, Residuals: -0.041\n",
      "Loss: 2.728, Residuals: -0.038\n",
      "Loss: 2.711, Residuals: -0.042\n",
      "Loss: 2.683, Residuals: -0.049\n",
      "Loss: 2.677, Residuals: -0.047\n",
      "Loss: 2.676, Residuals: -0.042\n",
      "Loss: 2.640, Residuals: -0.051\n",
      "Loss: 2.640, Residuals: -0.050\n",
      "Loss: 2.634, Residuals: -0.050\n",
      "Loss: 2.587, Residuals: -0.064\n",
      "Loss: 2.580, Residuals: -0.059\n",
      "Loss: 2.569, Residuals: -0.057\n",
      "Loss: 2.567, Residuals: -0.049\n",
      "Loss: 2.564, Residuals: -0.048\n",
      "Loss: 2.557, Residuals: -0.048\n",
      "Loss: 2.545, Residuals: -0.051\n",
      "Loss: 2.544, Residuals: -0.048\n",
      "Loss: 2.532, Residuals: -0.052\n",
      "Loss: 2.523, Residuals: -0.053\n",
      "Loss: 2.523, Residuals: -0.053\n",
      "Loss: 2.511, Residuals: -0.057\n",
      "Loss: 2.501, Residuals: -0.053\n",
      "Loss: 2.501, Residuals: -0.053\n",
      "Evidence -411.944\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 2.29e-02\n",
      "Loss: 13.688, Residuals: -0.035\n",
      "Loss: 13.618, Residuals: -0.043\n",
      "Loss: 13.487, Residuals: -0.039\n",
      "Loss: 13.280, Residuals: -0.035\n",
      "Loss: 13.278, Residuals: -0.036\n",
      "Loss: 13.202, Residuals: -0.033\n",
      "Loss: 13.199, Residuals: -0.033\n",
      "Loss: 13.068, Residuals: -0.025\n",
      "Loss: 13.067, Residuals: -0.027\n",
      "Loss: 12.996, Residuals: -0.022\n",
      "Loss: 12.914, Residuals: -0.012\n",
      "Loss: 12.910, Residuals: -0.015\n",
      "Loss: 12.901, Residuals: -0.016\n",
      "Loss: 12.888, Residuals: -0.016\n",
      "Loss: 12.783, Residuals: -0.007\n",
      "Loss: 12.782, Residuals: -0.009\n",
      "Loss: 12.773, Residuals: -0.010\n",
      "Loss: 12.706, Residuals: -0.002\n",
      "Loss: 12.702, Residuals: -0.005\n",
      "Loss: 12.695, Residuals: -0.004\n",
      "Loss: 12.682, Residuals: -0.003\n",
      "Loss: 12.674, Residuals: -0.001\n",
      "Loss: 12.673, Residuals: -0.001\n",
      "Loss: 12.666, Residuals: -0.000\n",
      "Loss: 12.654, Residuals: 0.002\n",
      "Loss: 12.654, Residuals: 0.001\n",
      "Loss: 12.646, Residuals: 0.002\n",
      "Loss: 12.645, Residuals: 0.002\n",
      "Loss: 12.644, Residuals: 0.002\n",
      "Loss: 12.638, Residuals: 0.004\n",
      "Loss: 12.638, Residuals: 0.002\n",
      "Loss: 12.637, Residuals: 0.003\n",
      "Loss: 12.636, Residuals: 0.003\n",
      "Loss: 12.635, Residuals: 0.003\n",
      "Loss: 12.635, Residuals: 0.002\n",
      "Loss: 12.635, Residuals: 0.003\n",
      "Loss: 12.628, Residuals: 0.004\n",
      "Loss: 12.627, Residuals: 0.004\n",
      "Loss: 12.627, Residuals: 0.004\n",
      "Loss: 12.627, Residuals: 0.004\n",
      "Loss: 12.626, Residuals: 0.005\n",
      "Loss: 12.625, Residuals: 0.005\n",
      "Loss: 12.625, Residuals: 0.004\n",
      "Loss: 12.624, Residuals: 0.005\n",
      "Loss: 12.624, Residuals: 0.005\n",
      "Loss: 12.624, Residuals: 0.005\n",
      "Loss: 12.623, Residuals: 0.004\n",
      "Loss: 12.623, Residuals: 0.005\n",
      "Loss: 12.622, Residuals: 0.005\n",
      "Loss: 12.622, Residuals: 0.005\n",
      "Loss: 12.622, Residuals: 0.005\n",
      "Loss: 12.621, Residuals: 0.005\n",
      "Loss: 12.621, Residuals: 0.005\n",
      "Loss: 12.621, Residuals: 0.005\n",
      "Loss: 12.620, Residuals: 0.006\n",
      "Loss: 12.620, Residuals: 0.005\n",
      "Loss: 12.620, Residuals: 0.006\n",
      "Loss: 12.620, Residuals: 0.005\n",
      "Loss: 12.619, Residuals: 0.006\n",
      "Loss: 12.619, Residuals: 0.006\n",
      "Loss: 12.618, Residuals: 0.006\n",
      "Loss: 12.618, Residuals: 0.006\n",
      "Loss: 12.617, Residuals: 0.007\n",
      "Loss: 12.617, Residuals: 0.006\n",
      "Loss: 12.616, Residuals: 0.006\n",
      "Loss: 12.616, Residuals: 0.007\n",
      "Loss: 12.615, Residuals: 0.007\n",
      "Loss: 12.613, Residuals: 0.007\n",
      "Loss: 12.613, Residuals: 0.007\n",
      "Loss: 12.612, Residuals: 0.007\n",
      "Loss: 12.612, Residuals: 0.008\n",
      "Loss: 12.609, Residuals: 0.009\n",
      "Loss: 12.608, Residuals: 0.009\n",
      "Loss: 12.606, Residuals: 0.009\n",
      "Loss: 12.604, Residuals: 0.009\n",
      "Loss: 12.602, Residuals: 0.010\n",
      "Loss: 12.601, Residuals: 0.010\n",
      "Loss: 12.600, Residuals: 0.010\n",
      "Loss: 12.599, Residuals: 0.010\n",
      "Loss: 12.597, Residuals: 0.010\n",
      "Loss: 12.595, Residuals: 0.010\n",
      "Loss: 12.595, Residuals: 0.010\n",
      "Loss: 12.594, Residuals: 0.010\n",
      "Loss: 12.594, Residuals: 0.010\n",
      "Loss: 12.592, Residuals: 0.010\n",
      "Loss: 12.592, Residuals: 0.011\n",
      "Loss: 12.592, Residuals: 0.011\n",
      "Loss: 12.592, Residuals: 0.011\n",
      "Loss: 12.592, Residuals: 0.011\n",
      "Loss: 12.591, Residuals: 0.011\n",
      "Loss: 12.591, Residuals: 0.011\n",
      "Loss: 12.591, Residuals: 0.011\n",
      "Loss: 12.591, Residuals: 0.011\n",
      "Loss: 12.591, Residuals: 0.011\n",
      "Loss: 12.590, Residuals: 0.011\n",
      "Loss: 12.590, Residuals: 0.011\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.011\n",
      "Loss: 12.590, Residuals: 0.011\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Loss: 12.590, Residuals: 0.010\n",
      "Evidence 103.966\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.29e-01\n",
      "Loss: 42.520, Residuals: 0.017\n",
      "Loss: 42.439, Residuals: 0.015\n",
      "Loss: 42.291, Residuals: 0.015\n",
      "Loss: 42.064, Residuals: 0.017\n",
      "Loss: 41.925, Residuals: 0.018\n",
      "Loss: 41.911, Residuals: 0.017\n",
      "Loss: 41.804, Residuals: 0.019\n",
      "Loss: 41.796, Residuals: 0.019\n",
      "Loss: 41.736, Residuals: 0.022\n",
      "Loss: 41.729, Residuals: 0.023\n",
      "Loss: 41.667, Residuals: 0.023\n",
      "Loss: 41.662, Residuals: 0.021\n",
      "Loss: 41.617, Residuals: 0.022\n",
      "Loss: 41.550, Residuals: 0.025\n",
      "Loss: 41.544, Residuals: 0.024\n",
      "Loss: 41.538, Residuals: 0.024\n",
      "Loss: 41.530, Residuals: 0.025\n",
      "Loss: 41.529, Residuals: 0.024\n",
      "Loss: 41.506, Residuals: 0.024\n",
      "Loss: 41.502, Residuals: 0.024\n",
      "Loss: 41.462, Residuals: 0.026\n",
      "Loss: 41.441, Residuals: 0.025\n",
      "Loss: 41.425, Residuals: 0.027\n",
      "Loss: 41.300, Residuals: 0.029\n",
      "Loss: 41.203, Residuals: 0.026\n",
      "Loss: 41.184, Residuals: 0.029\n",
      "Loss: 41.161, Residuals: 0.031\n",
      "Loss: 41.119, Residuals: 0.031\n",
      "Loss: 41.090, Residuals: 0.030\n",
      "Loss: 41.083, Residuals: 0.030\n",
      "Loss: 41.026, Residuals: 0.032\n",
      "Loss: 41.019, Residuals: 0.032\n",
      "Loss: 41.007, Residuals: 0.033\n",
      "Loss: 40.985, Residuals: 0.034\n",
      "Loss: 40.981, Residuals: 0.034\n",
      "Loss: 40.974, Residuals: 0.034\n",
      "Loss: 40.962, Residuals: 0.035\n",
      "Loss: 40.960, Residuals: 0.034\n",
      "Loss: 40.955, Residuals: 0.034\n",
      "Loss: 40.947, Residuals: 0.035\n",
      "Loss: 40.946, Residuals: 0.036\n",
      "Loss: 40.943, Residuals: 0.036\n",
      "Loss: 40.938, Residuals: 0.036\n",
      "Loss: 40.935, Residuals: 0.036\n",
      "Loss: 40.934, Residuals: 0.036\n",
      "Loss: 40.930, Residuals: 0.037\n",
      "Loss: 40.930, Residuals: 0.037\n",
      "Loss: 40.927, Residuals: 0.037\n",
      "Loss: 40.927, Residuals: 0.037\n",
      "Loss: 40.926, Residuals: 0.037\n",
      "Loss: 40.925, Residuals: 0.037\n",
      "Loss: 40.925, Residuals: 0.037\n",
      "Loss: 40.925, Residuals: 0.037\n",
      "Loss: 40.924, Residuals: 0.037\n",
      "Loss: 40.924, Residuals: 0.038\n",
      "Loss: 40.924, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Loss: 40.923, Residuals: 0.038\n",
      "Evidence 294.362\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 8.95e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 84.367, Residuals: 0.032\n",
      "Loss: 84.289, Residuals: 0.030\n",
      "Loss: 84.184, Residuals: 0.035\n",
      "Loss: 84.032, Residuals: 0.035\n",
      "Loss: 84.024, Residuals: 0.036\n",
      "Loss: 83.966, Residuals: 0.036\n",
      "Loss: 83.961, Residuals: 0.036\n",
      "Loss: 83.950, Residuals: 0.036\n",
      "Loss: 83.931, Residuals: 0.036\n",
      "Loss: 83.903, Residuals: 0.036\n",
      "Loss: 83.902, Residuals: 0.036\n",
      "Loss: 83.900, Residuals: 0.036\n",
      "Loss: 83.897, Residuals: 0.036\n",
      "Loss: 83.892, Residuals: 0.036\n",
      "Loss: 83.891, Residuals: 0.036\n",
      "Loss: 83.889, Residuals: 0.036\n",
      "Loss: 83.889, Residuals: 0.036\n",
      "Loss: 83.889, Residuals: 0.036\n",
      "Loss: 83.888, Residuals: 0.036\n",
      "Loss: 83.888, Residuals: 0.036\n",
      "Loss: 83.887, Residuals: 0.036\n",
      "Loss: 83.887, Residuals: 0.036\n",
      "Loss: 83.887, Residuals: 0.036\n",
      "Loss: 83.887, Residuals: 0.036\n",
      "Evidence 404.083\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.67e+00\n",
      "Loss: 122.702, Residuals: 0.039\n",
      "Loss: 122.384, Residuals: 0.030\n",
      "Loss: 122.187, Residuals: 0.027\n",
      "Loss: 122.144, Residuals: 0.029\n",
      "Loss: 122.105, Residuals: 0.029\n",
      "Loss: 122.046, Residuals: 0.029\n",
      "Loss: 122.045, Residuals: 0.029\n",
      "Loss: 122.035, Residuals: 0.029\n",
      "Loss: 122.019, Residuals: 0.029\n",
      "Loss: 122.018, Residuals: 0.029\n",
      "Loss: 122.017, Residuals: 0.029\n",
      "Loss: 122.013, Residuals: 0.029\n",
      "Loss: 122.013, Residuals: 0.029\n",
      "Loss: 122.012, Residuals: 0.029\n",
      "Loss: 122.011, Residuals: 0.029\n",
      "Loss: 122.011, Residuals: 0.029\n",
      "Loss: 122.011, Residuals: 0.029\n",
      "Loss: 122.010, Residuals: 0.029\n",
      "Loss: 122.010, Residuals: 0.029\n",
      "Evidence 442.523\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.87e+00\n",
      "Loss: 141.504, Residuals: 0.036\n",
      "Loss: 141.221, Residuals: 0.028\n",
      "Loss: 141.041, Residuals: 0.027\n",
      "Loss: 141.033, Residuals: 0.026\n",
      "Loss: 140.973, Residuals: 0.026\n",
      "Loss: 140.936, Residuals: 0.025\n",
      "Loss: 140.933, Residuals: 0.026\n",
      "Loss: 140.929, Residuals: 0.025\n",
      "Loss: 140.926, Residuals: 0.025\n",
      "Loss: 140.926, Residuals: 0.025\n",
      "Loss: 140.925, Residuals: 0.025\n",
      "Loss: 140.924, Residuals: 0.025\n",
      "Loss: 140.923, Residuals: 0.025\n",
      "Loss: 140.922, Residuals: 0.025\n",
      "Loss: 140.922, Residuals: 0.025\n",
      "Loss: 140.922, Residuals: 0.025\n",
      "Loss: 140.922, Residuals: 0.025\n",
      "Loss: 140.922, Residuals: 0.025\n",
      "Loss: 140.922, Residuals: 0.025\n",
      "Evidence 452.938\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.82e+00\n",
      "Loss: 148.239, Residuals: 0.026\n",
      "Loss: 147.986, Residuals: 0.027\n",
      "Loss: 147.826, Residuals: 0.024\n",
      "Loss: 147.738, Residuals: 0.023\n",
      "Loss: 147.723, Residuals: 0.024\n",
      "Loss: 147.699, Residuals: 0.024\n",
      "Loss: 147.671, Residuals: 0.023\n",
      "Loss: 147.670, Residuals: 0.023\n",
      "Loss: 147.667, Residuals: 0.023\n",
      "Loss: 147.662, Residuals: 0.023\n",
      "Loss: 147.662, Residuals: 0.023\n",
      "Loss: 147.662, Residuals: 0.023\n",
      "Loss: 147.661, Residuals: 0.023\n",
      "Loss: 147.660, Residuals: 0.023\n",
      "Loss: 147.659, Residuals: 0.023\n",
      "Loss: 147.659, Residuals: 0.023\n",
      "Evidence 456.906\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.77e+00\n",
      "Loss: 150.462, Residuals: 0.022\n",
      "Loss: 150.343, Residuals: 0.023\n",
      "Loss: 150.238, Residuals: 0.022\n",
      "Loss: 150.173, Residuals: 0.022\n",
      "Loss: 150.160, Residuals: 0.021\n",
      "Loss: 150.140, Residuals: 0.021\n",
      "Loss: 150.125, Residuals: 0.021\n",
      "Loss: 150.123, Residuals: 0.021\n",
      "Loss: 150.122, Residuals: 0.020\n",
      "Loss: 150.122, Residuals: 0.021\n",
      "Loss: 150.121, Residuals: 0.021\n",
      "Loss: 150.120, Residuals: 0.020\n",
      "Loss: 150.120, Residuals: 0.020\n",
      "Evidence 458.958\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.76e+00\n",
      "Loss: 151.359, Residuals: 0.019\n",
      "Loss: 151.289, Residuals: 0.020\n",
      "Loss: 151.226, Residuals: 0.019\n",
      "Loss: 151.183, Residuals: 0.019\n",
      "Loss: 151.172, Residuals: 0.018\n",
      "Loss: 151.156, Residuals: 0.018\n",
      "Loss: 151.148, Residuals: 0.019\n",
      "Loss: 151.148, Residuals: 0.019\n",
      "Loss: 151.147, Residuals: 0.019\n",
      "Loss: 151.147, Residuals: 0.018\n",
      "Loss: 151.147, Residuals: 0.019\n",
      "Loss: 151.147, Residuals: 0.019\n",
      "Loss: 151.146, Residuals: 0.019\n",
      "Loss: 151.146, Residuals: 0.018\n",
      "Loss: 151.146, Residuals: 0.019\n",
      "Loss: 151.146, Residuals: 0.018\n",
      "Loss: 151.146, Residuals: 0.018\n",
      "Loss: 151.146, Residuals: 0.018\n",
      "Evidence 460.298\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.78e+00\n",
      "Loss: 151.800, Residuals: 0.018\n",
      "Loss: 151.748, Residuals: 0.017\n",
      "Loss: 151.697, Residuals: 0.017\n",
      "Loss: 151.658, Residuals: 0.016\n",
      "Loss: 151.653, Residuals: 0.018\n",
      "Loss: 151.645, Residuals: 0.017\n",
      "Loss: 151.640, Residuals: 0.017\n",
      "Loss: 151.640, Residuals: 0.017\n",
      "Loss: 151.639, Residuals: 0.017\n",
      "Loss: 151.638, Residuals: 0.017\n",
      "Loss: 151.638, Residuals: 0.017\n",
      "Loss: 151.638, Residuals: 0.017\n",
      "Loss: 151.637, Residuals: 0.017\n",
      "Loss: 151.637, Residuals: 0.017\n",
      "Loss: 151.637, Residuals: 0.017\n",
      "Loss: 151.637, Residuals: 0.017\n",
      "Evidence 461.372\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.80e+00\n",
      "Loss: 152.038, Residuals: 0.017\n",
      "Loss: 151.995, Residuals: 0.016\n",
      "Loss: 151.943, Residuals: 0.017\n",
      "Loss: 151.912, Residuals: 0.015\n",
      "Loss: 151.911, Residuals: 0.015\n",
      "Loss: 151.908, Residuals: 0.015\n",
      "Loss: 151.903, Residuals: 0.016\n",
      "Loss: 151.898, Residuals: 0.016\n",
      "Loss: 151.897, Residuals: 0.016\n",
      "Loss: 151.897, Residuals: 0.016\n",
      "Loss: 151.896, Residuals: 0.016\n",
      "Loss: 151.895, Residuals: 0.016\n",
      "Loss: 151.894, Residuals: 0.016\n",
      "Loss: 151.894, Residuals: 0.016\n",
      "Loss: 151.894, Residuals: 0.016\n",
      "Loss: 151.894, Residuals: 0.016\n",
      "Loss: 151.893, Residuals: 0.016\n",
      "Loss: 151.893, Residuals: 0.016\n",
      "Loss: 151.893, Residuals: 0.016\n",
      "Loss: 151.893, Residuals: 0.016\n",
      "Loss: 151.893, Residuals: 0.016\n",
      "Evidence 462.406\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.84e+00\n",
      "Loss: 152.169, Residuals: 0.016\n",
      "Loss: 152.131, Residuals: 0.015\n",
      "Loss: 152.092, Residuals: 0.015\n",
      "Loss: 152.056, Residuals: 0.015\n",
      "Loss: 152.053, Residuals: 0.015\n",
      "Loss: 152.049, Residuals: 0.015\n",
      "Loss: 152.042, Residuals: 0.015\n",
      "Loss: 152.041, Residuals: 0.015\n",
      "Loss: 152.040, Residuals: 0.015\n",
      "Loss: 152.038, Residuals: 0.015\n",
      "Loss: 152.037, Residuals: 0.015\n",
      "Loss: 152.037, Residuals: 0.015\n",
      "Loss: 152.036, Residuals: 0.015\n",
      "Loss: 152.036, Residuals: 0.015\n",
      "Loss: 152.035, Residuals: 0.015\n",
      "Loss: 152.035, Residuals: 0.015\n",
      "Loss: 152.035, Residuals: 0.015\n",
      "Loss: 152.035, Residuals: 0.015\n",
      "Loss: 152.035, Residuals: 0.015\n",
      "Loss: 152.035, Residuals: 0.015\n",
      "Loss: 152.034, Residuals: 0.015\n",
      "Loss: 152.034, Residuals: 0.015\n",
      "Evidence 463.418\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.87e+00\n",
      "Loss: 152.216, Residuals: 0.015\n",
      "Loss: 152.192, Residuals: 0.014\n",
      "Loss: 152.159, Residuals: 0.014\n",
      "Loss: 152.141, Residuals: 0.013\n",
      "Loss: 152.138, Residuals: 0.013\n",
      "Loss: 152.133, Residuals: 0.013\n",
      "Loss: 152.133, Residuals: 0.013\n",
      "Loss: 152.132, Residuals: 0.013\n",
      "Loss: 152.131, Residuals: 0.014\n",
      "Loss: 152.131, Residuals: 0.014\n",
      "Loss: 152.131, Residuals: 0.014\n",
      "Loss: 152.130, Residuals: 0.013\n",
      "Loss: 152.130, Residuals: 0.014\n",
      "Evidence 464.341\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.89e+00\n",
      "Loss: 152.291, Residuals: 0.014\n",
      "Loss: 152.273, Residuals: 0.013\n",
      "Loss: 152.248, Residuals: 0.013\n",
      "Loss: 152.229, Residuals: 0.012\n",
      "Loss: 152.227, Residuals: 0.012\n",
      "Loss: 152.224, Residuals: 0.012\n",
      "Loss: 152.224, Residuals: 0.012\n",
      "Loss: 152.223, Residuals: 0.012\n",
      "Loss: 152.221, Residuals: 0.012\n",
      "Loss: 152.221, Residuals: 0.012\n",
      "Loss: 152.221, Residuals: 0.012\n",
      "Loss: 152.221, Residuals: 0.012\n",
      "Loss: 152.221, Residuals: 0.012\n",
      "Loss: 152.221, Residuals: 0.012\n",
      "Evidence 465.139\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.90e+00\n",
      "Loss: 152.367, Residuals: 0.012\n",
      "Loss: 152.351, Residuals: 0.012\n",
      "Loss: 152.331, Residuals: 0.011\n",
      "Loss: 152.320, Residuals: 0.011\n",
      "Loss: 152.319, Residuals: 0.011\n",
      "Loss: 152.317, Residuals: 0.010\n",
      "Loss: 152.316, Residuals: 0.010\n",
      "Loss: 152.316, Residuals: 0.011\n",
      "Loss: 152.316, Residuals: 0.011\n",
      "Loss: 152.315, Residuals: 0.011\n",
      "Loss: 152.315, Residuals: 0.011\n",
      "Loss: 152.315, Residuals: 0.011\n",
      "Loss: 152.315, Residuals: 0.011\n",
      "Loss: 152.315, Residuals: 0.011\n",
      "Loss: 152.315, Residuals: 0.011\n",
      "Loss: 152.315, Residuals: 0.011\n",
      "Evidence 465.781\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.92e+00\n",
      "Loss: 152.443, Residuals: 0.011\n",
      "Loss: 152.432, Residuals: 0.010\n",
      "Loss: 152.417, Residuals: 0.010\n",
      "Loss: 152.415, Residuals: 0.009\n",
      "Loss: 152.412, Residuals: 0.009\n",
      "Loss: 152.408, Residuals: 0.009\n",
      "Loss: 152.408, Residuals: 0.010\n",
      "Loss: 152.408, Residuals: 0.009\n",
      "Loss: 152.408, Residuals: 0.009\n",
      "Loss: 152.408, Residuals: 0.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 152.407, Residuals: 0.009\n",
      "Loss: 152.407, Residuals: 0.009\n",
      "Evidence 466.274\n",
      "Updating hyper-parameters...\n",
      "Total samples: 38, Updated regularization: 1.93e+00\n",
      "Loss: 152.520, Residuals: 0.010\n",
      "Loss: 152.514, Residuals: 0.009\n",
      "Loss: 152.505, Residuals: 0.008\n",
      "Loss: 152.497, Residuals: 0.008\n",
      "Loss: 152.497, Residuals: 0.009\n",
      "Loss: 152.496, Residuals: 0.008\n",
      "Loss: 152.496, Residuals: 0.008\n",
      "Loss: 152.495, Residuals: 0.008\n",
      "Evidence 466.634\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.861, Residuals: -0.089\n",
      "Loss: 7.210, Residuals: -0.011\n",
      "Loss: 5.145, Residuals: -0.035\n",
      "Loss: 4.250, Residuals: -0.021\n",
      "Loss: 3.813, Residuals: -0.024\n",
      "Loss: 3.770, Residuals: -0.029\n",
      "Loss: 3.487, Residuals: -0.005\n",
      "Loss: 3.426, Residuals: 0.026\n",
      "Loss: 3.317, Residuals: 0.011\n",
      "Loss: 3.145, Residuals: -0.002\n",
      "Loss: 3.108, Residuals: -0.001\n",
      "Loss: 3.041, Residuals: -0.011\n",
      "Loss: 2.931, Residuals: -0.027\n",
      "Loss: 2.914, Residuals: -0.005\n",
      "Loss: 2.883, Residuals: -0.011\n",
      "Loss: 2.827, Residuals: -0.024\n",
      "Loss: 2.813, Residuals: -0.020\n",
      "Loss: 2.787, Residuals: -0.025\n",
      "Loss: 2.743, Residuals: -0.034\n",
      "Loss: 2.739, Residuals: -0.024\n",
      "Loss: 2.706, Residuals: -0.032\n",
      "Loss: 2.697, Residuals: -0.030\n",
      "Loss: 2.696, Residuals: -0.025\n",
      "Loss: 2.682, Residuals: -0.029\n",
      "Loss: 2.658, Residuals: -0.035\n",
      "Loss: 2.654, Residuals: -0.032\n",
      "Loss: 2.650, Residuals: -0.028\n",
      "Loss: 2.649, Residuals: -0.027\n",
      "Loss: 2.632, Residuals: -0.034\n",
      "Loss: 2.632, Residuals: -0.033\n",
      "Loss: 2.625, Residuals: -0.036\n",
      "Loss: 2.614, Residuals: -0.043\n",
      "Loss: 2.614, Residuals: -0.041\n",
      "Loss: 2.612, Residuals: -0.042\n",
      "Loss: 2.601, Residuals: -0.050\n",
      "Loss: 2.601, Residuals: -0.050\n",
      "Loss: 2.601, Residuals: -0.050\n",
      "Loss: 2.600, Residuals: -0.050\n",
      "Loss: 2.595, Residuals: -0.055\n",
      "Loss: 2.595, Residuals: -0.054\n",
      "Loss: 2.595, Residuals: -0.054\n",
      "Loss: 2.594, Residuals: -0.055\n",
      "Loss: 2.594, Residuals: -0.054\n",
      "Loss: 2.594, Residuals: -0.054\n",
      "Loss: 2.589, Residuals: -0.059\n",
      "Loss: 2.589, Residuals: -0.059\n",
      "Loss: 2.589, Residuals: -0.059\n",
      "Loss: 2.586, Residuals: -0.063\n",
      "Loss: 2.586, Residuals: -0.063\n",
      "Loss: 2.586, Residuals: -0.063\n",
      "Loss: 2.586, Residuals: -0.063\n",
      "Loss: 2.585, Residuals: -0.064\n",
      "Loss: 2.585, Residuals: -0.064\n",
      "Loss: 2.583, Residuals: -0.068\n",
      "Loss: 2.583, Residuals: -0.068\n",
      "Loss: 2.583, Residuals: -0.068\n",
      "Loss: 2.583, Residuals: -0.068\n",
      "Loss: 2.582, Residuals: -0.068\n",
      "Loss: 2.582, Residuals: -0.069\n",
      "Loss: 2.582, Residuals: -0.069\n",
      "Loss: 2.582, Residuals: -0.069\n",
      "Loss: 2.582, Residuals: -0.069\n",
      "Loss: 2.581, Residuals: -0.070\n",
      "Loss: 2.581, Residuals: -0.070\n",
      "Loss: 2.580, Residuals: -0.071\n",
      "Loss: 2.580, Residuals: -0.071\n",
      "Loss: 2.577, Residuals: -0.073\n",
      "Loss: 2.577, Residuals: -0.073\n",
      "Loss: 2.576, Residuals: -0.073\n",
      "Loss: 2.576, Residuals: -0.072\n",
      "Loss: 2.574, Residuals: -0.072\n",
      "Loss: 2.574, Residuals: -0.072\n",
      "Loss: 2.573, Residuals: -0.073\n",
      "Loss: 2.572, Residuals: -0.073\n",
      "Loss: 2.572, Residuals: -0.073\n",
      "Loss: 2.565, Residuals: -0.073\n",
      "Loss: 2.564, Residuals: -0.073\n",
      "Loss: 2.563, Residuals: -0.072\n",
      "Loss: 2.563, Residuals: -0.070\n",
      "Loss: 2.561, Residuals: -0.072\n",
      "Loss: 2.561, Residuals: -0.072\n",
      "Loss: 2.560, Residuals: -0.072\n",
      "Loss: 2.550, Residuals: -0.073\n",
      "Loss: 2.549, Residuals: -0.072\n",
      "Loss: 2.548, Residuals: -0.072\n",
      "Loss: 2.547, Residuals: -0.071\n",
      "Loss: 2.547, Residuals: -0.070\n",
      "Loss: 2.547, Residuals: -0.070\n",
      "Loss: 2.538, Residuals: -0.072\n",
      "Loss: 2.537, Residuals: -0.073\n",
      "Loss: 2.537, Residuals: -0.073\n",
      "Loss: 2.537, Residuals: -0.073\n",
      "Loss: 2.537, Residuals: -0.073\n",
      "Loss: 2.529, Residuals: -0.074\n",
      "Loss: 2.527, Residuals: -0.076\n",
      "Loss: 2.527, Residuals: -0.075\n",
      "Loss: 2.527, Residuals: -0.075\n",
      "Loss: 2.527, Residuals: -0.076\n",
      "Loss: 2.527, Residuals: -0.076\n",
      "Loss: 2.526, Residuals: -0.076\n",
      "Loss: 2.525, Residuals: -0.076\n",
      "Loss: 2.525, Residuals: -0.077\n",
      "Loss: 2.523, Residuals: -0.076\n",
      "Loss: 2.523, Residuals: -0.076\n",
      "Loss: 2.523, Residuals: -0.076\n",
      "Loss: 2.523, Residuals: -0.076\n",
      "Loss: 2.523, Residuals: -0.076\n",
      "Loss: 2.523, Residuals: -0.076\n",
      "Evidence -410.815\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 8.90e-03\n",
      "Loss: 13.095, Residuals: -0.050\n",
      "Loss: 13.093, Residuals: -0.051\n",
      "Loss: 13.014, Residuals: -0.046\n",
      "Loss: 12.885, Residuals: -0.036\n",
      "Loss: 12.857, Residuals: -0.036\n",
      "Loss: 12.805, Residuals: -0.034\n",
      "Loss: 12.805, Residuals: -0.033\n",
      "Evidence 115.604\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 5.10e-02\n",
      "Loss: 44.411, Residuals: -0.029\n",
      "Loss: 44.409, Residuals: -0.028\n",
      "Evidence 315.592\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.25e-01\n",
      "Loss: 96.851, Residuals: -0.029\n",
      "Evidence 413.971\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.63e-01\n",
      "Loss: 136.302, Residuals: -0.047\n",
      "Loss: 136.232, Residuals: -0.042\n",
      "Loss: 135.580, Residuals: -0.039\n",
      "Loss: 134.544, Residuals: -0.033\n",
      "Loss: 134.542, Residuals: -0.034\n",
      "Evidence 439.431\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.77e-01\n",
      "Loss: 149.789, Residuals: -0.039\n",
      "Loss: 149.758, Residuals: -0.040\n",
      "Loss: 149.712, Residuals: -0.040\n",
      "Loss: 148.044, Residuals: -0.036\n",
      "Loss: 148.039, Residuals: -0.036\n",
      "Evidence 450.582\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.83e-01\n",
      "Loss: 155.534, Residuals: -0.028\n",
      "Loss: 154.355, Residuals: -0.027\n",
      "Loss: 152.721, Residuals: -0.033\n",
      "Loss: 152.689, Residuals: -0.032\n",
      "Loss: 152.633, Residuals: -0.031\n",
      "Loss: 152.541, Residuals: -0.031\n",
      "Loss: 151.668, Residuals: -0.030\n",
      "Loss: 150.155, Residuals: -0.025\n",
      "Loss: 150.047, Residuals: -0.022\n",
      "Loss: 149.108, Residuals: -0.019\n",
      "Loss: 149.104, Residuals: -0.019\n",
      "Evidence 460.079\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.97e-01\n",
      "Loss: 155.591, Residuals: -0.016\n",
      "Loss: 154.671, Residuals: -0.013\n",
      "Loss: 154.642, Residuals: -0.012\n",
      "Loss: 154.355, Residuals: -0.012\n",
      "Loss: 154.201, Residuals: -0.011\n",
      "Loss: 154.185, Residuals: -0.010\n",
      "Loss: 153.557, Residuals: -0.010\n",
      "Loss: 153.554, Residuals: -0.010\n",
      "Evidence 463.451\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.03e-01\n",
      "Loss: 156.859, Residuals: -0.010\n",
      "Loss: 156.707, Residuals: -0.010\n",
      "Loss: 156.697, Residuals: -0.010\n",
      "Loss: 155.314, Residuals: -0.008\n",
      "Loss: 155.199, Residuals: -0.007\n",
      "Loss: 155.192, Residuals: -0.008\n",
      "Evidence 466.775\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.09e-01\n",
      "Loss: 157.659, Residuals: -0.007\n",
      "Loss: 157.577, Residuals: -0.008\n",
      "Loss: 157.429, Residuals: -0.008\n",
      "Loss: 156.328, Residuals: -0.007\n",
      "Loss: 156.204, Residuals: -0.006\n",
      "Loss: 156.197, Residuals: -0.006\n",
      "Evidence 469.359\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.14e-01\n",
      "Loss: 157.922, Residuals: -0.006\n",
      "Loss: 157.828, Residuals: -0.007\n",
      "Loss: 157.013, Residuals: -0.006\n",
      "Loss: 157.000, Residuals: -0.005\n",
      "Evidence 471.058\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.17e-01\n",
      "Loss: 158.219, Residuals: -0.007\n",
      "Loss: 158.101, Residuals: -0.008\n",
      "Loss: 153.459, Residuals: 0.002\n",
      "Loss: 153.448, Residuals: 0.002\n",
      "Evidence 475.109\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.45e-01\n",
      "Loss: 157.246, Residuals: -0.006\n",
      "Loss: 157.241, Residuals: -0.006\n",
      "Evidence 476.266\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.48e-01\n",
      "Loss: 156.711, Residuals: -0.003\n",
      "Loss: 156.615, Residuals: -0.002\n",
      "Loss: 156.611, Residuals: -0.003\n",
      "Evidence 478.509\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.69e-01\n",
      "Loss: 157.746, Residuals: -0.004\n",
      "Loss: 157.743, Residuals: -0.005\n",
      "Evidence 478.939\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 13.051, Residuals: -0.098\n",
      "Loss: 7.129, Residuals: -0.022\n",
      "Loss: 5.046, Residuals: -0.042\n",
      "Loss: 4.339, Residuals: -0.037\n",
      "Loss: 3.842, Residuals: -0.046\n",
      "Loss: 3.482, Residuals: -0.057\n",
      "Loss: 3.424, Residuals: 0.027\n",
      "Loss: 3.315, Residuals: 0.019\n",
      "Loss: 3.124, Residuals: 0.003\n",
      "Loss: 2.861, Residuals: -0.026\n",
      "Loss: 2.825, Residuals: -0.016\n",
      "Loss: 2.807, Residuals: -0.017\n",
      "Loss: 2.795, Residuals: -0.014\n",
      "Loss: 2.772, Residuals: -0.018\n",
      "Loss: 2.730, Residuals: -0.025\n",
      "Loss: 2.724, Residuals: -0.020\n",
      "Loss: 2.673, Residuals: -0.028\n",
      "Loss: 2.593, Residuals: -0.043\n",
      "Loss: 2.581, Residuals: -0.037\n",
      "Loss: 2.570, Residuals: -0.032\n",
      "Loss: 2.550, Residuals: -0.037\n",
      "Loss: 2.547, Residuals: -0.036\n",
      "Loss: 2.520, Residuals: -0.043\n",
      "Loss: 2.513, Residuals: -0.042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.501, Residuals: -0.045\n",
      "Loss: 2.480, Residuals: -0.052\n",
      "Loss: 2.479, Residuals: -0.048\n",
      "Loss: 2.469, Residuals: -0.052\n",
      "Loss: 2.452, Residuals: -0.060\n",
      "Loss: 2.450, Residuals: -0.061\n",
      "Loss: 2.433, Residuals: -0.069\n",
      "Loss: 2.432, Residuals: -0.069\n",
      "Loss: 2.427, Residuals: -0.071\n",
      "Loss: 2.419, Residuals: -0.076\n",
      "Loss: 2.414, Residuals: -0.080\n",
      "Loss: 2.414, Residuals: -0.080\n",
      "Loss: 2.410, Residuals: -0.082\n",
      "Loss: 2.409, Residuals: -0.080\n",
      "Loss: 2.399, Residuals: -0.084\n",
      "Loss: 2.397, Residuals: -0.084\n",
      "Loss: 2.378, Residuals: -0.093\n",
      "Loss: 2.370, Residuals: -0.095\n",
      "Loss: 2.368, Residuals: -0.092\n",
      "Loss: 2.365, Residuals: -0.092\n",
      "Loss: 2.340, Residuals: -0.099\n",
      "Loss: 2.334, Residuals: -0.095\n",
      "Loss: 2.327, Residuals: -0.094\n",
      "Loss: 2.327, Residuals: -0.094\n",
      "Loss: 2.326, Residuals: -0.094\n",
      "Loss: 2.326, Residuals: -0.093\n",
      "Loss: 2.310, Residuals: -0.096\n",
      "Loss: 2.310, Residuals: -0.095\n",
      "Loss: 2.309, Residuals: -0.094\n",
      "Loss: 2.307, Residuals: -0.094\n",
      "Loss: 2.303, Residuals: -0.093\n",
      "Loss: 2.303, Residuals: -0.094\n",
      "Loss: 2.303, Residuals: -0.093\n",
      "Loss: 2.291, Residuals: -0.094\n",
      "Loss: 2.291, Residuals: -0.093\n",
      "Loss: 2.290, Residuals: -0.093\n",
      "Loss: 2.278, Residuals: -0.094\n",
      "Loss: 2.278, Residuals: -0.093\n",
      "Loss: 2.278, Residuals: -0.093\n",
      "Loss: 2.267, Residuals: -0.094\n",
      "Loss: 2.267, Residuals: -0.093\n",
      "Loss: 2.267, Residuals: -0.093\n",
      "Loss: 2.264, Residuals: -0.094\n",
      "Loss: 2.264, Residuals: -0.093\n",
      "Loss: 2.264, Residuals: -0.092\n",
      "Loss: 2.264, Residuals: -0.093\n",
      "Loss: 2.264, Residuals: -0.093\n",
      "Loss: 2.252, Residuals: -0.093\n",
      "Loss: 2.252, Residuals: -0.092\n",
      "Loss: 2.252, Residuals: -0.093\n",
      "Loss: 2.244, Residuals: -0.093\n",
      "Loss: 2.244, Residuals: -0.091\n",
      "Loss: 2.244, Residuals: -0.090\n",
      "Loss: 2.243, Residuals: -0.090\n",
      "Loss: 2.243, Residuals: -0.090\n",
      "Loss: 2.237, Residuals: -0.092\n",
      "Loss: 2.237, Residuals: -0.092\n",
      "Loss: 2.237, Residuals: -0.091\n",
      "Loss: 2.236, Residuals: -0.091\n",
      "Loss: 2.231, Residuals: -0.091\n",
      "Loss: 2.231, Residuals: -0.091\n",
      "Loss: 2.231, Residuals: -0.091\n",
      "Loss: 2.221, Residuals: -0.092\n",
      "Loss: 2.220, Residuals: -0.091\n",
      "Loss: 2.220, Residuals: -0.091\n",
      "Loss: 2.220, Residuals: -0.091\n",
      "Loss: 2.220, Residuals: -0.091\n",
      "Evidence -404.302\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.14e-03\n",
      "Loss: 12.747, Residuals: -0.073\n",
      "Loss: 12.730, Residuals: -0.072\n",
      "Loss: 12.602, Residuals: -0.064\n",
      "Loss: 12.460, Residuals: -0.045\n",
      "Loss: 12.457, Residuals: -0.048\n",
      "Loss: 12.456, Residuals: -0.047\n",
      "Loss: 12.447, Residuals: -0.046\n",
      "Loss: 12.432, Residuals: -0.044\n",
      "Loss: 12.404, Residuals: -0.041\n",
      "Loss: 12.394, Residuals: -0.036\n",
      "Loss: 12.391, Residuals: -0.036\n",
      "Loss: 12.391, Residuals: -0.037\n",
      "Loss: 12.391, Residuals: -0.037\n",
      "Loss: 12.391, Residuals: -0.037\n",
      "Loss: 12.354, Residuals: -0.033\n",
      "Loss: 12.306, Residuals: -0.025\n",
      "Loss: 12.305, Residuals: -0.025\n",
      "Loss: 12.303, Residuals: -0.025\n",
      "Loss: 12.301, Residuals: -0.025\n",
      "Loss: 12.298, Residuals: -0.025\n",
      "Loss: 12.297, Residuals: -0.024\n",
      "Loss: 12.297, Residuals: -0.025\n",
      "Loss: 12.297, Residuals: -0.024\n",
      "Loss: 12.297, Residuals: -0.025\n",
      "Evidence 116.978\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 2.35e-02\n",
      "Loss: 44.243, Residuals: -0.014\n",
      "Loss: 44.240, Residuals: -0.017\n",
      "Loss: 44.235, Residuals: -0.017\n",
      "Loss: 44.190, Residuals: -0.017\n",
      "Loss: 44.116, Residuals: -0.018\n",
      "Loss: 44.047, Residuals: -0.021\n",
      "Loss: 44.033, Residuals: -0.021\n",
      "Loss: 44.032, Residuals: -0.020\n",
      "Loss: 44.031, Residuals: -0.021\n",
      "Loss: 43.994, Residuals: -0.019\n",
      "Loss: 43.993, Residuals: -0.018\n",
      "Loss: 43.992, Residuals: -0.018\n",
      "Loss: 43.970, Residuals: -0.017\n",
      "Loss: 43.970, Residuals: -0.018\n",
      "Loss: 43.951, Residuals: -0.017\n",
      "Loss: 43.917, Residuals: -0.015\n",
      "Loss: 43.917, Residuals: -0.015\n",
      "Loss: 43.917, Residuals: -0.015\n",
      "Loss: 43.917, Residuals: -0.015\n",
      "Loss: 43.907, Residuals: -0.014\n",
      "Loss: 43.906, Residuals: -0.015\n",
      "Loss: 43.906, Residuals: -0.015\n",
      "Loss: 43.906, Residuals: -0.014\n",
      "Loss: 43.896, Residuals: -0.014\n",
      "Loss: 43.896, Residuals: -0.013\n",
      "Loss: 43.849, Residuals: -0.013\n",
      "Loss: 43.848, Residuals: -0.013\n",
      "Loss: 43.848, Residuals: -0.013\n",
      "Evidence 317.901\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.98e-02\n",
      "Loss: 94.249, Residuals: -0.021\n",
      "Loss: 94.092, Residuals: -0.015\n",
      "Loss: 93.901, Residuals: -0.025\n",
      "Loss: 93.897, Residuals: -0.025\n",
      "Loss: 93.895, Residuals: -0.024\n",
      "Loss: 93.894, Residuals: -0.025\n",
      "Loss: 93.852, Residuals: -0.025\n",
      "Loss: 93.781, Residuals: -0.026\n",
      "Loss: 93.658, Residuals: -0.026\n",
      "Loss: 93.651, Residuals: -0.025\n",
      "Loss: 93.580, Residuals: -0.025\n",
      "Loss: 93.031, Residuals: -0.022\n",
      "Loss: 93.020, Residuals: -0.024\n",
      "Loss: 93.002, Residuals: -0.021\n",
      "Loss: 92.836, Residuals: -0.019\n",
      "Loss: 92.000, Residuals: -0.021\n",
      "Loss: 91.909, Residuals: -0.011\n",
      "Loss: 91.803, Residuals: -0.014\n",
      "Loss: 91.630, Residuals: -0.015\n",
      "Loss: 91.619, Residuals: -0.013\n",
      "Loss: 91.616, Residuals: -0.014\n",
      "Loss: 91.585, Residuals: -0.014\n",
      "Loss: 91.532, Residuals: -0.015\n",
      "Loss: 91.526, Residuals: -0.015\n",
      "Loss: 91.525, Residuals: -0.015\n",
      "Loss: 91.523, Residuals: -0.015\n",
      "Loss: 91.523, Residuals: -0.015\n",
      "Evidence 418.703\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.57e-01\n",
      "Loss: 132.530, Residuals: -0.018\n",
      "Loss: 132.101, Residuals: -0.027\n",
      "Loss: 132.088, Residuals: -0.028\n",
      "Loss: 131.972, Residuals: -0.029\n",
      "Loss: 131.784, Residuals: -0.032\n",
      "Loss: 131.556, Residuals: -0.032\n",
      "Loss: 131.546, Residuals: -0.030\n",
      "Loss: 131.529, Residuals: -0.031\n",
      "Loss: 131.526, Residuals: -0.033\n",
      "Loss: 131.414, Residuals: -0.033\n",
      "Loss: 131.394, Residuals: -0.034\n",
      "Loss: 131.389, Residuals: -0.035\n",
      "Loss: 131.384, Residuals: -0.035\n",
      "Loss: 131.202, Residuals: -0.036\n",
      "Loss: 131.200, Residuals: -0.036\n",
      "Loss: 131.134, Residuals: -0.036\n",
      "Loss: 131.124, Residuals: -0.036\n",
      "Loss: 131.121, Residuals: -0.036\n",
      "Loss: 131.020, Residuals: -0.036\n",
      "Loss: 131.019, Residuals: -0.037\n",
      "Loss: 130.974, Residuals: -0.037\n",
      "Loss: 130.942, Residuals: -0.038\n",
      "Loss: 130.937, Residuals: -0.039\n",
      "Loss: 130.928, Residuals: -0.039\n",
      "Loss: 130.915, Residuals: -0.038\n",
      "Loss: 130.911, Residuals: -0.038\n",
      "Loss: 130.873, Residuals: -0.038\n",
      "Loss: 130.865, Residuals: -0.038\n",
      "Loss: 130.803, Residuals: -0.039\n",
      "Loss: 130.755, Residuals: -0.039\n",
      "Loss: 129.696, Residuals: -0.048\n",
      "Loss: 129.147, Residuals: -0.048\n",
      "Loss: 128.341, Residuals: -0.043\n",
      "Loss: 127.214, Residuals: -0.037\n",
      "Loss: 127.171, Residuals: -0.034\n",
      "Loss: 127.135, Residuals: -0.037\n",
      "Loss: 126.810, Residuals: -0.036\n",
      "Loss: 126.295, Residuals: -0.033\n",
      "Loss: 125.925, Residuals: -0.027\n",
      "Loss: 125.870, Residuals: -0.025\n",
      "Loss: 125.858, Residuals: -0.026\n",
      "Loss: 125.757, Residuals: -0.026\n",
      "Loss: 125.745, Residuals: -0.026\n",
      "Loss: 125.743, Residuals: -0.026\n",
      "Loss: 125.741, Residuals: -0.026\n",
      "Loss: 125.739, Residuals: -0.026\n",
      "Loss: 123.966, Residuals: -0.028\n",
      "Loss: 123.793, Residuals: -0.023\n",
      "Loss: 123.531, Residuals: -0.025\n",
      "Loss: 123.524, Residuals: -0.025\n",
      "Loss: 123.459, Residuals: -0.025\n",
      "Loss: 123.347, Residuals: -0.025\n",
      "Loss: 123.324, Residuals: -0.026\n",
      "Loss: 123.285, Residuals: -0.026\n",
      "Loss: 123.281, Residuals: -0.025\n",
      "Loss: 123.148, Residuals: -0.024\n",
      "Loss: 123.147, Residuals: -0.024\n",
      "Loss: 123.116, Residuals: -0.024\n",
      "Loss: 123.091, Residuals: -0.024\n",
      "Loss: 123.090, Residuals: -0.024\n",
      "Loss: 123.037, Residuals: -0.023\n",
      "Loss: 123.021, Residuals: -0.023\n",
      "Loss: 123.020, Residuals: -0.023\n",
      "Loss: 122.971, Residuals: -0.022\n",
      "Loss: 122.960, Residuals: -0.022\n",
      "Loss: 122.958, Residuals: -0.022\n",
      "Loss: 122.948, Residuals: -0.022\n",
      "Loss: 122.930, Residuals: -0.021\n",
      "Loss: 122.919, Residuals: -0.021\n",
      "Loss: 122.908, Residuals: -0.021\n",
      "Loss: 122.887, Residuals: -0.021\n",
      "Loss: 122.872, Residuals: -0.021\n",
      "Loss: 122.241, Residuals: -0.022\n",
      "Loss: 122.038, Residuals: -0.019\n",
      "Loss: 121.697, Residuals: -0.017\n",
      "Loss: 121.357, Residuals: -0.013\n",
      "Loss: 121.229, Residuals: -0.011\n",
      "Loss: 120.987, Residuals: -0.009\n",
      "Loss: 120.564, Residuals: -0.006\n",
      "Loss: 120.476, Residuals: -0.006\n",
      "Loss: 120.311, Residuals: -0.005\n",
      "Loss: 120.047, Residuals: -0.001\n",
      "Loss: 119.992, Residuals: 0.000\n",
      "Loss: 119.899, Residuals: 0.001\n",
      "Loss: 119.872, Residuals: 0.002\n",
      "Loss: 119.826, Residuals: 0.003\n",
      "Loss: 119.823, Residuals: 0.003\n",
      "Loss: 119.793, Residuals: 0.004\n",
      "Loss: 119.753, Residuals: 0.005\n",
      "Loss: 119.749, Residuals: 0.005\n",
      "Loss: 119.745, Residuals: 0.006\n",
      "Loss: 119.738, Residuals: 0.006\n",
      "Loss: 119.738, Residuals: 0.006\n",
      "Loss: 119.733, Residuals: 0.006\n",
      "Loss: 119.725, Residuals: 0.006\n",
      "Loss: 119.724, Residuals: 0.006\n",
      "Loss: 119.724, Residuals: 0.006\n",
      "Loss: 119.724, Residuals: 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 119.723, Residuals: 0.006\n",
      "Loss: 119.722, Residuals: 0.006\n",
      "Loss: 119.722, Residuals: 0.006\n",
      "Loss: 119.722, Residuals: 0.006\n",
      "Loss: 119.722, Residuals: 0.006\n",
      "Loss: 119.722, Residuals: 0.006\n",
      "Evidence 463.197\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.96e-01\n",
      "Loss: 143.795, Residuals: 0.009\n",
      "Loss: 143.557, Residuals: 0.007\n",
      "Loss: 143.274, Residuals: 0.006\n",
      "Loss: 142.864, Residuals: 0.007\n",
      "Loss: 142.848, Residuals: 0.007\n",
      "Loss: 142.704, Residuals: 0.007\n",
      "Loss: 142.523, Residuals: 0.008\n",
      "Loss: 142.522, Residuals: 0.007\n",
      "Loss: 142.519, Residuals: 0.007\n",
      "Loss: 142.514, Residuals: 0.007\n",
      "Loss: 142.511, Residuals: 0.007\n",
      "Loss: 142.509, Residuals: 0.007\n",
      "Loss: 142.498, Residuals: 0.007\n",
      "Loss: 142.496, Residuals: 0.007\n",
      "Loss: 142.493, Residuals: 0.007\n",
      "Loss: 142.493, Residuals: 0.007\n",
      "Loss: 142.492, Residuals: 0.007\n",
      "Loss: 142.491, Residuals: 0.007\n",
      "Loss: 142.490, Residuals: 0.007\n",
      "Evidence 487.627\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.20e+00\n",
      "Loss: 153.407, Residuals: 0.009\n",
      "Loss: 153.376, Residuals: 0.006\n",
      "Loss: 153.091, Residuals: 0.007\n",
      "Loss: 152.663, Residuals: 0.008\n",
      "Loss: 152.657, Residuals: 0.008\n",
      "Loss: 152.604, Residuals: 0.007\n",
      "Loss: 152.508, Residuals: 0.007\n",
      "Loss: 152.329, Residuals: 0.006\n",
      "Loss: 152.322, Residuals: 0.006\n",
      "Loss: 152.091, Residuals: 0.005\n",
      "Loss: 152.075, Residuals: 0.004\n",
      "Loss: 152.071, Residuals: 0.004\n",
      "Loss: 152.063, Residuals: 0.004\n",
      "Loss: 152.049, Residuals: 0.004\n",
      "Loss: 152.023, Residuals: 0.004\n",
      "Loss: 151.977, Residuals: 0.005\n",
      "Loss: 151.973, Residuals: 0.005\n",
      "Loss: 151.941, Residuals: 0.005\n",
      "Loss: 151.888, Residuals: 0.005\n",
      "Loss: 151.886, Residuals: 0.004\n",
      "Loss: 151.882, Residuals: 0.004\n",
      "Loss: 151.874, Residuals: 0.004\n",
      "Loss: 151.860, Residuals: 0.004\n",
      "Loss: 151.849, Residuals: 0.004\n",
      "Loss: 151.837, Residuals: 0.004\n",
      "Loss: 151.832, Residuals: 0.004\n",
      "Loss: 151.823, Residuals: 0.004\n",
      "Loss: 151.822, Residuals: 0.004\n",
      "Loss: 151.819, Residuals: 0.004\n",
      "Loss: 151.815, Residuals: 0.004\n",
      "Loss: 151.815, Residuals: 0.004\n",
      "Loss: 151.814, Residuals: 0.004\n",
      "Loss: 151.814, Residuals: 0.004\n",
      "Loss: 151.812, Residuals: 0.004\n",
      "Loss: 151.812, Residuals: 0.004\n",
      "Loss: 151.811, Residuals: 0.004\n",
      "Evidence 493.133\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.56e+00\n",
      "Loss: 155.177, Residuals: 0.006\n",
      "Loss: 154.947, Residuals: 0.004\n",
      "Loss: 154.874, Residuals: 0.005\n",
      "Loss: 154.765, Residuals: 0.005\n",
      "Loss: 154.679, Residuals: 0.004\n",
      "Loss: 154.675, Residuals: 0.003\n",
      "Loss: 154.650, Residuals: 0.003\n",
      "Loss: 154.632, Residuals: 0.003\n",
      "Loss: 154.631, Residuals: 0.002\n",
      "Loss: 154.630, Residuals: 0.003\n",
      "Loss: 154.630, Residuals: 0.003\n",
      "Loss: 154.628, Residuals: 0.003\n",
      "Loss: 154.628, Residuals: 0.003\n",
      "Loss: 154.628, Residuals: 0.003\n",
      "Loss: 154.627, Residuals: 0.003\n",
      "Loss: 154.627, Residuals: 0.003\n",
      "Loss: 154.627, Residuals: 0.003\n",
      "Loss: 154.626, Residuals: 0.003\n",
      "Evidence 499.629\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.66e+00\n",
      "Loss: 156.575, Residuals: 0.004\n",
      "Loss: 156.528, Residuals: 0.003\n",
      "Loss: 156.462, Residuals: 0.003\n",
      "Loss: 156.416, Residuals: 0.001\n",
      "Loss: 156.412, Residuals: 0.002\n",
      "Loss: 156.406, Residuals: 0.002\n",
      "Loss: 156.396, Residuals: 0.001\n",
      "Loss: 156.390, Residuals: 0.001\n",
      "Loss: 156.390, Residuals: 0.001\n",
      "Loss: 156.390, Residuals: 0.001\n",
      "Loss: 156.389, Residuals: 0.001\n",
      "Loss: 156.389, Residuals: 0.001\n",
      "Loss: 156.389, Residuals: 0.001\n",
      "Loss: 156.389, Residuals: 0.001\n",
      "Evidence 501.898\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.68e+00\n",
      "Loss: 157.285, Residuals: 0.001\n",
      "Loss: 157.237, Residuals: 0.000\n",
      "Loss: 157.214, Residuals: -0.000\n",
      "Loss: 157.211, Residuals: 0.000\n",
      "Loss: 157.206, Residuals: -0.000\n",
      "Loss: 157.200, Residuals: -0.000\n",
      "Loss: 157.200, Residuals: -0.000\n",
      "Loss: 157.200, Residuals: -0.000\n",
      "Loss: 157.200, Residuals: -0.000\n",
      "Loss: 157.199, Residuals: -0.001\n",
      "Loss: 157.199, Residuals: -0.001\n",
      "Evidence 503.199\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.69e+00\n",
      "Loss: 157.664, Residuals: -0.001\n",
      "Loss: 157.634, Residuals: -0.000\n",
      "Loss: 157.623, Residuals: -0.002\n",
      "Loss: 157.619, Residuals: -0.001\n",
      "Loss: 157.619, Residuals: -0.001\n",
      "Loss: 157.617, Residuals: -0.001\n",
      "Loss: 157.617, Residuals: -0.001\n",
      "Loss: 157.616, Residuals: -0.001\n",
      "Loss: 157.616, Residuals: -0.001\n",
      "Loss: 157.616, Residuals: -0.001\n",
      "Loss: 157.616, Residuals: -0.001\n",
      "Evidence 504.073\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.70e+00\n",
      "Loss: 157.896, Residuals: -0.002\n",
      "Loss: 157.879, Residuals: -0.001\n",
      "Loss: 157.872, Residuals: -0.002\n",
      "Loss: 157.871, Residuals: -0.002\n",
      "Loss: 157.869, Residuals: -0.002\n",
      "Loss: 157.869, Residuals: -0.002\n",
      "Loss: 157.868, Residuals: -0.002\n",
      "Loss: 157.868, Residuals: -0.002\n",
      "Loss: 157.868, Residuals: -0.002\n",
      "Loss: 157.868, Residuals: -0.002\n",
      "Loss: 157.868, Residuals: -0.002\n",
      "Evidence 504.697\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.71e+00\n",
      "Loss: 158.076, Residuals: -0.002\n",
      "Loss: 158.068, Residuals: -0.002\n",
      "Loss: 158.062, Residuals: -0.003\n",
      "Loss: 158.060, Residuals: -0.003\n",
      "Loss: 158.058, Residuals: -0.002\n",
      "Loss: 158.058, Residuals: -0.002\n",
      "Loss: 158.058, Residuals: -0.002\n",
      "Loss: 158.058, Residuals: -0.002\n",
      "Loss: 158.057, Residuals: -0.003\n",
      "Loss: 158.057, Residuals: -0.003\n",
      "Loss: 158.057, Residuals: -0.003\n",
      "Loss: 158.057, Residuals: -0.003\n",
      "Loss: 158.057, Residuals: -0.003\n",
      "Loss: 158.057, Residuals: -0.003\n",
      "Evidence 505.150\n",
      "Pass count  1\n",
      "Total samples: 39, Updated regularization: 1.00e-05\n",
      "Loss: 12.812, Residuals: -0.060\n",
      "Loss: 7.426, Residuals: -0.004\n",
      "Loss: 5.102, Residuals: -0.052\n",
      "Loss: 4.473, Residuals: -0.003\n",
      "Loss: 4.178, Residuals: 0.067\n",
      "Loss: 3.826, Residuals: -0.034\n",
      "Loss: 3.778, Residuals: -0.015\n",
      "Loss: 3.686, Residuals: -0.019\n",
      "Loss: 3.523, Residuals: -0.027\n",
      "Loss: 3.453, Residuals: 0.007\n",
      "Loss: 3.337, Residuals: -0.017\n",
      "Loss: 3.208, Residuals: -0.033\n",
      "Loss: 3.196, Residuals: -0.022\n",
      "Loss: 3.180, Residuals: -0.032\n",
      "Loss: 3.151, Residuals: -0.036\n",
      "Loss: 3.098, Residuals: -0.044\n",
      "Loss: 3.089, Residuals: -0.027\n",
      "Loss: 3.072, Residuals: -0.032\n",
      "Loss: 3.042, Residuals: -0.042\n",
      "Loss: 3.030, Residuals: -0.046\n",
      "Loss: 3.009, Residuals: -0.052\n",
      "Loss: 2.975, Residuals: -0.064\n",
      "Loss: 2.971, Residuals: -0.056\n",
      "Loss: 2.944, Residuals: -0.065\n",
      "Loss: 2.940, Residuals: -0.064\n",
      "Loss: 2.911, Residuals: -0.074\n",
      "Loss: 2.910, Residuals: -0.072\n",
      "Loss: 2.910, Residuals: -0.073\n",
      "Loss: 2.907, Residuals: -0.074\n",
      "Loss: 2.885, Residuals: -0.082\n",
      "Loss: 2.882, Residuals: -0.080\n",
      "Loss: 2.882, Residuals: -0.081\n",
      "Loss: 2.881, Residuals: -0.079\n",
      "Loss: 2.880, Residuals: -0.080\n",
      "Loss: 2.878, Residuals: -0.080\n",
      "Loss: 2.874, Residuals: -0.081\n",
      "Loss: 2.867, Residuals: -0.084\n",
      "Loss: 2.867, Residuals: -0.084\n",
      "Evidence -413.692\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 9.81e-03\n",
      "Loss: 14.016, Residuals: -0.070\n",
      "Loss: 14.012, Residuals: -0.071\n",
      "Loss: 13.978, Residuals: -0.067\n",
      "Loss: 13.916, Residuals: -0.061\n",
      "Loss: 13.817, Residuals: -0.049\n",
      "Loss: 13.808, Residuals: -0.043\n",
      "Loss: 13.792, Residuals: -0.041\n",
      "Loss: 13.761, Residuals: -0.037\n",
      "Loss: 13.706, Residuals: -0.032\n",
      "Loss: 13.701, Residuals: -0.031\n",
      "Loss: 13.654, Residuals: -0.025\n",
      "Loss: 13.653, Residuals: -0.027\n",
      "Loss: 13.643, Residuals: -0.024\n",
      "Loss: 13.625, Residuals: -0.021\n",
      "Loss: 13.620, Residuals: -0.018\n",
      "Loss: 13.575, Residuals: -0.013\n",
      "Loss: 13.574, Residuals: -0.012\n",
      "Loss: 13.563, Residuals: -0.010\n",
      "Loss: 13.551, Residuals: -0.009\n",
      "Loss: 13.454, Residuals: -0.003\n",
      "Loss: 13.452, Residuals: -0.002\n",
      "Loss: 13.448, Residuals: -0.002\n",
      "Loss: 13.443, Residuals: -0.002\n",
      "Loss: 13.434, Residuals: -0.001\n",
      "Loss: 13.418, Residuals: 0.003\n",
      "Loss: 13.392, Residuals: 0.004\n",
      "Loss: 13.391, Residuals: 0.005\n",
      "Loss: 13.387, Residuals: 0.005\n",
      "Loss: 13.348, Residuals: 0.006\n",
      "Loss: 13.348, Residuals: 0.005\n",
      "Evidence 101.554\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 2.09e-01\n",
      "Loss: 42.491, Residuals: 0.005\n",
      "Evidence 296.462\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 6.25e-01\n",
      "Loss: 87.783, Residuals: -0.007\n",
      "Loss: 87.006, Residuals: 0.005\n",
      "Loss: 86.995, Residuals: 0.006\n",
      "Loss: 86.893, Residuals: 0.006\n",
      "Loss: 86.712, Residuals: 0.006\n",
      "Loss: 86.423, Residuals: 0.007\n",
      "Loss: 86.394, Residuals: 0.003\n",
      "Loss: 86.117, Residuals: 0.004\n",
      "Loss: 86.115, Residuals: 0.004\n",
      "Evidence 401.597\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.04e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 124.738, Residuals: 0.000\n",
      "Loss: 124.095, Residuals: -0.001\n",
      "Loss: 123.590, Residuals: -0.006\n",
      "Loss: 123.431, Residuals: 0.002\n",
      "Loss: 123.397, Residuals: -0.001\n",
      "Loss: 122.419, Residuals: -0.001\n",
      "Loss: 122.221, Residuals: 0.001\n",
      "Loss: 122.212, Residuals: 0.001\n",
      "Loss: 122.197, Residuals: 0.001\n",
      "Loss: 121.749, Residuals: 0.001\n",
      "Loss: 121.671, Residuals: 0.002\n",
      "Loss: 121.664, Residuals: 0.002\n",
      "Loss: 121.656, Residuals: 0.002\n",
      "Loss: 121.381, Residuals: 0.002\n",
      "Loss: 121.370, Residuals: 0.003\n",
      "Loss: 121.367, Residuals: 0.003\n",
      "Loss: 121.350, Residuals: 0.003\n",
      "Loss: 121.182, Residuals: 0.004\n",
      "Loss: 120.918, Residuals: 0.008\n",
      "Loss: 120.915, Residuals: 0.008\n",
      "Loss: 120.911, Residuals: 0.008\n",
      "Loss: 120.906, Residuals: 0.008\n",
      "Loss: 120.896, Residuals: 0.008\n",
      "Loss: 120.809, Residuals: 0.009\n",
      "Loss: 120.807, Residuals: 0.009\n",
      "Loss: 120.803, Residuals: 0.009\n",
      "Loss: 120.629, Residuals: 0.018\n",
      "Loss: 120.607, Residuals: 0.016\n",
      "Loss: 120.592, Residuals: 0.018\n",
      "Loss: 120.565, Residuals: 0.017\n",
      "Loss: 120.523, Residuals: 0.016\n",
      "Loss: 120.450, Residuals: 0.017\n",
      "Loss: 120.438, Residuals: 0.016\n",
      "Loss: 120.414, Residuals: 0.017\n",
      "Loss: 120.371, Residuals: 0.019\n",
      "Loss: 120.353, Residuals: 0.020\n",
      "Loss: 120.323, Residuals: 0.021\n",
      "Loss: 120.320, Residuals: 0.021\n",
      "Loss: 120.293, Residuals: 0.021\n",
      "Loss: 120.285, Residuals: 0.022\n",
      "Loss: 120.271, Residuals: 0.023\n",
      "Loss: 120.270, Residuals: 0.023\n",
      "Loss: 120.257, Residuals: 0.023\n",
      "Loss: 120.248, Residuals: 0.024\n",
      "Loss: 120.246, Residuals: 0.024\n",
      "Loss: 120.242, Residuals: 0.024\n",
      "Loss: 120.236, Residuals: 0.024\n",
      "Loss: 120.234, Residuals: 0.024\n",
      "Loss: 120.232, Residuals: 0.024\n",
      "Loss: 120.232, Residuals: 0.024\n",
      "Loss: 120.230, Residuals: 0.024\n",
      "Loss: 120.228, Residuals: 0.024\n",
      "Loss: 120.228, Residuals: 0.024\n",
      "Loss: 120.227, Residuals: 0.025\n",
      "Loss: 120.226, Residuals: 0.025\n",
      "Loss: 120.226, Residuals: 0.025\n",
      "Loss: 120.226, Residuals: 0.025\n",
      "Loss: 120.225, Residuals: 0.025\n",
      "Loss: 120.225, Residuals: 0.025\n",
      "Loss: 120.224, Residuals: 0.025\n",
      "Loss: 120.224, Residuals: 0.025\n",
      "Loss: 120.224, Residuals: 0.025\n",
      "Loss: 120.224, Residuals: 0.025\n",
      "Loss: 120.224, Residuals: 0.025\n",
      "Loss: 120.224, Residuals: 0.025\n",
      "Loss: 120.223, Residuals: 0.025\n",
      "Loss: 120.223, Residuals: 0.025\n",
      "Loss: 120.223, Residuals: 0.025\n",
      "Loss: 120.223, Residuals: 0.025\n",
      "Loss: 120.223, Residuals: 0.025\n",
      "Loss: 120.223, Residuals: 0.025\n",
      "Evidence 441.879\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.58e+00\n",
      "Loss: 140.785, Residuals: 0.028\n",
      "Loss: 140.246, Residuals: 0.030\n",
      "Loss: 139.908, Residuals: 0.028\n",
      "Loss: 139.602, Residuals: 0.029\n",
      "Loss: 139.586, Residuals: 0.030\n",
      "Loss: 139.458, Residuals: 0.030\n",
      "Loss: 139.352, Residuals: 0.029\n",
      "Loss: 139.347, Residuals: 0.029\n",
      "Loss: 139.344, Residuals: 0.029\n",
      "Loss: 139.340, Residuals: 0.029\n",
      "Loss: 139.335, Residuals: 0.029\n",
      "Loss: 139.327, Residuals: 0.029\n",
      "Loss: 139.327, Residuals: 0.029\n",
      "Loss: 139.325, Residuals: 0.029\n",
      "Loss: 139.324, Residuals: 0.029\n",
      "Loss: 139.324, Residuals: 0.029\n",
      "Evidence 458.878\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.49e+00\n",
      "Loss: 148.297, Residuals: 0.029\n",
      "Loss: 148.125, Residuals: 0.029\n",
      "Loss: 147.860, Residuals: 0.030\n",
      "Loss: 147.634, Residuals: 0.028\n",
      "Loss: 147.488, Residuals: 0.030\n",
      "Loss: 147.430, Residuals: 0.029\n",
      "Loss: 147.406, Residuals: 0.029\n",
      "Loss: 147.394, Residuals: 0.030\n",
      "Loss: 147.386, Residuals: 0.028\n",
      "Loss: 147.370, Residuals: 0.028\n",
      "Loss: 147.347, Residuals: 0.028\n",
      "Loss: 147.347, Residuals: 0.028\n",
      "Loss: 147.341, Residuals: 0.028\n",
      "Loss: 147.333, Residuals: 0.028\n",
      "Loss: 147.333, Residuals: 0.028\n",
      "Loss: 147.333, Residuals: 0.028\n",
      "Loss: 147.331, Residuals: 0.028\n",
      "Loss: 147.330, Residuals: 0.028\n",
      "Loss: 147.330, Residuals: 0.028\n",
      "Loss: 147.329, Residuals: 0.028\n",
      "Loss: 147.329, Residuals: 0.028\n",
      "Loss: 147.329, Residuals: 0.028\n",
      "Loss: 147.329, Residuals: 0.028\n",
      "Evidence 464.338\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.41e+00\n",
      "Loss: 150.833, Residuals: 0.028\n",
      "Loss: 150.714, Residuals: 0.028\n",
      "Loss: 150.550, Residuals: 0.027\n",
      "Loss: 150.442, Residuals: 0.027\n",
      "Loss: 150.357, Residuals: 0.028\n",
      "Loss: 150.352, Residuals: 0.027\n",
      "Loss: 150.342, Residuals: 0.027\n",
      "Loss: 150.327, Residuals: 0.027\n",
      "Loss: 150.323, Residuals: 0.027\n",
      "Loss: 150.322, Residuals: 0.027\n",
      "Loss: 150.322, Residuals: 0.027\n",
      "Loss: 150.321, Residuals: 0.027\n",
      "Loss: 150.321, Residuals: 0.027\n",
      "Loss: 150.321, Residuals: 0.027\n",
      "Evidence 467.063\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.42e+00\n",
      "Loss: 151.928, Residuals: 0.027\n",
      "Loss: 151.858, Residuals: 0.027\n",
      "Loss: 151.748, Residuals: 0.026\n",
      "Loss: 151.669, Residuals: 0.027\n",
      "Loss: 151.611, Residuals: 0.026\n",
      "Loss: 151.601, Residuals: 0.027\n",
      "Loss: 151.589, Residuals: 0.027\n",
      "Loss: 151.588, Residuals: 0.026\n",
      "Loss: 151.585, Residuals: 0.026\n",
      "Loss: 151.584, Residuals: 0.027\n",
      "Loss: 151.583, Residuals: 0.027\n",
      "Loss: 151.583, Residuals: 0.026\n",
      "Loss: 151.583, Residuals: 0.026\n",
      "Loss: 151.583, Residuals: 0.026\n",
      "Loss: 151.583, Residuals: 0.026\n",
      "Loss: 151.583, Residuals: 0.026\n",
      "Loss: 151.583, Residuals: 0.026\n",
      "Loss: 151.583, Residuals: 0.026\n",
      "Evidence 468.808\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.45e+00\n",
      "Loss: 152.429, Residuals: 0.027\n",
      "Loss: 152.389, Residuals: 0.026\n",
      "Loss: 152.325, Residuals: 0.026\n",
      "Loss: 152.252, Residuals: 0.026\n",
      "Loss: 152.215, Residuals: 0.027\n",
      "Loss: 152.211, Residuals: 0.027\n",
      "Loss: 152.205, Residuals: 0.026\n",
      "Loss: 152.203, Residuals: 0.026\n",
      "Loss: 152.202, Residuals: 0.026\n",
      "Loss: 152.202, Residuals: 0.026\n",
      "Evidence 470.050\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.47e+00\n",
      "Loss: 152.720, Residuals: 0.026\n",
      "Loss: 152.701, Residuals: 0.026\n",
      "Loss: 152.670, Residuals: 0.026\n",
      "Loss: 152.625, Residuals: 0.026\n",
      "Loss: 152.601, Residuals: 0.026\n",
      "Loss: 152.595, Residuals: 0.026\n",
      "Loss: 152.589, Residuals: 0.026\n",
      "Loss: 152.588, Residuals: 0.026\n",
      "Loss: 152.587, Residuals: 0.026\n",
      "Loss: 152.586, Residuals: 0.026\n",
      "Evidence 470.945\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.49e+00\n",
      "Loss: 152.927, Residuals: 0.023\n",
      "Loss: 152.907, Residuals: 0.025\n",
      "Loss: 152.888, Residuals: 0.026\n",
      "Loss: 152.879, Residuals: 0.025\n",
      "Loss: 152.878, Residuals: 0.025\n",
      "Loss: 152.877, Residuals: 0.025\n",
      "Loss: 152.875, Residuals: 0.026\n",
      "Loss: 152.875, Residuals: 0.026\n",
      "Loss: 152.875, Residuals: 0.026\n",
      "Loss: 152.874, Residuals: 0.026\n",
      "Loss: 152.874, Residuals: 0.026\n",
      "Evidence 471.591\n",
      "Updating hyper-parameters...\n",
      "Total samples: 39, Updated regularization: 1.50e+00\n",
      "Loss: 153.125, Residuals: 0.024\n",
      "Loss: 153.110, Residuals: 0.025\n",
      "Loss: 153.100, Residuals: 0.026\n",
      "Loss: 153.094, Residuals: 0.025\n",
      "Loss: 153.094, Residuals: 0.025\n",
      "Loss: 153.094, Residuals: 0.025\n",
      "Loss: 153.093, Residuals: 0.025\n",
      "Loss: 153.093, Residuals: 0.025\n",
      "Loss: 153.092, Residuals: 0.025\n",
      "Loss: 153.092, Residuals: 0.025\n",
      "Loss: 153.092, Residuals: 0.025\n",
      "Loss: 153.092, Residuals: 0.025\n",
      "Loss: 153.092, Residuals: 0.025\n",
      "Loss: 153.092, Residuals: 0.025\n",
      "Evidence 472.053\n",
      "Pass count  1\n",
      "Total samples: 40, Updated regularization: 1.00e-05\n",
      "Loss: 12.936, Residuals: -0.086\n",
      "Loss: 7.202, Residuals: -0.011\n",
      "Loss: 4.828, Residuals: -0.022\n",
      "Loss: 4.005, Residuals: 0.005\n",
      "Loss: 3.755, Residuals: 0.018\n",
      "Loss: 3.650, Residuals: 0.034\n",
      "Loss: 3.461, Residuals: 0.015\n",
      "Loss: 3.409, Residuals: 0.024\n",
      "Loss: 3.311, Residuals: 0.014\n",
      "Loss: 3.146, Residuals: -0.009\n",
      "Loss: 3.081, Residuals: 0.000\n",
      "Loss: 2.979, Residuals: -0.021\n",
      "Loss: 2.974, Residuals: -0.017\n",
      "Loss: 2.930, Residuals: -0.024\n",
      "Loss: 2.856, Residuals: -0.039\n",
      "Loss: 2.843, Residuals: -0.032\n",
      "Loss: 2.829, Residuals: -0.039\n",
      "Loss: 2.805, Residuals: -0.047\n",
      "Loss: 2.804, Residuals: -0.043\n",
      "Loss: 2.796, Residuals: -0.046\n",
      "Loss: 2.782, Residuals: -0.053\n",
      "Loss: 2.760, Residuals: -0.067\n",
      "Loss: 2.758, Residuals: -0.068\n",
      "Loss: 2.753, Residuals: -0.066\n",
      "Loss: 2.718, Residuals: -0.081\n",
      "Loss: 2.710, Residuals: -0.078\n",
      "Loss: 2.707, Residuals: -0.077\n",
      "Loss: 2.701, Residuals: -0.079\n",
      "Loss: 2.691, Residuals: -0.081\n",
      "Loss: 2.679, Residuals: -0.082\n",
      "Loss: 2.678, Residuals: -0.084\n",
      "Loss: 2.678, Residuals: -0.083\n",
      "Loss: 2.677, Residuals: -0.081\n",
      "Loss: 2.666, Residuals: -0.082\n",
      "Loss: 2.666, Residuals: -0.082\n",
      "Loss: 2.656, Residuals: -0.083\n",
      "Loss: 2.654, Residuals: -0.079\n",
      "Loss: 2.641, Residuals: -0.081\n",
      "Loss: 2.639, Residuals: -0.078\n",
      "Loss: 2.621, Residuals: -0.082\n",
      "Loss: 2.621, Residuals: -0.080\n",
      "Loss: 2.621, Residuals: -0.080\n",
      "Loss: 2.619, Residuals: -0.080\n",
      "Loss: 2.599, Residuals: -0.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.599, Residuals: -0.084\n",
      "Loss: 2.598, Residuals: -0.083\n",
      "Loss: 2.596, Residuals: -0.082\n",
      "Loss: 2.593, Residuals: -0.081\n",
      "Loss: 2.593, Residuals: -0.079\n",
      "Loss: 2.588, Residuals: -0.081\n",
      "Loss: 2.588, Residuals: -0.080\n",
      "Loss: 2.573, Residuals: -0.088\n",
      "Loss: 2.573, Residuals: -0.087\n",
      "Loss: 2.572, Residuals: -0.087\n",
      "Loss: 2.571, Residuals: -0.086\n",
      "Loss: 2.570, Residuals: -0.087\n",
      "Loss: 2.570, Residuals: -0.086\n",
      "Loss: 2.552, Residuals: -0.095\n",
      "Loss: 2.550, Residuals: -0.094\n",
      "Loss: 2.549, Residuals: -0.092\n",
      "Loss: 2.548, Residuals: -0.092\n",
      "Loss: 2.546, Residuals: -0.092\n",
      "Loss: 2.546, Residuals: -0.091\n",
      "Loss: 2.530, Residuals: -0.096\n",
      "Loss: 2.529, Residuals: -0.095\n",
      "Loss: 2.528, Residuals: -0.094\n",
      "Loss: 2.526, Residuals: -0.094\n",
      "Loss: 2.526, Residuals: -0.095\n",
      "Loss: 2.525, Residuals: -0.094\n",
      "Loss: 2.525, Residuals: -0.094\n",
      "Loss: 2.511, Residuals: -0.097\n",
      "Loss: 2.510, Residuals: -0.097\n",
      "Loss: 2.510, Residuals: -0.097\n",
      "Loss: 2.506, Residuals: -0.097\n",
      "Loss: 2.506, Residuals: -0.097\n",
      "Loss: 2.506, Residuals: -0.096\n",
      "Loss: 2.496, Residuals: -0.099\n",
      "Loss: 2.496, Residuals: -0.098\n",
      "Loss: 2.496, Residuals: -0.097\n",
      "Loss: 2.480, Residuals: -0.101\n",
      "Loss: 2.479, Residuals: -0.100\n",
      "Loss: 2.479, Residuals: -0.100\n",
      "Loss: 2.479, Residuals: -0.100\n",
      "Loss: 2.478, Residuals: -0.100\n",
      "Loss: 2.478, Residuals: -0.101\n",
      "Loss: 2.459, Residuals: -0.105\n",
      "Loss: 2.455, Residuals: -0.103\n",
      "Loss: 2.455, Residuals: -0.104\n",
      "Loss: 2.455, Residuals: -0.104\n",
      "Loss: 2.454, Residuals: -0.104\n",
      "Loss: 2.453, Residuals: -0.103\n",
      "Loss: 2.452, Residuals: -0.104\n",
      "Loss: 2.450, Residuals: -0.104\n",
      "Loss: 2.450, Residuals: -0.104\n",
      "Evidence -407.906\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 6.28e-03\n",
      "Loss: 13.494, Residuals: -0.076\n",
      "Loss: 13.482, Residuals: -0.075\n",
      "Loss: 13.460, Residuals: -0.075\n",
      "Loss: 13.420, Residuals: -0.075\n",
      "Loss: 13.354, Residuals: -0.074\n",
      "Loss: 13.267, Residuals: -0.074\n",
      "Loss: 13.257, Residuals: -0.063\n",
      "Loss: 13.172, Residuals: -0.062\n",
      "Loss: 13.172, Residuals: -0.062\n",
      "Loss: 13.171, Residuals: -0.062\n",
      "Loss: 13.142, Residuals: -0.061\n",
      "Loss: 13.089, Residuals: -0.058\n",
      "Loss: 13.088, Residuals: -0.058\n",
      "Loss: 13.088, Residuals: -0.058\n",
      "Loss: 13.035, Residuals: -0.054\n",
      "Loss: 13.034, Residuals: -0.054\n",
      "Loss: 13.034, Residuals: -0.054\n",
      "Evidence 117.943\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 3.17e-02\n",
      "Loss: 46.808, Residuals: -0.054\n",
      "Loss: 46.804, Residuals: -0.054\n",
      "Loss: 46.762, Residuals: -0.053\n",
      "Loss: 46.688, Residuals: -0.051\n",
      "Loss: 46.573, Residuals: -0.047\n",
      "Loss: 46.403, Residuals: -0.042\n",
      "Loss: 46.399, Residuals: -0.042\n",
      "Loss: 46.397, Residuals: -0.041\n",
      "Loss: 46.316, Residuals: -0.040\n",
      "Loss: 46.306, Residuals: -0.041\n",
      "Loss: 46.211, Residuals: -0.039\n",
      "Loss: 46.210, Residuals: -0.039\n",
      "Evidence 315.405\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 7.42e-02\n",
      "Loss: 99.124, Residuals: -0.040\n",
      "Loss: 99.020, Residuals: -0.038\n",
      "Loss: 98.828, Residuals: -0.038\n",
      "Loss: 98.499, Residuals: -0.040\n",
      "Loss: 98.058, Residuals: -0.043\n",
      "Loss: 98.053, Residuals: -0.043\n",
      "Loss: 97.856, Residuals: -0.043\n",
      "Loss: 97.830, Residuals: -0.044\n",
      "Loss: 97.594, Residuals: -0.043\n",
      "Loss: 97.593, Residuals: -0.043\n",
      "Evidence 411.326\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 9.63e-02\n",
      "Loss: 136.159, Residuals: -0.044\n",
      "Loss: 135.991, Residuals: -0.045\n",
      "Loss: 135.742, Residuals: -0.046\n",
      "Loss: 135.328, Residuals: -0.052\n",
      "Loss: 135.106, Residuals: -0.057\n",
      "Loss: 135.017, Residuals: -0.055\n",
      "Loss: 134.285, Residuals: -0.056\n",
      "Loss: 134.277, Residuals: -0.057\n",
      "Loss: 133.965, Residuals: -0.058\n",
      "Loss: 133.788, Residuals: -0.062\n",
      "Loss: 133.785, Residuals: -0.063\n",
      "Loss: 133.365, Residuals: -0.060\n",
      "Loss: 133.361, Residuals: -0.061\n",
      "Loss: 133.355, Residuals: -0.060\n",
      "Loss: 133.113, Residuals: -0.059\n",
      "Loss: 133.108, Residuals: -0.060\n",
      "Loss: 133.101, Residuals: -0.059\n",
      "Loss: 132.810, Residuals: -0.058\n",
      "Loss: 132.807, Residuals: -0.058\n",
      "Evidence 440.322\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.09e-01\n",
      "Loss: 150.083, Residuals: -0.059\n",
      "Loss: 149.984, Residuals: -0.059\n",
      "Loss: 149.804, Residuals: -0.061\n",
      "Loss: 149.502, Residuals: -0.064\n",
      "Loss: 149.093, Residuals: -0.071\n",
      "Loss: 149.075, Residuals: -0.071\n",
      "Loss: 148.905, Residuals: -0.071\n",
      "Loss: 148.880, Residuals: -0.070\n",
      "Loss: 148.008, Residuals: -0.067\n",
      "Loss: 147.970, Residuals: -0.068\n",
      "Loss: 147.961, Residuals: -0.068\n",
      "Loss: 147.881, Residuals: -0.068\n",
      "Loss: 147.800, Residuals: -0.071\n",
      "Loss: 147.799, Residuals: -0.071\n",
      "Evidence 450.998\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.13e-01\n",
      "Loss: 154.913, Residuals: -0.074\n",
      "Loss: 154.806, Residuals: -0.074\n",
      "Loss: 154.617, Residuals: -0.074\n",
      "Loss: 154.329, Residuals: -0.074\n",
      "Loss: 154.303, Residuals: -0.071\n",
      "Loss: 153.400, Residuals: -0.070\n",
      "Loss: 153.374, Residuals: -0.071\n",
      "Loss: 153.370, Residuals: -0.070\n",
      "Loss: 153.328, Residuals: -0.071\n",
      "Loss: 153.304, Residuals: -0.073\n",
      "Loss: 153.080, Residuals: -0.073\n",
      "Loss: 152.986, Residuals: -0.074\n",
      "Loss: 152.984, Residuals: -0.074\n",
      "Evidence 455.438\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.21e-01\n",
      "Loss: 156.596, Residuals: -0.073\n",
      "Loss: 156.452, Residuals: -0.072\n",
      "Loss: 156.208, Residuals: -0.074\n",
      "Loss: 156.202, Residuals: -0.073\n",
      "Loss: 156.150, Residuals: -0.074\n",
      "Loss: 156.055, Residuals: -0.074\n",
      "Loss: 156.039, Residuals: -0.073\n",
      "Loss: 155.518, Residuals: -0.073\n",
      "Loss: 155.514, Residuals: -0.073\n",
      "Evidence 457.873\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.27e-01\n",
      "Loss: 157.538, Residuals: -0.074\n",
      "Loss: 157.406, Residuals: -0.073\n",
      "Loss: 157.262, Residuals: -0.074\n",
      "Loss: 157.249, Residuals: -0.074\n",
      "Loss: 157.126, Residuals: -0.074\n",
      "Loss: 157.119, Residuals: -0.074\n",
      "Loss: 156.855, Residuals: -0.075\n",
      "Loss: 156.854, Residuals: -0.075\n",
      "Evidence 459.279\n",
      "Updating hyper-parameters...\n",
      "Total samples: 40, Updated regularization: 1.31e-01\n",
      "Loss: 158.047, Residuals: -0.074\n",
      "Loss: 157.763, Residuals: -0.074\n",
      "Loss: 157.761, Residuals: -0.074\n",
      "Evidence 459.701\n",
      "Pass count  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run kfold for each file \n",
    "for file in files:\n",
    "    \n",
    "    # import data\n",
    "    df = pd.read_csv(f\"data/{file}\")\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "\n",
    "    # separate mono culture data \n",
    "    # mono_df = pd.concat([df_i for name, df_i in df.groupby(\"Treatments\") if \"Mono\" in name])\n",
    "    dfs = [df_i for name, df_i in df.groupby(\"Treatments\") if \"Mono\" not in name]\n",
    "\n",
    "    # init kfold object\n",
    "    kf = KFold(n_splits=20, shuffle=True, random_state=21)\n",
    "\n",
    "    # keep track of all predictions\n",
    "    all_pred_species = []\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    all_stdv = []\n",
    "\n",
    "    # run Kfold \n",
    "    # train_index, test_index = next(iter(kf.split(dfs)))\n",
    "    for train_index, test_index in kf.split(dfs):\n",
    "\n",
    "        # get train df \n",
    "        train_df = pd.concat([dfs[i] for i in train_index])\n",
    "        # train_df = pd.concat((mono_df, train_df))\n",
    "\n",
    "        # get test df\n",
    "        test_df = pd.concat([dfs[i] for i in test_index])\n",
    "\n",
    "        # instantiate gLV fit \n",
    "        model = gLV(species, train_df)\n",
    "\n",
    "        # fit to data \n",
    "        model.fit() \n",
    "\n",
    "        # plot fitness to data\n",
    "        pred_species, true, pred, stdv = predict_df(model, test_df, species)\n",
    "\n",
    "        # append predictions \n",
    "        all_pred_species = np.append(all_pred_species, pred_species)\n",
    "        all_true = np.append(all_true, true)\n",
    "        all_pred = np.append(all_pred, pred)\n",
    "        all_stdv = np.append(all_stdv, stdv)\n",
    "\n",
    "    # save prediction results to a .csv\n",
    "    strain = file.split(\"_\")[1]\n",
    "    kfold_df = pd.DataFrame()\n",
    "    kfold_df['species'] = all_pred_species\n",
    "    kfold_df['true'] = all_true\n",
    "    kfold_df['pred'] = all_pred\n",
    "    kfold_df['stdv'] = all_stdv\n",
    "    kfold_df.to_csv(f\"kfold/{strain}_kfold.csv\", index=False)\n",
    "        \n",
    "    # show prediction performance of individual species\n",
    "    for sp in species:\n",
    "        sp_inds = all_pred_species == sp\n",
    "        R = linregress(all_true[sp_inds], all_pred[sp_inds]).rvalue\n",
    "        plt.scatter(all_true[sp_inds], all_pred[sp_inds], label=f\"{sp} \" + \"R={:.3f}\".format(R))\n",
    "        plt.errorbar(all_true[sp_inds], all_pred[sp_inds], yerr=all_stdv[sp_inds], \n",
    "                     fmt='.', capsize=3)\n",
    "\n",
    "    plt.xlabel(\"Measured OD\")\n",
    "    plt.ylabel(\"Predicted OD\")\n",
    "    plt.legend()\n",
    "    plt.title(strain)\n",
    "    plt.savefig(f\"kfold/{strain}_kfold.pdf\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7db59dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for file in files:\n",
    "    strain = file.split(\"_\")[1]\n",
    "    kfold_df = pd.read_csv(f\"kfold/{strain}_kfold.csv\")\n",
    "        \n",
    "    all_pred_species = kfold_df['species'].values\n",
    "    all_true = kfold_df['true'].values \n",
    "    all_pred = kfold_df['pred'].values\n",
    "    all_stdv = kfold_df['stdv'].values\n",
    "        \n",
    "    R_overall = linregress(all_true, all_pred).rvalue\n",
    "        \n",
    "    # show prediction performance of individual species\n",
    "    for sp in species:\n",
    "        sp_inds = all_pred_species == sp\n",
    "        R = linregress(all_true[sp_inds], all_pred[sp_inds]).rvalue\n",
    "        plt.scatter(all_true[sp_inds], all_pred[sp_inds], label=f\"{sp} \" + \"R={:.3f}\".format(R))\n",
    "        plt.errorbar(all_true[sp_inds], all_pred[sp_inds], yerr=all_stdv[sp_inds], \n",
    "                     fmt='.', capsize=3)\n",
    "\n",
    "    plt.xlabel(\"Measured OD\")\n",
    "    plt.ylabel(\"Predicted OD\")\n",
    "    plt.legend()\n",
    "    plt.title(strain + \" R={:.2f}\".format(R_overall))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f30f45",
   "metadata": {},
   "source": [
    "# Show example fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf1986d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_species, true, pred, stdv = predict_df(model, train_df, species)\n",
    "\n",
    "for sp in species:\n",
    "    sp_inds = pred_species == sp\n",
    "    if sum(true[sp_inds]) > 0:\n",
    "        R = linregress(true[sp_inds], pred[sp_inds]).rvalue\n",
    "        plt.scatter(true[sp_inds], pred[sp_inds], label=f\"{sp} \" + \"R={:.3f}\".format(R))\n",
    "        plt.errorbar(true[sp_inds], pred[sp_inds], yerr= stdv[sp_inds], \n",
    "                     fmt='.', capsize=3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
