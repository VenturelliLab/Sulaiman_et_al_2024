{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a637f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-tnydvcw0 because the default path (/home/jaron/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from glove.mse_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06280f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXP0019_MS001_processed.csv',\n",
       " 'EXP0019_DSM27147_processed.csv',\n",
       " 'EXP0019_MS008_processed.csv',\n",
       " 'EXP0019_MS014_processed.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import file names\n",
    "files = os.listdir(\"data/\")\n",
    "files = [f for f in files if \"processed\" in f]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66f683",
   "metadata": {},
   "source": [
    "# fit gLV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af71ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 63, Updated regularization: 1.00e-05\n",
      "Loss: 17.595, Residuals: 0.049\n",
      "Loss: 10.667, Residuals: 0.022\n",
      "Loss: 7.690, Residuals: -0.056\n",
      "Loss: 7.487, Residuals: -0.070\n",
      "Loss: 7.111, Residuals: -0.060\n",
      "Loss: 6.571, Residuals: -0.030\n",
      "Loss: 6.104, Residuals: -0.032\n",
      "Loss: 6.019, Residuals: -0.026\n",
      "Loss: 5.964, Residuals: -0.021\n",
      "Loss: 5.889, Residuals: -0.014\n",
      "Loss: 5.876, Residuals: -0.016\n",
      "Loss: 5.851, Residuals: -0.018\n",
      "Loss: 5.807, Residuals: -0.021\n",
      "Loss: 5.804, Residuals: -0.011\n",
      "Loss: 5.777, Residuals: -0.015\n",
      "Loss: 5.728, Residuals: -0.021\n",
      "Loss: 5.728, Residuals: -0.021\n",
      "Loss: 5.721, Residuals: -0.019\n",
      "Loss: 5.711, Residuals: -0.018\n",
      "Loss: 5.691, Residuals: -0.021\n",
      "Loss: 5.691, Residuals: -0.021\n",
      "Loss: 5.690, Residuals: -0.020\n",
      "Loss: 5.665, Residuals: -0.021\n",
      "Loss: 5.665, Residuals: -0.022\n",
      "Loss: 5.664, Residuals: -0.021\n",
      "Loss: 5.663, Residuals: -0.020\n",
      "Loss: 5.655, Residuals: -0.019\n",
      "Loss: 5.639, Residuals: -0.021\n",
      "Loss: 5.639, Residuals: -0.021\n",
      "Loss: 5.638, Residuals: -0.019\n",
      "Loss: 5.613, Residuals: -0.023\n",
      "Loss: 5.611, Residuals: -0.024\n",
      "Loss: 5.610, Residuals: -0.020\n",
      "Loss: 5.578, Residuals: -0.024\n",
      "Loss: 5.571, Residuals: -0.026\n",
      "Loss: 5.571, Residuals: -0.025\n",
      "Evidence -398.475\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 1.86e-02\n",
      "Loss: 32.694, Residuals: -0.025\n",
      "Loss: 32.449, Residuals: -0.026\n",
      "Loss: 32.275, Residuals: -0.021\n",
      "Loss: 32.267, Residuals: -0.020\n",
      "Loss: 32.253, Residuals: -0.020\n",
      "Loss: 32.132, Residuals: -0.015\n",
      "Loss: 32.118, Residuals: -0.013\n",
      "Loss: 31.999, Residuals: -0.010\n",
      "Loss: 31.999, Residuals: -0.010\n",
      "Evidence 328.982\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 1.92e-01\n",
      "Loss: 109.537, Residuals: -0.009\n",
      "Loss: 109.258, Residuals: -0.008\n",
      "Loss: 108.784, Residuals: -0.011\n",
      "Loss: 108.145, Residuals: -0.015\n",
      "Loss: 107.360, Residuals: -0.010\n",
      "Loss: 107.245, Residuals: -0.013\n",
      "Loss: 107.241, Residuals: -0.012\n",
      "Loss: 107.233, Residuals: -0.011\n",
      "Loss: 106.969, Residuals: -0.010\n",
      "Loss: 106.968, Residuals: -0.011\n",
      "Evidence 643.412\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 7.75e-01\n",
      "Loss: 194.321, Residuals: -0.010\n",
      "Loss: 193.462, Residuals: -0.008\n",
      "Loss: 192.257, Residuals: -0.011\n",
      "Loss: 192.225, Residuals: -0.012\n",
      "Loss: 191.919, Residuals: -0.012\n",
      "Loss: 191.381, Residuals: -0.011\n",
      "Loss: 190.700, Residuals: -0.012\n",
      "Loss: 190.695, Residuals: -0.012\n",
      "Loss: 190.657, Residuals: -0.012\n",
      "Loss: 190.317, Residuals: -0.013\n",
      "Loss: 190.247, Residuals: -0.011\n",
      "Loss: 190.243, Residuals: -0.014\n",
      "Loss: 190.105, Residuals: -0.013\n",
      "Loss: 189.860, Residuals: -0.013\n",
      "Loss: 189.551, Residuals: -0.012\n",
      "Loss: 189.547, Residuals: -0.013\n",
      "Loss: 189.541, Residuals: -0.011\n",
      "Loss: 189.532, Residuals: -0.011\n",
      "Loss: 189.517, Residuals: -0.012\n",
      "Loss: 189.489, Residuals: -0.012\n",
      "Loss: 189.460, Residuals: -0.012\n",
      "Loss: 189.454, Residuals: -0.012\n",
      "Loss: 189.407, Residuals: -0.012\n",
      "Loss: 189.406, Residuals: -0.012\n",
      "Loss: 189.377, Residuals: -0.012\n",
      "Loss: 189.375, Residuals: -0.012\n",
      "Loss: 189.359, Residuals: -0.012\n",
      "Loss: 189.359, Residuals: -0.012\n",
      "Loss: 189.328, Residuals: -0.012\n",
      "Loss: 189.328, Residuals: -0.012\n",
      "Loss: 189.327, Residuals: -0.012\n",
      "Loss: 189.326, Residuals: -0.012\n",
      "Loss: 189.287, Residuals: -0.012\n",
      "Loss: 189.285, Residuals: -0.012\n",
      "Loss: 189.282, Residuals: -0.012\n",
      "Loss: 189.278, Residuals: -0.012\n",
      "Loss: 189.277, Residuals: -0.013\n",
      "Loss: 187.762, Residuals: -0.009\n",
      "Loss: 187.439, Residuals: -0.007\n",
      "Loss: 187.359, Residuals: -0.012\n",
      "Loss: 186.686, Residuals: -0.010\n",
      "Loss: 186.567, Residuals: -0.007\n",
      "Loss: 186.346, Residuals: -0.007\n",
      "Loss: 186.249, Residuals: -0.006\n",
      "Loss: 186.071, Residuals: -0.006\n",
      "Loss: 186.050, Residuals: -0.006\n",
      "Loss: 185.861, Residuals: -0.006\n",
      "Loss: 185.582, Residuals: -0.006\n",
      "Loss: 185.574, Residuals: -0.006\n",
      "Loss: 185.561, Residuals: -0.006\n",
      "Loss: 185.538, Residuals: -0.006\n",
      "Loss: 185.497, Residuals: -0.006\n",
      "Loss: 185.487, Residuals: -0.006\n",
      "Loss: 185.411, Residuals: -0.006\n",
      "Loss: 185.403, Residuals: -0.005\n",
      "Loss: 185.391, Residuals: -0.005\n",
      "Loss: 185.368, Residuals: -0.005\n",
      "Loss: 185.365, Residuals: -0.005\n",
      "Loss: 185.358, Residuals: -0.005\n",
      "Loss: 185.346, Residuals: -0.005\n",
      "Loss: 185.345, Residuals: -0.005\n",
      "Loss: 185.337, Residuals: -0.005\n",
      "Loss: 185.334, Residuals: -0.005\n",
      "Loss: 185.334, Residuals: -0.004\n",
      "Loss: 185.330, Residuals: -0.004\n",
      "Loss: 185.329, Residuals: -0.004\n",
      "Loss: 185.327, Residuals: -0.004\n",
      "Loss: 185.325, Residuals: -0.004\n",
      "Loss: 185.324, Residuals: -0.004\n",
      "Loss: 185.324, Residuals: -0.004\n",
      "Loss: 185.324, Residuals: -0.004\n",
      "Loss: 185.324, Residuals: -0.004\n",
      "Loss: 185.323, Residuals: -0.004\n",
      "Loss: 185.323, Residuals: -0.004\n",
      "Evidence 764.333\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 1.04e+00\n",
      "Loss: 231.706, Residuals: -0.003\n",
      "Loss: 231.589, Residuals: -0.003\n",
      "Loss: 231.381, Residuals: -0.002\n",
      "Loss: 231.032, Residuals: -0.002\n",
      "Loss: 230.509, Residuals: -0.008\n",
      "Loss: 229.748, Residuals: -0.007\n",
      "Loss: 229.676, Residuals: -0.004\n",
      "Loss: 229.540, Residuals: -0.005\n",
      "Loss: 229.300, Residuals: -0.005\n",
      "Loss: 228.902, Residuals: -0.005\n",
      "Loss: 228.717, Residuals: -0.006\n",
      "Loss: 228.714, Residuals: -0.005\n",
      "Loss: 228.709, Residuals: -0.005\n",
      "Loss: 228.701, Residuals: -0.005\n",
      "Loss: 228.626, Residuals: -0.005\n",
      "Loss: 228.504, Residuals: -0.005\n",
      "Loss: 228.500, Residuals: -0.005\n",
      "Loss: 228.493, Residuals: -0.005\n",
      "Loss: 228.440, Residuals: -0.005\n",
      "Loss: 228.438, Residuals: -0.005\n",
      "Loss: 228.420, Residuals: -0.005\n",
      "Loss: 228.419, Residuals: -0.005\n",
      "Loss: 228.409, Residuals: -0.005\n",
      "Loss: 228.392, Residuals: -0.005\n",
      "Loss: 228.391, Residuals: -0.005\n",
      "Loss: 228.390, Residuals: -0.005\n",
      "Loss: 228.378, Residuals: -0.005\n",
      "Loss: 228.378, Residuals: -0.005\n",
      "Loss: 228.377, Residuals: -0.005\n",
      "Loss: 228.377, Residuals: -0.005\n",
      "Loss: 228.375, Residuals: -0.005\n",
      "Loss: 228.372, Residuals: -0.005\n",
      "Loss: 228.372, Residuals: -0.005\n",
      "Loss: 228.371, Residuals: -0.005\n",
      "Loss: 228.370, Residuals: -0.005\n",
      "Loss: 228.370, Residuals: -0.005\n",
      "Evidence 799.956\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 8.01e-01\n",
      "Loss: 244.540, Residuals: -0.004\n",
      "Loss: 244.483, Residuals: -0.003\n",
      "Loss: 244.382, Residuals: -0.004\n",
      "Loss: 244.226, Residuals: -0.006\n",
      "Loss: 243.954, Residuals: -0.007\n",
      "Loss: 243.599, Residuals: -0.008\n",
      "Loss: 243.578, Residuals: -0.008\n",
      "Loss: 243.406, Residuals: -0.008\n",
      "Loss: 243.245, Residuals: -0.008\n",
      "Loss: 243.229, Residuals: -0.009\n",
      "Loss: 243.214, Residuals: -0.009\n",
      "Loss: 243.208, Residuals: -0.009\n",
      "Loss: 243.197, Residuals: -0.009\n",
      "Loss: 243.179, Residuals: -0.009\n",
      "Loss: 243.178, Residuals: -0.009\n",
      "Loss: 243.167, Residuals: -0.009\n",
      "Loss: 243.167, Residuals: -0.009\n",
      "Loss: 243.161, Residuals: -0.009\n",
      "Loss: 243.154, Residuals: -0.009\n",
      "Loss: 243.153, Residuals: -0.009\n",
      "Loss: 243.153, Residuals: -0.009\n",
      "Loss: 243.153, Residuals: -0.009\n",
      "Loss: 243.153, Residuals: -0.009\n",
      "Loss: 243.153, Residuals: -0.009\n",
      "Loss: 243.153, Residuals: -0.009\n",
      "Evidence 808.468\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 6.24e-01\n",
      "Loss: 248.057, Residuals: -0.007\n",
      "Loss: 248.001, Residuals: -0.009\n",
      "Loss: 247.914, Residuals: -0.011\n",
      "Loss: 247.843, Residuals: -0.012\n",
      "Loss: 247.839, Residuals: -0.011\n",
      "Loss: 247.810, Residuals: -0.011\n",
      "Loss: 247.773, Residuals: -0.012\n",
      "Loss: 247.771, Residuals: -0.012\n",
      "Loss: 247.770, Residuals: -0.012\n",
      "Loss: 247.768, Residuals: -0.012\n",
      "Loss: 247.765, Residuals: -0.012\n",
      "Loss: 247.765, Residuals: -0.011\n",
      "Loss: 247.763, Residuals: -0.011\n",
      "Loss: 247.761, Residuals: -0.012\n",
      "Loss: 247.761, Residuals: -0.011\n",
      "Loss: 247.761, Residuals: -0.012\n",
      "Evidence 811.152\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 5.54e-01\n",
      "Loss: 249.322, Residuals: -0.010\n",
      "Loss: 249.305, Residuals: -0.011\n",
      "Loss: 249.282, Residuals: -0.012\n",
      "Loss: 249.259, Residuals: -0.013\n",
      "Loss: 249.256, Residuals: -0.012\n",
      "Loss: 249.252, Residuals: -0.012\n",
      "Loss: 249.251, Residuals: -0.012\n",
      "Loss: 249.246, Residuals: -0.013\n",
      "Loss: 249.246, Residuals: -0.012\n",
      "Loss: 249.245, Residuals: -0.012\n",
      "Loss: 249.244, Residuals: -0.013\n",
      "Loss: 249.242, Residuals: -0.013\n",
      "Loss: 249.242, Residuals: -0.012\n",
      "Loss: 249.242, Residuals: -0.012\n",
      "Evidence 812.238\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 5.32e-01\n",
      "Loss: 249.854, Residuals: -0.012\n",
      "Loss: 249.842, Residuals: -0.013\n",
      "Loss: 249.833, Residuals: -0.013\n",
      "Loss: 249.831, Residuals: -0.013\n",
      "Loss: 249.830, Residuals: -0.013\n",
      "Loss: 249.828, Residuals: -0.013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 249.828, Residuals: -0.013\n",
      "Loss: 249.827, Residuals: -0.013\n",
      "Loss: 249.827, Residuals: -0.013\n",
      "Loss: 249.827, Residuals: -0.013\n",
      "Loss: 249.827, Residuals: -0.013\n",
      "Loss: 249.827, Residuals: -0.013\n",
      "Evidence 812.820\n",
      "Pass count  1\n",
      "Total samples: 63, Updated regularization: 1.00e-05\n",
      "Loss: 15.632, Residuals: 0.012\n",
      "Loss: 9.186, Residuals: -0.000\n",
      "Loss: 7.413, Residuals: -0.017\n",
      "Loss: 6.804, Residuals: -0.053\n",
      "Loss: 6.509, Residuals: -0.029\n",
      "Loss: 6.053, Residuals: -0.040\n",
      "Loss: 5.537, Residuals: -0.043\n",
      "Loss: 5.431, Residuals: -0.014\n",
      "Loss: 5.251, Residuals: -0.010\n",
      "Loss: 5.054, Residuals: -0.003\n",
      "Loss: 5.036, Residuals: -0.006\n",
      "Loss: 5.016, Residuals: -0.007\n",
      "Loss: 4.980, Residuals: -0.011\n",
      "Loss: 4.922, Residuals: -0.015\n",
      "Loss: 4.921, Residuals: -0.016\n",
      "Loss: 4.919, Residuals: -0.015\n",
      "Loss: 4.916, Residuals: -0.011\n",
      "Loss: 4.891, Residuals: -0.013\n",
      "Loss: 4.846, Residuals: -0.013\n",
      "Loss: 4.812, Residuals: -0.010\n",
      "Loss: 4.750, Residuals: -0.012\n",
      "Loss: 4.745, Residuals: 0.004\n",
      "Loss: 4.693, Residuals: -0.002\n",
      "Loss: 4.693, Residuals: -0.003\n",
      "Loss: 4.672, Residuals: -0.005\n",
      "Loss: 4.634, Residuals: -0.010\n",
      "Loss: 4.634, Residuals: -0.011\n",
      "Loss: 4.625, Residuals: -0.011\n",
      "Loss: 4.609, Residuals: -0.010\n",
      "Loss: 4.579, Residuals: -0.014\n",
      "Loss: 4.579, Residuals: -0.014\n",
      "Loss: 4.578, Residuals: -0.013\n",
      "Loss: 4.569, Residuals: -0.014\n",
      "Loss: 4.551, Residuals: -0.018\n",
      "Loss: 4.551, Residuals: -0.018\n",
      "Loss: 4.551, Residuals: -0.017\n",
      "Loss: 4.550, Residuals: -0.016\n",
      "Loss: 4.540, Residuals: -0.018\n",
      "Loss: 4.539, Residuals: -0.013\n",
      "Loss: 4.530, Residuals: -0.014\n",
      "Loss: 4.513, Residuals: -0.018\n",
      "Loss: 4.487, Residuals: -0.025\n",
      "Loss: 4.487, Residuals: -0.024\n",
      "Loss: 4.486, Residuals: -0.025\n",
      "Loss: 4.485, Residuals: -0.024\n",
      "Loss: 4.482, Residuals: -0.024\n",
      "Loss: 4.482, Residuals: -0.022\n",
      "Loss: 4.466, Residuals: -0.027\n",
      "Loss: 4.466, Residuals: -0.026\n",
      "Evidence -395.368\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 1.34e-02\n",
      "Loss: 27.381, Residuals: -0.028\n",
      "Loss: 27.377, Residuals: -0.027\n",
      "Loss: 27.340, Residuals: -0.027\n",
      "Loss: 27.282, Residuals: -0.027\n",
      "Loss: 27.178, Residuals: -0.026\n",
      "Loss: 27.178, Residuals: -0.026\n",
      "Evidence 346.374\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 9.34e-02\n",
      "Loss: 109.016, Residuals: -0.024\n",
      "Loss: 108.818, Residuals: -0.024\n",
      "Loss: 108.453, Residuals: -0.026\n",
      "Loss: 107.851, Residuals: -0.030\n",
      "Loss: 107.813, Residuals: -0.028\n",
      "Loss: 106.493, Residuals: -0.024\n",
      "Loss: 106.471, Residuals: -0.026\n",
      "Loss: 106.436, Residuals: -0.025\n",
      "Loss: 106.107, Residuals: -0.024\n",
      "Loss: 105.556, Residuals: -0.021\n",
      "Loss: 105.464, Residuals: -0.019\n",
      "Loss: 105.463, Residuals: -0.019\n",
      "Evidence 666.133\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 2.92e-01\n",
      "Loss: 201.363, Residuals: -0.020\n",
      "Loss: 200.238, Residuals: -0.027\n",
      "Loss: 200.160, Residuals: -0.019\n",
      "Loss: 199.420, Residuals: -0.019\n",
      "Loss: 198.571, Residuals: -0.026\n",
      "Loss: 198.558, Residuals: -0.025\n",
      "Loss: 198.055, Residuals: -0.024\n",
      "Loss: 198.053, Residuals: -0.024\n",
      "Evidence 766.461\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 4.03e-01\n",
      "Loss: 236.783, Residuals: -0.026\n",
      "Loss: 236.559, Residuals: -0.026\n",
      "Loss: 236.165, Residuals: -0.027\n",
      "Loss: 235.578, Residuals: -0.025\n",
      "Loss: 235.576, Residuals: -0.025\n",
      "Evidence 783.535\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 4.31e-01\n",
      "Loss: 245.892, Residuals: -0.024\n",
      "Loss: 245.725, Residuals: -0.026\n",
      "Loss: 245.418, Residuals: -0.025\n",
      "Loss: 244.894, Residuals: -0.025\n",
      "Loss: 244.892, Residuals: -0.025\n",
      "Evidence 787.521\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 4.42e-01\n",
      "Loss: 248.248, Residuals: -0.026\n",
      "Loss: 248.196, Residuals: -0.027\n",
      "Loss: 247.706, Residuals: -0.027\n",
      "Loss: 247.696, Residuals: -0.027\n",
      "Loss: 247.297, Residuals: -0.026\n",
      "Loss: 247.292, Residuals: -0.026\n",
      "Loss: 246.575, Residuals: -0.026\n",
      "Loss: 246.571, Residuals: -0.026\n",
      "Evidence 789.927\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 4.57e-01\n",
      "Loss: 248.923, Residuals: -0.025\n",
      "Loss: 248.531, Residuals: -0.026\n",
      "Loss: 248.484, Residuals: -0.026\n",
      "Loss: 248.047, Residuals: -0.025\n",
      "Loss: 248.045, Residuals: -0.025\n",
      "Evidence 791.417\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 4.65e-01\n",
      "Loss: 249.560, Residuals: -0.025\n",
      "Evidence 791.980\n",
      "Pass count  1\n",
      "Total samples: 63, Updated regularization: 1.00e-05\n",
      "Loss: 17.595, Residuals: 0.050\n",
      "Loss: 10.412, Residuals: 0.041\n",
      "Loss: 8.153, Residuals: 0.019\n",
      "Loss: 7.832, Residuals: -0.048\n",
      "Loss: 7.320, Residuals: -0.037\n",
      "Loss: 6.670, Residuals: -0.026\n",
      "Loss: 6.421, Residuals: 0.004\n",
      "Loss: 6.396, Residuals: 0.003\n",
      "Loss: 6.350, Residuals: 0.005\n",
      "Loss: 6.272, Residuals: -0.001\n",
      "Loss: 6.158, Residuals: -0.012\n",
      "Loss: 6.152, Residuals: 0.001\n",
      "Loss: 6.104, Residuals: -0.004\n",
      "Loss: 6.026, Residuals: -0.009\n",
      "Loss: 6.020, Residuals: -0.006\n",
      "Loss: 5.969, Residuals: -0.007\n",
      "Loss: 5.965, Residuals: -0.009\n",
      "Loss: 5.958, Residuals: -0.003\n",
      "Loss: 5.946, Residuals: -0.001\n",
      "Loss: 5.883, Residuals: -0.001\n",
      "Loss: 5.875, Residuals: -0.003\n",
      "Loss: 5.862, Residuals: 0.001\n",
      "Loss: 5.841, Residuals: 0.008\n",
      "Loss: 5.800, Residuals: 0.005\n",
      "Loss: 5.765, Residuals: 0.009\n",
      "Loss: 5.764, Residuals: 0.009\n",
      "Loss: 5.711, Residuals: 0.006\n",
      "Loss: 5.707, Residuals: 0.008\n",
      "Loss: 5.574, Residuals: 0.002\n",
      "Loss: 5.569, Residuals: 0.005\n",
      "Loss: 5.561, Residuals: 0.008\n",
      "Loss: 5.548, Residuals: 0.012\n",
      "Loss: 5.546, Residuals: 0.017\n",
      "Loss: 5.480, Residuals: 0.013\n",
      "Loss: 5.480, Residuals: 0.012\n",
      "Evidence -410.083\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 5.51e-02\n",
      "Loss: 31.478, Residuals: 0.012\n",
      "Loss: 31.453, Residuals: 0.014\n",
      "Loss: 31.405, Residuals: 0.014\n",
      "Loss: 31.319, Residuals: 0.014\n",
      "Loss: 31.190, Residuals: 0.015\n",
      "Loss: 30.983, Residuals: 0.018\n",
      "Loss: 30.983, Residuals: 0.018\n",
      "Loss: 30.780, Residuals: 0.019\n",
      "Loss: 30.778, Residuals: 0.019\n",
      "Loss: 30.615, Residuals: 0.019\n",
      "Loss: 30.614, Residuals: 0.019\n",
      "Loss: 30.604, Residuals: 0.020\n",
      "Loss: 30.518, Residuals: 0.019\n",
      "Loss: 30.515, Residuals: 0.022\n",
      "Loss: 30.384, Residuals: 0.020\n",
      "Loss: 30.384, Residuals: 0.019\n",
      "Evidence 330.591\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 3.33e-01\n",
      "Loss: 107.597, Residuals: 0.019\n",
      "Loss: 107.299, Residuals: 0.015\n",
      "Loss: 106.814, Residuals: 0.013\n",
      "Loss: 106.370, Residuals: 0.011\n",
      "Loss: 106.302, Residuals: 0.013\n",
      "Loss: 106.173, Residuals: 0.013\n",
      "Loss: 105.968, Residuals: 0.014\n",
      "Loss: 105.968, Residuals: 0.013\n",
      "Evidence 653.661\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 7.18e-01\n",
      "Loss: 196.762, Residuals: 0.013\n",
      "Loss: 196.291, Residuals: 0.012\n",
      "Loss: 195.528, Residuals: 0.007\n",
      "Loss: 194.689, Residuals: 0.002\n",
      "Loss: 194.620, Residuals: -0.002\n",
      "Loss: 193.994, Residuals: -0.001\n",
      "Loss: 193.081, Residuals: 0.002\n",
      "Loss: 193.066, Residuals: 0.001\n",
      "Loss: 193.048, Residuals: 0.005\n",
      "Loss: 192.436, Residuals: 0.005\n",
      "Loss: 192.430, Residuals: 0.005\n",
      "Loss: 192.425, Residuals: 0.004\n",
      "Loss: 192.266, Residuals: 0.004\n",
      "Loss: 192.242, Residuals: 0.004\n",
      "Loss: 192.023, Residuals: 0.004\n",
      "Loss: 192.020, Residuals: 0.005\n",
      "Loss: 191.902, Residuals: 0.005\n",
      "Loss: 191.689, Residuals: 0.005\n",
      "Loss: 191.688, Residuals: 0.005\n",
      "Evidence 768.274\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 7.64e-01\n",
      "Loss: 235.169, Residuals: 0.007\n",
      "Loss: 235.010, Residuals: 0.006\n",
      "Loss: 234.714, Residuals: 0.004\n",
      "Loss: 234.226, Residuals: 0.000\n",
      "Loss: 233.703, Residuals: -0.008\n",
      "Loss: 233.701, Residuals: -0.008\n",
      "Evidence 791.612\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 7.95e-01\n",
      "Loss: 246.105, Residuals: -0.008\n",
      "Loss: 246.082, Residuals: -0.008\n",
      "Loss: 246.044, Residuals: -0.007\n",
      "Loss: 245.703, Residuals: -0.008\n",
      "Loss: 245.208, Residuals: -0.010\n",
      "Loss: 245.206, Residuals: -0.010\n",
      "Evidence 796.785\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 8.02e-01\n",
      "Loss: 248.625, Residuals: -0.007\n",
      "Loss: 248.191, Residuals: -0.008\n",
      "Loss: 247.894, Residuals: -0.013\n",
      "Loss: 247.892, Residuals: -0.013\n",
      "Evidence 799.572\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 8.00e-01\n",
      "Loss: 249.094, Residuals: -0.006\n",
      "Loss: 249.093, Residuals: -0.006\n",
      "Evidence 800.875\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 8.00e-01\n",
      "Loss: 248.210, Residuals: -0.010\n",
      "Loss: 248.121, Residuals: -0.010\n",
      "Loss: 248.052, Residuals: -0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 247.947, Residuals: -0.011\n",
      "Loss: 247.751, Residuals: -0.011\n",
      "Loss: 247.736, Residuals: -0.011\n",
      "Loss: 247.180, Residuals: -0.012\n",
      "Loss: 247.176, Residuals: -0.012\n",
      "Evidence 804.418\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 7.33e-01\n",
      "Loss: 249.294, Residuals: -0.012\n",
      "Evidence 805.396\n",
      "Updating hyper-parameters...\n",
      "Total samples: 63, Updated regularization: 7.40e-01\n",
      "Loss: 250.158, Residuals: -0.012\n",
      "Loss: 250.148, Residuals: -0.011\n",
      "Loss: 249.757, Residuals: -0.012\n",
      "Loss: 249.756, Residuals: -0.012\n",
      "Evidence 806.025\n",
      "Pass count  1\n",
      "Total samples: 44, Updated regularization: 1.00e-05\n",
      "Loss: 14.744, Residuals: -0.011\n",
      "Loss: 7.431, Residuals: -0.029\n",
      "Loss: 5.499, Residuals: -0.020\n",
      "Loss: 4.648, Residuals: -0.010\n",
      "Loss: 4.202, Residuals: 0.023\n",
      "Loss: 4.171, Residuals: 0.030\n",
      "Loss: 3.914, Residuals: -0.005\n",
      "Loss: 3.890, Residuals: 0.008\n",
      "Loss: 3.682, Residuals: -0.006\n",
      "Loss: 3.394, Residuals: -0.033\n",
      "Loss: 3.367, Residuals: -0.010\n",
      "Loss: 3.319, Residuals: -0.019\n",
      "Loss: 3.239, Residuals: -0.034\n",
      "Loss: 3.228, Residuals: -0.023\n",
      "Loss: 3.206, Residuals: -0.027\n",
      "Loss: 3.166, Residuals: -0.036\n",
      "Loss: 3.150, Residuals: -0.036\n",
      "Loss: 3.121, Residuals: -0.044\n",
      "Loss: 3.080, Residuals: -0.058\n",
      "Loss: 3.077, Residuals: -0.051\n",
      "Loss: 3.074, Residuals: -0.057\n",
      "Loss: 3.050, Residuals: -0.063\n",
      "Loss: 3.045, Residuals: -0.061\n",
      "Loss: 3.038, Residuals: -0.062\n",
      "Loss: 3.025, Residuals: -0.063\n",
      "Loss: 3.023, Residuals: -0.061\n",
      "Loss: 3.011, Residuals: -0.064\n",
      "Loss: 2.993, Residuals: -0.068\n",
      "Loss: 2.993, Residuals: -0.068\n",
      "Loss: 2.986, Residuals: -0.068\n",
      "Loss: 2.985, Residuals: -0.066\n",
      "Loss: 2.974, Residuals: -0.067\n",
      "Loss: 2.974, Residuals: -0.067\n",
      "Loss: 2.973, Residuals: -0.067\n",
      "Loss: 2.966, Residuals: -0.068\n",
      "Loss: 2.958, Residuals: -0.065\n",
      "Loss: 2.955, Residuals: -0.068\n",
      "Loss: 2.933, Residuals: -0.072\n",
      "Loss: 2.932, Residuals: -0.071\n",
      "Loss: 2.932, Residuals: -0.072\n",
      "Loss: 2.931, Residuals: -0.072\n",
      "Loss: 2.930, Residuals: -0.070\n",
      "Loss: 2.918, Residuals: -0.072\n",
      "Loss: 2.916, Residuals: -0.071\n",
      "Loss: 2.914, Residuals: -0.069\n",
      "Loss: 2.913, Residuals: -0.067\n",
      "Loss: 2.907, Residuals: -0.069\n",
      "Loss: 2.902, Residuals: -0.067\n",
      "Loss: 2.900, Residuals: -0.064\n",
      "Loss: 2.897, Residuals: -0.064\n",
      "Loss: 2.896, Residuals: -0.062\n",
      "Loss: 2.895, Residuals: -0.062\n",
      "Loss: 2.886, Residuals: -0.065\n",
      "Loss: 2.886, Residuals: -0.064\n",
      "Loss: 2.886, Residuals: -0.065\n",
      "Loss: 2.876, Residuals: -0.066\n",
      "Loss: 2.875, Residuals: -0.064\n",
      "Loss: 2.875, Residuals: -0.063\n",
      "Loss: 2.874, Residuals: -0.061\n",
      "Loss: 2.873, Residuals: -0.061\n",
      "Loss: 2.866, Residuals: -0.063\n",
      "Loss: 2.866, Residuals: -0.062\n",
      "Loss: 2.866, Residuals: -0.063\n",
      "Evidence -413.082\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.66e-02\n",
      "Loss: 15.881, Residuals: -0.048\n",
      "Loss: 15.876, Residuals: -0.047\n",
      "Loss: 15.834, Residuals: -0.051\n",
      "Loss: 15.752, Residuals: -0.048\n",
      "Loss: 15.606, Residuals: -0.044\n",
      "Loss: 15.393, Residuals: -0.033\n",
      "Loss: 15.392, Residuals: -0.033\n",
      "Loss: 15.392, Residuals: -0.033\n",
      "Evidence 150.097\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.02e-01\n",
      "Loss: 53.520, Residuals: -0.033\n",
      "Loss: 53.513, Residuals: -0.033\n",
      "Loss: 53.452, Residuals: -0.030\n",
      "Loss: 52.962, Residuals: -0.030\n",
      "Loss: 52.959, Residuals: -0.030\n",
      "Loss: 52.936, Residuals: -0.028\n",
      "Loss: 52.714, Residuals: -0.027\n",
      "Loss: 52.350, Residuals: -0.022\n",
      "Loss: 52.347, Residuals: -0.022\n",
      "Loss: 52.342, Residuals: -0.022\n",
      "Loss: 52.138, Residuals: -0.019\n",
      "Loss: 51.759, Residuals: -0.013\n",
      "Loss: 51.745, Residuals: -0.012\n",
      "Loss: 51.304, Residuals: -0.003\n",
      "Loss: 51.300, Residuals: -0.004\n",
      "Loss: 51.298, Residuals: -0.004\n",
      "Loss: 51.277, Residuals: -0.003\n",
      "Loss: 51.094, Residuals: 0.000\n",
      "Loss: 51.043, Residuals: 0.005\n",
      "Loss: 51.042, Residuals: 0.005\n",
      "Evidence 371.749\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 2.85e-01\n",
      "Loss: 108.728, Residuals: 0.004\n",
      "Loss: 108.557, Residuals: 0.005\n",
      "Loss: 108.253, Residuals: 0.005\n",
      "Loss: 107.708, Residuals: 0.003\n",
      "Loss: 106.905, Residuals: -0.003\n",
      "Loss: 106.429, Residuals: -0.010\n",
      "Loss: 105.759, Residuals: -0.007\n",
      "Loss: 105.755, Residuals: -0.007\n",
      "Loss: 105.747, Residuals: -0.007\n",
      "Loss: 105.678, Residuals: -0.006\n",
      "Loss: 105.626, Residuals: -0.005\n",
      "Loss: 105.620, Residuals: -0.004\n",
      "Loss: 105.568, Residuals: -0.004\n",
      "Loss: 105.478, Residuals: -0.003\n",
      "Loss: 105.474, Residuals: -0.003\n",
      "Loss: 105.335, Residuals: -0.003\n",
      "Loss: 105.335, Residuals: -0.003\n",
      "Loss: 105.237, Residuals: -0.003\n",
      "Loss: 105.077, Residuals: -0.002\n",
      "Loss: 105.076, Residuals: -0.002\n",
      "Loss: 105.075, Residuals: -0.002\n",
      "Loss: 105.062, Residuals: -0.002\n",
      "Loss: 105.061, Residuals: -0.001\n",
      "Loss: 105.012, Residuals: -0.001\n",
      "Loss: 105.012, Residuals: -0.001\n",
      "Loss: 105.004, Residuals: -0.001\n",
      "Loss: 105.004, Residuals: -0.001\n",
      "Evidence 485.289\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 5.38e-01\n",
      "Loss: 146.712, Residuals: 0.004\n",
      "Loss: 145.633, Residuals: -0.003\n",
      "Loss: 145.152, Residuals: -0.009\n",
      "Loss: 144.755, Residuals: -0.012\n",
      "Loss: 144.734, Residuals: -0.012\n",
      "Loss: 144.696, Residuals: -0.012\n",
      "Loss: 144.630, Residuals: -0.011\n",
      "Loss: 144.514, Residuals: -0.011\n",
      "Loss: 144.512, Residuals: -0.011\n",
      "Loss: 144.290, Residuals: -0.010\n",
      "Loss: 144.196, Residuals: -0.010\n",
      "Loss: 144.193, Residuals: -0.010\n",
      "Loss: 143.770, Residuals: -0.009\n",
      "Loss: 143.758, Residuals: -0.008\n",
      "Loss: 143.653, Residuals: -0.008\n",
      "Loss: 142.919, Residuals: -0.004\n",
      "Loss: 142.840, Residuals: -0.004\n",
      "Loss: 142.248, Residuals: -0.002\n",
      "Loss: 142.106, Residuals: 0.003\n",
      "Loss: 141.918, Residuals: 0.001\n",
      "Loss: 141.893, Residuals: 0.001\n",
      "Loss: 141.661, Residuals: 0.001\n",
      "Loss: 141.640, Residuals: 0.001\n",
      "Loss: 141.440, Residuals: 0.002\n",
      "Loss: 141.413, Residuals: 0.003\n",
      "Loss: 141.168, Residuals: 0.004\n",
      "Loss: 141.150, Residuals: 0.003\n",
      "Loss: 140.988, Residuals: 0.005\n",
      "Loss: 140.968, Residuals: 0.005\n",
      "Loss: 140.800, Residuals: 0.006\n",
      "Loss: 140.780, Residuals: 0.007\n",
      "Loss: 140.741, Residuals: 0.007\n",
      "Loss: 140.671, Residuals: 0.008\n",
      "Loss: 140.659, Residuals: 0.008\n",
      "Loss: 140.638, Residuals: 0.009\n",
      "Loss: 140.600, Residuals: 0.009\n",
      "Loss: 140.588, Residuals: 0.009\n",
      "Loss: 140.566, Residuals: 0.009\n",
      "Loss: 140.563, Residuals: 0.009\n",
      "Loss: 140.544, Residuals: 0.009\n",
      "Loss: 140.542, Residuals: 0.009\n",
      "Loss: 140.538, Residuals: 0.010\n",
      "Loss: 140.532, Residuals: 0.010\n",
      "Loss: 140.531, Residuals: 0.010\n",
      "Loss: 140.529, Residuals: 0.010\n",
      "Loss: 140.526, Residuals: 0.010\n",
      "Loss: 140.525, Residuals: 0.010\n",
      "Loss: 140.525, Residuals: 0.010\n",
      "Loss: 140.523, Residuals: 0.010\n",
      "Loss: 140.523, Residuals: 0.010\n",
      "Loss: 140.523, Residuals: 0.010\n",
      "Loss: 140.522, Residuals: 0.010\n",
      "Loss: 140.522, Residuals: 0.010\n",
      "Loss: 140.522, Residuals: 0.011\n",
      "Loss: 140.522, Residuals: 0.011\n",
      "Evidence 523.023\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.62e+00\n",
      "Loss: 161.483, Residuals: 0.016\n",
      "Loss: 160.928, Residuals: 0.014\n",
      "Loss: 160.613, Residuals: 0.015\n",
      "Loss: 160.596, Residuals: 0.015\n",
      "Loss: 160.453, Residuals: 0.015\n",
      "Loss: 160.291, Residuals: 0.015\n",
      "Loss: 160.282, Residuals: 0.015\n",
      "Loss: 160.279, Residuals: 0.015\n",
      "Loss: 160.273, Residuals: 0.015\n",
      "Loss: 160.270, Residuals: 0.016\n",
      "Loss: 160.265, Residuals: 0.016\n",
      "Loss: 160.265, Residuals: 0.015\n",
      "Loss: 160.265, Residuals: 0.015\n",
      "Loss: 160.264, Residuals: 0.015\n",
      "Loss: 160.262, Residuals: 0.015\n",
      "Loss: 160.262, Residuals: 0.015\n",
      "Loss: 160.262, Residuals: 0.015\n",
      "Loss: 160.262, Residuals: 0.015\n",
      "Evidence 542.876\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.69e+00\n",
      "Loss: 169.079, Residuals: 0.018\n",
      "Loss: 168.831, Residuals: 0.019\n",
      "Loss: 168.594, Residuals: 0.019\n",
      "Loss: 168.461, Residuals: 0.013\n",
      "Loss: 168.364, Residuals: 0.013\n",
      "Loss: 168.342, Residuals: 0.015\n",
      "Loss: 168.330, Residuals: 0.016\n",
      "Loss: 168.326, Residuals: 0.014\n",
      "Loss: 168.318, Residuals: 0.015\n",
      "Loss: 168.317, Residuals: 0.015\n",
      "Loss: 168.311, Residuals: 0.015\n",
      "Loss: 168.311, Residuals: 0.015\n",
      "Loss: 168.309, Residuals: 0.015\n",
      "Loss: 168.308, Residuals: 0.015\n",
      "Loss: 168.308, Residuals: 0.015\n",
      "Loss: 168.307, Residuals: 0.015\n",
      "Loss: 168.307, Residuals: 0.015\n",
      "Evidence 548.270\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.69e+00\n",
      "Loss: 171.480, Residuals: 0.014\n",
      "Loss: 171.378, Residuals: 0.015\n",
      "Loss: 171.293, Residuals: 0.013\n",
      "Loss: 171.209, Residuals: 0.013\n",
      "Loss: 171.195, Residuals: 0.015\n",
      "Loss: 171.173, Residuals: 0.014\n",
      "Loss: 171.171, Residuals: 0.013\n",
      "Loss: 171.166, Residuals: 0.013\n",
      "Loss: 171.160, Residuals: 0.013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 171.159, Residuals: 0.013\n",
      "Loss: 171.158, Residuals: 0.013\n",
      "Loss: 171.156, Residuals: 0.013\n",
      "Loss: 171.156, Residuals: 0.013\n",
      "Loss: 171.156, Residuals: 0.013\n",
      "Loss: 171.155, Residuals: 0.013\n",
      "Loss: 171.154, Residuals: 0.013\n",
      "Loss: 171.154, Residuals: 0.013\n",
      "Loss: 171.154, Residuals: 0.013\n",
      "Loss: 171.154, Residuals: 0.013\n",
      "Loss: 171.154, Residuals: 0.013\n",
      "Evidence 550.571\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.72e+00\n",
      "Loss: 172.474, Residuals: 0.012\n",
      "Loss: 172.417, Residuals: 0.012\n",
      "Loss: 172.347, Residuals: 0.012\n",
      "Loss: 172.300, Residuals: 0.011\n",
      "Loss: 172.297, Residuals: 0.012\n",
      "Loss: 172.291, Residuals: 0.012\n",
      "Loss: 172.284, Residuals: 0.012\n",
      "Loss: 172.284, Residuals: 0.012\n",
      "Loss: 172.282, Residuals: 0.012\n",
      "Loss: 172.281, Residuals: 0.012\n",
      "Loss: 172.280, Residuals: 0.012\n",
      "Loss: 172.280, Residuals: 0.012\n",
      "Loss: 172.280, Residuals: 0.012\n",
      "Loss: 172.279, Residuals: 0.012\n",
      "Loss: 172.279, Residuals: 0.012\n",
      "Loss: 172.279, Residuals: 0.012\n",
      "Loss: 172.278, Residuals: 0.012\n",
      "Loss: 172.278, Residuals: 0.012\n",
      "Loss: 172.278, Residuals: 0.012\n",
      "Loss: 172.278, Residuals: 0.012\n",
      "Loss: 172.278, Residuals: 0.012\n",
      "Evidence 551.929\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.78e+00\n",
      "Loss: 172.923, Residuals: 0.011\n",
      "Loss: 172.875, Residuals: 0.011\n",
      "Loss: 172.828, Residuals: 0.011\n",
      "Loss: 172.791, Residuals: 0.011\n",
      "Loss: 172.789, Residuals: 0.011\n",
      "Loss: 172.785, Residuals: 0.011\n",
      "Loss: 172.779, Residuals: 0.011\n",
      "Loss: 172.779, Residuals: 0.011\n",
      "Loss: 172.775, Residuals: 0.011\n",
      "Loss: 172.772, Residuals: 0.011\n",
      "Loss: 172.772, Residuals: 0.011\n",
      "Loss: 172.771, Residuals: 0.011\n",
      "Loss: 172.771, Residuals: 0.011\n",
      "Loss: 172.770, Residuals: 0.011\n",
      "Loss: 172.770, Residuals: 0.011\n",
      "Loss: 172.770, Residuals: 0.011\n",
      "Loss: 172.770, Residuals: 0.011\n",
      "Loss: 172.770, Residuals: 0.011\n",
      "Evidence 553.025\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.83e+00\n",
      "Loss: 173.144, Residuals: 0.010\n",
      "Loss: 173.104, Residuals: 0.011\n",
      "Loss: 173.051, Residuals: 0.010\n",
      "Loss: 173.030, Residuals: 0.010\n",
      "Loss: 173.025, Residuals: 0.010\n",
      "Loss: 173.019, Residuals: 0.010\n",
      "Loss: 173.018, Residuals: 0.010\n",
      "Loss: 173.016, Residuals: 0.010\n",
      "Loss: 173.014, Residuals: 0.010\n",
      "Loss: 173.013, Residuals: 0.010\n",
      "Loss: 173.013, Residuals: 0.010\n",
      "Loss: 173.012, Residuals: 0.010\n",
      "Loss: 173.012, Residuals: 0.010\n",
      "Loss: 173.012, Residuals: 0.010\n",
      "Loss: 173.012, Residuals: 0.010\n",
      "Loss: 173.012, Residuals: 0.010\n",
      "Loss: 173.012, Residuals: 0.010\n",
      "Loss: 173.012, Residuals: 0.010\n",
      "Evidence 554.021\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.88e+00\n",
      "Loss: 173.271, Residuals: 0.010\n",
      "Loss: 173.239, Residuals: 0.010\n",
      "Loss: 173.202, Residuals: 0.011\n",
      "Loss: 173.172, Residuals: 0.010\n",
      "Loss: 173.169, Residuals: 0.010\n",
      "Loss: 173.164, Residuals: 0.010\n",
      "Loss: 173.157, Residuals: 0.010\n",
      "Loss: 173.156, Residuals: 0.010\n",
      "Loss: 173.156, Residuals: 0.010\n",
      "Loss: 173.155, Residuals: 0.010\n",
      "Loss: 173.153, Residuals: 0.010\n",
      "Loss: 173.153, Residuals: 0.010\n",
      "Loss: 173.153, Residuals: 0.010\n",
      "Loss: 173.153, Residuals: 0.010\n",
      "Loss: 173.153, Residuals: 0.010\n",
      "Loss: 173.153, Residuals: 0.010\n",
      "Loss: 173.153, Residuals: 0.010\n",
      "Loss: 173.153, Residuals: 0.010\n",
      "Loss: 173.152, Residuals: 0.010\n",
      "Evidence 554.929\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.92e+00\n",
      "Loss: 173.328, Residuals: 0.010\n",
      "Loss: 173.308, Residuals: 0.009\n",
      "Loss: 173.279, Residuals: 0.010\n",
      "Loss: 173.274, Residuals: 0.009\n",
      "Loss: 173.266, Residuals: 0.009\n",
      "Loss: 173.259, Residuals: 0.009\n",
      "Loss: 173.258, Residuals: 0.009\n",
      "Loss: 173.258, Residuals: 0.009\n",
      "Loss: 173.257, Residuals: 0.009\n",
      "Loss: 173.256, Residuals: 0.009\n",
      "Loss: 173.256, Residuals: 0.009\n",
      "Evidence 555.695\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.94e+00\n",
      "Loss: 173.402, Residuals: 0.010\n",
      "Loss: 173.386, Residuals: 0.009\n",
      "Loss: 173.364, Residuals: 0.009\n",
      "Loss: 173.361, Residuals: 0.009\n",
      "Loss: 173.354, Residuals: 0.008\n",
      "Loss: 173.349, Residuals: 0.009\n",
      "Loss: 173.349, Residuals: 0.009\n",
      "Loss: 173.348, Residuals: 0.008\n",
      "Loss: 173.348, Residuals: 0.008\n",
      "Loss: 173.347, Residuals: 0.008\n",
      "Loss: 173.347, Residuals: 0.008\n",
      "Loss: 173.347, Residuals: 0.008\n",
      "Evidence 556.323\n",
      "Updating hyper-parameters...\n",
      "Total samples: 44, Updated regularization: 1.96e+00\n",
      "Loss: 173.462, Residuals: 0.009\n",
      "Loss: 173.451, Residuals: 0.008\n",
      "Loss: 173.441, Residuals: 0.008\n",
      "Loss: 173.428, Residuals: 0.008\n",
      "Loss: 173.427, Residuals: 0.008\n",
      "Loss: 173.426, Residuals: 0.008\n",
      "Loss: 173.424, Residuals: 0.008\n",
      "Loss: 173.424, Residuals: 0.008\n",
      "Loss: 173.424, Residuals: 0.008\n",
      "Loss: 173.423, Residuals: 0.008\n",
      "Loss: 173.423, Residuals: 0.008\n",
      "Loss: 173.423, Residuals: 0.008\n",
      "Evidence 556.808\n",
      "Pass count  1\n"
     ]
    }
   ],
   "source": [
    "# for each data set \n",
    "for file in files:\n",
    "    # import data\n",
    "    df = pd.read_csv(f\"data/{file}\")\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "    n_species = len(species)\n",
    "\n",
    "    # instantiate gLV fit \n",
    "    model = gLV(species, df) \n",
    "\n",
    "    # fit to data \n",
    "    model.fit()\n",
    "    \n",
    "    # plot parameter distribution\n",
    "    Avec = model.params[n_species:]\n",
    "    Aij_std = np.sqrt(np.diag(model.Ainv))[n_species:]\n",
    "    \n",
    "    plt.figure(figsize=(18,18))\n",
    "    # set counter for parameter std. \n",
    "    k = 0\n",
    "\n",
    "    for i in range(n_species):\n",
    "        for j in range(n_species):\n",
    "            plt.subplot(n_species, n_species, k+1)\n",
    "            a = np.linspace(Avec[k]-np.std(Avec), Avec[k]+np.std(Avec))\n",
    "            plt.plot(a, norm.pdf(a,Avec[k],Aij_std[k]))\n",
    "            plt.axvline(x=0, c='k', alpha=.5)\n",
    "            k += 1\n",
    "            if j == 0:\n",
    "                plt.ylabel(species[i], fontsize=18)\n",
    "            if i == n_species-1:\n",
    "                plt.xlabel(species[j], fontsize=18)\n",
    "            #plt.xlim([-2,2])\n",
    "\n",
    "    plt.suptitle(file.split(\"_\")[1], fontsize=24)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(\"params/\"+file.split(\"_\")[1]+\".pdf\")\n",
    "    plt.close()\n",
    "    \n",
    "    # compute Wald test for each parameter\n",
    "    std_errors = np.sqrt(np.diag(model.Ainv))\n",
    "    walds = model.params/std_errors\n",
    "    wald_p_vals = 2*norm.cdf(-np.abs(walds))\n",
    "\n",
    "    # list of parameter names \n",
    "    param_names = []\n",
    "    for s1 in species:\n",
    "        for s2 in species:\n",
    "            param_names += [s1+\"*\"+s2]\n",
    "    param_names = list(species) + param_names\n",
    "    \n",
    "    # save to df \n",
    "    df = pd.DataFrame()\n",
    "    df[\"Param name\"] = param_names\n",
    "    df[\"Param value\"] = model.params\n",
    "    df[\"Param stdv\"]  = np.sqrt(np.diag(model.Ainv))\n",
    "    df[\"Param p-value\"] = wald_p_vals\n",
    "    for j, param_name in enumerate(param_names):\n",
    "        df[param_name]  = model.Ainv[:, j]\n",
    "    df.to_csv(\"params/\"+file.split(\"_\")[1]+\".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
