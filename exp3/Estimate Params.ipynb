{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a637f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from glove.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06280f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file names\n",
    "files = os.listdir(\"data/\")\n",
    "strains = [\"MS014\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66f683",
   "metadata": {},
   "source": [
    "# fit gLV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af71ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 88, Initial regularization: 1.00e-03\n",
      "Loss: 15.726, Residuals: 0.043\n",
      "Loss: 9.564, Residuals: 0.124\n",
      "Loss: 7.973, Residuals: 0.115\n",
      "Loss: 7.793, Residuals: 0.088\n",
      "Loss: 7.457, Residuals: 0.076\n",
      "Loss: 6.896, Residuals: 0.053\n",
      "Loss: 6.338, Residuals: 0.028\n",
      "Loss: 6.215, Residuals: 0.053\n",
      "Loss: 6.036, Residuals: 0.027\n",
      "Loss: 6.004, Residuals: 0.022\n",
      "Loss: 5.948, Residuals: 0.012\n",
      "Loss: 5.870, Residuals: -0.003\n",
      "Loss: 5.864, Residuals: -0.000\n",
      "Loss: 5.853, Residuals: -0.002\n",
      "Loss: 5.834, Residuals: -0.007\n",
      "Loss: 5.817, Residuals: -0.011\n",
      "Loss: 5.816, Residuals: -0.011\n",
      "Loss: 5.804, Residuals: -0.014\n",
      "Loss: 5.793, Residuals: -0.019\n",
      "Loss: 5.792, Residuals: -0.019\n",
      "Loss: 5.791, Residuals: -0.018\n",
      "Loss: 5.788, Residuals: -0.019\n",
      "Loss: 5.788, Residuals: -0.019\n",
      "Loss: 5.788, Residuals: -0.020\n",
      "Loss: 5.787, Residuals: -0.020\n",
      "Loss: 5.787, Residuals: -0.020\n",
      "Loss: 5.786, Residuals: -0.020\n",
      "Loss: 5.786, Residuals: -0.021\n",
      "Loss: 5.785, Residuals: -0.021\n",
      "Loss: 5.785, Residuals: -0.021\n",
      "Loss: 5.785, Residuals: -0.021\n",
      "Loss: 5.785, Residuals: -0.021\n",
      "Loss: 5.784, Residuals: -0.021\n",
      "Loss: 5.784, Residuals: -0.021\n",
      "Loss: 5.784, Residuals: -0.021\n",
      "Loss: 5.784, Residuals: -0.021\n",
      "Loss: 5.784, Residuals: -0.021\n",
      "Loss: 5.784, Residuals: -0.021\n",
      "Loss: 5.784, Residuals: -0.021\n",
      "Loss: 5.784, Residuals: -0.022\n",
      "Loss: 5.784, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Loss: 5.783, Residuals: -0.022\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "Evidence -59.132\n",
      "Updating hyper-parameters...\n",
      "Total samples: 88, Updated regularization: 7.82e-01\n",
      "Loss: 95.452, Residuals: -0.010\n",
      "Loss: 93.670, Residuals: 0.003\n",
      "Loss: 93.146, Residuals: -0.001\n",
      "Loss: 92.177, Residuals: 0.003\n",
      "Loss: 91.119, Residuals: 0.003\n",
      "Loss: 91.107, Residuals: 0.002\n",
      "Optimization terminated successfully.\n",
      "Evidence 789.593\n",
      "Updating hyper-parameters...\n",
      "Total samples: 88, Updated regularization: 1.19e+00\n",
      "Loss: 262.147, Residuals: 0.004\n",
      "Loss: 261.457, Residuals: 0.001\n",
      "Loss: 260.655, Residuals: 0.001\n",
      "Loss: 260.591, Residuals: 0.001\n",
      "Loss: 260.104, Residuals: 0.004\n",
      "Loss: 260.099, Residuals: 0.004\n",
      "Optimization terminated successfully.\n",
      "Evidence 1045.041\n",
      "Updating hyper-parameters...\n",
      "Total samples: 88, Updated regularization: 1.50e+00\n",
      "Loss: 335.954, Residuals: 0.006\n",
      "Loss: 335.641, Residuals: 0.003\n",
      "Loss: 335.295, Residuals: 0.001\n",
      "Loss: 335.272, Residuals: 0.002\n",
      "Loss: 335.253, Residuals: 0.002\n",
      "Loss: 335.221, Residuals: 0.002\n",
      "Loss: 335.200, Residuals: 0.003\n",
      "Loss: 335.199, Residuals: 0.003\n",
      "Optimization terminated successfully.\n",
      "Evidence 1072.673\n",
      "Updating hyper-parameters...\n",
      "Total samples: 88, Updated regularization: 1.68e+00\n",
      "Loss: 348.833, Residuals: 0.002\n",
      "Loss: 348.756, Residuals: 0.001\n",
      "Loss: 348.743, Residuals: 0.001\n",
      "Loss: 348.721, Residuals: 0.001\n",
      "Loss: 348.699, Residuals: 0.002\n",
      "Loss: 348.698, Residuals: 0.001\n",
      "Optimization terminated successfully.\n",
      "Evidence 1075.841\n",
      "Updating hyper-parameters...\n",
      "Total samples: 88, Updated regularization: 1.72e+00\n",
      "Loss: 351.147, Residuals: 0.001\n",
      "Loss: 351.115, Residuals: 0.000\n",
      "Loss: 351.087, Residuals: 0.000\n",
      "Loss: 351.085, Residuals: 0.000\n",
      "Optimization terminated successfully.\n",
      "Evidence 1076.977\n",
      "Updating hyper-parameters...\n",
      "Total samples: 88, Updated regularization: 1.73e+00\n",
      "Loss: 351.813, Residuals: -0.000\n",
      "Loss: 351.806, Residuals: -0.000\n",
      "Optimization terminated successfully.\n",
      "Evidence 1077.442\n",
      "Pass count  1\n"
     ]
    }
   ],
   "source": [
    "exp_names = []\n",
    "for strain in strains:\n",
    "    # import data\n",
    "    df_universal = pd.read_csv(\"data/Universal.csv\")\n",
    "    df_strain = pd.concat([pd.read_csv(f\"data/{fname}\") for fname in files if strain in fname])\n",
    "    df = pd.concat((df_universal, df_strain))\n",
    "    df.sort_values(by=[\"Treatments\", \"Time\"], inplace=True)\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "\n",
    "    # instantiate gLV fit \n",
    "    model = gLV(species, df)\n",
    "\n",
    "    # fit to data \n",
    "    model.fit()\n",
    "    \n",
    "    # list of parameter names \n",
    "    param_names = []\n",
    "    for s1 in species:\n",
    "        for s2 in species:\n",
    "            param_names += [s1+\"*\"+s2]\n",
    "    param_names = list(species) + param_names\n",
    "    \n",
    "    # plot parameter distribution\n",
    "    n_species = len(species)\n",
    "    Avec = model.params[n_species:]\n",
    "    Aij_std = np.sqrt(np.diag(model.Ainv))[n_species:]\n",
    "\n",
    "    plt.figure(figsize=(18,18))\n",
    "    # set counter for parameter std. \n",
    "    k = 0\n",
    "\n",
    "    for i in range(n_species):\n",
    "        for j in range(n_species):\n",
    "            plt.subplot(n_species, n_species, k+1)\n",
    "            a = np.linspace(Avec[k]-np.std(Avec), Avec[k]+np.std(Avec))\n",
    "            plt.plot(a, norm.pdf(a,Avec[k],Aij_std[k]))\n",
    "            plt.axvline(x=0, c='k', alpha=.5)\n",
    "            k += 1\n",
    "            if j == 0:\n",
    "                plt.ylabel(species[i], fontsize=18)\n",
    "            if i == n_species-1:\n",
    "                plt.xlabel(species[j], fontsize=18)\n",
    "            #plt.xlim([-2,2])\n",
    "\n",
    "    plt.suptitle(strain, fontsize=24)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(\"figures/\"+strain+\".pdf\")\n",
    "    plt.close()\n",
    "    \n",
    "    # compute Wald test for each parameter\n",
    "    std_errors = np.sqrt(np.diag(model.Ainv))\n",
    "    walds = model.params/std_errors\n",
    "    wald_p_vals = 2*norm.cdf(-np.abs(walds))\n",
    "\n",
    "    # save to df \n",
    "    df = pd.DataFrame()\n",
    "    df[\"Param name\"] = param_names\n",
    "    df[\"Param value\"] = model.params\n",
    "    df[\"Param stdv\"]  = np.sqrt(np.diag(model.Ainv))\n",
    "    df[\"Param p-value\"] = wald_p_vals\n",
    "    for j, param_name in enumerate(param_names):\n",
    "        df[param_name]  = model.Ainv[:, j]\n",
    "    df.to_csv(\"params/\"+strain+\".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
