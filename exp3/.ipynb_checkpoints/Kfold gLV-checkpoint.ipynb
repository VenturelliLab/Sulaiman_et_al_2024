{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a637f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm, linregress\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from glove.model import *\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06280f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file names\n",
    "files = os.listdir(\"data/\")\n",
    "strains = [\"DSM\", \"MS001\", \"MS008\", \"MS014\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66f683",
   "metadata": {},
   "source": [
    "# fit gLV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104c6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(df, species):\n",
    "    \n",
    "    # save measured and predicted values\n",
    "    exp_names = []\n",
    "    pred_species = []\n",
    "    pred = []\n",
    "    stdv = []\n",
    "    true = []\n",
    "\n",
    "    # pull just the community data\n",
    "    test_data = process_df(df, species) \n",
    "\n",
    "    # plot the results\n",
    "    for exp, t_span, Y_m in test_data:\n",
    "\n",
    "        # predict \n",
    "        Y_p, Y_std = model.predict(Y_m, t_span)\n",
    "        \n",
    "        # set NaN to zero\n",
    "        Y_p = np.nan_to_num(Y_p)\n",
    "        Y_std = np.nan_to_num(Y_std)\n",
    "        \n",
    "        ### prediction results for species that were present ###\n",
    "        inds_present = Y_m[0] > 0 \n",
    "        exp_names.append([exp]*sum(inds_present)*(Y_m.shape[0]-1))\n",
    "        pred_species.append(np.tile(np.vstack(species)[inds_present], Y_m.shape[0]-1).T.ravel())\n",
    "        true.append(Y_m[1:,inds_present].ravel())\n",
    "        pred.append(Y_p[1:,inds_present].ravel())\n",
    "        stdv.append(Y_std[1:,inds_present].ravel())\n",
    "                \n",
    "    # concatenate list\n",
    "    exp_names = np.concatenate(exp_names)\n",
    "    pred_species = np.concatenate(pred_species)\n",
    "    true = np.concatenate(true)\n",
    "    pred = np.concatenate(pred)\n",
    "    stdv = np.concatenate(stdv)\n",
    "        \n",
    "    return exp_names, pred_species, true, pred, stdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1147f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 78, Initial regularization: 1.00e-03\n",
      "Loss: 14.388, Residuals: 0.054\n",
      "Loss: 9.311, Residuals: -0.018\n",
      "Loss: 7.940, Residuals: 0.109\n",
      "Loss: 6.691, Residuals: -0.015\n",
      "Loss: 6.340, Residuals: 0.067\n",
      "Loss: 6.026, Residuals: 0.039\n",
      "Loss: 5.926, Residuals: 0.037\n",
      "Loss: 5.772, Residuals: 0.019\n",
      "Loss: 5.628, Residuals: 0.002\n",
      "Loss: 5.613, Residuals: 0.008\n",
      "Loss: 5.588, Residuals: 0.003\n",
      "Loss: 5.583, Residuals: 0.007\n",
      "Loss: 5.573, Residuals: 0.005\n",
      "Loss: 5.555, Residuals: -0.000\n",
      "Loss: 5.549, Residuals: 0.006\n",
      "Loss: 5.539, Residuals: 0.003\n",
      "Loss: 5.522, Residuals: -0.003\n",
      "Loss: 5.515, Residuals: 0.003\n",
      "Loss: 5.502, Residuals: 0.000\n",
      "Loss: 5.479, Residuals: -0.005\n",
      "Loss: 5.478, Residuals: -0.003\n",
      "Loss: 5.476, Residuals: -0.002\n",
      "Loss: 5.458, Residuals: -0.009\n",
      "Loss: 5.454, Residuals: -0.006\n",
      "Loss: 5.448, Residuals: -0.009\n",
      "Loss: 5.446, Residuals: -0.009\n",
      "Loss: 5.446, Residuals: -0.009\n",
      "Loss: 5.445, Residuals: -0.010\n",
      "Loss: 5.443, Residuals: -0.011\n",
      "Loss: 5.443, Residuals: -0.011\n",
      "Loss: 5.443, Residuals: -0.012\n"
     ]
    }
   ],
   "source": [
    "# run kfold for each file \n",
    "for strain in strains:\n",
    "    \n",
    "    # import data\n",
    "    df_universal = pd.read_csv(\"data/Universal.csv\")\n",
    "    df_strain = pd.concat([pd.read_csv(f\"data/{fname}\") for fname in files if strain in fname])\n",
    "    df = pd.concat((df_universal, df_strain))\n",
    "    df.sort_values(by=[\"Treatments\", \"Time\"], inplace=True)\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "\n",
    "    # separate mono culture data \n",
    "    mono_df = pd.concat([df_i for name, df_i in df.groupby(\"Treatments\") if \"Mono\" in name])\n",
    "    dfs = [df_i for name, df_i in df.groupby(\"Treatments\") if \"Mono\" not in name]\n",
    "\n",
    "    # init kfold object\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=21)\n",
    "\n",
    "    # keep track of all predictions\n",
    "    all_exp_names = []\n",
    "    all_pred_species = []\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    all_stdv = []\n",
    "\n",
    "    # run Kfold \n",
    "    for train_index, test_index in kf.split(dfs):\n",
    "        #train_index, test_index = next(iter(kf.split(dfs)))\n",
    "\n",
    "        # get train df \n",
    "        train_df = pd.concat([dfs[i] for i in train_index])\n",
    "        train_df = pd.concat((mono_df, train_df))\n",
    "\n",
    "        # get test df\n",
    "        test_df = pd.concat([dfs[i] for i in test_index])\n",
    "\n",
    "        # instantiate gLV fit \n",
    "        model = gLV(species, train_df)\n",
    "\n",
    "        # fit to data \n",
    "        model.fit()\n",
    "\n",
    "        # plot fitness to data\n",
    "        exp_names, pred_species, true, pred, stdv = predict_df(test_df, species)\n",
    "\n",
    "        # append predictions \n",
    "        all_exp_names = np.append(all_exp_names, exp_names)\n",
    "        all_pred_species = np.append(all_pred_species, pred_species)\n",
    "        all_true = np.append(all_true, true)\n",
    "        all_pred = np.append(all_pred, pred)\n",
    "        all_stdv = np.append(all_stdv, stdv)\n",
    "\n",
    "        # save prediction results to a .csv\n",
    "        kfold_df = pd.DataFrame()\n",
    "        kfold_df['Treatments'] = all_exp_names\n",
    "        kfold_df['species'] = all_pred_species\n",
    "        kfold_df['true'] = all_true\n",
    "        kfold_df['pred'] = all_pred\n",
    "        kfold_df['stdv'] = all_stdv\n",
    "        kfold_df.to_csv(f\"kfold/{strain}_10fold.csv\", index=False)\n",
    "        \n",
    "    # show prediction performance of individual species\n",
    "    for sp in species:\n",
    "        sp_inds = all_pred_species == sp\n",
    "        R = linregress(all_true[sp_inds], all_pred[sp_inds]).rvalue\n",
    "        plt.scatter(all_true[sp_inds], all_pred[sp_inds], label=f\"{sp} \" + \"R={:.3f}\".format(R))\n",
    "        plt.errorbar(all_true[sp_inds], all_pred[sp_inds], yerr=all_stdv[sp_inds], \n",
    "                     fmt='.', capsize=3)\n",
    "\n",
    "    plt.xlabel(\"Measured OD\")\n",
    "    plt.ylabel(\"Predicted OD\")\n",
    "    plt.legend()\n",
    "    plt.title(strain)\n",
    "    plt.savefig(f\"figures/{strain}_10fold.pdf\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f984c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    # import data\n",
    "    df = pd.read_csv(f\"data/{file}\")\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "    \n",
    "    strain = file.split(\"_\")[1]\n",
    "    kfold_df = pd.read_csv(f\"kfold/{strain}_10fold.csv\")\n",
    "        \n",
    "    all_pred_species = kfold_df['species'].values\n",
    "    all_true = kfold_df['true'].values \n",
    "    all_pred = kfold_df['pred'].values\n",
    "    all_stdv = kfold_df['stdv'].values\n",
    "        \n",
    "    R_overall = linregress(all_true, all_pred).rvalue\n",
    "        \n",
    "    # show prediction performance of individual species\n",
    "    for sp in species:\n",
    "        sp_inds = all_pred_species == sp\n",
    "        R = linregress(all_true[sp_inds], all_pred[sp_inds]).rvalue\n",
    "        plt.scatter(all_true[sp_inds], all_pred[sp_inds], label=f\"{sp} \" + \"R={:.3f}\".format(R))\n",
    "        plt.errorbar(all_true[sp_inds], all_pred[sp_inds], yerr=all_stdv[sp_inds], \n",
    "                     fmt='.', capsize=3)\n",
    "\n",
    "    plt.xlabel(\"Measured OD\")\n",
    "    plt.ylabel(\"Predicted OD\")\n",
    "    plt.legend()\n",
    "    plt.title(strain + \" R={:.2f}\".format(R_overall))\n",
    "    plt.savefig(f\"figures/{strain}_10fold.pdf\", dpi=300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
